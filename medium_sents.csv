tool,sentence
appdynamics,"This article was originally published on The Chief I/O: AIOps Tools: Dynatrace vs AppDynamics

In this article, I‚Äôll be highlighting the AIOps tools ‚Äî AppDynamics and Dynatrace."
appdynamics,The term ‚ÄúAIOps‚Äù is an acronym for Artificial Intelligence for IT Operations.
appdynamics,The term was first coined by Garnet in 2017 in reference to how data and information from applications are managed by IT teams (using AI in this case).
appdynamics,AIOps is used to describe multi-layered technology platforms that can enhance and automate IT operations using Machine Learning and data analytics.
appdynamics,"Such platforms leverage large collections of data sourced from various IT tools, operations devices, and analyzes them using AI."
appdynamics,This allows IT teams to be able to spot issues and react to them in real-time.
appdynamics,AIOps platforms also provide traditional historic data analytics.
appdynamics,Machine Learning and Big Data are the two main components of AIOps.
appdynamics,They work by aggregating observational data (typically sourced in monitoring systems) and engagement data (sourced from event recordings or incident tickets) into a single big data platform.
appdynamics,The platform then implements comprehensive analytics of these combined data.
appdynamics,The main goal of AIOps is to be able to deliver automation driven insights that make it possible to continually improve and fix application.
appdynamics,"Generally, AIOps tools can leverage Artificial Intelligence and/or Machine Learning to analyze large data volumes."
appdynamics,The scope of data they can deal with is virtually unlimited as they integrate with various IT systems and can monitor data from these various systems both reactively and proactively.
appdynamics,"Some of the most popular AIOps software vendors include Dynatrace, Datadog, Splunk Enterprise, AppDynamics, PagerDuty, and BigPanda."
appdynamics,"However, two vendors that seem to stand out on pretty much any AIOps lists of enterprise platforms are AppDynamics and Dynatrace."
appdynamics,Both platforms have been around for years with each undergoing different stages of evolution into their current applications.
appdynamics,Both AppDynamics and Dynatrace have their roots in Java diagnostics.
appdynamics,"However, Dynatrace was more of a pre-production performance testing tool built for QA testers and developers."
appdynamics,AppDynamics on the other hand started in production use cases and was geared more towards support teams for operations and app development.
appdynamics,"Today, both platforms have crossed into each other‚Äôs territories and now serve the performance monitoring needs for various enterprises."
appdynamics,What is Dynatrace?
appdynamics,"Dynatrace is an all-in-one platform that is designed to monitor app performance and deliver precise answers about the application‚Äôs performance, its underlying infrastructure, and user experience."
appdynamics,The goal of Dynatrace is to accelerate digital transformation while simplifying cloud complexity using software intelligence.
appdynamics,Companies that use Dynatrace love it because it serves as an intelligent tool for collaboration and faster innovation allowing you to deliver more value with less effort.
appdynamics,"Nordstorm, Luckyvitamin, McGraw Hill Education, Westfield Insurance, and Thomas Cook and some of the many companies that use Dynatrace for performance testing and measuring user experience."
appdynamics,Dynatrace is very intelligent and does a lot of heavy lifting for you once installed.
appdynamics,"It allows you to discover assets, carry out automatic injection while monitoring the connectivity rates of processes and identifying potential issues."
appdynamics,"Dynatrace also produces a multi-dimensional baseline of application data designed to make it easy to make real-time comparisons
What is AppDynamics?"
appdynamics,AppDynamics is a part of the Cisco Network and one of the most popular tools for Application Performance Monitoring.
appdynamics,It is a full-stack AIOps platform designed with a business-centric edge.
appdynamics,It is renowned for its ease of use and how efficiently it helps in the prevention of digital performance issues through the monitoring of traditional infrastructure as well as cloud-native technologies.
appdynamics,"Leading companies such as Vodafone, Carhartt, Nasdaq, and Alaska Airlines make use of app dynamics to help them create better customer experiences by identifying potential issues before they arise."
appdynamics,AppDynamics makes it easier for companies to identify and understand the factors that drive user experiences on their app and to find ways to make improvements and impact their bottom-line.
appdynamics,It provides efficient end-to-end monitoring with insights into your application performance and overall customer experience spotting issues that require urgent action.
appdynamics,"Dynatrace vs AppDyanamics
In terms of ease-of-use, both tools are relatively easy to set up and run."
appdynamics,"However, due to certain differences in how it collects and transmits data, you might find AppDyanmics slightly easier and cheaper to deploy especially in larger environments."
appdynamics,Dynatrace has great breadth and depth in terms of end-user experience monitoring but their products for this use case are less unified compared to that of Appdynamics.
appdynamics,"Dynatrace also has a relatively short list of ecosystem integrations and plugins although these plugins cover various categories like Splunk for Big Data, Docker for Ecosystem, Jira and PagerDuty for notifications, and so on."
appdynamics,Appdynamics on the other hand has an open platform for developers to allow more integrations and development of community-based plugins.
appdynamics,Both platforms offer similar tools that are efficient for capturing anomalies in business transactions.
appdynamics,"However, Dynatrace has a somewhat limited interface."
appdynamics,Many users find AppDynamics a bit more intuitive in this respect since you don‚Äôt need to frequently drill-down/rotate views to find what you need.
appdynamics,In comparing both solutions Dynatrace seems to be the easier of the two solutions in terms of setup and use.
appdynamics,"Although AppDynamics is positioned more for business use, Dynatrace offers more in terms of ongoing product support which is great for business."
appdynamics,"Hi, I‚Äôm Jenna üëã, Design Program Manager at AppDynamics!"
appdynamics,"At the end of October, I traveled ‚úàÔ∏è to Brooklyn, NY to attend Rosenfeld‚Äôs 4th annual DesignOps Summit."
appdynamics,"Having been the sole DPM on my team for over a year, I enjoyed the freedom of being able to define DesignOps for our team and focus on the projects I thought were bringing the most impact."
appdynamics,"But, I still felt like I was missing some key pieces that would really help move the needle on how to make Design at AppD the best it could be ü§î."
appdynamics,"I purchased my ticket for the DesignOps Summit the second they were released, hoping that by immersing myself for three days around other like-minded DesignOps folks, I‚Äôd be able to figure out how to take DesignOps at AppD to the next level."
appdynamics,"The website promised two full days of engaging speakers providing case studies, tools, and techniques that we‚Äôd be able to implement and use as soon as we got back to work."
appdynamics,"The talks focused on three main themes: Proving Value, Measuring Outcomes, Partnering Outside Design, and Change Management."
appdynamics,Rosenfeld held true to their promise!
appdynamics,"After returning to San Francisco üåâ, I immediately got to work on putting my learnings into practice!"
appdynamics,"Learning 1 ‚Äî Create a baseline and continue to measure against it
One of the first speakers of the day was Diane, a Design Program Manager from Pandora whose team was struggling with ambiguity, instability, and uncertainty after a recent acquisition by SiriusXM ü§∑."
appdynamics,"To address these issues, they decided to create a playbook that covered the team‚Äôs roles, responsibilities, workflows, processes, systems, tools, and more."
appdynamics,"To ensure that the playbook was adding value, they first surveyed the team to create a baseline of how clear things were today."
appdynamics,"Once the playbook was rolled out, she resent that same survey to see how much clarity the playbook broughtüìà."
appdynamics,The playbook ended up being a huge success and increased clarity on her team by 30%.
appdynamics,"By creating a baseline and measuring against it, Diane was able to turn feelings into metrics and quantify the success of the playbook."
appdynamics,This was a big ‚Äúah ha‚Äù‚ùómoment for me and a great reminder to take the time to measure where we‚Äôre at before making changes so we can really know if what we‚Äôre doing is moving the needle.
appdynamics,"When I got back from Brooklyn, I had the team complete a skills wheel."
appdynamics,This gave the team the opportunity to assess where they felt they were currently with different skills and also where they‚Äôd like to be.
appdynamics,"The team was able to reflect on their skills, while also giving me insight into where the team felt weaker and areas they‚Äôd want to improve upon."
appdynamics,"After collecting the wheels, it was eye-opening to see that the majority of the team wanted to improve their skills in UX analytics, inclusive design, and communication."
appdynamics,Being aware of the team‚Äôs interests has allowed us to tailor the skills and growth workshops we‚Äôll host over the upcoming months.
appdynamics,"Additionally, since we now have this baseline ‚Äî after trainings or workshops, we‚Äôll be able to ask folks to assess themselves again and measure what impact they had on skills growth ‚úÖ."
appdynamics,Learning 2 ‚Äî Aligning on how we got here is just as important.
appdynamics,"The second big lesson came when the Head of Design at Atlassian, Alastair, started debunking myths of cross-disciplinary collaboration."
appdynamics,The myth starts when teams get together to begin a new project.
appdynamics,"They align themselves on what they want the solution to be and how they want to get there, but as they start marching into a sprint cadence, they realize that the problem is much tougher than anticipated üòî."
appdynamics,"If teams start with a shared understanding of how they got there and why the product or feature is how it is today, they can create a sense of purpose and fully understand the product‚Äôs journey in order to move forward."
appdynamics,This really resonated with me üí°.
appdynamics,Our product has gone through lots of iterations and changes over the years.
appdynamics,The reasons for those changes and decisions have never really been documented or explained.
appdynamics,"To combat this, our team instituted Design Worksheets üóíÔ∏è."
appdynamics,These became a common tool the entire team could use.
appdynamics,"We intentionally made them lightweight and flexible, giving designers enough structure to document who was working on projects, highlight the work that was being done and why certain decisions were being made without overloading the team."
appdynamics,"This allowed us to describe work from a design perspectiveüñåÔ∏è, instead of leaving the documentation up to a TPM, PM, or someone else who might not capture all of the design specific decisions."
appdynamics,"When rolling out worksheets, the team was a bit hesitant and concerned that adding in a worksheet would create unnecessary workload."
appdynamics,"We went through multiple iterations trying to find that sweet spot of including enough information to make them valuable, but not so cumbersome that designers felt they were spending hours upon hours trying to maintain them."
appdynamics,"We finally landed on a format that gives the team flexibility to keep the worksheet to just the basics (who‚Äôs included, why decisions were made, etc.)"
appdynamics,"or go all in and include links to assets, all meeting notes, and more."
appdynamics,"Both versions give teams insight into why decisions were made, making it easier to figure out where we should go next üòå."
appdynamics,"Learning 3 ‚Äî Change is constant
The last learning was a theme that came up time and time again throughout the three days."
appdynamics,"It‚Äôs one that I‚Äôve always known, but didn‚Äôt always appreciate or take to heart when I stepped into this role."
appdynamics,Change.
appdynamics,"Teams go through re-orgs, processes change, new people join, and some folks leave."
appdynamics,"Change is constant, and part of the role as a Design Program Manager is to help prepare and navigate that change with their team üó∫Ô∏è."
appdynamics,"In a way, this makes my job easier."
appdynamics,I don‚Äôt have to come up with processes that are going to be set in stone and that the team is going to have to follow super strictly for the next five years.
appdynamics,"I‚Äôm working with the team to figure out what works now, and when things change, how we can iterate and change with it üîÑ."
appdynamics,It‚Äôs something that I say to myself during moments when trying to work through particularly hairy problems and I‚Äôm wracking my brain trying to figure out the perfect solution.
appdynamics,"Perfection is not the end game for DPMs ‚Äî the focus needs to be on making small, incremental changes that support the team and help them create their best work even when things outside of design are changing."
appdynamics,"It‚Äôs been a little over four months since the DesignOps Summit, and each day I keep going back to these three learnings when thinking about my role, how the team operates, and what I can do to help take DesignOps at AppD to the next level."
appdynamics,"By focusing on measuring the impact of my work üìè, understanding why we‚Äôre doing the things that we‚Äôre doing, and keeping change top of mind when coming up with solutions, I‚Äôve been able to elevate the work that I do and focus on what really matters üôå."
appdynamics,Interested in joining our team?
appdynamics,We‚Äôre hiring!
appdynamics,Do you use AppDynamics?
appdynamics,Join our user panel!
appdynamics,Design@AppD is leading a transformation of AppDynamics into a user-centered enterprise product company.
appdynamics,Interested in following along?
appdynamics,Consider following us on Medium!
appdynamics,"Reflections on working in user research at AppDynamics, a leading application performance management (APM) solution serving over 3,000 organizations."
appdynamics,"Members of Product Management, Design & Experience, and Platform Engineering debriefing in the AppDynamics London office between customer onsite visits."
appdynamics,"Notable Team Stats (over a 2 year period):
Studies completed: 80+
Interviews conducted: 150+
Interview hours: 250+
Number of cities traveled for contextual inquiry: 20+
Start with the Persona
In the enterprise world, you are selling a product to a group of individuals and a persona is a general depiction of a particular user type with certain needs and motivations."
appdynamics,The CIO or executive with the authority to sign off on a multi-million dollar contract is quite different from the end user who sets up and configures the tool.
appdynamics,"Both of these personas play a role in product success but have to be considered independently as their use cases with the product may be distinct, overlapping, or somewhere in between."
appdynamics,2.
appdynamics,"Every Customer Organization is Different
When you have thousands of large organizations as customers, it becomes important to assess the unique characteristics of each customer company across different dimensions."
appdynamics,Does the organization support centralized vs. de-centralized ownership and responsibility for its software releases?
appdynamics,Has the customer moved to a more distributed microservices architecture?
appdynamics,Do the teams within the customer organization have a clearly defined process to identify and remediate application issues?
appdynamics,All of these factors can greatly influence how your product is adopted and utilized within their organization.
appdynamics,Categorizing organizations across these dimensions also becomes a challenging exercise but one in which the idea of a persona can extend to a customer company.
appdynamics,3.
appdynamics,"You are NOT a Special Snowflake
When you live and breathe your product and its feature set on a daily basis it is easy to get caught up in the hype."
appdynamics,Spend a few hours observing how your product is used at a customer company and you will realize it is one tool among a myriad of tools needed to satisfy a business need.
appdynamics,One team within a company might be using your product while another team within the same company might be piloting a competing product.
appdynamics,"Understanding how customer companies utilize different products is extremely useful when assessing which areas your product has a competitive advantage and more importantly, conceding on feature ideas where a competitor is much further ahead."
appdynamics,4.
appdynamics,"Uncover the Relative Value
Sharing a new shiny mock up or prototype showcasing an upcoming feature will quite often illicit a favorable reaction (‚ÄúYES, I need this feature!‚Äù)."
appdynamics,Determining its value relative to other capabilities is a much more difficult endeavor but one that can be highly valuable for product and engineering teams who have to make difficult tradeoffs with a road map of competing items.
appdynamics,"Research exercises and tools our team has used with prioritization and general usability include the bulls eye diagram, buy-a-feature, and UMUX-Lite."
appdynamics,5.
appdynamics,"Make it Intuitive
Users don‚Äôt know what they don‚Äôt know."
appdynamics,Rich and powerful features are of no value if they (1) cannot be discovered and (2) are not intuitive to use.
appdynamics,Enterprise customer engagements may offer hands-on support from sales engineering and customer success teams but a large number of users may never realize this benefit and have to learn and adopt product capabilities on their own.
appdynamics,"Strong design, writing / contextual help, documentation, and user research (shameless plug) will increase the likelihood a new feature is well received and adopted."
appdynamics,"Final Thoughts
Our research team and practice is still relatively young and while we have gained an immense amount of knowledge and insights there is still a lot to be uncovered."
appdynamics,The landscape of enterprise solutions and technology stacks are constantly changing and evolving.
appdynamics,Keeping abreast of all these developments in combination with planning and conducting effective customer studies will be an ongoing priority.
appdynamics,Interested in joining our team?
appdynamics,We‚Äôre hiring!
appdynamics,Do you use AppDynamics?
appdynamics,Join our user panel!
appdynamics,Design@AppD is leading a transformation of AppDynamics into a user-centered enterprise product company.
appdynamics,Interested in following along?
appdynamics,Consider following us on Medium!
appdynamics,"In an organization, we keep hearing about Marketing strategy, Product Strategy, Sales Strategy etc."
appdynamics,but UX Strategy is relatively new to the industry (especially the Enterprise world).
appdynamics,What is UX Strategy?
appdynamics,Why it matters?
appdynamics,What value does it add in the organization?
appdynamics,These were the few questions I always had in mind.
appdynamics,I started looking for avenues that can help me understand this term better.
appdynamics,And then stumbled upon the workshop by one and only J. Spool.
appdynamics,"Jared M. Spool is the founder of User Interface Engineering, the largest usability research organization of its kind in the world."
appdynamics,He‚Äôs probably the most effective and knowledgeable communicator on the User Experience subject today.
appdynamics,He‚Äôs been working in the field of usability and experience design since 1978 before the term ‚Äúusability‚Äù was ever associated with computers.
appdynamics,"Day 1 ‚Äî While I was approaching the venue, could see a face that looked familiar."
appdynamics,"As I went close, found Jared standing near the elevator."
appdynamics,I was thrilled to see him and knew this was my ‚Äòfan‚Äô moment.
appdynamics,"We spoke for a brief period and he thanked me for travelling ~5000 miles (from Bengaluru) to attend his workshop in Manchester, UK."
appdynamics,I was humbled!
appdynamics,Day 1 started with a rule ‚Äî ‚ÄòNone of the things we learn here is going to be easy‚Äô.
appdynamics,Understanding the term ‚ÄòStrategy‚Äô ‚Äî It‚Äôs a Military term.
appdynamics,A path to reach the outcome.
appdynamics,A long game that consists of many tactics.
appdynamics,"UX Strategy ‚Äî It‚Äôs an action plan to muster all the UX expertise, knowledge & resources to help our organizations create better-designed products & services."
appdynamics,"These are the three essential components of any UX strategy: the improvement to the users‚Äô experience, the benefit delivered to the organization, and the resources required to achieve success."
appdynamics,"Few good UX Strategy plays to adopt:
Building an Experience Vision

A story describing what will the experience of our customers might look like in future."
appdynamics,It‚Äôs a flag on the horizon that everybody can see and march towards.
appdynamics,"Take an example of Apple‚Äôs 1987 Knowledge Navigator:

Apple‚Äôs Experience Vision ‚Äî Knowledge Navigator (1987)
In this video, the team showed the story of a Professor who is preparing for a lecture and needs some interesting research data to present to the students."
appdynamics,"In this short video, they made use of an assistant, video conferencing with a friend on a compact device; discussing effectively and transferring the data seamlessly to create a report."
appdynamics,Professor who is unprepared before the call manages to finish his job in just 5 mins.
appdynamics,This was envisioned when people were frustrated with the 1987 technology without internet.
appdynamics,"The vision gave direction to the entire company to march towards the flag and we can see the result in the form of iPad (2010), Siri (2012)."
appdynamics,"Creating Experience Vision:
First step is to assess the current experience of our product or service and identify the frustration points of our users."
appdynamics,"Cost of frustrations:
- Lost sales
- Increased costs (because of support)
- Waste from rework
- Waste from unused work (no adoption)
Then think ‚ÄòWhat could be the best experience for our users, when we remove all these frustrations‚Äô."
appdynamics,This is the aspiration where we want to reach.
appdynamics,Next up to determine the timeframe of the horizon.
appdynamics,"Ideally, 5 years of the horizon is a good time to think, as we can move away from legacy systems and use currently available technology that hasn‚Äôt made it into our users‚Äô experiences."
appdynamics,"Eg: ML/AI, Voice commands."
appdynamics,This also reduces the risk of turning the project into a science fiction.
appdynamics,"Remember, Vision helps us see ‚ÄòPotential‚Äô of a solution than ‚ÄòBlind spots‚Äô."
appdynamics,2.
appdynamics,"Going beyond the UX Tipping point

As an organisation, we need to identify where do we stand in terms of UX growth stages (maturity):

Growth stages of Organizational UX Design
The UX Tipping Point is the moment when an organization no longer compromises on well-designed user experiences."
appdynamics,"Before they hit the tipping point, they might talk about great design, but they‚Äôll still ship a mediocre experience."
appdynamics,"However, once they‚Äôve passed it, design has become an embedded part of their culture and DNA."
appdynamics,Eg: Honeywell (Established company) vs. Nest (Startup).
appdynamics,Honeywell mainly thought in terms of features and not end-to-end experience of the user.
appdynamics,"Nest, on the other hand, always had Design infused in their culture that thought in terms of user pain points and solved user problems."
appdynamics,Google bought Nest in 2014.
appdynamics,3.
appdynamics,"Strengthening & Growing the UX Team

Staffing is as important as the design itself."
appdynamics,"For this, team skills need to be assessed."
appdynamics,"For an organization to move beyond the UX Tipping Point, it must first become literate in user experience, then fluent in how to produce great experiences."
appdynamics,"This doesn‚Äôt happen all at once, it can take years."
appdynamics,"However, if it never happens, the organization won‚Äôt make it beyond the tipping point."
appdynamics,Skills are not equal to Roles.
appdynamics,"If a PM wants to take up Research skills, it is advantageous for an organization as the idea of a specialist is luxury to few companies."
appdynamics,They might want to have people on the team with the breadth of knowledge in few areas and depth in few (a T-shaped person).
appdynamics,4.
appdynamics,"Thinking differently ‚Äî Reframing

Strategy is not just about doing things differently but also thinking about things differently."
appdynamics,We need to reframe a few terms that we are accustomed to using in a particular way.
appdynamics,From Requirements ‚Üí to Assumptions/Hypothesis: We need to treat requirements as assumptions and validate them.
appdynamics,"SMEs from User Advocates ‚Üí to Translator/Guides: We need to ask SMEs to help us identify the details that we wouldn‚Äôt have known otherwise, in User Research sessions."
appdynamics,From Output ‚Üí to Outcome: We need to think in terms of outcomes that bring change to the world than just thinking about deliverables like mockups.
appdynamics,From Features ‚Üí to Problems to solve: We need to include ‚ÄòProblems to solve‚Äô in the Product roadmap that adds value to customers‚Äô life than adding features that we tend to think in terms of Solutions.
appdynamics,From Inferences ‚Üí to Observations: We need to treat Inferences as hypothesis and validate with Research to turn into Observations.
appdynamics,I walked into the AppDynamics offices in San Francisco as an employee for the first time in September of 2015 and was ushered to the front of an all hands meeting.
appdynamics,"Jyoti Bansal, the visionary founder of AppDynamics, introduced me to the 500 AppD employees around the world as the new CEO and we spent an hour taking questions together ‚Äî the core message was how blessed I was to join AppDynamics at such a formative stage."
appdynamics,"It goes without saying that I‚Äôm incredibly proud of what we accomplished as a team at AppD and, in particular, how far we‚Äôve come in the four years I‚Äôve had the opportunity to serve as its CEO."
appdynamics,"It has been a truly incredible ride, with its fair share of twists, turns, and surprises, but always both exhilarating and profoundly rewarding."
appdynamics,"And so, it is with mixed emotions that I share my plans to move on from AppDynamics and with great excitement that I begin my journey with Greylock Partners."
appdynamics,AppDynamics has been like a family to me and the opportunity ahead continues to be a thrilling prospect for the two thousand employees around the globe as we‚Äôve expanded the surface area of what AppD monitors from application performance to database and infrastructure performance to end user behavior and business outcomes ‚Äî in real time.
appdynamics,We have become the hub of real-time intelligence across thousands of enterprises around the world.
appdynamics,"But there is so much more potential and I wish Danny Winokur, my successor and long-time friend, and the entire AppD team all the best as they pursue the audacious and worthy goal of becoming the Central Nervous System for enterprises in the years ahead."
appdynamics,I also want to thank all the Cisco employees for their incredible support of the business since the acquisition.
appdynamics,"As I think about my journey over the last 17 years (Macromedia, Adobe and AppDynamics) I‚Äôve realized that I‚Äôm happiest when I‚Äôm surrounded by passionate leaders, who challenge each other, are willing to take real risks to achieve true greatness and persevere despite the ups and downs, despite the headwinds and despite their own self-doubts."
appdynamics,"It‚Äôs difficult to create an organization that fosters these kinds of leaders, it‚Äôs harder to maintain this mindset as a company grows and experiences success and it‚Äôs incredibly rare to transform an organization once the mindset is lost."
appdynamics,"During my time at Adobe, I was lucky enough to be part of one such (very well documented) transformation."
appdynamics,"Shantanu Narayen (Adobe‚Äôs CEO) and every one of us on his staff had to rethink the fundamentals of product innovation, business model and company culture."
appdynamics,"I played my part transitioning the Digital Media business and culture, but could not have been successful were it not for the passion and leadership of every other member of Adobe‚Äôs senior leadership team."
appdynamics,"What we did together, was much more than transform a business ‚Äî we somehow regained the ‚Äúfounder mindset‚Äù and took ownership of the vision even when it ran counter to what the market and competitors were saying."
appdynamics,We manically believed in what we were doing before others could see the opportunity.
appdynamics,And nothing ‚Äî not even our own occasional self-doubt ‚Äî was going to stop the collective conviction we felt.
appdynamics,"As I think about how lucky I‚Äôve been to spend the majority of my career surrounded by fiercely passionate people who are obsessed with an idea they believe can change the world, or at least an industry, I realize that I want to spend more time working with, advising, learning from and continuing to be one of them."
appdynamics,"As the CEO of a fast growing Silicon Valley company, I‚Äôve had the distinct privilege of spending time speaking with and advising dozens of remarkable founders over the last few years ‚Äî and I can think of nothing more fulfilling at the moment than doing more of that."
appdynamics,Which is why I‚Äôve decided to join Greylock Partners as a Venture Partner.
appdynamics,Greylock has partnered with entrepreneurs to help build market-leading businesses since 1965.
appdynamics,"They continue to focus on early stage investing (including seeds, As and Bs) while also selectively leading later stage rounds."
appdynamics,"Greylock has maintained a disciplined approach to investing and company building ‚Äî remaining a focused partnership, where every partner is committed to the success of each and every Greylock-backed company."
appdynamics,"It‚Äôs a place where partners actively work together to ensure Greylock-backed founders have the edge they need to see trends before they form, the conviction and support to persevere through the inevitable twists and turns and the network to accelerate them throughout their entrepreneurship journey ‚Äî from the proverbial garage, to first revenue, to future funding, to sustainable growth, to acquisition or IPO and beyond."
appdynamics,Greylock and Lightspeed were founding investors in AppDynamics and co-led the Series A in 2008.
appdynamics,"I‚Äôve had the distinct pleasure of getting to know all the Greylock partners (starting with Asheem Chandna, who led Greylock‚Äôs investment) and several of the Greylock LPs over the last few years."
appdynamics,"Greylock‚Äôs steady approach to investing for the long game has been a privilege to observe and I couldn‚Äôt be more excited to be a part of such a smart, humble and dedicated team."
appdynamics,"While I‚Äôll be exclusively investing with Greylock, I‚Äôm also looking forward to maintaining my relationship with Lightspeed and Ravi Mhatre (who led Lightspeed‚Äôs investment in AppDynamics)."
appdynamics,"I will be joining as an inaugural member of the Lightspeed CEO Advisory Council, along with John Thompson (Chairman of Microsoft), Bipul Sinha (Founder and CEO of Rubrik) and Gregg Schott (CEO of Mulesoft)."
appdynamics,"Additionally, I look forward to continuing my role on the Digital Advisory Board for the Metropolitan Museum of Art, the Board of Advisors for Brown University‚Äôs Computer Science Department and the Board of Trustees for StoryCorps and the Fine Arts Museums of San Francisco."
appdynamics,We live in exciting times.
appdynamics,"The rise of cloud computing, the wide-spread adoption of distributed application models and the increasingly practical introduction of artificial intelligence is opening up completely new markets we couldn‚Äôt contemplate a decade ago, while making it faster and more cost effective to start companies that go after new opportunities and disrupt old ones."
appdynamics,I couldn‚Äôt be more excited to join Greylock and engage with amazing founders as a venture capitalist.
appdynamics,"And, as an operator at heart, I can‚Äôt wait to stand by their side during the ups and downs, through the headwinds and, especially, during the inevitable periods of self-doubt."
appdynamics,I want to help entrepreneurs persevere and realize their visions so they can reshape the world around us.
appdynamics,Feel free to reach out at dwadhwani [at] greylock.com.
appdynamics,"In our previous article, Continuous Delivery 101, we covered the basic concepts of what CD is."
appdynamics,"If you haven‚Äôt read it, I strongly recommend you read that first."
appdynamics,This article is going to expand into more advanced concepts building off the first article.
appdynamics,"Specifically, I‚Äôm going to cover canary and blue/green release methodologies and, also, introduce you to the concept of continuous verification."
appdynamics,"Release Methodologies
In our 101 article, I discussed a concept called release strategy."
appdynamics,A release strategy is a method of releasing software into production that reduces risk and exposure to both customers and the business.
appdynamics,"Why this matters
When releasing software, you‚Äôre exposing yourself to risk."
appdynamics,"Specifically, you‚Äôre exposing your customers and your business."
appdynamics,The risk comes from poorly performant software.
appdynamics,"As good as your testing and QA might be, you still run the risk of a malfunctioning deployment, security issues, and performance and quality degradation."
appdynamics,It happens.
appdynamics,"So, to offset this risk, organizations today leverage release methodologies that triage their exposure to risk in how they deploy their software."
appdynamics,"Blue/Green Deployments
A blue/green release is replicating a production environment and switching traffic between live environments as each non-live environment receives the later update."
appdynamics,This process then repeats with the other environment as a new version is re-released.
appdynamics,The router will switch traffic once the deployment is complete in the new environment.
appdynamics,This method can pose a higher risk and higher cost.
appdynamics,Risk is higher because an application issue is exposed to your entire user base.
appdynamics,"Cost is high because you have to maintain a whole replica of your production environment, quickly increasing unnecessary cost."
appdynamics,"If you‚Äôre interested in further reading, here is a good introduction by Martin Fowler."
appdynamics,"Canary Deployments
Canary is a method of slowly releasing in small stages or batches to only a select number of users, data centers, or random nodes within your deployment before a full roll-out."
appdynamics,Canary is perhaps the most popular for the release methods as it is both effective and cost-efficient.
appdynamics,A canary release involves first selecting how many test groups you want to phase your deployment across.
appdynamics,"Then, determine how large each test group will be."
appdynamics,"If the deployment into the canary group is successful, the deployment will proceed."
appdynamics,"If it fails ‚Äî for whatever reason ‚Äî then the deployment will not continue, and the canary group will be rolled back to the previous version of the software."
appdynamics,"If it isn‚Äôt obvious by now, a Canary methodology is brilliant in ensuring the least amount of risk for both your users and your business."
appdynamics,"In catching application issues early, you remove all risk of having a faulty version of your software deployed across your entire infrastructure ‚Äî definitely a no-no."
appdynamics,"To illustrate a Canary deployment, let‚Äôs say your application ‚Äî we‚Äôll call it version 1.1 ‚Äî is deployed across 50 nodes."
appdynamics,"If you‚Äôre using Kubernetes, these could also be pods."
appdynamics,You want to release a new version ‚Äî version 1.2 ‚Äî but do not want the entire deployment to go down if the release is faulty.
appdynamics,"So, we decide to only deploy across 10% of our nodes and observe the performance and quality carefully among these five nodes, in purple:

If the performance and quality of the five nodes is acceptable, we can then deploy across the remaining 45 nodes."
appdynamics,Keep in mind; you can also stagger the release into multiple canary deployments across the same environment.
appdynamics,"So, let‚Äôs say you want to deploy in 4 stages:
Stage 1: 10%
Stage 2: 20%
Stage 3: 50%
Stage 4: 100%
Your deployment would then look like this, as corresponding to the color of each stage:

Stage 1

Stage 2

Stage 3

Stage 4
If you‚Äôre doing this manually, or have written custom scripts to achieve this, you may want to take a look at this video."
appdynamics,Harness allows you to perform a canary test with a few configuration options automatically.
appdynamics,Harness also uses unsupervised machine learning to understand and analyze the performance metrics to conduct a canary release; here is a blog demonstrating one of the models used for this.
appdynamics,"Continuous Verification
A concept that is gaining popularity ‚Äî because it is so darn critical ‚Äî within mature CD conversations is a concept called Continous Verification."
appdynamics,"When software is released into an environment (e.g., stage or production), the performance and quality of that software must be tested."
appdynamics,"Usually, the performance and quality is tested using an APM and/or logging solution, such as:
AppDynamics
New Relic
Datadog
Splunk
Performing this step manually does not scale and is limited to human error."
appdynamics,Trying to automate this process is with scripts is near impossible.
appdynamics,"So, modern CD solutions have solved for this critical step using a concept called Continuous Verification."
appdynamics,CV checks the performance of the deployed service and automatically rolls back the deployment if it fails.
appdynamics,Here is a basic sequence diagram to outline exactly what is happened.
appdynamics,"In this case, I‚Äôm using Harness as an example to show how during the deployment phase, the service is tested using AppDynamics and Splunk."
appdynamics,"If it fails performance tests, Harness can automatically roll back the deployment."
appdynamics,"How Harness performs Continuous Verification
Advanced Continuous Verification
Alright, verifying performance and quality is great during the release process."
appdynamics,"But, let‚Äôs be honest, shitty code can creep on us like a terrible meal: much, much later."
appdynamics,The way that most companies hedge their risk is by investing in monitoring tools.
appdynamics,The amount of tools applied can reach up to 10‚Äì20.
appdynamics,This raises the question: how do you monitor so many different services across so many different dependencies and environment?
appdynamics,"Consider the following diagram as a visual representation of what I‚Äôm referring to:

Orchestrating continuous monitoring of services among major performance monitors
How do we solve for this?"
appdynamics,Simple.
appdynamics,"Using the same algorithms for performing your CV, you turn it on to monitor round the clock."
appdynamics,"This is an extremely advanced CD technique that (pretty much) no one else on the planet can do, aside from Harness."
appdynamics,Take a look at our 24/7 Service Guard feature.
appdynamics,Service Guard orchestrates the monitoring of multiple services across their many dependencies.
appdynamics,It‚Äôs a sophisticated technique of Continuous Verification and one of the most valuable capabilities that our customers love.
appdynamics,"Eliminate After-Hour Releases
Imagine a scenario in which your team is ready to deploy a new version of your software."
appdynamics,"Using, for example, a canary release process you have an all-hands-on-deck release."
appdynamics,"Of course, this is happening during regular working hours."
appdynamics,"Or, in the least, during waking hours."
appdynamics,Why is this a problem?
appdynamics,It‚Äôs a problem because your team has to be available for the deployment process and you‚Äôre only able to deploy after-hours to minimize risk.
appdynamics,"By combining CD and CV, you can reach true continuous deployments and you have the safety and security of deploying at any hour."
appdynamics,You‚Äôre both automatically deploying and verifying with a safety harness (pun intended) of automatically rolling back if the deployment fails.
appdynamics,"Conclusion
Between both the 101 and 102 articles, you should be well equipped to tackle your organization‚Äôs CD challenges."
appdynamics,"Equally as important, you understand from a high level the various terms and concepts that make up a modern CD platform."
appdynamics,"With Harness, these capabilities are baked into the core feature-set, allowing you to leverage the capabilities with minimal configuration."
appdynamics,"Once you‚Äôre up and running, you can build new pipelines in minutes with almost no code involved."
appdynamics,"Keep an eye for a third part to this series, CD 103."
appdynamics,"In the meanwhile, signup for a free trial."
appdynamics,"Leveraging Appdynamic‚Äôs flow map through intuitive engineering

vizceral‚Äôs flow map
Recently I watched Josh Evans talk on Youtube (yeah pretty late but never too late) and found out among many other interesting topics his use of this amazing visualization opensource Netflix tool called Vizceral which got me eager to try it out."
appdynamics,It has a good wiki to get started here and a all setup example here.
appdynamics,The json template is pretty straighforward and carefully explained so that you can easily port any topology you already have.
appdynamics,Similar to D3js nodes and links structure but Vizceral uses ThreeJs (Webgl) with nodes and connections hierarchy structure where each node can have other nodes and connections inside it.
appdynamics,The block below was taken from here.
appdynamics,"{

  renderer: 'global',
  name: 'edge',
  maxVolume: 100000,
  entryNode: 'INTERNET',
  // list of nodes for this graph
  nodes: [
    {
      renderer: 'region',
      layout: 'ltrTree',
      name: 'us-west-2',
      updated: 1462471847,
      maxVolume: 100000,
      nodes: [],
      connections: []
    }
  ]
}
So my architecture was like this:

And the results were astouding as expected:


Where you can easily spot pressure points in your microservices infrastruture as well as slow response calls and errors."
appdynamics,And we can also add it to your Grafana dashboard as shown here.
appdynamics,That‚Äôs all!
appdynamics,Application Performance Monitoring(APM) is one of the hot topics in the current industry where we are depending on software applications to fulfil almost our every need.
appdynamics,"When we talk about software applications, the main consideration will be the performance."
appdynamics,We should be aware of every possible reason which influences the performance of a software application.
appdynamics,"For that, we should monitor the application."
appdynamics,That's where APM comes into the story.
appdynamics,"When we decide to monitor our application, the next question comes into our mind is,
How are we going to monitor?"
appdynamics,There are so many tools in the market which can be used for this purpose.
appdynamics,"Depending on our requirements, we can decide on the tool to be used."
appdynamics,Here I am going to make your job easy by comparing two popular commercial APM tools against some important aspects.
appdynamics,"First of all, let me introduce the two tools that I have chosen for my comparison."
appdynamics,"AppDynamics
Dynatrace
Thankfully both the above tools have 15 days of a free trial."
appdynamics,So I was able to give it a try and see how it works and compare depending on the results I got.
appdynamics,This article will be published in 3 parts.
appdynamics,"The first two parts will talk about the Architecture, Features, Deployability and Usability of the products separately."
appdynamics,In part 3 we will see how we can deploy and monitor WSO2 Identity Server using these two products and compare the results.
appdynamics,"AppDynamics
Architecture

Architecture of AppDynamics
AppDynamics can be seen as three main components."
appdynamics,"Controller
Central repository and analytics engine
Collects the data sent by the app agents, stores, baselines, analyzes performance and present it in the browser
Can be installed on-premise or accessed as SaaS model
2."
appdynamics,"Application Server Agent
Monitors an application server in runtime and send data to the controller
For each application, a separate agent should be instrumented
3."
appdynamics,"Machine Agent
Instrumented on a machine to report data about hardware, memory and network to the controller
Installed on virtual or physical machine operating systems
Browser UI is used to access performance data interactively."
appdynamics,"AppDynamics maps an application environment into a hierarchical system of business applications, tiers, nodes and backends."
appdynamics,"Business Application :
A logical construction of all components and models of an application environment with a complete functionality
Contains multiple tiers
Tiers :
Provides a view of the runtime operation of the code via an AppDynamics App server agent
Represents a key module in the application environment (Eg: website, processing application, virtual machine)
Composed of one or more nodes (similar nodes belong to the same tier)
Helps to logically organize and manage application
Need to manually configure it in the agent during the instrumentation
Policies and processes differ tier to tier
A tier can belong to only one application environment
Nodes :
The basic unit in the monitoring environment
Instrumented by an agent (app server agent or machine agent)
Belong to tiers
All the components in an application are considered as nodes
Backends :
Not instrumented(components in an environment which are not directly attached) with an AppDynamics agent but that participates in the processing of a business transaction instance
Eg: web server, database, message queue, or other types of service
The agent detects calls to a service entry point at the tier and follows the execution path for the call through the call stack."
appdynamics,"It sends data about usage metrics, code exceptions, error conditions, exit calls to backend systems to the Controller, either a SaaS or on-premises."
appdynamics,"Key Features
Dependency model
Agents collect application data and metrics to build dependency model using built-in application detection and configuration settings."
appdynamics,"For more details

2."
appdynamics,"Log Analytics
Log analytics is used to capture and present log records as analytics data."
appdynamics,One or more log sources should be configured for the Analytics Agent.
appdynamics,"The Analytics Agent uses the log source configuration to,
Capture records from the log file
Structure the log data according to your configuration
Send the data to the Analytics Processor
Log monitor extension is used to monitor log file
3."
appdynamics,"Event tracing
The agent sent an internal event containing event traces."
appdynamics,Event traces enable tracing a code path that passes through a specified class/method.
appdynamics,"The App Agent for Java uses them to provide object instance tracking (OIT) and automatic leak detection (ALD)
4."
appdynamics,"Baselines
AppDynamics uses self-learned baselines."
appdynamics,It calculates the dynamic baselines automatically using the periodic load patterns of given metrics.
appdynamics,A rolling time period can be used as a baseline to include trends (eg: A retail application may experience heavier traffic on the weekend than the rest of the week).
appdynamics,A baseline deviation is the standard deviation from a baseline at a point in time.
appdynamics,Health rule conditions can be set based on the baseline deviation.
appdynamics,"The baseline can be customized
5."
appdynamics,"Thresholds
AppDynamics provides a default threshold by comparing the performance of every business transaction."
appdynamics,"Classifications of transactions (based on the performance of a transaction instance relative to the usual performance of the business transaction): normal, slow, very slow, stall and error
Dynamic thresholds:
Based on the performance of the most recent time (by default last 2 hours)
Specified using either a percentage deviation or a standard deviation measure based on the moving average
The moving average is calculated using the exponential moving average formula
6."
appdynamics,"Metrics
Metrics reflects the performance of the application."
appdynamics,We can create or customize metrics based on the requirements.
appdynamics,"Information points:
Used to define custom metrics for an application based on the collected data
Similar to data collectors which capture application data only in the context of a business transaction
Comes along with default metrics (called call metrics): Total call count, Calls per minute count, Errors per minute and Average response time
Percentile metrics are used to configure metrics at deviation points."
appdynamics,"Important metrics :
Availability ‚Äî Shows whether the application is running or not."
appdynamics,An indicator of health.
appdynamics,"Response Time ‚Äî The time spent on processing business transaction or call instances from start to finish
JVM CPU Burnt ‚Äî Amount of time the JVM used the CPU to process transactions monitored by the Java Agent."
appdynamics,Calls per Minute ‚Äî The average number of incoming or outgoing calls per minute during the specified time from the node to their destination.
appdynamics,"Errors per minute ‚Äî Any exception that prevents a business transaction from completing successfully are counted as errors
For more details on AppDynamics metrics, refer."
appdynamics,"Deployment of Applications
SaaS and on-premise options are available
SaaS :
AppDynamics itself stores the data and hosts the server components of the system in the cloud
Need to install only the agent components
On-premise :
Hosting the components and storing data should be done by the user
Need to install the agent components and the controller and event service components
Involves additional setup and administration
Should be instrumented with separate agents for each application."
appdynamics,"To monitor applications ‚Äî Application agent
To monitor servers ‚Äî machine agent
Need to configure the agent during instrumentation."
appdynamics,"Application agents for the following languages are already available in the AppDynamics Wizard
Java
.NET
PHP
Node.js
Python
Let‚Äôs see how a Java application can be instrumented with the AppDynamics agent,
If we download the agent from the startup wizard, then we don‚Äôt need to do the basic configurations because the downloaded agent will be already configured."
appdynamics,"If not, you can download the agent from AppDynamics downloads page."
appdynamics,Should configure the versioned configuration file: <agent_home>/<version_number>/ conf/controller-info.xml.
appdynamics,"Add the values for application-name, tier-name and node-name for your application environment
Example configuration of controller-info.xml file:

-javaagent parameter should be added to the startup script of the server with the value of the parameter set to the path of the javaagent.jar file
Eg:
export JAVA_OPTS=‚Äù$JAVA_OPTS -javaagent:/home/abi/Documents/AppServerAgent-4.4.0.21351/javaagent.jar‚Äù
Attach the agent with the Java process
Eg:
java -Xbootclasspath/a:/usr/lib/jvm/java-8-oracle/lib/tools.jar -jar /home/abi/Documents/AppServerAgent-4.4.0.21351/javaagent.jar 12708
Now the application will be visible under the Applications tab in the controller UI

Usability
I have listed the following points related to the usability of AppDynamics which I felt was important from my experience while using the product."
appdynamics,"Clear document
Free trial for 15 days
It takes less than 30 mins to set up in an environment."
appdynamics,"This includes the time taken to sign up, download agent, do configuration and attach the application with the agent."
appdynamics,"User-friendly UI
Dependency graph
Comparatively takes a bit longer time to load the dependency map
Other than the above points on the usability of AppDynamics, I wanted to talk about the Metric Browser which contains the performance metric graphs of the applications."
appdynamics,Let‚Äôs see the pros and cons of the Metric Browser.
appdynamics,"Pros:
Can plot more than one performance metrics in the same graph."
appdynamics,It helps to compare the different performance metrics easily.
appdynamics,"Cons:
If we want to check the graph of a specific performance metric, then we need to open the metric browser and search and find the metric and add it to the graph."
appdynamics,The added graph will be lost once we close the metric browser.
appdynamics,"So if we want to check something else in between analysing the graph, then we need to add the metrics plots again which we had before."
appdynamics,"For more details on Metric Browser, please refer
Access performance data via REST API
Other than the interactive Browser UI of AppDynamics, there are REST APIs to retrieve the details about the monitoring environment and metrics."
appdynamics,Note: AppDynamics controller REST APIs can be accessed using the Java SDK called RESTAccess.
appdynamics,"Here we are concluding the first part of this article with the details on AppDynamics and this article will be continued with,
The details on Dynatrace
Deploy and monitor WSO2 IS with AppDynamics and Dynatrace
Thanks!"
appdynamics,"GIF extracted from https://www.youtube.com/watch?v=nXXyWLft1zc
Disclaimer: Some contents written were based solely from my experience uppon using the Appdynamics dashboard."
appdynamics,So suggestions and a more in-depth overview about appdynamic‚Äôs products are much appreciated.
appdynamics,"Appdynamics
Appdynamics like many other Application Performance Management (APM) tools helps you to trace, spot outliers and setup warnings when a certain service-level objectives (SLOs) such as response time or errors per minute, etc, happens by providing incredible visuals as well as the ability to drill down into the call stack methods to find the method at the exact moment an incident occured."
appdynamics,Image taken from https://solucaoprimeitapmappdynamics.wordpress.com/tag/appdynamics/.
appdynamics,"D3.js
D3.js is a javascript framework in which my first use case to it was to better organize basic lists and blocks with data loaded from APIs but its strongest feature and use case is that it allows you to bind arbitrary data to the Document Object Model (DOM) and then let‚Äôs you to pretty much render anything you want on the browser using HTML, SVGs, CANVAS and CSS."
appdynamics,All D3.js examples here https://github.com/d3/d3/wiki/Gallery.
appdynamics,"Appdynamics caveats
To state that this isn‚Äôt a ‚Äúflaw‚Äù tothe Appdynamics product."
appdynamics,It‚Äôs just that it didn‚Äôt suit my use case at first.
appdynamics,Consider for example the first GIF of this article and the image below.
appdynamics,Image taken from http://dailyrevshare.com/database-transaction-flow-chart/database-transaction-flow-chart-elegant-overview-of-application-monitoring-4-4-x-documentation/.
appdynamics,"By seeing those two pictures one can tell that Appdynamics perfectly describes each remote calls (called business transactions) and generates a component (represented by a visual circle) based on each application and features, such as the Database server and its model + database name or the Message Queue (MQ) server and its topics."
appdynamics,So one cannot have a macro view of the infrastructure as a whole.
appdynamics,What if I want to see which applications talk to one database?
appdynamics,Which MQs depend on application X?
appdynamics,"Application Y is on top of which infrastructure (physical, vm, cloud)?"
appdynamics,To answer the questions above one would have to manually go through all the applications and check if each one of them has a connection to database X for example.
appdynamics,And when you have more than 50.. 100.. 1000.. applications.. you see where this is going.
appdynamics,right?
appdynamics,Appdynamics menu taken from https://www.g2.com/products/appdynamics/details.
appdynamics,"So the image above shows the appdynamics menu taken from the browser where you can see the tabs Applications, Databases and Servers segregated."
appdynamics,The ‚ÄúApplications‚Äù tab indeed shows all the communications between them except for the databases and each objects representing the topics of each MQ server is shown instead of a unique node representing each MQ server.
appdynamics,"Appdynamics API
Luckly appdynamics has an extensive and well documented API where you can follow these few and easy steps to get access to its REST API or RESTUI."
appdynamics,The latter not documented though with warning of unnoticed changes on further releases.
appdynamics,"So you can just POST to `/controller/api/oauth/access_token` with your credentials to get your token:
curl -X POST -H ""Content-Type: application/vnd.appd.cntrl+protobuf;v=1"" ""https://<controller address>/controller/api/oauth/access_token""

{
""access_token"": ""..."",
""expires_in"": 300
}
After this step you can just thought all Application‚Äôs Business Transactions and build a Directed Acyclic Graph (DAG) characterizing each Application‚Äôs dependencies."
appdynamics,You can save this graph in structure you want but remember that if you save it in one of these two JSON formats you‚Äôre pretty much up to plug-n-play your new JSON to any hierarchy or treemap style of d3 example to see your data in action without needing to touch any javascript code‚Ä¶ yet.
appdynamics,Layout 1 on the left.
appdynamics,Layout 2 on the right.
appdynamics,"Push data to D3.js
So I found one example that best suited my needs and.. boom!"
appdynamics,Right what I was looking for.
appdynamics,D3.js result from DAG graph generated from Appdynamics.
appdynamics,"Then after filtering some keywords that belonged to other applications and services it became more like this:

After hovering over one node:

Then moving to the hacking phase where you‚Äôre able to tweak some parts of the code to suit your needs."
appdynamics,"Like if I want to place them divided by its categories:

Making it more organized and insightful when hovering:

You can pretty much do whatever you like by messing with the force."
appdynamics,Like my attempt to copy appdynamics‚Äô layout.
appdynamics,"After hovering:

I know there‚Äôs plenty of tutorials about D3 and force graphs but I wanned to show you my use case and how you can first preview your data before having to mess or build a D3.js code from scratch which has a considerable learning curve like 
Paul Sweeney
 commented."
appdynamics,Thank you!
appdynamics,Mankzo solutions a leading e-platform for apparels have launched a promotional plan on 15th August .
appdynamics,"Customer on anticipated gifts ordered heavily, online hits reached all time high in few minutes since launch of this promotion."
appdynamics,Un-expectedly subscribers calling customer care increased.
appdynamics,Management & engineering teams are clueless on this recent glitch.
appdynamics,"After few hours of analysis, churning of logs & board room discussions finally verdict was out."
appdynamics,Customers were calling as they didn‚Äôt received promised gifts on checkout.
appdynamics,Some faced queue timeout.
appdynamics,"What could have been a fabulous day turned out to be a nightmare; slow responsiveness, analysis taking too much time all lead to this debacle."
appdynamics,Impediments like the one mentioned above faced by leading web solution companies brought the need to utilize analytics.
appdynamics,End customer experience is becoming critical in connected world where distributed platforms and technologies are prevalent.
appdynamics,"Analytics is the measurement, collection & analysis of web data for purpose of understanding and optimizing web usage."
appdynamics,"As rightly said ‚ÄúNecessity is the mother of Invention‚Äù, thanks for development in field of analytics this typical problem can now be resolved using tools like AppDynamics."
appdynamics,Cisco‚Äôs AppDynamics provides business and application monitoring platform that empowers the worlds largest enterprises to build and run the application they need to thrive in todays competitive world.
appdynamics,HOW AppDynamics works???
appdynamics,Appdynamics agents based on your service technology are deployed on individual nodes to monitor individual transactions.
appdynamics,These controllers monitors and automatically sends data and metrics to central AppDynamics controller.With machine learning baseline is created for all those metrics and in case any deviation is observed then transactions snapshots are captured to the individual level.This helps application developers to Identify potential root cause in pre-production environment.
appdynamics,Just to give you an Insight AppDynamics is able to provide SQL query which is resulting in delayed record fetch from DB due to incorrect query design and formatting.
appdynamics,This helps in designing early resolution to potential problems in record time.
appdynamics,"Fig :Work Flow Diagram of AppDynamics Functionality
Supported Applications and Technologies


Fig: Installation Steps of Monitoring Agent
Once Agents are installed AppDynamics automatically start monitoring application,EUM,Database or servers."
appdynamics,Agents captures transactions on all the ports deployed on the server where Agent process is running.To avoid many transactions getting monitored and too much information getting highlighted Specific Rules are created to Monitor Transactions related to ports where service is deployed.
appdynamics,"Once a load is triggered at application ,we can check performance metrics on Application with parameters like response time, calls,calls/min,errors %, errors."
appdynamics,"To get detailed view on errors one can view dashboard providing transactions marked in categories ‚ÄúNormal‚Äù, ‚ÄúSlow‚Äù and ‚ÄúVery Slow‚Äù."
appdynamics,"We can also view Top Business Transactions based on response time, load."
appdynamics,Also slow and erroneous transactions are listed on same page.
appdynamics,Transactions which are slow are monitored and there snapshots are captured on periodic basis.These snapshot captures the underlying issues which is resulting in sluggish behavior.
appdynamics,Also other anomalies are identified and notified on dashboard.
appdynamics,On clicking a particular transaction snaphot you can further drill down on potential issues.
appdynamics,"Just below some slow and error transactions are captured

On clicking further we can see details and potential issues

Similarly we can find potential issues which are making business transaction sluggish."
appdynamics,Also we can identify specific parameters to capture and create customized Dashboard.
appdynamics,In fact configurations can be done to receive periodic email to get customized report regarding executions.
appdynamics,With powerful capabilities exhibited by AppDynamics surely it‚Äôs becoming increasing popular in capturing business transaction monitoring.
appdynamics,"Many organizations are already reaping benefits of creating customized promotions, business patterns & improving user experience."
appdynamics,"Many platforms are using its capabilities to increase revenues, launching builds regularly, launch promotions and new features without waiting for longer product cycle."
appdynamics,Truly as its name suggest tool is ‚ÄúDynamically‚Äù ENHANCING ‚ÄúApp‚Äù for GOOD J J J J
appdynamics,"Appdynamics exploited version: 4.4.1.0
Before we begin, I would like to thank Appdynamics Security team for the support and the patience during the time until the disclosure."
appdynamics,I‚Äôm extremely happy for exposing our work on their security patch page (https://docs.appdynamics.com/display/PRO44/Release+Notes#ReleaseNotes-4.4.3.10598(HF4)Updates).
appdynamics,"One more time, thanks Appdynamics :)
To start, I would like to explain the reason behind this research."
appdynamics,Me and my co-workers regularly stay at night studding and challenging ourselves to find new vulnerabilities or simple have fun with our ‚Äúwork‚Äù xD.
appdynamics,"During one of this nights, we intend to find some issues in solutions that our own enterprise actually use."
appdynamics,"After some time of planing we have chosen Appdynamics(CISCO) to make a vulnerability research, during the processes it was possible to identify a valid SQL Injection vulnerability and it‚Äôs possible to gain total access to the app database."
appdynamics,"Ok, stop talking and let‚Äôs see the POC ;) :

First request, some parameters to play whats happens if I put‚Ä¶
hmmm, interesting ... the application have some parameters, let‚Äôs focus on one parameter at a time, let‚Äôs take a look."
appdynamics,"Well we have chosen the moment when the application loaded some services and used the parameter ‚ÄújobName‚Äù to choose the ‚Ä¶ name of the job o.O‚Äô‚Äô, lol."
appdynamics,and ‚Ä¶ Whats happens when we put something that he don't have in it's database?
appdynamics,Simple ... Internal error (500).
appdynamics,"Using a simple payload, that we saw at the previous image, an error appears ‚Ä¶

Fuzzing fuzzing fuzzing ‚Ä¶
Well, this is very interesting time to use a tool to fuzz the application and we will be planing something to exploit with this parameter."
appdynamics,"So‚Ä¶ After a few minutes, the tool found a parameter that could be injected ‚Ä¶(I Mean ‚Ä¶ Whaaaat !?!?)."
appdynamics,"So we decided to focus at that possible injection point ‚Ä¶ And this happend ‚Ä¶

A Blind SQL Injection with SQLMap appears

(At this moment I had a heart attack </3‚Ä¶)
Ohh..."
appdynamics,"Such an incredible sensation, for some people this is a simple database banner .. for me a World Cup Championship Win."
appdynamics,"Such as you can see above this is a Blind SQL Injection,this attack consist in asking the database true or false questions, and determines the answer based on the applications response."
appdynamics,"Hmm Interesting, but this could be a false positive, this happens a lot :/."
appdynamics,"We try to see more information using other parameters of the Sqlmap tool, to see what happens, and ‚Ä¶ Yeah ‚Ä¶ We can see a lot of tables *-* this is amazing."
appdynamics,"Tables of database platform_admin
After dumping tables, we tried to see the table ‚Äúuser‚Äù(lol why not !?)"
appdynamics,"and here it is ‚Ä¶

Entries for table ‚Äúuser‚Äù
Time to report :D. We reported the vulnerability to Appdynamics‚Äô Security Team and they‚Äôve invited us to a conference in order to explain better the issue that we found."
appdynamics,After the conference they asked us about the possibility of waiting the security patch release.
appdynamics,Finish !!!
appdynamics,after a long time we can publish about it !!!!
appdynamics,"One more time, thanks Appdynamics‚Äô team for the patience during all the process, it was quite an experience."
appdynamics,"More details about the Prof of Concept:
Parameter: jobName (GET)
Type: boolean-based blind
Title: MySQL RLIKE boolean-based blind ‚Äî WHERE, HAVING, ORDER BY or GROUP BY clause
Payload: jobName=aa‚Äô RLIKE (SELECT (CASE WHEN (3975=3975) THEN 0x6161 ELSE 0x28 END)) AND ‚ÄòoLYc‚Äô=‚ÄôoLYc&includeStates=21&platformId=3
CVE Related to this Post:
CVE-2018-0225 ‚Äî https://cve.mitre.org/cgi-bin/cvename.cgi?name=2018-0225"
appdynamics,"Reference: https://docs.appdynamics.com/display/PRO45/Install+the+Cluster+Agent
AppDynamics cluster agent can be used to monitor OpenShift/Kubernetes cluster."
appdynamics,We‚Äôll refer to the reference link mentioned above to setup cluster agent on OpenShift 3.11.
appdynamics,"Step 1: Create a new project using oc new-project appdynamics
Step 2: Download cluster agent 20.7 from https://download.appdynamics.com/download/ and unzip it on the server."
appdynamics,You‚Äôll need to create an account with appdynamics before you can download packages.
appdynamics,"Step 3: If Dockerhub registry is not allowed in your cluster, you need to modify /etc/sysconfig/docker and allow it temporarily."
appdynamics,"Edit /etc/sysconfig/docker file and allow docker hub by adding
--add-registry docker.io
in ADD_REGISTRY line."
appdynamics,You need to restart docker by executing sudo service docker restart command.
appdynamics,Step 4: Now we‚Äôll pull some images from docker hub and store it in our local repository.
appdynamics,"Execute following commands on the host:
sudo docker pull docker.io/appdynamics/cluster-agent-operator:0.5.2
sudo docker pull docker.io/appdynamics/cluster-agent:20.7.0
sudo docker pull docker.io/appdynamics/machine-agent-analytics:latest
sudo docker pull docker.io/appdynamics/machine-agent-netviz:latest
sudo docker pull docker.io/appdynamics/java-agent:latest
Step 5: Now we‚Äôll push all these images to our local OpenShift registry."
appdynamics,"oc login

docker login -u `whoami` -p `oc whoami -t` docker-registry.default.svc:5000
docker tag docker.io/appdynamics/cluster-agent-operator:0.5.2 docker-registry.default.svc:5000/appdynamics/cluster-agent-operator:0.5.2
docker push docker-registry.default.svc:5000/appdynamics/cluster-agent-operator:0.5.2
Execute these commands for all 5 images we pulled from docker hub."
appdynamics,"After this you can remove docker.io from allowed registries in /etc/sysconfig/docker
Step 6: Now edit cluster-agent-operator-openshift-1.14-or-less.yaml file which we got when we unzipped cluster-agent package and change image to docker-registry.default.svc:5000/appdynamics/cluster-agent-operator:0.5.2
Now deploy cluster-agent-operator using oc project appdynamics && oc create -f cluster-agent-operator-openshift-1.14-or-less.yaml
Once done, verify that the AppDynamics Operator is running using oc -n appdynamics get pods
Step 7: Login to AppD controller url and create a user in controller console named api-user with Account Owner permission."
appdynamics,"Step 8: Create a secret with the Controller access key using oc -n appdynamics create secret generic cluster-agent-secret ‚Äî from-literal=controller_key=<controller_access_key> ‚Äî from-literal=api-user=‚Äùapi-user@<account_name>:<password>‚Äù
Step 9: Add necessary permission to appdynamics-cluster-agent service account so that pod can start process with the specified UID."
appdynamics,"For this, execute
oc adm policy add-scc-to-user anyuid -z appdynamics-cluster-agent
Step 10: Now we need to download controller SSL certificate .Login to Enterprise Console-Configurations-AppServer Configurations-SSL Certificate Management-Edit Certificate and copy the content of certificate into a file named custom-ssl.pem."
appdynamics,This is required only for hosted AppDynamics.
appdynamics,"If you are using AppDynamics as SaaS, then you don‚Äôt need to do this."
appdynamics,"Step 11: Create a secret using following command
oc -n appdynamics create secret generic ssl-cert --from-file=custom-ssl.pem
Step 12: Now edit cluster-agent.yaml."
appdynamics,You can refer to https://docs.appdynamics.com/display/PRO45/Configure+the+Cluster+Agent for all the available specs.
appdynamics,You can use given yaml file as reference.
appdynamics,"Provide values for controllerUrl, account and nsToInstrumentRegex
apiVersion: appdynamics.com/v1alpha1
kind: Clusteragent
metadata:
  name: k8s-cluster-agent
  namespace: appdynamics
spec:
  appName: ""openshift_prod""
  controllerUrl: ""https://xyz.com:443""
  account: <account_name>
  customSSLSecret: ""ssl-cert""
  # docker image info
  image: ""docker-registry.default.svc:5000/appdynamics/cluster-agent:20.7.0""
  serviceAccountName: appdynamics-cluster-agent
  ### Uncomment the following two lines if you need pull secrets
  #imagePullSecrets:
  #  name: ""<your-docker-pull-secret-name>""
  instrumentationMethod: Env
  defaultAppName: App
  nsToInstrumentRegex: project1|project2
  resourcesToInstrument: [DeploymentConfig]
  imageInfo:
    java:
      image: ""docker-registry.default.svc:5000/appdynamics/java-agent:latest""
      agentMountPath: /opt/appdynamics
  instrumentationRules:
    - namespaceRegex: project1|project2
      env: JAVA_OPTIONS
  netvizInfo:
    bciEnabled: true
    port: 3892
Step 13: Now deploy cluster-agent using oc create -f cluster-agent.yaml."
appdynamics,Check pod logs using oc logs and ensure there is no error while registering cluster-agent.
appdynamics,"Once cluster agent is up, it will automatically instrument agent as init container to the pods running in the projects which you mentioned in cluster-agent.yaml file."
appdynamics,You can check the status of instrumentation using oc get pods -n <project1>-w command.
appdynamics,"Once registration process is successful, you‚Äôll see cluster listed in AppDynamics controller console by selecting Servers-Clusters
By default pods in default namespace are monitored."
appdynamics,"You can add additional namespaces in cluster-agent.yaml file itself or via controller console.Go to controller console and click on Settings-AppDynamics Agents-Cluster Agents-Select Agent-Configure and add Namespaces
Step 14: Next we‚Äôll install infra monitoring agent."
appdynamics,Execute following command to add necessary permission to service account.
appdynamics,"oc adm policy add-scc-to-user privileged -z appdynamics-infraviz
Step 15: Use following infraviz.yaml file."
appdynamics,"Make sure to change values for controllerUrl, account and globalAccount which you can get from AppDynamics Controller settings."
appdynamics,"apiVersion: v1
kind: ServiceAccount
metadata:
  name: appdynamics-infraviz
  namespace: appdynamics
---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: appdynamics-infraviz
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
spec:
  privileged: true
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - '*'
  volumes:
  - '*'
  hostNetwork: true
  hostIPC: true
  hostPID: true
  hostPorts:
  - min: 0
    max: 65535
  runAsUser:
    rule: 'RunAsAny'
  seLinux:
    rule: 'RunAsAny'
  supplementalGroups:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: appdynamics-infraviz
rules:
- apiGroups:
  - """"
  resources:
  - pods
  - nodes
  - events
  - namespaces
  verbs:
  - get
  - watch
  - list
- apiGroups:
  - apps
  resources:
  - statefulsets
  - deployments
  - replicasets
  - daemonsets
  verbs:
  - get
  - watch
  - list
- apiGroups: 
  - ""batch""
  - ""extensions""
  resources: 
  - ""jobs""
  verbs: 
  - ""get""
  - ""list""
  - ""watch""
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: appdynamics-infraviz
subjects:
- kind: ServiceAccount
  name: appdynamics-infraviz
  namespace: appdynamics
roleRef:
  kind: ClusterRole
  name: appdynamics-infraviz
  apiGroup: rbac.authorization.k8s.io
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: appdynamics-infraviz
  namespace: appdynamics
rules:
- apiGroups:
  - extensions
  resources:
  - podsecuritypolicies
  resourceNames:
  - appdynamics-infraviz
  verbs:
  - use
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: appdynamics-infraviz
  namespace: appdynamics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: appdynamics-infraviz
subjects:
- kind: ServiceAccount
  name: appdynamics-infraviz
  namespace: appdynamics
---
apiVersion: appdynamics.com/v1alpha1
kind: InfraViz
metadata:
  name: appd-infraviz
  namespace: appdynamics
spec:
  controllerUrl: ""https://xyz.com:443""
  image: ""docker-registry.default.svc:5000/appdynamics/machine-agent-analytics:latest""
  account: <account>
  globalAccount: <global_account>
  netVizImage: ""docker-registry.default.svc:5000/appdynamics/machine-agent-netviz:latest""
  netVizPort: 3892
  enableDockerViz: ""false""
  enableMasters: true
  stdoutLogging: true
  resources:
    limits:
      cpu: 500m
      memory: ""1G""
    requests:
      cpu: 200m
      memory: ""800M""
Step 16: Execute oc apply -f infraviz.yaml command."
appdynamics,Check whether all pods are up and running using oc get pods -n appdynamics command.
appdynamics,"Once this setup is done, you can verify agent details."
appdynamics,"Note: If new pods in your monitored projects are getting restarted, you may need to raise CPU limits for your deployment config."
appdynamics,"In cluster-agent pod logs, if you see Failed to send agent registration request: Post ‚Äúhttps://xyz.com:443/sim/v2/agent/clusterRegistration"": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
then check if your server is using a proxy to connect to external urls."
appdynamics,"In that case add below property in cluster-agent.yaml
proxyUrl: <protocol>://<host>:<port>
Then redeploy the cluster agent."
appdynamics,This should resolve the issue.
appdynamics,"Last week, AppDynamics announced a new partnership with Harness to help customers embrace continuous delivery and understand the business impact of every application deployment."
appdynamics,"Our integration at that time focused on the deployment and verification of specific application artifacts (Containers, AMI, WAR, Functions, Helm charts, etc)."
appdynamics,"For example, you deploy a new microservice container to your production environment and Harness will use AppDynamics data to tell you if that microservice is performing better or worse post-deployment."
appdynamics,Yesterday we enhanced our AppDynamics integration even further: we now have the ability to perform true service impact verification across all microservices within your application environment.
appdynamics,A large F500 bank requested this feature so they could instantly know the upstream and downstream impact of every microservice deployment.
appdynamics,"Now when you deploy a new microservice container, Harness will identify and verify all mciroservice dependencies so you know the real impact."
appdynamics,"A Simple Microservices Application (Said No One Ever)
Let‚Äôs imagine we‚Äôre monitoring a simple microservices environment using AppDynamics:
microservices_env
The above application has 4 microservices: Inventory, Checkout, Payment and Record Processing."
appdynamics,"Now let‚Äôs imagine we deploy and verify a new version of the Payment microservice using Harness and AppDynamics:
AppD_deploy_payment
Using our original AppDynamics integration, our verification process would have looked like this:
payment_verification
You can see clearly that our deployment caused a performance regression for the payment service after the new version was deployed."
appdynamics,The scope of the Harness verification and impact analysis is limited to where the new artifacts were deployed.
appdynamics,"Exploiting Application Performance Monitoring (APM) Service Maps
One benefit of APM solutions like AppDynamics is their ability to automatically map application service dependencies."
appdynamics,They do this by tracing user requests (aka business transactions) across the various application services and components (aka tiers).
appdynamics,All of this data is stored and modeled as application and transaction flow maps.
appdynamics,"Using REST, Harness can query these maps to learn of all upstream and downstream service dependencies."
appdynamics,This capability is very useful because it allows Harness to verify all microservice dependencies related to a specific microservices deployment.
appdynamics,"With our enhanced integration, the Harness verification and impact analysis now looks like this:
payment_new_verification
Harness verification now discovers all microservices dependencies related to the payment microservice (by querying the AppDynamics service model)."
appdynamics,This allows our unsupervised machine learning to observe and evaluate what is happening upstream and downstream by analyzing all time-series metrics for impacted microservices.
appdynamics,"In the example above, we can see that the payment performance regression has an upstream impact to the checkout microservice but no downstream impact to the record processing service."
appdynamics,Customers now see the big picture and get complete visibility of everything that is impacted by a microservices deployment.
appdynamics,"Better still, Harness can automatically roll back these deployments when these AppDynamics verifications fail, thus avoiding downtime and a bad end user experience."
appdynamics,Sign up for your free trial of Harness to test this new feature for yourself!
appdynamics,"Regards,
Steve"
appdynamics,"By Ali Siddiqui, General Manager, Agile Operations, CA Technologies

Traditional APM solutions are not built to meet the new demands of modern technologies and challenges introduced by digital transformations."
appdynamics,"Just like many of our customers, we too embarked on a digital transformation to improve our APM solution, delivering new patent-pending innovations, analytics, and a full-stack monitoring & analytics SaaS platform with the goal being to help DevOps organizations succeed in understanding and delivering the best possible customer experience."
appdynamics,"To gain this new perspective, we sought to understand how real people solved real problems ‚Äî regardless of whether they even owned an APM tool."
appdynamics,This gave us a good understanding of the challenges that needed to be solved and allowed us to create new innovations based in analytics that are ground-breaking and industry leading (more to come).
appdynamics,"Next, we focused on design."
appdynamics,"Good design is so much more than simply making our products look pretty it‚Äôs also about interaction design, making things intuitive, easy to use and allowing the user to be the most efficient, effective and successful as possible."
appdynamics,At CA we take design very seriously and have teams whose role is solely focus on design.
appdynamics,"Unlike others in the APM space, one great advantage we had was that we didn‚Äôt have to start over ‚Äî we are building upon a technology (Wily) that is often credited with creating what is now a multi-billion-dollar modern APM market."
appdynamics,"We are very proud to offer our customers one of the best and most modern solutions in the market today and though our constant innovation, honored to be recognized as a leader in the APM market!"
appdynamics,"Taking A New Approach
Meeting the challenges introduced by modern architectures, technologies, platforms and changing business models requires a new approach to monitoring, the old way of monitoring no longer meets the needs."
appdynamics,APM tools must go beyond the confines of traditional monitoring of production applications to become an integral part of the software delivery lifecycle ‚Äî to identify problems earlier and to enable continuous optimization across various development and testing phases.
appdynamics,APM tools must also unify the visibility across business and technical stakeholders through shared business insights ‚Äî one of our key priorities at CA.
appdynamics,Too much of today‚Äôs business insight is predicated on the need for business users to manually define context into their applications.
appdynamics,Users shouldn‚Äôt have to define their conversion funnels and pipelines manually; the system should be able to detect them through simple goal definitions and perform automated analyses to generate business insights.
appdynamics,We have the right solutions in place to offer full stack monitoring and the analytic insights that will help to align IT with business outcomes.
appdynamics,"CA APM, a modern future-proofed solution
Over the past 3 years, we have redefined our APM solution to include digital experience, built-in analytics, smart instrumentation, zero-config agents, ease-of-use and yes, we are proven at scale."
appdynamics,It‚Äôs not the same old Wily but a modern analytics platform built for cloud and microservices architectures.
appdynamics,"In those 3 years, we have filed over 40+ patents in APM, 23 patents-pending in analytics and almost 13 new patents filed in this past year."
appdynamics,We are innovating and changing our architecture to meet the demands of today‚Äôs changing market.
appdynamics,"Here are some of our own unique capabilities for addressing the needs of the market and modern application architectures:
Digital Experience
Customer experience and interaction with your application across digital channels is critical to your business, but delivering exceptional user experience is harder than it appears."
appdynamics,"An intuitive design, error-free code and flawless performance are the keys to a great customer journey."
appdynamics,"Our solution provides the key insights into the buyer‚Äôs journey, usage, code crashes, performance, heat maps, app flows and session replay across web, mobile and wearables."
appdynamics,We believe it is important to understand the entire digital experience but also apply the analytics needed to automate the insights required to deliver a five-star experience.
appdynamics,"Analytics Foundation Lays the Path to Self-Healing
Most vendors would agree that AI is now at the core of monitoring and is evolving past normalization and correlation to advance causal analysis, pattern detection and machine learning."
appdynamics,We‚Äôve invested heavily in this space and believe that our approach uniquely positions us to leap ahead in AIOps and starts to lay the path to self-healing.
appdynamics,"Some of our unique capabilities include:
¬∑ Graphical topology model is the foundation to pattern detection, causality and machine learning as it provides the context to the context."
appdynamics,"Our model is based on an open, extensible, ontology agnostic, and using time as a primary dimension, this dynamic model allows teams to purposefully apply algorithmic methods and machine learning to drive substantive improvements in application performance without sacrificing speed."
appdynamics,¬∑ Differential analysis uses analytics and machine learning to automatically detect anomalies and impending problems ahead of time.
appdynamics,"¬∑ Assisted triage, an intelligent engine that utilizes the graphical topology model, analytics, ML, and expert heuristics to guide users through the resolution path and help them determine and verify the exact root cause of an issue."
appdynamics,"¬∑ Powerful analytics engine, built using the CA Jarvis Big Data Analytics platform leverages open source technologies such ElasticSearch, Hadoop, Spark and Kafka, etc."
appdynamics,It goes well beyond simply linking the UIs which is what many of our competitors do.
appdynamics,"Our approach, rather, unifies these data sources into a single, correlated big-data pipeline and big-data repository that enables us to perform aggregations and analyses that have previously been unimaginable."
appdynamics,"¬∑ Intelligent, flexible and extensible new and advanced methods for monitoring microservices, containers, cloud and API-centric architecture ‚Äî including agentless topology and automated flow maps, smart instrumentation, zero configuration agent, API performance tracing, and automated context mapping with app to infrastructure correlation."
appdynamics,"DevOps
A significant part of our ongoing and future engineering investment is going toward building integrations with AppDev, testing and release automation tools."
appdynamics,We are also fully leveraging our corporate presence in API management and Continuous Delivery businesses to create a compelling and highly differentiated solution that seamlessly bridges the gap between application development and performance monitoring worlds.
appdynamics,"Full Stack Monitoring
CA Digital Experience Insights (DXI), a SaaS platform offers customers user-experience centric set of integrated services to monitor the entire digital service chain ‚Äî all the way from a user‚Äôs mobile devices to business transactions to infrastructure heath and usage."
appdynamics,"The DXI platform today offers integrated App Experience Analytics, Application Performance Management and Infrastructure Management services with consistent user interface, cross-product workflows, and a common data repository and analytics engine."
appdynamics,"Scale you can trust
Unlike competitors we offer an enterprise scaling monitoring and analytics solution engineered to meet the performance demands of modern cloud-apps, containers and VMs ‚Äî this means faster time to value for customers with less cost."
appdynamics,"CA APM clusters can process well over 1,000,000 metrics across 1,000+ agents and analyze 1M+ graphical components."
appdynamics,"CA APM is proven in large enterprise environments ‚Äî for example, a telco company using CA APM has 30‚Äì40K agents with 144B metrics/day."
appdynamics,"Our CA Digital Experience Insights solution including APM, digital experience, infrastructure and analytics is today one of the most compelling products in the market ‚Äî catering to a much larger audience with a highly-differentiated set of capabilities, built for the largest scale our customers need."
appdynamics,We continue to receive resounding positive feedback from our customers and analyst community for our strategy and vision.
appdynamics,We are building on this leadership with continued speed and innovation.
appdynamics,"To learn more, read about how CA compares against Dynatrace and AppDynamics."
appdynamics,"I also encourage you to attend our upcoming AIOps Virtual Summit to hear more from our experts, customers and industry thought leaders."
appdynamics,*This post also appeared on APMDigest.
appdynamics,"The AppDynamics enables you to monitor and manage your entire application-delivery ecosystem, from the mobile app or browser client request through your network, backend databases and application servers and more."
appdynamics,"It gives you a single view across your application landscape, letting you quickly navigate from the global view of your distributed application right down to the call graphs or exception reports generated on individual hosts."
appdynamics,"This article describes how to configure AppDyanamics to monitor an API Management platform implemented using WSO2 middleware stack (ESB, APIM and DSS)."
appdynamics,"AppDynamics Essentials
AppDynamics consists of two main components: Controller and Agent."
appdynamics,Agent collects metrics from applications and publish it to Controller.
appdynamics,"Controller collects metrics from many agents, aggregates, analyzes and presents diagnostics information in a very user-friendly dashboard."
appdynamics,"Setting up AppDynamics Controller
Controller can either be a SaaS controller or on-premise controller."
appdynamics,"I‚Äôll be using a SaaS controller in this article to monitor an API management platform implemented using WSO2 middleware stack (ESB v5.0.0, APIM 1.10 and DSS 3.2.0)."
appdynamics,The following video explains how we can get an AppDynamics SaaS controller.
appdynamics,"Setting up AppDynamics Agent
I‚Äôll be using Java agent (v4.3.7.1) in this article to monitor WSO2 servers."
appdynamics,The following video explains how we can configure AppDynamics agent to monitor WSO2 servers.
appdynamics,"Configure Transaction Discovery and Correlation
AppDynamics doesn‚Äôt discover transactions flowing through WSO2 ESB and API Manager by default."
appdynamics,"Reason is ESB and APIM are using a custom transport, AppDynamics doesn‚Äôt know the entry and exit points of this custom transport."
appdynamics,"So, we will have to configure custom POJO entry point and a logical endpoint to instruct AppDynamics to monitor transactions flowing through ESB and APIM."
appdynamics,Custom POJO entry point is ‚Äúorg.apache.synapse.core.axis2.SynapseMessageReceive#receive()‚Äù.
appdynamics,We don‚Äôt have do this for DSS and Key Manager since they expose web services using servlet transport and AppDynamics is capable of discovering servlet entry/exit points by default.
appdynamics,The following video explains how to configure transaction discovery and correlation.
appdynamics,"Configure Transaction Splitting
We might want to track transactions in API level, or even in API resource level."
appdynamics,AppDynamics provides a way to do this using something called transaction splitting.
appdynamics,We can split the transactions using request URL (or part of request URL).
appdynamics,"In our custom POJO entry point, we can access the request URL using the getter chain ‚ÄúgetOptions().getTo().getAddress()‚Äù on the 0th parameter of receive() method."
appdynamics,The following video explains how we can configure transaction splitting.
appdynamics,"Configure Call Graph
AppDynamics uses a dynamic baseline approach and identifies intermittent performance issues (by comparing current transaction‚Äôs metrics against previous transactions‚Äô metrics)."
appdynamics,"If it identifies a performance issue, it will take a snapshot of that transaction."
appdynamics,"Snapshot contains more diagnostic information such as call-graph within each layer, request payload, headers, etc."
appdynamics,The following video explains transaction snapshots and call-graphs.
appdynamics,"Configure Asynchronous Transaction
AppDynamics doesn‚Äôt calculate the end-to-end latency of transactions flowing through WSO2 stack by default."
appdynamics,The reason is that ESB and APIM (GW) are using asynchronous non-blocking HTTP outbound calls.
appdynamics,"For example, if ESB or GW is calling a backend, they don‚Äôt wait for the response."
appdynamics,"Instead, they register a callback and return immediately."
appdynamics,"In our application stack, once GW sends out the request to ESB, AppDynamics assumes the transaction is complete."
appdynamics,"Hence, the latency AppDynamics captures by default is just the latency introduced in the request path of GW."
appdynamics,AppDynamics provides a way to configure a logical termination point for a transaction to calculate the end-to-end latency.
appdynamics,The logical transaction termination point in WSO2 is ‚Äúorg.apache.synapse.core.axis2.Axis2Sender#sendBack()‚Äù.The following video explains how we can do that.
appdynamics,Follow me on Twitter @raj10x for latest blogs!
appdynamics,"Image result for wso2 ei
WSO2 Enterprise Integrator is a 100% Open Source Integration Platform which brings together all the functionalities of WSO2 Enterprise Service Bus (WSO2 ESB), WSO2 Message Broker (WSO2 MB), WSO2 Data Services Server and WSO2 Business Process Server to one package."
appdynamics,"You can download WSO2 Enterprise Integrator from here, simply by entering your email."
appdynamics,AppDynamics is a platform for Application Performance Monitoring & Management.
appdynamics,"It can be used to monitor various types of application performance metrics, to analyze the performance of your applications and database servers, to measure the user experience of your app and many more."
appdynamics,So then let‚Äôs see how to monitor the performance of WSO2 EI with the AppDyanamics platform.
appdynamics,1.
appdynamics,"Setting up the environment
First, log into AppDynamics and then click on ‚ÄúStart Free Trial‚Äù."
appdynamics,Note: AppD platform has main two components.
appdynamics,One is the AppD Agent and other is the AppD Controller.
appdynamics,Agents are the ones who collect the data from our applications.
appdynamics,Agents are reporting to a common Controller and it stores and analyzes our data.
appdynamics,Now we are going to get into our controller.
appdynamics,It can be a SaaS controller hosted by AppD or an On Premise controller which we have to setup on our own server.
appdynamics,Let‚Äôs try the SaaS controller as it has everything setup and pre-configured for us.
appdynamics,Click on ‚ÄúSaaS Controller‚Äù and wait for few seconds until your platform is setuped.
appdynamics,Then select Java under Applications in Getting Started Wizard.
appdynamics,"Keep all the selections as it is ( JVM as Sun/JRockit and Configure as the default address, port and SSL enabled)and download the App Agent."
appdynamics,Unzip the download App Agent and copy the path to the javaagent.jar.
appdynamics,"Note: AppD has mainly three types of Agents; App Agent, Standalone Machine Agent and Database Agent."
appdynamics,App Agent runs in the application process and collects metrics about the app.
appdynamics,"Standalone Machine Agent runs separately and collects performance metrics of the server; CPU, Memory, Network utilization and etc."
appdynamics,Database Agents monitor your database server.
appdynamics,2.
appdynamics,"Configuring App Agent and WSO2 EI
Go to conf directory of the extracted App Server Agent and edit the controller-info.xml file to have values for <application-name>, <tier-name> and <node-name>."
appdynamics,"controller-info.xml
Then edit the integrator.sh in the EI-Installation/bin by inserting the line
‚Äî javaagent:""/path-to-app-agent-directory/javaagent.jar"" \
as another $JAVA_OPTS, as shown below, to make App Agent run with the WSO2 EI."
appdynamics,"integrator.sh
Now we are good to go, after these configurations."
appdynamics,3.
appdynamics,"Monitoring WSO2 EI
Start EI server from integrator.sh and wait for the connection at the Getting Started Wizard page of AppD controller."
appdynamics,"After there appeared ‚ÄúAgent Connected‚Äù, put some load on EI for agent to send data to the controller."
appdynamics,"After all green, continue to monitor your application."
appdynamics,"Main Dashboard
Main dashboard shows an overview of the whole infrastructure of your application; nodes, remote web services and app databases."
appdynamics,It shows Load and Response Time variation graphs and an overview of the application health.
appdynamics,"AppD automatically identifies all the Business Transactions and Service Endpoints, and monitor their performance."
appdynamics,You can view them by clicking the respective tabs on the left side pane.
appdynamics,"Business Transaction details

Service Endpoints details
You can monitor EI‚Äôs memory usage through AppD platform."
appdynamics,Go to Tiers & Nodes ‚Üí Select your tier and node ‚Üí Memory ‚Üí Heap & Garbage Collection.
appdynamics,"Heap and Garbage Collection
Automatic Leak Detection gives us the capability to track the memory leaked objects."
appdynamics,‚ÄúOn‚Äù the detection and start a capturing session by giving a session time period and minimum age for Collections to reside in memory.
appdynamics,You can configure the minimum Collection size from right top Gear icon ‚Üí AppDynamics Agents ‚Üí select the agent ‚Üí Configure ‚Üí minimum-size-for-evaluation-in-mb.
appdynamics,"In Object Instance Tracking, we can view the number of instances created from various classes in EI."
appdynamics,"Object Instance Tracking
In Slow Response Times, you can identify the slow business transactions happened and their time."
appdynamics,"By viewing the details of each transaction, from the below table, you can even drill down the it to analyse the time taken by each step in the transaction and find the reason for the slowness."
appdynamics,Another cool feature in AppDynamics platform is alerting.
appdynamics,Left pane ‚Üí Alert & Respond navigates you to the page.
appdynamics,"‚ÄãWe can create Health Rules on Transaction Performance, Node Health, Error rates and etc, which affects to the whole application or a specific transaction/node/tier."
appdynamics,Critical conditions and Warning conditions can be defined to a health rule based on previous records or a specific value.
appdynamics,"You can define Actions to send an email, send a SMS, create a JIRA ticket etc."
appdynamics,Policies can be configured to trigger Actions when Health Rule/s violated.
appdynamics,"After all these, you can even create custom dashboards to monitor EI."
appdynamics,Various widgets can be easily added to the dashboard to view all the metrics at a glance.
appdynamics,"Sample Custom Dashboard to monitor WSO2 EI
These are some of the important features in AppDynamics which are really useful in monitoring the performance of WSO2 Enterprise Integrator."
appdynamics,Refer to AppDynamics Documentation to have a deeper knowledge about the platform.
appdynamics,So that‚Äôs all for this blog and happy monitoring üòõ !
appdynamics,Application performance management (APM) providers like New Relic and AppDynamics are in a market adjacent to Seerene.
appdynamics,"While they focus on the intersection of hardware and software, Seerene looks at the intersection of software and people."
appdynamics,These management systems are both critical to building a world-class company.
appdynamics,"Seerene will help you speed up the pace of product innovation and accelerate time to market by giving you a clear view across codebases and development capacity, both internal and outsourced."
appdynamics,"It creates visual maps so you can see the number of FTEs invested into a project, understand its code quality, and gain clarity on the risks and key person dependencies."
appdynamics,"With both a APM and code+people management, you‚Äôll be able to achieve true operational excellence and run faster than the competition."
appdynamics,People talk a lot about digital transformation.
appdynamics,I talk a lot about digital transformation because I am in tech sales and those are words we tech sales people say these days.
appdynamics,"Here are a few of IT sales‚Äô favorite words by year, perhaps you‚Äôve heard them a million times: digital transformation (2016), big data (2015), cloud (2014), consumerization of IT & BYOD (2013), DevOps (2012)."
appdynamics,We say these words a lot because they sound clever and because it makes our managers happy.
appdynamics,But is IT transformation always good just because it‚Äôs trendy?
appdynamics,Wow!
appdynamics,Not if you were in a leadership position at Cambridge University NHS Trust‚Äôs Addenbrooke‚Äôs and Rosie Hospitals!!
appdynamics,AN NHS HOSPITAL DID WHAT?
appdynamics,TO CHILDREN??
appdynamics,SURELY YOU‚ÄôRE MAKING THAT UP!
appdynamics,"With likely the best intentions, leaders reportedly spent ¬£200M on an Epic paperless records system in 2014."
appdynamics,There were ‚Ä¶ technical glitches ‚Ä¶ in the roll out.
appdynamics,Patient records were lost.
appdynamics,The system caused mistakes in prescriptions‚Ä¶ for children!
appdynamics,"Staffing issues were exacerbated by the extra time it took everyone to learn the new system, wait for it to complete records requests, and having to write everything down a second time on a piece of paper in case the system lost it."
appdynamics,Important communication broke down.
appdynamics,Patient care deteriorated.
appdynamics,"Within a year, the hospitals were put into special measures after losing ¬£1.2M per week!"
appdynamics,The CEO resigned in September of 2015.
appdynamics,"Thanks to the professionalism of the staff no one was hurt, although the Care Quality Commission (CQC) report claims there were several ‚Äúnear misses‚Äù of mistaken prescriptions in the pediatric department prevented only by the vigilance of the staff."
appdynamics,Total time elapsed between well intentioned software purchase and CEO resigning over nearly killing children: 11 months.
appdynamics,Software is hard!
appdynamics,I am not.
appdynamics,Making this up.
appdynamics,"ANOTHER SIDE OF THE STORY
‚ÄúAn incompetent government IT failure,‚Äù so the popular story goes and so it was reported in the press."
appdynamics,But was it really?
appdynamics,"It is tempting to blame the people and software involved because this flatters all our preconceived stereotypes about inefficient government, incompetent IT and technology doing more to impede than improve our lives."
appdynamics,But are they any different from us?
appdynamics,It wasn‚Äôt a bad idea and it wasn‚Äôt necessarily bad software!
appdynamics,Paperless records are great!
appdynamics,"They improve cooperation, decrease miscommunication, and free up staff to provide better care."
appdynamics,"Even the CQC report admits, ‚ÄúEPIC had improved efficiency within the department giving staff better access to patient information.‚Äù The CEO made a good decision in deciding to implement them."
appdynamics,The software functioned well mostly.
appdynamics,What went wrong?
appdynamics,It is also easy to blame the NHS.
appdynamics,I am American.
appdynamics,I am accustomed to going to the hospital with a minor ailment and returning with a major bankruptcy.
appdynamics,There is a check box on US medical forms as to whether you‚Äôd like Chapter 7 filed automatically or if you prefer to do it yourself later.
appdynamics,"But lucky me, I‚Äôve got Donald Trump working on a solution."
appdynamics,"As an impartial outsider I‚Äôve found the NHS to be compassionate, efficient, and tech forward."
appdynamics,"In the UK, you can even safely see your GP without an attorney present!"
appdynamics,And who can argue with the price?
appdynamics,"Similarly, I have great respect for those public servants who sacrifice higher salaries in the private sector to fight the daily frustrations of government IT working to ensure we all get better care."
appdynamics,Good people.
appdynamics,So again what went wrong?
appdynamics,"WHAT REALLY WENT WRONG: SOFTWARE CAN BE SCARRY, BUT USERS?"
appdynamics,USERS ARE TERRIFYING!
appdynamics,In reading the 157 page CQC report a few things stand out.
appdynamics,The underlying issue was not the software.
appdynamics,"The underlying issue was the funding crisis and chronic under staffing common in most hospitals, and most businesses, these days."
appdynamics,But the Epic software still got called out by name 130 times in the report!
appdynamics,Marketing must have been thrilled!
appdynamics,"When staff were interviewed about the root cause of underperformance they weren‚Äôt about to blame themselves or their colleagues, they blamed that annoying bit of new software that had been grating on them."
appdynamics,Herein lies the problem.
appdynamics,"If your software is perfect you will be taken for granted and forgotten, because it will function seamlessly as part of your users‚Äô every day lives."
appdynamics,"If your software under performs, they will blame everything from their lack of productivity to the poor taste of their coffee on you."
appdynamics,You will wish you were forgotten.
appdynamics,They will complain to their children at dinner about you.
appdynamics,Reporters will write articles.
appdynamics,You will not like the Google search results for your name.
appdynamics,"A successful software roll out hides many failures, but a high profile, expensive botch will render all of your other successes meaningless."
appdynamics,"Your software can be good, but if users don‚Äôt like the implementation they might blame the failure of an entire business on you."
appdynamics,"It‚Äôs not fair, but it is reality."
appdynamics,"One can blame the unrealistic expectations of users, but is it really their fault?"
appdynamics,They have been trained to expect intuitive functional software.
appdynamics,Blame that on Google and Facebook.
appdynamics,So now you have to compete with Sergey Brin and Mark Zuckerberg.
appdynamics,Mark Zuckerberg makes billions.
appdynamics,How much do you make?
appdynamics,"Again it‚Äôs not fair, but it is reality."
appdynamics,"‚ÄúIt‚Äôs easy, why can‚Äôt you be more like me?‚Äù
A SIMPLE SOLUTION: DON‚ÄôT FORGET YOUR USERS!"
appdynamics,Don‚Äôt forget your users!
appdynamics,Think of your users first and the brilliant capabilities/fantastic ROI of your software second.
appdynamics,A simple way to do this is to monitor user transactions.
appdynamics,"You can see problems as they arise, in context and in real time, with greater clarity than the users themselves."
appdynamics,Not only do you know exactly what‚Äôs going wrong (i.e.
appdynamics,"3rd party data base transaction) and how it is impacting people (slow patient records transfer) you can precisely identify the code, infrastructure or network at fault in minutes, not hours."
appdynamics,"If you are reactively using logs, stop it."
appdynamics,"Monitor your users, not your servers."
appdynamics,"You don‚Äôt have to buy AppDynamics just because we have a bedrock culture of excellence in everything we do and happen to produce the best application performance monitoring platform in the world, but you should do something!"
appdynamics,Think of your poor users!
appdynamics,"In Aldenbrooke‚Äôs and Rosie‚Äôs case simple user transaction monitoring could have identified where records were being lost, where bottle necks were slowing transactions, in short where users felt the pain and frustration they later took out on IT."
appdynamics,"The problem was not bad software, the problem was being blind to where code conflicted with people."
appdynamics,So they threw the software under the bus.
appdynamics,Can you blame them?
appdynamics,"The beauty of application intelligence done right is not just better software performance, but better human performance & cooperation."
appdynamics,Better implementation of software leads to better culture.
appdynamics,"Don‚Äôt forget your users, or they won‚Äôt forget you!"
appdynamics,"First, look after your users."
appdynamics,"Hopefully they will never have to testify to the CQC, but if they do, at least they won‚Äôt blame you."
appdynamics,They will probably blame HR.
appdynamics,"- MK
Please remember to thank all our NHS professionals you see today!"
appdynamics,"If you have similar horror stories or lessons, I‚Äôd love to hear about them in the comments."
appdynamics,If you would like to be part of our culture of excellence at AppDynamics and take advantage of our fantastic platform our trial is completely free for anyone who likes this post.
appdynamics,Download it here and be amazed!
appdynamics,Thank you to Sooraj Shah‚Äôs omnipresent reporting for making me aware of this story.
appdynamics,Give him a follow or scoop @sooraj_shah.
appdynamics,"All contents of this article are entirely my own opinion/research and do not reflect the views/consent of my employer, AppDynamics."
appdynamics,CQC report here.
appdynamics,"March, 2020 ( Painful Integration of Kafka with Appdynamics )
Another big surprise came to me that New Relic Contract will be gone and New Product called Appdynamics, will take over it."
appdynamics,I already spent around a month on New Relic Integrations and Now I have to do it fucking again with Appdynamics.
appdynamics,"I knew that it has to be done, I can‚Äôt do anything about decision."
appdynamics,I decided that let me ask for help so other teammates can learn things as well.
appdynamics,"I asked my colleague to check it out and let me know how it can be done, I gave him examples from New Relic experience but he was too naive and honestly wasn‚Äôt that much interested in doing it."
appdynamics,Anyways he found Appdynamics Kafka Integration.
appdynamics,"It looked okay to me, I asked my colleague to implement on one machine and let‚Äôs see how it will appear in Appdynamics Portal."
appdynamics,I had very high expectations from Appdynamics about it and it fell apart.
appdynamics,"The Appdynamics Bummer List
how confusing Appdynamics Portal :( ."
appdynamics,No easy docs for Appdynamics?
appdynamics,No Support for Labels or similar things.
appdynamics,Old Style Custom Dashboards where everything was supposed to be static.
appdynamics,Integrations were super hard to configure and check?
appdynamics,"No support for API, where I can download and upload custom dashboards."
appdynamics,configuration files should small so can be updated easily.
appdynamics,"Anyways, my colleague did the integration on one machine and showed me a small demo on installation and other aspects."
appdynamics,"As he wasn‚Äôt interested so I had to do it and I said to myself that how fucking hard it can be, I will give a proper shot to it."
appdynamics,If it didn‚Äôt worked then I will run current Production Kafka without Monitoring ( Already had CMAK so wan‚Äôt that concerned ).
appdynamics,"Integration Documentations:
Kafka Monitoring Extension for AppDynamics
Kafka Monitoring Extension for AppDynamics Use Case Apache Kafka¬Æ is a distributed, fault-tolerant streaming platform‚Ä¶
www.appdynamics.com

Zookeeper - Monitoring Extension
Before the extension is installed, the prerequisites mentioned here need to be met."
appdynamics,"Please do not proceed with the‚Ä¶
www.appdynamics.com

Very Odd Part in documentation was that I need define each and every metric which I need to collect and It will make my Config quite log and very hard to update later."
appdynamics,"Configure Tier
under which the metrics need to be reported."
appdynamics,"This can be done by changing the value of <Component-ID> in
metricPrefix: ""Server|Component:<Component-ID>|Custom Metrics|Kafka"".<br/>Please refer this link to find Component-ID of your tiers."
appdynamics,"For example,
metricPrefix: ""Server|Component:19|Custom Metrics|Kafka""
Config.yml
- objectName: ""kafka.server:type=BrokerTopicMetrics,*""
          metrics:
              - Count:
                 alias: ""Count""
                 multiplier: """"
                 delta: false
                 aggregationType: ""OBSERVATION""
                 timeRollUpType: ""AVERAGE""
                 clusterRollUpType: ""INDIVIDUAL""
    
              - MeanRate:
                 alias: ""Mean Rate""
                 multiplier: """"
                 delta: false
                 aggregationType: ""AVERAGE""
                 timeRollUpType: ""AVERAGE""
                 clusterRollUpType: ""INDIVIDUAL""
I didn‚Äôt understood why the fuck I need to add these ‚ÄúCount‚Äù / ‚ÄúMeanRate‚Äù and many more?"
appdynamics,If you remember that New Relic was monitoring more than 200+ JMX objects and above type of config.yml will be too long.
appdynamics,"Custom Dashboards
Each Kafka Server was reporting its metric separately so you have to find each server in ‚Äúmetric browser‚Äù and then export each metric to custom dashboard."
appdynamics,"If just do small calculations
36 Kafka Servers * 10 Metrics = 360 ( Only small portion of NewRelic Dashboard )
above steps I need to do 360 times which was just too much manual work, Even I didn‚Äôt had any Junior DevOps so I can‚Äôt handover to someone :( ."
appdynamics,Finally !
appdynamics,"I decided no matter what happens, I won‚Äôt be doing it because of too much work on Appdynamics Integration which provides very little insights to myself aka Kafka Administrator."
appdynamics,Journey will continue to actual custom monitoring!
appdynamics,"INTERN PERSPECTIVE
Because learning never stops ‚Äî Virtual Summer Internship at AppDynamics
Dear COVID19,
You really have brought the entire world to a standstill but guess what, learning and growth still continues."
appdynamics,Even in the toughest of times.
appdynamics,"üå±

Always wanted a picture here, people will say it‚Äôs a sketch üòè
Hi, I am Abhishek Dhar, pursuing Masters in Design at IIT Guwahati."
appdynamics,I will be sharing my experience and 7 lessons from the 10-Week UX Design Internship at AppDynamics.
appdynamics,"AppDynamics
[AppD] / verb
The art of identifying the root cause of a problem and finding a
solution for it."
appdynamics,"User experience is the heart and soul of any business and in today‚Äôs fast-paced industry, companies are harnessing the power of cutting edge technologies to provide faster and better solutions."
appdynamics,"But is that enough to provide a ‚ÄúGood experience?‚Äù
No."
appdynamics,"A digital environment comprises of servers, virtual machines, data warehouses, cloud storage etc."
appdynamics,"The list is mammoth, and to provide a ‚ÄúGood experience‚Äù it becomes important for organizations to ensure that their environment is performing optimally."
appdynamics,"AppDynamics provides APM (Application performance management) solutions that helps organizations to consistently monitor their environment, detect problems before the users are impacted, and rapidly resolve those issues."
appdynamics,"My Journey to becoming an AppDynamo
September 2019, AppDynamics India Design team came to IIT Guwahati to hire interns and a pre-placement talk was organized where the candidates were given a glimpse of the life at AppDynamics."
appdynamics,"I was completely amazed by their presentation, especially when they spoke about the significant role Design plays at AppD, the plans to expand the team, and the ‚ÄúDesign Bytes‚Äù newsletter, which is edited by the team and distributed company-wide to celebrate the design milestones aimed at spreading design awareness."
appdynamics,The presentation ended with the attendees getting an AppDynamics T-shirt.
appdynamics,"I told myself then and there, ‚Äúyou gotta earn it Abhishek!‚Äù That‚Äôs where it all began :)
From there on, we received a design task which was followed by a comprehensive interview by an expert panel."
appdynamics,"The interviews were held remotely and if you ask me what it takes to get through it ‚Äî It‚Äôs simple, just stay calm and have confidence in your work."
appdynamics,It‚Äôs completely okay to be open about what you don‚Äôt know.
appdynamics,"After all, you would want to learn the rest during the internship."
appdynamics,"The final list of candidates were announced and 
Shiva Sah
 and I made it through."
appdynamics,"The team made a welcome video for us :‚Äô)

Virtual internship vs In-Office internship
Fast forward to 15th March 2020, we got a notice from college that due to the COVID19 pandemic we have to vacate the campus ASAP!"
appdynamics,I was worried about my internship with AppD.
appdynamics,"One fine day, we received a mail from AppD confirming that the summer internship program will now be conducted virtually."
appdynamics,"The questions that I pondered since the beginning were -
How will the virtual experience be?"
appdynamics,Will I be able to make the most out of it?
appdynamics,All my doubts were laid to rest.
appdynamics,I had never imagined that I would feel sad when I receive the email to complete the exit formalities from AppD.
appdynamics,I sat down for a while reflecting upon the past few weeks.
appdynamics,"The culture, the people in the company, they pull you in."
appdynamics,Every day a new chapter unfolds.
appdynamics,"You understand the user, the product better."
appdynamics,It‚Äôs like a journey in itself.
appdynamics,What did I miss the most in this virtual internship?
appdynamics,Getting to meet the amazing people I worked with during the internship.
appdynamics,AppDynamics workplace.
appdynamics,"My work setup
Virtual internship tips
1) Time management is super important
Yes, flexibility is definitely a plus point."
appdynamics,But remember you are a part of a team and you have to walk along with the team.
appdynamics,Respect the deadlines!
appdynamics,Creating a to-do list always helps you to keep track of things.
appdynamics,Communication is the key.
appdynamics,Talk to your mentor.
appdynamics,Reach out to them in times of need.
appdynamics,"Remember, the person on the other side of the screen knows where you‚Äôre coming from."
appdynamics,"Schedule mindful meetings even if it is just for 10 minutes, the agenda and the outcome of the meeting should be really clear."
appdynamics,If you have scheduled a meeting but are not prepared.
appdynamics,It is completely fine to discuss with the other person and move the dates ahead.
appdynamics,"Remember, always respect other‚Äôs time!"
appdynamics,"2) Productive off-days
Weekends are the best time to reflect upon the work and plan the next week ahead."
appdynamics,"As a designer, it is important that you document everything you did in the process."
appdynamics,"One doesn‚Äôt realize this, but a lot of ideas are hidden in those scribbles you made during the meeting or while brainstorming."
appdynamics,Weekends are the best the time to collate all those ideas.
appdynamics,"3) Find a balance
When at home, one has to take care of many things."
appdynamics,Finding a balance between work and personal life is very important.
appdynamics,"My parents asked me, what do you work on?"
appdynamics,"So, one day I took some time, simplified my problem statement and what AppD does and I explained it to them."
appdynamics,"To my surprise, they got very involved and started helping me with the root cause analysis!"
appdynamics,"There were also days when I had to spend more time doing house chores, it does takes away your scheduled work time."
appdynamics,No worries!
appdynamics,"go ahead, put in that extra effort, extra hours."
appdynamics,Always meet your targets!
appdynamics,Tip : 15 Minute power naps are the best!
appdynamics,"üòé
4) Use the right tools
The team introduced us to a range of tools we could use to get the best out of this virtual experience."
appdynamics,"Apart from fine-tuning my design skills, another thing I learned is efficient collaboration & people management skills."
appdynamics,"With the research team located in San Francisco, you have to keep them in the loop too."
appdynamics,"From late-night calls to early morning testing sessions, it was super exciting to be a part of it!"
appdynamics,"7 lessons I learnt from Internship at AppDynamics
1) You are more than just an intern
The first day of our internship, we were told ‚Äúnow you are an employee of the company for the next 10 weeks‚Äù."
appdynamics,"Having been surrounded by such brilliant minds and an open and inviting culture, it was very easy to settle in."
appdynamics,"Having access to a huge library of information, being able to learn what everyone on the team is working on, getting to know their journey to the solution, I can go on and on about it!"
appdynamics,Take ownership of your work!
appdynamics,"2) Always keep an open mind
We learn something from every person we interact with."
appdynamics,101% true.
appdynamics,Every little appreciation counts!
appdynamics,I was very touched with how everyone in the team acknowledges each other‚Äôs effort.
appdynamics,People here at AppDynamics want you to grow.
appdynamics,"They may not hold your hand and help you walk, they teach you how to sprint!‚ö°
Mentors play a huge role during your internship, the effort they have to put in also doubles up."
appdynamics,"So, please make sure that you mindfully work on the feedback you receive."
appdynamics,Take every single critique and feedback into account because you never know what you seek might be seeking you.
appdynamics,3) Love challenges?
appdynamics,"Then AppD is the place to be
Curiosity was at its peak for those 10 weeks and every day was a new challenge."
appdynamics,Oh!
appdynamics,"the beautiful world of APM, it will keep amazing you as you dig in more."
appdynamics,"The time we joined the company, we were introduced to something that would bring in a paradigm shift in the monitoring world."
appdynamics,There were so many cool innovations happening and getting to see it unfold was an amazing experience.
appdynamics,"4) Mentor will push you to thrive
As a person, I tend to grow in an environment where I have people to look up to, people who tell you ‚ÄúGo take that extra mile, even if that‚Äôs a path you have never taken.‚Äù I couldn‚Äôt be luckier to have had two amazing mentors."
appdynamics,They are the driving force of AppDynamics‚Äôs design @ India.
appdynamics,I got to learn something out of every conversation I had with them.
appdynamics,5) Take regular breaks from work!
appdynamics,The first week of our Internship ‚Äî Pictionary Session followed by a Me-Day Friday off!
appdynamics,"Onboarding couldn‚Äôt have been more fun ;D
Shorter breaks in between work were all about Football Manager!"
appdynamics,"Won the treble with Borussia Dortmund üèÜüèÜüèÜ

The slack channel was the primary source of communication apart from email."
appdynamics,There were many sessions and fun events that were conducted.
appdynamics,The alerting team party!
appdynamics,"6) It‚Äôs 95% process and 5% solution
While working at AppDynamics there were several times when my mentors and PM stressed how important the process is."
appdynamics,The difference between working on a college project and working in the industry is very clear.
appdynamics,Here you have a real-time opportunity to address the user‚Äôs needs.
appdynamics,How to create great user-centered products?
appdynamics,Follow the process holistically.
appdynamics,That‚Äôs it.
appdynamics,There are various design methodologies.
appdynamics,"It looks very enticing like the dessert section of any menu, where you feel like trying it all."
appdynamics,But this is where your decision-making abilities come into the picture.
appdynamics,"Spend time and understand your problem statement, and use the methods which you feel suits your project the best."
appdynamics,"7) The best part ‚Äî User testing
Getting this opportunity to test our Designs with the user is something which I had always wished for."
appdynamics,That immense satisfaction you get is paramount even if a single design intervention matches the user‚Äôs mental model.
appdynamics,The major innovators of the product are the users.
appdynamics,A single function can be interpreted in multiple ways by different users.
appdynamics,AppDynamics users love user testing sessions as much as we do.
appdynamics,"Suppose, we are testing a feature A, the user testing sessions are open-ended and the user while talking about A, also points out other features which then paves the way for innovations."
appdynamics,"One with the team :)
While penning down my experience, I realized how much I had gained during those 10 weeks."
appdynamics,It was an absolute pleasure to be able to work with such amazing people.
appdynamics,"It definitely feels good when you go back to college on such
a high note!"
appdynamics,"It gives me immense pleasure to share that I have been offered a
Pre-Placement Offer and I will be joining the team next year as a
Product Designer üòÉ
I want to thank my mentors, and the team who played a pivotal role in making the internship experience a walk to remember."
appdynamics,As easy as it is to change configuration in User Interfaces maintaining this over a long time becomes a hassle.
appdynamics,This is especially true if you are looking after configuration for multiple environments and applications.
appdynamics,"In this article, we look at a new Terraform provider for AppDynamics to get around this issue using configuration as code."
appdynamics,"Why Configuration as Code
The ‚Äòas code‚Äô practice has been thrown around a lot recently."
appdynamics,You may recognise it in infrastructure as code which is often used to build applications on AWS.
appdynamics,"Ther are various tools used for this such as Terraform, CDK, CloudFormation and Puppet to name a few."
appdynamics,"We will be using Terraform later on, an introduction to this can be found here."
appdynamics,The alternative to this practice is to manually create and change things.
appdynamics,This could be running commands on servers or changing things in user interfaces (UIs).
appdynamics,This makes reproducing things hard as you have to remember and manually apply the changes.
appdynamics,By defining our config as code we get the benefit of being able to reuse it.
appdynamics,If we apply good programming techniques we can modularise it and use it in many places.
appdynamics,Some examples of this are using the same configuration in pre-production and production environments and sharing common configuration between similar applications.
appdynamics,Configuration as code allows us to keep our configuration close to the related codebase.
appdynamics,This makes it easy to find and edit but also allows people to easily view the configuration without having to log into third-party applications.
appdynamics,The config can also be checked into version control allowing it to change with the application and also have audit and collaboration tools.
appdynamics,If your company is SOX compliant this could be used as a control.
appdynamics,"What is AppDynamics
AppDynamics (AppD) is an Application Performance Monitoring (APM) tool."
appdynamics,It instruments your applications so you can see how the internals are working.
appdynamics,"This in includes database queries, HTTP requests and more."
appdynamics,"It provides you with various metrics such as latency, requests and errors to give you confidence things are working as expected."
appdynamics,Alerts can be set up to notify you when things are not working as expected for someone to intervene and fix.
appdynamics,One of AppDynamics key selling points is autoconfiguration.
appdynamics,"In reality, teams generally need to manually configure their applications, especially if it is a rest application with ids in the path."
appdynamics,To configure applications teams would have to use the UI provided by AppD and have to make this configuration in every environment.
appdynamics,Show me the code!
appdynamics,"To configure AppDyanmics using code, a Terraform AppDynamics provider has been made."
appdynamics,This can be found in the Terraform community registry and GitHub.
appdynamics,Below is an example Terraform file which configures a restful endpoint with transactions and sets up an alert.
appdynamics,The example makes use of the new provider syntax in version 0.13 allowing easy integration of community providers.
appdynamics,Documentation for the AppDynamics provider can be found here.
appdynamics,"That's a fair bit of code, lets break it down."
appdynamics,The first 27 lines are defining variables so we can reuse them later on.
appdynamics,Don‚Äôt worry all the values in this file are fake.
appdynamics,If you were running this in a pipeline the values for the variables would be passed in.
appdynamics,See the documentation for assigning variables for more information.
appdynamics,"The first main configuration block starts at line 29, this creates a transaction detection rule which tells AppDynamics how to group requests together."
appdynamics,"In this example, we are using regex to group the restful user endpoint together which ends with an id."
appdynamics,"By default, AppD would create a new transaction for each user id."
appdynamics,The next block starting at line 42 creates a health rule.
appdynamics,This rule checks all business transactions in an application and compares them to a baseline.
appdynamics,Health rules are used to define what is healthy for an application.
appdynamics,"An action is defined starting at line 56, when an action is triggered it performs something."
appdynamics,"In this case, it sends an email to a list of addresses."
appdynamics,Lastly starting at line 65 a policy is defined.
appdynamics,This connects health rules and actions together.
appdynamics,When the health rule changes the action is triggered.
appdynamics,Notice how we can reference attributes from the health rule and action so if they change the policy is automatically updated.
appdynamics,"In this example, the policy is looking at all the health rules in the application and triggering the previously set up action."
appdynamics,Due to how the AppDynamics API works for an email action we have to use the list of emails as the action name.
appdynamics,"Future Config
The terraform provider is currently limited to single metric health rules."
appdynamics,This is mainly to reduce the complexity of the initial release but also as having multiple metrics in one rule could be an anti-pattern.
appdynamics,Should they not be separate rules?
appdynamics,There are some resources which have not been implemented yet such as Scopes and Action Suppression.
appdynamics,These can still be created in the UI until they are included in a future release.
appdynamics,If you do need a feature which is missing in the provider please raise an issue on GitHub or vote if one already exists.
appdynamics,"Issues with more users will be prioritised and as with all good open-source software, pull requests are welcome."
appdynamics,I hope this Terraform provider can help you keep your engineering practices intact by providing a config as code solution for AppDynamics.
appdynamics,Please feel free to raise a GitHub issue if you have any issues or suggestions.
appdynamics,I passed the Certified Kubernetes Application Developer Exam in June 2020.
appdynamics,These notes summarize what you should expect if you‚Äôre preparing for the CKAD exam.
appdynamics,"Preparation
CKAD is a hands-on performance-based exam."
appdynamics,"As a result, lots of practice to build enough muscle memory over an extended period is an absolute requirement."
appdynamics,Beware of the ‚Äúcurse of knowledge‚Äù.
appdynamics,"Whilst your mileage may differ if you are already familiar with Kubernetes and perhaps you work with it every day, be cautious of the ‚Äúcourse of knowledge‚Äù."
appdynamics,"Your prior knowledge, if not properly channelled can trip you."
appdynamics,I know folks who know Kubernetes more than I do but failed the exam.
appdynamics,You need muscle memory to help you gain speed and accuracy.
appdynamics,"These are the materials that I used:
1."
appdynamics,"Kubernetes Certified Application Developer (CKAD) with Tests ‚Äî Fantastic Udemy course, especially if you‚Äôre new to Kubernetes."
appdynamics,I would recommend that you start with this course.
appdynamics,2.
appdynamics,"CKAD Exercises ‚Äî I got bored of watching Udemy videos mid-way into the course, this is not a reflection on the quality of the content, it‚Äôs due to my personality and the way I learn."
appdynamics,I like to get stuck in.
appdynamics,I wanted to dig deeper the moment I felt comfortable with the general concept; my quest led me to CKDA Exercises.
appdynamics,"I went over the whole exercises (the number of times is withheld so you can do it at your pace) until I could answer ALL the questions without looking at the answers or making reference to the documentation, except for the persistent volume and network policy questions."
appdynamics,I was also lucky enough to able to contribute to the CKAD Exercises repo.
appdynamics,"‚ÄòCKAD Exercises‚Äô is not enough though, seriously!"
appdynamics,"CKAD Exercises
Most blog posts that I read before the exam gave me the impression that being able to answer all the questions in CKAD Exercises is an indication that one is ready for the exam."
appdynamics,"Whilst this assertion may be true for older versions of the exam, I found it not to be true in my experience with version 1.18."
appdynamics,"The exercises provide a good foundation, but the actual exam questions are a lot harder and are not as straightforward."
appdynamics,"I felt the need for more time-bound practices so I went back to the KodeKloud course via Udemy but this time, I focused ONLY on the mock exams and the lightning labs."
appdynamics,You may skip the ReplicaSets and Ingress Controller questions as it‚Äôs not relevant to the exam (anymore).
appdynamics,Stick to the curriculum.
appdynamics,3.
appdynamics,"CKAD Simulator ‚Äî My preparation took a bit longer because the exams were upgraded from Kubernetes 1.16 to 1.18 when I was almost ready to sit for it, I had to add about 3 more weeks to practice on 1.18 to unlearn the deprecated commands and to learn the new 1.18 imperative commands."
appdynamics,"The contents on killer.sh simulator is excellent, especially with the new scoring system."
appdynamics,The exam environment and layout is kind of similar to the actual exam.
appdynamics,Aim to score ‚â• 60% and pay close attention to the network policy question ‚Äî note the difference in the way ports are defined as an OR or an AND operator.
appdynamics,4.
appdynamics,Linux Academy ‚Äî My crusade for more practice led me to the Linux Academy CKAD course.
appdynamics,"At first, I was disappointed as the test environment is in version 1.13 (at the time of writing this note), the tutor solved most of the questions by writing YAML too; don‚Äôt do this in the exam, use imperative commands wherever possible."
appdynamics,"Having said that and without going into too much detail (for obvious reasons), I attribute my success to the ‚Äòquality‚Äô of Linux academy‚Äôs CKAD practice questions."
appdynamics,Take all the CKAD practice questions in Linux academy very seriously.
appdynamics,"Take all the CKAD practice questions in Linux academy very seriously
I didn‚Äôt go through any of the video tutorials on Linux Academy, but what I can say is focus on each session‚Äôs practice questions about 2‚Äì3 days before the exam."
appdynamics,5.
appdynamics,Kubernetes.io docs ‚Äî Go through the task session of the docs.
appdynamics,"Exam Tips
Kubernetes.io search: I got a bit frustrated by typing long words like ‚Äúpersistentvolume claim‚Äù or ‚Äúnetworkpolicy‚Äù into the search box, so one day I thought I‚Äôd try the kubectl shortcodes instead."
appdynamics,Guess what?
appdynamics,It worked!
appdynamics,"So instead of typing ‚Äúpersistentvolume claim‚Äù or ‚Äúnetwork policy‚Äù into the docs, I simply typed in pvc, netpol, pv, etc and I got the same result set."
appdynamics,Do all you possibly can to save time.
appdynamics,VIM: Get comfortable with VIM text editor.
appdynamics,Please refer to the ‚ÄúCKAD browser terminal‚Äù guide.
appdynamics,"Use AutoComplete: Autocomplete is enabled for you in the exam, but it will not work if you have the k=kubectl alias set."
appdynamics,One of the first things I did in the exam was to add complete -F __start_kubectl k command to ~/.bashrc.
appdynamics,"I memorized the command, but you don‚Äôt have to as you can copy it from the docs."
appdynamics,Autocomplete is an absolute time-saver.
appdynamics,"For example, if I need to quickly delete a pod called webone, I‚Äôd type: k del<tab-key> po we<tab-key> --for<tab-key> --gr<tab-key> 0."
appdynamics,"This translates to k delete po webone --force ‚Äî-grace-period 0
Persistent Volumes: Practice this Persistent Volume question thoroughly."
appdynamics,"I will, however, recommend that you practice this on a cluster with 2 or more worker nodes for the following reasons: i) SSH into any of the nodes and create the said file ii) You need to sudo -i to be able to create files in some directories such /etc/, /opt/ etc."
appdynamics,"iii) Type exit to return to the master node iv) Ensure that the nginx pod is scheduled on the intended node by using either nodeName (this is faster), nodeSelector or nodeAffinity."
appdynamics,"Always return: You‚Äôd need to use sudo -i to be able to create or edit files in certain directories, remember to type exit when done."
appdynamics,Always remember to return to the master node.
appdynamics,"Use ~/.bashrc: Due to 4 and 5 above, do not simply type your aliases in the terminal, use ~/.bashrc for all your aliases so you don‚Äôt have to do it all over again when you return to the master node."
appdynamics,"My ~/.bashrc aliases in the exam look like this:
alias k=kubectl
alias kns=‚Äôk config set-context --current --namespace  ‚Äô
alias kgc='k get po -l x=y'                                   complete -F __start_kubectl k
dr='--dry-run=client -o yaml'
Don‚Äôt forget to reload your terminal by typing source ~/.bashrc
I bet you‚Äôre familiar with all of the above aliases, except you‚Äôre questioning why I‚Äôd need to do alias kgc=‚Äôk get po -l x=y‚Äô instead of kgc=‚Äòk config get-contexts‚Äô?"
appdynamics,Your answer is in tip #7.
appdynamics,"My ~/.vimrc settings look like this:
set tabstop=2
set expandtab 
set shiftwidth=2 # very usefuly for indentation
7."
appdynamics,"Less is more: Except it‚Äôs a one-liner solution, I did not use -n <namespace> in any questions in the exam because I sometimes forget to add -n. I used kns <namespace> to be absolutely sure."
appdynamics,"k get po -l x=y on the other hand, returns a decluttered name of the namespace to me."
appdynamics,"For example:
~ $ k get po -l x=y
No resources found in israelo namespace."
appdynamics,"Now, go ahead and type k config get-contexts , the result is a lot if all you‚Äôre interested in is just the name of your current namespace."
appdynamics,"k config get-contexts
8."
appdynamics,"Namespaces: When you switch to a new cluster, notice that the namespace doesn‚Äôt change automatically to the default namespace."
appdynamics,This is so important.
appdynamics,So be sure to return to the default namespace if the question doesn't specify a namespace.
appdynamics,kns default then kgc for your own peace of mind.
appdynamics,9.
appdynamics,"Deployment Strategy: There is no mention of deployment strategy in any of the practice resources I mentioned above, including CKAD Exercises."
appdynamics,Learn the two types of deployment strategies ‚Äî Recreate and Rolling update.
appdynamics,Know how to change maxUnavailable and maxSurge values.
appdynamics,"Practice how to avoid downtime by combining rolling update with readinesssProbe and livenessProbe
10."
appdynamics,"Immutable objects: Pods are immutable objects so before you delete a pod, remember to take a backup (k get po webone -o yaml > 1.pod.yaml)."
appdynamics,This also applies to any YAML file that you‚Äôre asked to modify.
appdynamics,Take a backup before you edit it.
appdynamics,"In summary, there‚Äôs no such thing as over-preparation in my opinion, the exam is hard, no doubt."
appdynamics,Use practice environments that can vet and score your performance under time pressure ‚Äî good examples are killer.sh and KodeKloud.
appdynamics,I attempted 17 out of the 19 questions and I scored 82%.
appdynamics,Good luck and stay hungry.
appdynamics,"Hello, DevOps Engineers,
In this blog would like to explain about AppDynamics installation over Linux environment."
appdynamics,AppDynamics is one of the monitoring tools.
appdynamics,it is managing performance and availability of applications across the environments.
appdynamics,It is not an open-source tool to download and use.
appdynamics,AppDynamics for Applications and Databases can monitor three categories of collectors.
appdynamics,There are several collector types within these categories.
appdynamics,"The following lists the supported databases, servers, and storage systems now supported:
1."
appdynamics,"Database Collector: DB2, Greenplum, MongoDB, Microsoft SQL Server, Microsoft SQL Azure Database, MySQL, Oracle, PostgreSQL, Sybase ASE, and Sybase IQ Server
2."
appdynamics,"Collector: IBM AIX Server, Linux Server, Solaris Server, and Windows Server Storage
3."
appdynamics,"Collector: NetApp, Java (JVM‚Äôs) and NetApp E-Series
Before I go and explain the pre-requisites, would like to explain one important point."
appdynamics,Need to understand the below two aspects and it will be easy to install.
appdynamics,Appdynamics Controller is the central management server.
appdynamics,"All Data is stored and analyzed and the controller provides a browser-based UI for monitoring application, servers, database, and troubleshooting performance."
appdynamics,AppDynamics has it‚Äôs own MySQL database to store the data while installing the controller it will automatically install the database.
appdynamics,"But for Other database monitoring required to install DB agent (will cover in my another blog how to install and configure DB agent)
AppDynamics Agents connect to the Controller to report data."
appdynamics,Here are the Pre-Requisites all the supported OS and hardware requirements for AppDynamics.
appdynamics,"Download Appdynamics Controller:
Once you open the link in the left-hand side can see all the checkboxes and search box."
appdynamics,"- Now you can see only Linux Controller for download,

Note: Registration is required for download but it will not ask for any credit card details and other stuff."
appdynamics,"Installation Steps:
Transfer the AppDynamics file into a Linux machine where you want to install."
appdynamics,"Step:2 Run the below command AppDynamics required few dependencies to install
Step:3 Controller file is a shell script.Command to run ./controller_xxxx_xxx.sh
Step:4 Script is in an interactive mode just follow the instruction."
appdynamics,"Required to enter
- Ports as per your server ports availability
- Controller UI username and password."
appdynamics,"Step:5 Once successfully installed at the end it will give you the URL details for AppDynamics UI and it will exist the controller.sh script
Note: Licence.lic file has to place in the controller folder in the server, otherwise, it will not allow to login to UI
For the Screenshots of installation, Refer the below link."
appdynamics,"Summary
The impact of APM is heavily measured by the depth of understanding it generates across IT environments."
appdynamics,"However, it also delivers other valuable benefits."
appdynamics,There‚Äôs no question digital transformation is fueling demand for application performance management (APM).
appdynamics,"Cloud adoption, rapid change, and the deployment of new technologies are the cornerstones of the transition, as is a shift in focus to applications, developers, and ultimately improving the customer experience."
appdynamics,But how does that translate to business success?
appdynamics,"As Managing Director at Devcon in South Africa, I think we have a real-world view of what APM can deliver."
appdynamics,It‚Äôs in part our privilege to work at the cutting edge of innovation.
appdynamics,South Africa has been identified as one of the world‚Äôs top 10 countries for digital innovation according to research by Vanson Bourne to compile Dell‚Äôs Digital Transformation Index.
appdynamics,"And as a partner of AppDynamics since its inception, we‚Äôve seen firsthand the powerful impact of APM‚Äôs ‚Äúinvisible‚Äù influences."
appdynamics,"While the perspective that follows is the product of our experience delivering services domestically, our learnings translate globally and are indicative of benefits being felt by smart businesses in every imaginable industry, right across the world."
appdynamics,"APM: Delivering Unexpected Value
The impact of APM is heavily measured by the depth of understanding it generates across IT environments."
appdynamics,"However, it also delivers other valuable benefits."
appdynamics,"We stress to our customers that, in implementing APM, they should not overlook its role as a strategic tool ‚Äî in helping to build a high-performance organization and foster a culture for better business success."
appdynamics,Here are six ways I believe APM will empower your organization to make a progressive cultural shift.
appdynamics,1.
appdynamics,"Leverage your very own truth serum
For the first time, APM enables you to prove what‚Äôs going on in your environment."
appdynamics,"No conjecture, no guesswork, just simple facts."
appdynamics,"And when teams and stakeholders are dealing in facts, better decisions are made faster ‚Äî whether that‚Äôs identifying where service issues exist, determining which systems need attention, or even determining where to modernize first."
appdynamics,"Furthermore, when people trust in information, decision-making becomes less convoluted and teams feel better able to push boundaries and break new ground."
appdynamics,"Obtaining the facts is only possible using a single end-to-end toolset like AppDynamics, however."
appdynamics,2.
appdynamics,"Joined-up thinking reduces risk
We recently saw a customer lose a significant contract because their end service was not performing against the service levels they had committed to."
appdynamics,"After several penalties, the contract was eventually terminated."
appdynamics,"Following some exploration into their systems with the help of the AppDynamics toolset, it was clear the committed service levels were far too ambitious."
appdynamics,"However, a disconnect between IT and the business (in this case sales) had led to a situation where a group had made a commitment on behalf of the company that carried serious business implications, without any evidence to suggest it was either achievable or commercially prudent."
appdynamics,"This is a sobering example of how, if used sooner, APM could have helped the company manage risk differently."
appdynamics,"Importantly, it would have revealed their performance norms, potentially enabling them to negotiate different contract terms, to make changes to improve their offering, or even to take a different view on the opportunity altogether."
appdynamics,3.
appdynamics,"Bring IT and business teams closer together
APM generates piercing insight into infrastructure and service experience."
appdynamics,"As I mentioned, this helps information flow but also supports greater collaboration and cultivates trust between teams when it is valued, rather than feared."
appdynamics,"Responsibility for the success or failure of a customer experience should not reside solely with IT ‚Äî but should span development, IT operations, and business teams."
appdynamics,"Thanks to tools like Business iQ, code-level monitoring can be turned into immediate, clear, and actionable insights, by correlating application performance with the user experience and business outcomes."
appdynamics,This helps to cut through traditional silos and better enable cross-functional collaboration and a feeling of shared responsibility for the solution from the start.
appdynamics,4.
appdynamics,"Have the confidence to move faster
‚ÄúInnovation‚Äù is the watchword for all businesses today."
appdynamics,"How can offerings be enhanced, or new opportunities captured?"
appdynamics,It‚Äôs the reason why DevOps is going mainstream ‚Äî organizations want the freedom to release software updates faster and create custom apps built-for-purpose.
appdynamics,"The test and development process of debugging code and getting apps production-ready takes time, and is often seen as a dark art."
appdynamics,"Using APM, apps can be tested and fixed the moment issues are pinpointed, rather than hypothesized."
appdynamics,"In turn, this builds greater quality into the development process, reduces debugging overheads, increases release velocity, and liberates resources for yet further innovation."
appdynamics,"In the world of DevOps, Continuous Delivery is the endgame."
appdynamics,APM gets you there faster.
appdynamics,5.
appdynamics,"Make smarter digital plans
According to McKinsey, digital leaders spend more time on planning the future and a strategy to achieve it."
appdynamics,"However, planning is only as good as the information inputs that guide it."
appdynamics,"Without knowing which systems aren‚Äôt performing, which services are challenged, and the impact they have on customer experience, how can any realistic plans be made?"
appdynamics,"The feedback from APM helps illuminate app deficiencies, differences between on-premises and public cloud performance, and whether workloads would be better supported on alternative infrastructure ‚Äî all of which are vital ingredients to good digital planning."
appdynamics,Transformation is risky and has the potential to become protracted.
appdynamics,APM stacks the odds in your favor and provides the insight to ensure digital transformation occurs in the fewest possible steps.
appdynamics,6.
appdynamics,"Proactively manage customer experience (even when it could be better)
Your customer could be just one bad experience away from leaving you, so it‚Äôs important to keep ahead of them and properly understand the quality of service they are receiving."
appdynamics,"Additionally, APM helps you understand when things aren‚Äôt right and provides you with the opportunity to engage the customer sooner."
appdynamics,Engagement is one of the best ways to run interference and get in front of any complaints that might come up.
appdynamics,APM buys you the time to do this before things get critical.
appdynamics,I can say from experience that it‚Äôs an exciting time to be working with companies on their digital transformation.
appdynamics,"Notably, in South Africa, the adoption of artificial intelligence (AI), Big Data, and robotic process automation (RPA) is strong, but like in every economy, there are early adopters, laggards, and innovators."
appdynamics,Success depends on ambition matched with good plans and great execution.
appdynamics,"It, therefore, stands to reason that APM is playing a critical role in helping businesses in South Africa and beyond to assemble next-generation IT architectures ‚Äî and to make sense of the complex ecosystems emerging around us to continually support business outcomes."
appdynamics,"A post AppDynamics Implementer Foundations Workshop reflection
AppDynamic logo over a blurred Application Dashboard background
AppDynamic logo over a blurred Application Dashboard background
Introduction
I recently attended the 5-day AppDynamics Implementer Foundations Workshop in Auckland, New Zealand."
appdynamics,"This course covered on-premise deployment of AppDynamics version 4.5.x and we got an opportunity to do multiple hands-on lab sessions along the way, and get a feel of the product."
appdynamics,This article intends to be a reflection of what I learned and some key concepts that stood out for me.
appdynamics,Disclaimer: All views are a personal reflection only.
appdynamics,Some information may differ should you compare it with their Software-as-a-Service (SaaS) offering or any other version of the product.
appdynamics,What is AppDynamics?
appdynamics,AppDynamics is an Application Performance Monitoring (APM) solution offering you real-time view of your application and business health.
appdynamics,"In a nutshell, as David Wadhwani, CEO of AppDynamics shared in a keynote speech, ‚ÄúAppDynamics helps you move fast without breaking things, helps you follow things in an increasingly distributed environment, and lets you focus your teams on what really drives your business.‚Äù
Gartner‚Äôs Magic Quadrant 2019 report for APM puts AppDynamics as a market leader."
appdynamics,"Gartner defines APM suites as one or more software components that facilitate application monitoring to meet three main functional dimensions: Digital experience monitoring (DEM), Application discovery, tracing and diagnostics (ADTD), and Artificial intelligence for IT operations (AIOps)."
appdynamics,"Application Flow Map view from AppDynamics
Application Flow Map view from AppDynamics
Their core Application Performance Monitoring (APM) solution does not just give visibility into an organisation‚Äôs IT ecosystem in the form of a neat Application Flow Map, but it also gives visibility into the lines of code that might be causing the system or service to run slow."
appdynamics,"With the right Database Agent installed, you can even see the if any database queries are resulting in a performance impact."
appdynamics,"With Infrastructure Visibility, you get insights into the server‚Äôs performance like CPU and memory usage, disk I/O, plus visibility of issues in the network, if any."
appdynamics,End User Monitoring focuses on the customer experience.
appdynamics,How do the users use the application?
appdynamics,What browsers do most users use?
appdynamics,What are the top 5 countries that generate traffic to the website?
appdynamics,"If the mobile app crashes, do we know what device, the user was using?"
appdynamics,AppDynamics provides all of that and more!
appdynamics,"AppDynamics offers Browser RUM, Mobile RUM, Synthetic monitoring and even IoT monitoring."
appdynamics,"Finally, Business iQ is an offering to translate metrics collected into insights."
appdynamics,It correlates application performance to business outcomes.
appdynamics,"For instance, if the application performance view tells you that the checkout services of an e-commerce site are running awfully slow, you could correlate that with the business view to see the affect this slowness is having on the sales."
appdynamics,"AppDynamics on-premise platform architecture
Let‚Äôs quickly take a look at AppDynamics‚Äô on-premise platform architecture before we look at the 13 concepts that caught my attention."
appdynamics,"AppDynamics on-premise platform architecture
Courtesy of AppDynamics."
appdynamics,"For more downloadable PDFs, click here."
appdynamics,"Enterprise Console
Enterprise Console is the first thing you would install as part of your AppDynamics implementation."
appdynamics,Enterprise Console offers a UI through which you can install the Controller and Events Service.
appdynamics,"Controller
All agents deployed will collect data and send it to the controller."
appdynamics,The Controller offers a UI through which you can view and analyse the data.
appdynamics,"Agents
In an AppDynamics deployment, Agents are the elements that are deployed across all the components in your environment that monitor and collect data and send it across to the controller."
appdynamics,"Because there could be a variety of components in your environment, you‚Äôll find different agents for them."
appdynamics,"For example, you would install a Java Agent to monitor a Java application."
appdynamics,"Events Service
Events Service is the data storage facility for the high-volume, performance-intensive unstructured data generated by Application Analytics, Database Visibility, and End User Monitoring."
appdynamics,Events Service can be deployed as a single node or as a cluster with three or more nodes which can always be horizontally scaled.
appdynamics,"End User Monitoring (EUM) server
EUM collects data from web browsers, mobile apps, and IoT devices, thus allowing you to get insights from the actual user experience."
appdynamics,"In an on-premise set up, you would need to install the EUM server and Events Service in addition to the Controller and EUM agents, to process and store the data being collected."
appdynamics,What caught my attention?
appdynamics,Here are 13 concepts that intrigued me during this course.
appdynamics,"1) SaaS v/s on-premise offering
At the beginning of this article, I mentioned that this workshop was about an on-premise AppDynamics installation."
appdynamics,"So, let‚Äôs first understand what are the major differences between the SaaS and on-premise offering, and why you might choose one over the other."
appdynamics,"If you choose to go with the on-premise option, you would need to use your own hardware and be responsible for it‚Äôs maintenance."
appdynamics,"Whereas, with the SaaS option, everything is managed for you."
appdynamics,"With the on-premise option, a good amount of time will be spent in capacity planning as each component of the AppDynamics platform has it‚Äôs own hardware requirements."
appdynamics,"On the contrary, going with the SaaS option eliminates quite a bit of that effort."
appdynamics,You would need to plan and implement software upgrades yourselves in an on-premise setup.
appdynamics,"With SaaS, you automatically get all the upgrades."
appdynamics,"With the on-premise option, you would have to be responsible for scaling and performance."
appdynamics,Whereas the SaaS architecture ensures that it can scale for even trillions of metrics per day.
appdynamics,"If there are strict data storage policies to keep the data in-house, then the on-premise offering would be more suitable as you would host all the data yourselves."
appdynamics,"With the move towards AIOps, AppDynamics releases new features to deliver the grand vision of the Central Nervous System."
appdynamics,One such SaaS-only feature is a machine learning based Cognition Engine for automatic anomaly detection to identify the root cause of issues down to the line of code and offers meaningful alerting reducing alert fatigue.
appdynamics,AppDynamics also introduced Serverless APM for AWS Lambda to monitor and manage Lambda functions which is also only available in their SaaS offering.
appdynamics,"Basically, if you‚Äôre after these newer features then you‚Äôd have to choose SaaS."
appdynamics,"2) Common settings across Agent installation
Over the 5 days, we ended up installing different types of Agents (among other things, of course) ‚Äî Java Agent, .NET Agent, Machine Agent with Analytics plugin, and the Database Monitoring Agent."
appdynamics,I noted that there were a few settings that had the exact same values across all Agents ‚Äî and this made sense since all the Agents need to communicate with the Controller to post data to it and get the latest configuration.
appdynamics,"The settings were:
Account name: Since this is a single tenant set up in a demo environment, we set this to ‚Äòcustomer1‚Äô but in a real-world scenario, you‚Äôd name this after your client."
appdynamics,Access key: This can be obtained from the License page.
appdynamics,You would want to restrict how you distribute the access key ‚Äî more about this in the ‚ÄòLicense rules‚Äô section below.
appdynamics,"Controller host: Since we had a load balancer in front of our controllers (similar to the diagram above), we needed to enter the load balancer‚Äôs internal fully qualified domain name (FQDN)."
appdynamics,Controller port: The default port number for a Controller is 8090.
appdynamics,A full list of port settings can be found here.
appdynamics,"3) Difference between Java and .NET Agent
Let‚Äôs start with the obvious one ‚Äî the .NET Agent is used to monitor .NET applications while the Java Agent is used to monitor a Java application."
appdynamics,"You only require one .NET agent per Windows Server even if you want to monitor multiple applications, whereas, you require one Java Agent per Java Virtual Machine (JVM)."
appdynamics,"The .NET Agent comes with a .NET machine agent (which is different from a standalone Machine Agent), while the Java Agent doesn‚Äôt come packaged with anything else."
appdynamics,The .NET Agent requires Windows Coordinator Service while a Java Agent doesn‚Äôt depend on any additional service.
appdynamics,The .NET Agent is GUI based (for IIS applications) while the Java Agent is command line based.
appdynamics,"4) License rules
While working with multiple teams to implement AppDynamics, you might find yourself giving out the same access key to many."
appdynamics,All the teams may not require to consume all types of license units.
appdynamics,"For example, the server team would only need to install a Machine Agent but may not require to consume a language specific Agent."
appdynamics,"To restrict the use of license units, AppDynamics provides you with License rules."
appdynamics,You can create a rule and allocate n number of license units across all the available types for that team.
appdynamics,"Add license rule dialog box
Add license rule dialog box
After creating the rule, you will see it in the list along with its own access key."
appdynamics,You can now distribute this access key to the team instead of giving the default one.
appdynamics,"List of license rules
List of license rules
5) Controller Administration Console
To configure Controller‚Äôs global settings such as metric retention periods, UI notification triggers, tenancy mode, and accounts in multi-tenancy mode, you would need to access the Controller‚Äôs Administration Console."
appdynamics,The URL is http://<Your Controller URL:port number>/controller/admin.jsp.
appdynamics,"Ensure you logout of the Controller UI, if you‚Äôre logged in as an account user, before trying to log in to the Administration Console."
appdynamics,Note: It is not recommended to change anything in here except if instructed in the documentation provided or if guided by an AppDynamics representative.
appdynamics,"6) Controller availability
In a high availability (HA) scenario, it is recommended that the traffic to the Controller be directed at the reverse proxy/load balancer rather than directly at the controller."
appdynamics,"So, should the primary Controller go down, the load balancer can direct all Agent communication to the secondary Controller instead."
appdynamics,"The proxy can monitor the status of the Controller using this address http://<Your Controller URL:port number>/rest/serverstatus which returns an HTTP 503 Service Unavailable response to GET requests, and an XML response with <available>false</available> for a passive/down node."
appdynamics,"Example of the XML returned from the Controller‚Äôs monitor endpoint
Example of the XML returned from the Controller‚Äôs monitor endpoint
Note: HA is only available if you‚Äôre Controller‚Äôs are set up on Linux machines."
appdynamics,The secondary controller must have a HA licence.
appdynamics,"For a complete list of prerequisites, refer to this article."
appdynamics,"7) Enterprise Console and Controller downtime
If the Enterprise Console experiences a downtime, the Controller will not be impacted."
appdynamics,"However, if the primary Controller (in a high availability scenario) and Enterprise Console is down at the same time, it wouldn‚Äôt auto failover to the secondary Controller because, by default, in the 4.5.x release the ‚ÄòEnable auto failover‚Äô is auto enabled (as pictured below) in the Enterprise Console ‚Äî which means it is the Enterprise Console‚Äôs responsibility to monitor the Controller‚Äôs and initiate an auto failover when necessary."
appdynamics,"By default, in the 4.5.x release the Enable auto failover is auto enabled
By default, in the 4.5.x release the Enable auto failover is auto enabled
The solution to that is the new HA Module that installs the Controller watchdog on the Controller hosts making the Controller hosts now responsible for performing a failover."
appdynamics,The HA module is packaged with the Enterprise Console but just isn‚Äôt enabled by default ‚Äî although it can be activated anytime as per this article.
appdynamics,The HA Module activation will be automated in future Enterprise Console releases.
appdynamics,"While we‚Äôre on the topic, it is also worth noting how the Agent behaves when a Controller is down."
appdynamics,"If the Controller is unreachable for one minute, the Agents goes on standby during which it doesn‚Äôt detect any transactions."
appdynamics,All metrics not posted to the Controller is stored in the memory.
appdynamics,It keeps retrying every minute and resumes function once reconnected.
appdynamics,"If this persists for more than three minutes and after three retries, the Agent is muted, all business transactions are disabled, and all metrics prior to three minutes are deleted."
appdynamics,"And after five minutes, the license is freed for another Agent to use."
appdynamics,"8) Authentication provider fallback to local login
By default, AppDynamics is the authentication provider ‚Äî which means local users and groups that you‚Äôd need to configure."
appdynamics,You can also configure an LDAP or SAML provider to handle your authentication needs so AppDynamics can only manage the authorization aspect.
appdynamics,"In case the LDAP or SAML authentication provider is down, AppDynamics will automatically switch to local user logins for authentication seamlessly."
appdynamics,"As part of the implementation, it is therefore advised to create few local users with the appropriate roles even though you‚Äôre configuring LDAP/SAML‚Äî just as a contingency plan."
appdynamics,"9) AppDynamics Query Language (ADQL)
AppDynamics provides their query language to be able to query data available in Application Analytics."
appdynamics,"For example, I‚Äôve written a simple ADQL query below:
SELECT transactionName, userExperience, responseTime FROM transactions WHERE responseTime > 200
This gives me all the business transactions with a response time greater than 200ms along with the User Experience (UX)."
appdynamics,The UX is calculated by AppDyanmics by comparing the response time with the baseline it has maintained.
appdynamics,"Image of ADQL query results
You can use ADQL to visualize this data as a graph in a widget, and then add this widget to your dashboard."
appdynamics,"For a full ADQL reference, refer to this page."
appdynamics,"10) Browser Real-User Monitoring JavaScript injection
Browser Real-User Monitoring (Browser RUM) allows you to see how your web application is performing from the point of view of a real end user."
appdynamics,"For this to work, you‚Äôd have to inject the JavaScript Agent into your website, and you have 5 ways to achieve this:
Manual injection: You would need to copy the JavaScript from the Controller UI and paste it into the HTML directly after the <head> tag."
appdynamics,Automatic injection: This method relies on the server-side app agent injecting the JavaScript at runtime.
appdynamics,"You would, however, need to specify the business transactions that you‚Äôd like automatic injection enabled."
appdynamics,Only the Java Agent and .NET Agent supports this.
appdynamics,Assisted injection using rules (Java only): You tell AppDynamics which Java classes and methods write to the output stream of your application and AppDynamics will intercept those methods and injects the JavaScript Agent into the output stream.
appdynamics,Assisted injection using attribute: You copy two variables JS_HEADER and JS_FOOTER into your page templates.
appdynamics,The App Agent then replaces these variables with the required code to load the JavaScript Agent on your website.
appdynamics,Container-based injection: You can use directives to inject the JavaScript Agent into the response of your website if you‚Äôre using Nginx or Apache as a web container or reverse proxy.
appdynamics,Further details on how the JavaScript Agent works and detailed can be found here.
appdynamics,"11) Upgrading the platform components
On day 4, we upgraded all the components that we had installed."
appdynamics,"The high-level steps was to: 1) back up everything‚Äî common convention is to back up all the components before backing up the Controller and finally the Enterprise Console, and 2) upgrade the components ‚Äî order is Enterprise Console, Events Service, EUM Server, and finally the Controller."
appdynamics,"We also upgraded all the Agents we had installed ‚Äî Java Agent, .NET Agent, Machine Agent with Analytics plugin, and Database Monitoring Agent."
appdynamics,Note: Upgrading an Agent may require an outage as we need to restart the application.
appdynamics,"Overall, I found that the process would require a lot of planning (in a real-life scenario) even before you can get to actually upgrading."
appdynamics,"Depending on what components you‚Äôre upgrading, this may involve quite a bit of manual effort."
appdynamics,"12) Email templates
Email notifications can make use of email templates should a health rule get violated."
appdynamics,Email templates can be customized using variables ‚Äî predefined and custom ‚Äî so the same email template with different values can be sent to the recipients based on the trigger.
appdynamics,Templates use Velocity to process these variables and add the correct value in the right places.
appdynamics,"Sample email template below:
...
Email notification for ""${latestEvent.application.name}"" application on the ""${policy.name}"" event notification."
appdynamics,...
appdynamics,Please see this article ${potentialResolutionSteps} from the KB for next steps.
appdynamics,"...
From the email above, ${latestEvent.application.name} and ${policy.name} are predefined variables which relate to the application name set in AppDynamics and the health rule policy respectively."
appdynamics,"On the other hand, ${potentialResolutionSteps} is a custom variable which can be set while configuring the email notification."
appdynamics,"Assuming we set the value of our custom variable to https://shopztream.confluence.com/wiki/actions/slow-checkout-process for the policy ‚ÄúSlow checkout process‚Äù of the ‚ÄúShopZtream‚Äù application, this is what the final email message would look like in the recipients mailbox:
...
Email notification for ""ShopZtream"" application on the ""Slow checkout process"" event notification."
appdynamics,...
appdynamics,Please see this article https://shopztream.confluence.com/wiki/actions/slow-checkout-process from the KB for next steps.
appdynamics,"...
13) Extensions
Extensions, as the name suggests, extend the functionality of AppDynamics so it can be used with an even larger set of technologies."
appdynamics,You either build your own Extension or use one that‚Äôs available on the AppDynamics Exchange site.
appdynamics,"Note, if the Extension is AppDynamics supported then you can open a support case with the AppDynamics support team, but if it‚Äôs Author supported then you can‚Äôt."
appdynamics,"Image of a couple of AppDynamics Extensions
Where to get started?"
appdynamics,Give AppDynamics a try with a 15-day free trial.
appdynamics,A hands-on experience is always the best way to learn.
appdynamics,"During this trial, you may want to refer to their technical documentation site to read the detailed steps on how to set up each component."
appdynamics,"If you have any questions along the way, feel free to post a question on their community-driven site."
appdynamics,"If you‚Äôre interested in attending the Implementer Foundations Workshop, check out this page to know when you may be able to attend next."
appdynamics,"Summary
Alright, time for a quick recap ‚Äî
We started off with an introduction to AppDynamics and what the core APM offerings are."
appdynamics,We quickly followed that with the on-premise platform architecture and a quick summary of each component.
appdynamics,"To some degree of detail, we then looked at 13 concepts that caught my attention."
appdynamics,"Finally, we noted what the next steps would be like if you‚Äôd like to get started with AppDynamics."
appdynamics,That‚Äôs it!
datadog,"Photo by Viviana Rishe on Unsplash
One of the reasons why we‚Äôve been putting performance on the back burner was that we didn‚Äôt trust our measurements."
datadog,"The variability of the score was high, we used different tools to measure performance and kept comparing apples to oranges."
datadog,And most importantly we have attributed all the negative impact to the third party scripts and gave up on checking our own code.
datadog,"This post is a part of the series: read more about the performance problem Homegate was facing in the first post of this series: Optimizing for Core Web Vitals at Homegate: things we learned along the way
We needed a new way to monitor performance that would allow us to:
Measure performance automatically
Measure frequently (and look at the average values)
Measure in a uniform way
Measure with reduced variability
Measure both complete pages and pages with no third-party scripts
Make measuring require as little setup for the new projects as possible
Make historical data accessible (so that we can correlate performance drops with our own releases as well as the changes in third-party code)
Lighthouse scores as DataDog metrics
Since Lighthouse is available as an NPM package, it‚Äôs quite easy to run it on a given URL as a scheduled job."
datadog,"Wiring it together
With Homegate‚Äôs setup the easiest way to do so was a scheduled GitLab job run in a Docker container containing Chrome."
datadog,The results of the Lighthouse run can be reported as HTML (similar to what we see in Chrome Dev Tools UI) and JSON.
datadog,We save the former as a GitLab job artifact (in case we would like to review it) and parse the latter to send the audit scores we want to monitor to the DataDog as custom metrics.
datadog,"What we monitor
Beyond performance score and individual performance metrics, we also monitor:
accessibility, SEO, PWA and best practices scores
the amount of the downloaded javascript in Kb
server response time in ms
With or without third-party scripts?"
datadog,"Since we were interested in the impact of the third party scripts on our overall performance score, we wanted to run Lighthouse twice for one page ‚Äî once with all the scripts and once without the third party ones."
datadog,Luckily it is possible to block certain domains during the Lighthouse run Lighthouse by specifying the patterns in the the custom config (see https://github.com/GoogleChrome/lighthouse/blob/master/docs/configuration.md for reference).
datadog,Setting up a job that checks a bunch of URLs on a regular basis is really easy now.
datadog,For each new project we want to monitor we add a JSON config to the repository.
datadog,"Things to specify ‚Äî a URL to test, a DataDog metric namespace and a custom Lighthouse config (if needed)."
datadog,Get the full source code for the lighthouse-datadog GitLab job here.
datadog,"Setting up the dashboard
To display our newly sent metrics we used DataDog‚Äôs Query Value widgets that are able to:
display the last value from the given timeframe
apply conditional formatting
Conditional formatting is useful to display data similarly to how Lighthouse does (green-orange-red values)."
datadog,This way we can see at a glance where we stand.
datadog,"Lighthouse scores for one of our pages: with and without third-party scripts
Each metric can be viewed plotted over time if we expand the corresponding widget:

For the total performance score we've added the widget displaying a trend line:

The unexpected benefits
The dashboard was intended to provide quality insights to our engineers."
datadog,"What we didn‚Äôt expect is for it to become a communication tool for many different parties:
Product managers and data analysts were able to see the impact of the scripts they injected
Engineers were able to use the dashboard to illustrate the necessity of prioritizing performance improvements over the new features."
datadog,A little legend with the links to related Google documentation helped all of us learn more about the Lighthouse and its metrics.
datadog,This is the third post of the ‚ÄúOptimizing for Core Web Vitals at Homegate‚Äù series.
datadog,"For the full story be sure to check other posts:
Optimizing for Core Web Vitals at Homegate: things we learned along the way
A story of how we dropped our page speed to absolute low and what we learned from it
Understanding web performance metrics and tools
Lighthouse?"
datadog,PageSpeed Insights?
datadog,Core Web Vitals report?
datadog,Which tool to use and how to decide which performance improvements will have the biggest impact.
datadog,"Monitoring page speed continuously with Lighthouse, DataDog and GitLab (this post)
Improving page speed of the isomorphic Vue.js application
Exploring various lazy-loading tactics that work for isomorphic Vue.js applications."
datadog,You too can use Datadog to monitor your applications!
datadog,The following is my step-by-step experience following the Datadog documentation on how to set up an AWS integration.
datadog,"I recommend reading their docs for the latest up-to-date information, but thought it was worthwhile to share my successful installation!"
datadog,"First I navigated to https://app.datadoghq.com/

The Datadog Quick Start
Next, I hovered over Integrations on the left and selected ‚ÄúIntegrations‚Äù."
datadog,"The Integrations option is on the left
Then I hovered over the AWS Integration that I had installed when originally setting up the account and clicked ‚ÄúConfigure‚Äù."
datadog,"Select the Amazon Web Services Integration
I then selected the blue ‚ÄúAdd another account‚Äù button."
datadog,"(For context, I had installed this integration during account setup but ended up removing the account."
datadog,"So for this step, the integration was installed but no account was configured)."
datadog,"Add another account from this view
I then selected the blue ‚ÄúAutomatically Using CloudFormation‚Äù button."
datadog,"This presents an option to install with CloudFormation
This took me to the AWS Console and loaded the Datadog Cloudformation stack."
datadog,Be sure to change the region if you want to deploy the stack in a different region.
datadog,Simply picking a different region presented the same ‚ÄúQuick create stack‚Äù page.
datadog,"Creating the Stack requires you to input the API Key
To get the DdApiKey, I went back to the Datadog page and selected the ‚ÄúDatadog API key‚Äù link that now appeared in the New Account window."
datadog,"I went back to this page to figure out where my API Key could be found
This took me to my API Keys page, where I copied the API key behind the purple box."
datadog,"Copy your API Key over to the CloudFormation stack
I copied the API key over into the CloudFormation stack parameters and pasted it in the DdAPIKey field."
datadog,"I then scrolled to the bottom, checked the checkboxes, and selected ‚ÄúCreate stack‚Äù."
datadog,"Accept the terms (only if you want to) and create the Stack
Cloudformation began to spin up the stack and I could see the CREATE_IN_PROGRESS Status for the ‚Äúdatadog‚Äù Stack."
datadog,"CloudFormation is hard at work
When the Stack completed, I saw that the one CloudFormation template created 3 nested templates."
datadog,"Not 1, not 2, but 3 Nested CFN templates!"
datadog,"I then selected the datadog-DatadogIntegrationRoleStack-* Stack and, under the Resources tab, identified that the integration IAM role was named DatadogIntegrationRole ."
datadog,"Here‚Äôs the Integration Role Stack
I then went back to the AWS Integration page and updated my AWS Account ID and the role name, as specified."
datadog,"As soon as I finished typing, Datadog tried to access my account via the Assumed Role."
datadog,"Unfortunately, I ran into a small error where Datadog could not assume the role."
datadog,"Uh Oh, something might be wrong with the IAM Role
Datadog is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::00123456789:role/DatadogIntegrationRole."
datadog,"See https://docs.datadoghq.com/integrations/amazon_web_services/
Not to fear, this error appears in the Datadog FAQ docs: Error: Datadog is not authorized to perform sts:AssumeRole

Following the steps, I just updated the AWS External ID value and gave it some time."
datadog,Note: Be sure to give it enough time!
datadog,I reached out for support but came back to this an hour later and the connection was working.
datadog,"I was sure to evaluate the integration role and verify that the Account and Condition were correct
Hooray!"
datadog,Datadog is now connecting to the AWS Account.
datadog,Nice!
datadog,"Datadog is pulling data from your account
The next step was to move over the ‚ÄúCollect Logs‚Äù tab and add the arn of a Lambda in my account I wanted to monitor."
datadog,"Add a Lambda that you‚Äôd like to monitor via Datadog
I entered the Lambda‚Äôs arn, and also selected some general services below via checkbox."
datadog,"I also checked some other general services for experimentation
I then went back to the Dashboard tab on the left (above the integration tab) and viewed the dashboard lists."
datadog,"Wow, Datadog has so many turnkey dashboards
Finally, I scrolled down and selected ‚ÄúAWS Lambda‚Äù and could see the data for my Lambda!"
datadog,"Nice, my Lambda metrics look good!"
datadog,"Overall, a really nice experience with helpful documentation."
datadog,"Next, I‚Äôll probably create some custom dashboard views for my applications."
datadog,"If you have a question, feel free to leave a comment, and be sure to check out the Datadog Documentation!"
datadog,"Adobe Experience Manager aka AEM is a popular Content Management System (CMS) that allows builders, developers to create websites, user interfaces and experiences for a variety of devices."
datadog,AEM platform has and is rated as the beat & a leader in Content Management systems by major analyst firms.
datadog,AEM adoption numbers show it‚Äôs popularity.
datadog,"While the focus of this article is not about AEM‚Äôs greatness, but to make it performant, identify (if any) leaks, slowness, breaches, downtimes and such."
datadog,"Unless we know what the problem(s) is(are), teams will not be able to fix them."
datadog,As a popular quote goes ‚ÄúYou cannot shoot what you don‚Äôt know you‚Äôre aiming for‚Äù.
datadog,And we will use Datadog to do the analysis & reporting job for us.
datadog,"TL;DR
This article is about analyzing Adobe Experience Manger (AEM) with visualization of the data like dashboard, reports, charts using a tool called Datadog which collects information from AEM‚Äôs logs, action calls and other details."
datadog,"Before we begin
Assumptions
This article is for readers with some working knowledge on AEM."
datadog,Please check here for more details on what is AEM.
datadog,"Focus of this article
This article is about integrating AEM with Datadog and how to access the various reports from within Datadog."
datadog,We will not discuss about the functionalities AEM and Datadog in detail.
datadog,"Organization of this article
The content of this article in three parts."
datadog,"(1)What are AEM and Datadog and Why do we need them; (2) How to install, configure Datadog and integrate it with AEM; (3) Finally How to access and view the reports."
datadog,"Now that the stage is set, let‚Äôs dive in to the abyss."
datadog,"Part 1 ‚Äî The What
Caution: A lot of theory
What is AEM?"
datadog,"To put is simple, Adobe Experience Manager is a platform (more than a tool) that lets enterprises build websites and manage digital assets."
datadog,More.
datadog,What is Datadog?
datadog,"Datadog is a SaaS tool that monitors servers and software applications generating metrics, analysis and various reports."
datadog,More.
datadog,Why do we need analytics on AEM?
datadog,"While AEM is a popular, comprehensive and a robust platform offering a lot of features, it does not include tools that track, analyze and report on the platform itself."
datadog,It does have a few reports but not extensive.
datadog,The focus of Adobe on AEM has been more on enabling teams to develop varied customer experiences.
datadog,"Having said that, AEM et better with more features and capabilities with it‚Äôs annual releases/updates."
datadog,Why Datadog?
datadog,"Monitoring a platform like AEM is very crucial , teams have several options to monitor AEM."
datadog,Datadog comes in the same category but is beyond any of the tools comparable.
datadog,"The options, in-depth analysis, reporting makes it unique in the market space."
datadog,Datadog does a real good job at this.
datadog,"In the next section we will see how to install, configure Datadog and integrate it with AEM."
datadog,"Part 2 ‚Äî How
Caution: This gets very technical
Step 1: Installing Datadog
Login to your Datadog account to see instructions on how to install."
datadog,"Screenshot of Datadog Installation Instructions
Step 2: Configuration
You will see something like this if Datadog is running successful yon your machine

Screenshot of Datadog Agent Manager Running Successfully
Step 3: Running AEM
AEM can be setup to be run as a service (servers) or we can run it from a command (developers machines) like below:
$ java -jar cq-quickstart-version-p4502.jar

Adobe Experience Manager Home Page
Step 4: Integrating AEM with Datadog
Following the instructions from Datadog‚Äôs documentation site
Enable logs in datadog.yml file under /opt/datadog-agent/etc/datadog.yaml file."
datadog,"vi /opt/datadog-agent/etc/datadog.yaml
Find and change from ""# logs_enbaled: false"" to ""logs_enabled: true""
Create
$ cd /opt/datadog-agent/etc/conf.d
$ mkdir adobe.experience.manager.d
$ cd adobe.experience.manager.d
$ vi conf.yaml
<add the below lines>
logs:
  - type: file
    path: /Users/Software/aem65/author/crx-quickstart/logs/*.log
    service: aem
    source: adobe.experience.manager
Restart datadog-agent
Get the status of the Agent 
$ launchctl list com.datadoghq.agent 
Stop the agent
$ datadog-agent stop
Start the agent
$ datadog-agent start
That‚Äôs it."
datadog,We are done setting up Datadog and AEM.
datadog,In the next section we will see how to access the analytics and read them.
datadog,"Part 3 ‚Äî Reading the Analysis/Reports
Caution: Get your eye/reading glasses, we will be reading between numbers
Now that we have AEM and Datadog running, to access the analytics and reports, we have to do the following:
Open a browser and go to this url http://127.0.0.1:5002 and under Status, scroll down the page until you see adobe.experience.manager under Logs Agent

Login to Datadog portal
There‚Äôs so many reports you can view here."
datadog,"Below are some of them
Logs > Live Tail

Sample report of Logs > Live Tail
Logs > Analytics > Log Explorer

Sample report of Logs > Analytics > Log Explorer
Logs > Patterns (this is a great feature)

Sample report of Logs > Patterns
Dashboard (of my local mac)

There are several other reports and metrics Datadog console has like Dashboards, Monitors, Metrics, and several others."
datadog,Also all the above are happy paths without any exceptions or errors or warnings because we are tracking AEM from my local machine.
datadog,"If we are tracking from real servers these make a lot of sense to system administrators, architects, developers and a lot of stakeholders (if they can read between the lines)."
datadog,These are invaluable and save a lot of time when managing and debugging AEM running on production servers.
datadog,This bring us to the end of the core content.
datadog,What‚Äôs next?
datadog,"There is so much that can be done on AEM, the numerous report on Datadog."
datadog,"Both platforms will not stop continuously innovating coming up with new features, options, simplifying things."
datadog,"This innovation and enablement helps businesses a lot with value creation and keeps us builders, developers, architects, system administrators busy learning the new tricks."
datadog,"Keep learning, ALWAYS!"
datadog,!
datadog,"At Kin, we are building open source tools to help developers quickly onboard and build great applications on top of the Kin Blockchain."
datadog,"We understand that running infrastructure and services on top of the blockchain can be a pain and, sometimes, destructive for innovation."
datadog,This is why we provide our partners and Kin Developer Program participants a managed service that we run with ensured SLA.
datadog,Running a software as a service (SAAS) requires an extensive monitoring plan.
datadog,"We chose Datadog as our monitoring platform, and use it to collect metrics, display graphs, and alert us on different events."
datadog,"As a simplified overview, our backend stack is divided into four layers:
Blockchain Core: Performs consensus, pulls in blocks, mints blocks
Blockchain API: Gives developers a simple API on top of Blockchain Core
Payment Service: Manages incoming and outgoing payments using the Blockchain API
Marketplace Service: Manages users and wallets, and powers the earn/ spend/peer-to-peer flows using the Payment Service
Each of these services requires a unique set of monitoring schemes, of which, I‚Äôll give a few examples."
datadog,"Blockchain Core
Loss of consensus: Track when a core is out of sync."
datadog,When a core falls too far behind we might want to replace it.
datadog,"Loss of consensus
Quorum size: The number of nodes participating in the consensus."
datadog,We must have five out of seven.
datadog,"Quorum size
Blockchain API
As its implemented in go, we can monitor number of goroutines."
datadog,"Goroutines
Number of developer connections: Number of ecosystem apps connected to the API."
datadog,"Client connections
Rate of 5xx errors: As a REST server, we can follow 5xx errors."
datadog,"5xx errors
Payment Service
Queue size and number of idle vs busy workers: Our payment service provides an asynchronous API using a queue on its backend."
datadog,We monitor the size of the queue and the number of available workers.
datadog,"Queue size
Time to submit a transaction: Monitor the time it takes to submit a transaction to the blockchain."
datadog,"Transaction acceptance time
Number of concurrent transactions: We can view the load we‚Äôre creating on the blockchain using this metric."
datadog,"Concurrent transactions
We also monitor the amount of Kin left in each server wallet and the rate of Kin being paid to users for this service."
datadog,"Marketplace service
Request Latency: The marketplace service is used directly by our SDK, which is used by ecosystem applications, and it is hit by real users."
datadog,We must make sure we provide a fast experience.
datadog,"Request Latency
Time of earn/spend complete flow: Our SDK provides simple earn and spend flows."
datadog,We monitor the completion of the entire flow of earn and spend.
datadog,"Earn/ Spend completion
Other than these custom metrics, we also collect dry metrics such as %CPU, memory, and disk space."
datadog,"Tagged Metrics
We use metric reporting similar to Datadog, which allows us to tag metrics and filter them later on."
datadog,"Some of the tags we use are:
app_id: As we provide services to multiple partners we want to be able to view the SLA and performance per application."
datadog,git_version: We use a blue/green deployment methodology.
datadog,Each service is ‚Äúcolored‚Äù with the git_version of the code.
datadog,"When we deploy a new version, we can make sure there are no regressions in our services by comparing the metrics of each version."
datadog,"git_version tag filter
The following is the latency of the payment-service across deployments of different versions:

Latency across git versions
Failure Reporting and Debugging
We strive to provide a 100 percent failure free experience to Kin apps, but sometimes failures do occur."
datadog,"When we detect a failure, it is shipped as an event to Datadog where we can be alerted and find the reason for the failure."
datadog,"To debug such failures and run post-mortems, we ship all our logs to Datadog‚Äôs centralized logging service."
datadog,"We trace all our logs with a unique request_id, letting us follow the entire flow of the request across services."
datadog,"Introduction
Datadog is a powerful platform for measuring ElasticSearch."
datadog,Recently our team met some issues when we upgrade our ElasticSearch.
datadog,"With Datadog, we can easily monitor memory, query time and garbage collection."
datadog,Today I try to install that.
datadog,"Unfortunately, it is only free for 14 days‚Ä¶.."
datadog,"Installing Datadog on Ubuntu
Use our easy one-step install."
datadog,"DD_API_KEY=b96a25a6cf77c77f2ad1292480011aeb bash -c ""$(curl -L https://raw.githubusercontent.com/DataDog/datadog-agent/master/cmd/agent/install_script.sh)""
reference: https://app.datadoghq.com/signup/agent#ubuntu
Notice: if you met the problem, it would be proxy issue in apt-get
Datadog Configuration
The configuration files and folders for the Agent are located in:
/etc/datadog-agent/datadog.yaml
Configuration files for Integrations:
/etc/datadog-agent/conf.d/
Configure the Agent (conf.yaml + datadog.yaml)
create conf.yaml
Firstly, we just clone the sample file (conf.yaml.example) to our target file (conf.yaml)
cd /etc/datadog-agent/conf.d/elastic.d
sudo cp conf.yaml.example conf.yaml
Configure conf.yaml
in /etc/datadog-agent/conf.d/elastic.d/conf.yam
we set the url, stats, tags and logs."
datadog,"Configure datadog.yaml
/etc/datadog-agent/datadog.yaml
edit api_key, proxyand logs

Launch the datadog-agent
sudo service datadog-agent start
check the status
sudo datadog-agent status

NOTICE: each time you edit the files, please stop and start again
sudo service datadog-agent stop
sudo service datadog-agent start
sudo service datadog-agent restart
Here are more commands:
https://docs.datadoghq.com/agent/basic_agent_usage/?tab=chefcookbook
Check the result in datadog
Go to dashboard
https://app.datadoghq.com/dashboard/lists
and click Elasticsearch ‚Äî Metrics
then you will see"
datadog,1.
datadog,"Platform Engineering to Kubernetes
The following story will show how it is possible to create a 100% automated software delivery using CircleCI to deploy into Kubernetes step by step, from Development to Staging and from Staging to Production using crafted tools."
datadog,"Infrastructure
I have a Kubernetes Cluster 1.8 launched via Kops in AWS."
datadog,"If you need to understand how to create a cluster, then go to its official Github page https://github.com/kubernetes/kops which is really well documented."
datadog,2.
datadog,"Kubernetes Operations Tool
Defining the right branch strategy
Defining the right branch strategy is key for success in the long-term when too many features and engineers are involved in the development process."
datadog,"By adopting a DevOps mindset when working with the platform, engineers needs to find the accurate balance between developing a new feature, fixing the application and delivering software faster as possible to production frictionless and timeless."
datadog,Our scenario is going to work based on Release from trunk so we merge continuously to master and master is delivered through the deployment pipeline until production.
datadog,"Development will happen in short-lived feature branches which last as max a few days then it will be merged into master branch to be delivered via automation to the environments, manual tasks must not be allowed."
datadog,Teams who uses release from trunk have a high release cadence.
datadog,"Lets define what a release cadence is:
One of the things that a delivery team needs to do, often in collaboration with product management, is choose the release cadence of their product."
datadog,‚Ä¶ Your release cadence defines how often you release your solution both internally and externally into production (or the marketplace).
datadog,3.
datadog,"Release from trunk
The more low release cadence teams would need to use a more Trunk-based development approach in order to support every release properly since they will last more time in production and will need to be stable / frictionless and timeless consuming for engineers."
datadog,4.
datadog,"Trunk based development
Who else support this idea?"
datadog,Microsoft does it in its VSTS internal development via what they call The Release Flow.
datadog,Google does Trunk Based Development.
datadog,"I would say that it is the only way to run away from the merge hell where we spent hours trying to move code between environments and it is not a surprise, it will probably fail in the next environment, maybe because the merge was too big, maybe there were too many conflicts to solve, etc."
datadog,"Use trunk as a single source of truth and keep it stable, deliver it, tag it."
datadog,"I have seen too many teams doing anything with master branch, that simply does not make any sense to merge something we cannot probe it works."
datadog,Git-Flow or Trunk Based Development?
datadog,"Both strategies are really well accepted in the industry, these are the standards nowadays."
datadog,As engineers we will probably fall in one of the two options.
datadog,This is true and it should be a well thought decision.
datadog,"Gitflow
Gitflow work with the following branches:
Develop
Master
Feature
Hotfix
Release
Every iteration the development team will create branches from develop and integrate into it via pull requests."
datadog,"Once develop is ready to release, a release branch is created from it."
datadog,When release branch is ready to production it is merged to master branch.
datadog,Several merges are involved in order to move forward.
datadog,"When to use:
When you are working on an open source projects."
datadog,When the team has several junior members.
datadog,"When do not use:
When running an startup project it will produce a speed decrease in development team."
datadog,When you want to attach to DevOps and trust on automation.
datadog,When the team members are seniors.
datadog,"Trunk Based Development
The branches involved in this strategy are:
Master
Short-lived feature branches
Engineers will work on a short-lived feature branch taken from master for a small period of time then release it."
datadog,The release cadence tends to be really high since the team is going quickly into production and they trust in automated workflows to move faster.
datadog,"When to use:
When adapting DevOps mindset."
datadog,When the team is adapting automation.
datadog,When the team have senior members.
datadog,When it is an startup project.
datadog,"When do not use:
When the team is not senior."
datadog,When it is a large open source project.
datadog,So think before adapting the right strategy.
datadog,"After all, it is all about learning by doing, learning by measuring our processes, gaining feedback from the team, we can change it to improve the workflow as needed."
datadog,There is not always a unique way of doing things.
datadog,Every team and project is different.
datadog,"Choosing the right tools for the job
Now that a branching strategy model is chosen it is time to think what is needed and easy to perform our job."
datadog,"I will describe below the reason I choose the following tools:
Helm Package Manager: It is the Kubernetes package manager."
datadog,So it means we can convert a bunch on YML files used to deploy to Kubernetes in a package.
datadog,"Better yet, we can deploy every package as a single unit, so it gets abstraction, so it means we can deploy everything the same way."
datadog,I found HELM really powerfull and one of the best tools to deploy into K8S.
datadog,"Imagine dozens of microservices all deployed the same way no matter the technology, it makes really easy to automate things."
datadog,4.
datadog,"Helm
CircleCI: A container based platform that allows to use ephemeral Docker containers to deploy our environments and die after completing the job."
datadog,"We use our own Docker images fully connected to the environments with the right tooling inside it, so every container has everything I need to accomplish my deployment."
datadog,"CircleCI is really fast technology, and since Circle 2.0, it allows custom workflows so engineers can choose the right path to go live."
datadog,5.
datadog,"CircleCI
Quay: Quay is a platform that builds and save docker images in a Registry."
datadog,So far it does not do a good job at building images but it does on security.
datadog,Every built image is fully analyzed in search of vulnerabilities which are always displayed nicely.
datadog,6.
datadog,"Quay
Datadog: This is a metrics backend like Graphite/Grafana which is really impressive and really easy to use."
datadog,"I use Datadog to measure infrastructure metrics like CPU/Memory utilization, custom business metrics and pipelines metrics."
datadog,So the deployment tooling sends its deployment metrics to Datadog in order to count deployments/failures/timing via HTTP protocol (it can be via UDP protocol as well).
datadog,"Preparing the API to CI/CD
The first step is to configure our service to be deployed via CircleCI."
datadog,In order to do this we need to add a folder .circleci/config.yml which uses CircleCI workflows.
datadog,6.
datadog,"API Project

7."
datadog,"CircleCI Workflow
We can see that the workflow steps are:
Build & Run tests
Request to CircleCI an instance of docker daemon to build an image and upload it into Quay.io hashed (which will store this in the registry and perform the security analysis)."
datadog,Perform the deployment in development environment without approval via Helm Package Manager.
datadog,Send the approvals for QA nd Production environments which must be manually approved by the release manager or whoever is in charge.
datadog,Deployments to QA/Prod are automatically triggered once approved.
datadog,We can see in the YML definition from CircleCI the usage of Global commands.
datadog,As I mentioned before we use pre-built docker images with tools installed inside globally.
datadog,In this case they are a bunch of bash scripts versioned to keep an historial of changes made and support retro-compatibility in case something was wrong with new versions of the tools.
datadog,"I have a docker image per environment with the following inside:
Custom bash scripting for build and upload images to Quay."
datadog,Custom bash scripting for deploying to Kubernetes.
datadog,All necesary set of credentials for connecting the cluster in AWS are injected by CircleCI secrets when it runs the deployment containers.
datadog,"Lets see how the docker image is built below:

8."
datadog,"Dockerfile CircleCI Custom
The Build Tool
The following bash script will do the following:
Receive a bunch of environment variables with desired configuration."
datadog,Send metrics to datadog backend via HTTP protocol.
datadog,Login into Quay.
datadog,Request the Docker Daemon to CircleCI.
datadog,"(I strongly suggest to avoid having Quay building images, it fail too often without reason.)"
datadog,Push the Docker Image to Quay and run vulnerabilities check.
datadog,9.
datadog,"Build Tool
Below we can appreciate the vulnerability check in the images pushed."
datadog,10.
datadog,"Vulnerability Report
The Release Tool
The following Bash script will be executed after the docker image is pushed and the deployment is ready to be performed."
datadog,"This script is going to do the following:
Receive a bunch of configuration via environment variables."
datadog,Send metrics to Datadog via HTTP.
datadog,Initialize Helm.
datadog,Setup out private Helm repo in AWS.
datadog,Download the Helm values.yaml files from S3 (I prefer to keep deployment configuration isolated from Developer code).
datadog,Figure out if it needs to install / upgrade the application.
datadog,Install / Upgrade via Helm.
datadog,11.
datadog,"Release Tool
Platform Metrics
DevOps mindset trust strongly on automation."
datadog,The best known way to understand whats going on in our automated workflows is to measuring metrics.
datadog,"This is a change enabler, it is our eyes."
datadog,We cannot improve anything which is not measured.
datadog,It is just working blind.
datadog,"I send metrics during my pipelines execution in order to understand what is being deployed, how often deployments happen, how much time consumes doing it."
datadog,After some time by looking at the metrics you will be surprised on how much time was saved thanks to automation.
datadog,"There outside exists too many time-series backend metrics that can be used as Datadog, in the image below to display them graphically."
datadog,12.
datadog,"Metrics

13."
datadog,"Kubernetes Logs
CircleCI offers a 2.0 feature named Insights which provides some beautiful information too."
datadog,14.
datadog,"CircleCI Insights
Ending Words
This is a really full crafted CI/CD workflow with an interesting toolset (at least to me)."
datadog,There are too many fancy options around we can use.
datadog,The next generation CD tool for deploying Kubernetes is Spinakker which provides a bunch of features to improve automation and change significantly the concept of zero-downtime deployment via customizable strategies like Blue-Green/Canary/Black-Deployments that I will post later.
datadog,15.
datadog,"CircleCI Ending Workflow
Crafted CI/CD Tools Repo & API Repo below:
hmarcelodn/helm-tool
Bash Tools."
datadog,Contribute to hmarcelodn/helm-tool development by creating an account on GitHub.
datadog,"github.com

hmarcelodn/ts-sample
CircleCI / Helm."
datadog,Contribute to hmarcelodn/ts-sample development by creating an account on GitHub.
datadog,"github.com

I spent a lot of time preparing this full cycle, so if you liked, clap me."
datadog,Thanks for reading.
datadog,TL;DR OpenCensus provides a one-way proxy between your app sources and monitoring solution sinks.
datadog,OpenCensus Importers provide the return path.
datadog,"My days are a happy union of walking my new puppy, writing code, eating & sleeping."
datadog,This leaves less time for blogging.
datadog,I‚Äôm still short on the Medium asymmetry of taking my stories but not giving much back.
datadog,"Until I decide whether to go elsewhere, I‚Äôll write ‚Äî albeit less frequently ‚Äî here."
datadog,One of my interests is in Google‚Äôs open-sourced OpenCensus project.
datadog,I think I‚Äôm interested in monitoring solutions because I like to measure ‚Äòthings‚Äô.
datadog,Using a solution like OpenCensus enables things that produce data (your apps) to do so in a monitoring agnostic way.
datadog,"Write your monitoring code once and be confident that, when DevOps wants to monitor it, they‚Äôll be able to do so using their preferred monitoring system; Prometheus, Datadog, Stackdriver (AWS|Google), AWS‚Äô and Azure‚Äôs homegrown solutions are all supported and more are being added."
datadog,Google‚Äôs Trillian project supports Prometheus.
datadog,"In attempting to write (needs updating: link) an OpenCensus solution for Trillian, I was unable to pass Trillian‚Äôs monitoring-specific tests."
datadog,"This is because, Trillian‚Äôs interface for monitoring assumes the ability to read measurements and OpenCensus Exporters (!)"
datadog,don‚Äôt permit reading values from the monitoring system.
datadog,"And, since OpenCensus is a pluggable solution that supports arbitrary Exporters, each of the services would require a solution for reading values too."
datadog,My use[ful|less](?)
datadog,solution is to consider the notion of OpenCensus Importers (sic.)
datadog,"and mirror the interface of Exporters to see whether it‚Äôs practical and useful to read values too:
https://github.com/DazWilkin/opencensus-testing
Working
OpenCensus covers stats|monitoring and tracing."
datadog,Everything hereafter relates to the stats|monitoring functionality only.
datadog,The OpenCensus nomenclature is precise and distinct.
datadog,"In summary, at least one exporter is registered, e.g."
datadog,Stackdriver.
datadog,Multiple measures are then defined.
datadog,These are either ints or floats.
datadog,Each Measure may be associated with one of more Views.
datadog,Views represent the data that is sent to the exporters.
datadog,"Here‚Äôs the snapshot of that code from my test:
sd, err := stackdriver.NewExporter(stackdriver.Options{
  MetricPrefix: ""test2"",
})
if err != nil {
  glog.Fatal(err)
}

defer sd.Flush()
view.RegisterExporter(sd)
view.SetReportingPeriod(60 * time.Second)
prefix := ""181221""
separator := ""_""
name := ""counter0""
prefixedName := prefix + separator + name
measure := stats.Float64(prefixedName, ""Testing"", ""1"")
...
v := &view.View{
  Name:        prefixedName,
  Measure:     measure,
  Description: ""Testing"",
  Aggregation: view.Sum(),
  TagKeys:     tagKeys,
 }
if err := view.Register(v); err != nil {
  glog.Fatal(err)
}
In the test case (code) below, I‚Äôm using a float64 measure called counter0."
datadog,And a view with the same name (though I should probably have given this a different name for clarity).
datadog,The view aggregates measurements made using the measure by summing the values.
datadog,"To make a measurement using the measure:
stats.Record(ctx, measure.M(val))
NB Just like trees falling in the forest, measurements aren‚Äôt heard (are discarded) if there are no views that represent and export them."
datadog,"Here‚Äôs the Importer code that reads values from the above ‚Äòmetric‚Äô back:
sdIn, err := importer_stackdriver.NewImporter(stackdriver.Options{
  MetricPrefix: ""test2"",
 })
importer_view.RegisterImporter(sdIn)
iv := &view.View{
  Name:       prefixedName,
  LabelNames: labelNames,
}
if err := view.Register(iv); err != nil {
  glog.Fatal(err)
}
NB The Importer uses Views not Measures because Exporter Views are the interface to the monitoring system."
datadog,"Hopefully, you can see the symmetry between the exporter|writer and importer|reader code."
datadog,"Here‚Äôs the test code:

Apologies on my package naming."
datadog,"The code expects:
export PROJECT=[[YOUR-PROJECT]]
export GOOGLE_APPLICATION_CREDENTIALS=[[YOUR-SERVICE-ACCOUNT-KEY]]
The PROJECT is associated with your Stackdriver workspace."
datadog,The service account must have either roles/monitoring.viewer and roles/monitoring.metricWriter or roles.monitoring.editor.
datadog,"You can debug in Visual Studio code with a configuration:
{
  ""name"": ""[[YOUR-PROJECT]]"",
  ""type"": ""go"",
  ""request"": ""launch"",
  ""mode"": ""auto"",
  ""program"": ""${fileDirname}"",
  ""env"": {
    ""GOOGLE_APPLICATION_CREDENTIALS"":""[[YOUR-SERVICE-ACCOUNT-KEY"",
    ""PROJECT"":""[[YOUR-PROJECT]]""
  },
  ""args"": []
}
By the way, a hidden gem is that you can run the tests within Visual Studio Code too but you need a way to specify the above in user or (preferably) workspace settings:
{
  ""go.testEnvVars"": {
    ""GOOGLE_APPLICATION_CREDENTIALS"":""[[YOUR-SERVICE-ACCOUNT-KEY]]"",
    ""PROJECT"":""[[YOUR-PROJECT]]""
  }
}
Conclusion
Here‚Äôs the results from a test."
datadog,The test creates an OpenCensus Measurement and View (Sum) using Stackdriver as an exporter.
datadog,The test runs for 10-minutes.
datadog,"Every 10 seconds, a random float64 is recorded."
datadog,"Every 30 seconds, Stackdriver is polled for the most-recent value."
datadog,"Because OpenCensus sums recorded measurements, the writer outputs the random value and the running total."
datadog,"This total is what can be compared with Stackdriver‚Äôs value:

You can see in the above that, there‚Äôs a small lag before Stackdriver begins reporting receipt of the measurements."
datadog,I‚Äôve edited the output to space the reads.
datadog,"For each read value, you can find where the write total hit it."
datadog,I‚Äôve added ‚Äú‚Üê‚Äù to help you identify the matches.
datadog,Here‚Äôs the timeseries pulled using Google APIs Explorer.
datadog,"You can see the read values repeated here:

Here‚Äôs the Stackdriver metric."
datadog,"I can‚Äôt explain how this chart represents the data shown above (will work on an explanation:

For now, I must go walk the puppy."
datadog,"Update: 2012‚Äì12‚Äì28
I added a Datadog Importer."
datadog,The implementations for both Stackdriver and Datadog and examples of each are described in more detail in the README on the GitHub repo.
datadog,Freddie
datadog,"As more and more teams within my company start to use our web stack, we need to quickly detect and react to errors."
datadog,Datadog is a great solution for monitoring the health of our servers but what good is a Datadog dashboard if you have to login to it on your computer?
datadog,We wanted them up all the time.
datadog,So we decided to install some TVs on the wall and show the stats.
datadog,Raspberry pi is a low power computer that can do the job.
datadog,Its 3rd generation has a processor and memory that is more than enough for running Chrome on full screen and point it to some web page.
datadog,"Some fire for the Christmas
Even though the title of this post is about Datadog stats but the solution mentioned here works for any web page."
datadog,In fact we put a full screen YouTube of a chimney creating that Christmassy vibe around this time.
datadog,"So here are the requirements:
The TV should always show the page
The URL for the page is put in plain text in a file called url.txt in the /boot folder of the Raspberry Pi microSD card (this partition is visible even on windows so it is easy to update)."
datadog,The reason for putting it on the boot partition is because this is the part of the microSD card that is editable when inserted to a Mac or Windows computer.
datadog,"Raspberry Pi should boot directly to Chrome
Chrome should open in full screen
Chrome should not require any user input, choices or user profiles
Buy the parts
Pi 3 B+ (Raspberry Pi 4 is an overkill for this application, besides it consumes too much power and is less environment friendly)
Adapter
Box
microSD (buy the fastest you can, this affects performance)
HDMI cable
Wireless keyboard with mouse control (optional)
Download Raspbian
You can download it for free on Raspberry Pi‚Äôs website."
datadog,Choose the version with desktop but without the recommended software.
datadog,"Write the disk
I use Etcher."
datadog,It works great on Linux and Mac (haven‚Äôt tried Windows).
datadog,I put the microSD card to my Linux computer that has a built-in SD card reader (the new Macbooks don‚Äôt have that port and you may need to use a memory card reader).
datadog,All the setup steps can be done either on Raspberry Pis graphical desktop or while the disk is mounted to your Linux machine.
datadog,"You can easily access both of the microSD card partitions at:
/media/boot/ for the boot partition where the url.txt and autostart.sh are supposed to be created
/media/rootfs/ for the wifi settings and autostart applications
Setup the Wifi
Boot the Raspberry Pi with the TV and set up the network graphically."
datadog,"Alternatively you can put the relevant information to the config file /etc/wpa_supplicant/wpa_supplicant.conf
Run chrome on startup and prevent sleep
Paste this to your /home/pi/.config/lxsession/LXDE-pi/autostart
@lxpanel --profile LXDE-pi
@pcmanfm --desktop --profile LXDE-pi
@xscreensaver -no-splash
@point-rpi
@xset s noblank
@xset s off
@xset -dpms
@sh /boot/autostart.sh
Set the autostart script
Make /boot/autostart.sh with this contents:
chromium-browser --incognito‚Ää‚Ää --start-fullscreen --start-maximized --disable-sync-preferences --disk-cache-dir=/tmp/cache --no-first-run `cat /boot/url.txt`
Update: a couple of months later I settled for this version which prevents google‚Äôs auto translate popup from showing up and doesn‚Äôt screw up when the file has more than one line:
chromium-browser --incognito‚Ää‚Ää --start-fullscreen --start-maximized --disable-sync-preferences --disk-cache-dir=/tmp/cache --no-first-run --app=`head -n 1 /boot/url.txt`
The whole command is in one line."
datadog,"It will:
Start chrome in incognito mode (so it will not nag about creating a user profile and goes directly to the site)
Starts the browser in full screen mode to maximize the usable area for showing the page
Uses a RAM disk for caching which improves the performance
Read the url from a plain text file called url.txt in the boot partition
Put the URL
Make a Datadog dashboard and create a publicly shareable link (so that the TV doesn‚Äôt have to authenticate every time it boots up):

Make /boot/url.txt with the url of the site you want to show:
https://p.datadoghq.com/sb/XXXXXXXXXXXXXXXXXX?tv_mode=true&theme=dark
If you want the plain old white theme, remove that &theme=dark part but in our experience the dark theme reduces the light pollution in the work environment for the screens that are on all-day-long."
datadog,"Tip for YouTube videos
Take the Video ID from the URL and create a URL that shows the video in full screen and loops it non-stop:
For example:
https://www.youtube.com/watch?v=kRXrqURyRy0
Becomes:
https://www.youtube.com/embed/kRXrqURyRy0?controls=0&autoplay=true
Auto update
Update: our Raspberry Pis ran without any issue for 13+ months."
datadog,But then I noticed that they are not automatically updated.
datadog,This can open up the security risk that your Raspberry Pis will be hacked and used to penetrated your internal network (we use an isolated network for IoT devices) or simply be used as a part of a botnet (from your company IPs).
datadog,Let‚Äôs avoid that by setting them up for auto update during night time.
datadog,"Install the unattended-upgrades package (you can learn more about that here):
sudo apt-get install unattended-upgrades
Then add the following configurations to /etc/apt/apt.conf.d/50unattended-upgrades:
// Split the upgrade into the smallest possible chunks so that
// they can be interrupted with SIGTERM."
datadog,"This makes the upgrade
// a bit slower but it has the benefit that shutdown while a upgrade
// is running is possible (with a small delay)
Unattended-Upgrade::MinimalSteps ""true"";
// Do automatic removal of new unused dependencies after the upgrade
// (equivalent to apt-get autoremove)
Unattended-Upgrade::Remove-Unused-Dependencies ""true"";
// Automatically reboot *WITHOUT CONFIRMATION*
//  if the file /var/run/reboot-required is found after the upgrade
Unattended-Upgrade::Automatic-Reboot ""true"";
// If automatic reboot is enabled and needed, reboot at the specific
// time instead of immediately
//  Default: ""now""
Unattended-Upgrade::Automatic-Reboot-Time ""04:00"";
And add the following configurations to /etc/apt/apt.conf.d/20auto-upgrades:
// Enables auto clean packages for X days."
datadog,"This configuration displays 7 days
APT::Periodic::AutocleanInterval ""7"";
// Enables upgrading the Raspbian distro every 30 days
APT::Periodic::Unattended-Upgrade ""30"";
The environment
Sweden produces 100% of its electricity from renewable sources."
datadog,However this doesn‚Äôt mean we have to generate unnecessary heat and degrade hardware.
datadog,"Since these TVs and Raspberry Pis are set up to be on 24/7, it can have a big environment cost."
datadog,"Also the electronics have a limited life time and by keeping them on all the time, they‚Äôll degrade faster and demand a replacement which costs money and nature‚Äôs resources."
datadog,Many TVs and monitors have an economy mode which they adjust the backlight to the light in the environment.
datadog,"When people leave the office and all lights are off, they consume less energy."
datadog,Also a good number of them have a setting for scheduling them to automatically turn off in the evening and turn on in the morning.
datadog,"Bonus
If you have a bunch of TVs (we have 8), you can prepare the disk once and clone it multiple times."
datadog,"To clone a microSD card, put it in your computer and detect its device name."
datadog,I‚Äôve written more about it on my FreeBSD installation on Raspberry Pi guide.
datadog,But the easiest way is to use the gnome-disks that is available on Gnome (like the one comes with Ubuntu).
datadog,"Then run this command to make an image file in your Downloads folder
sudo dd if=/dev/mmcblk0 of=~/Downloads/pi-image.img bs=1M status=progress
Then you can use Etcher to write that image to another microSD card (you don‚Äôt even have to format it)."
datadog,For past couple of weeks we observed an extraordinary increase in traffic on our website (graana.com).
datadog,We are using aws for our production environment but it was difficult to keep an eye on the metrics using htop or other command line tool we love.
datadog,So we decided to move to datadog which gave us excellent insights of our whole infrastructure.
datadog,"We found many difficulties in integrating elasticbeanstalk with datadog as other events can be handled with lambda and for EC2 instances we need to have datadog agent to be installed on each of the machine, but elasticbeanstalk behaviour is quite different, it replaces whole instance group after the deployment so we had to figure out a way to automate this with each deployment."
datadog,After putting efforts we found a way to achieve this.
datadog,"In root of .ebextensions, create a file named ‚Äú99datadog.config‚Äù
As we want realtime insights of each process too, create another file named: ‚Äúdatadog-process.config‚Äù
Repos to install data dog agent from."
datadog,"named: .ebextensions/datadog/datadog.repo
finally the start hook: ‚Äú.ebextensions/datadog/hooks/99start_datadog.sh‚Äù
and stop hook, ‚Äú.ebextensions/datadog/hooks/99stop_datadog.sh‚Äù"
datadog,"Hey everyone, so I recently made a Statistics Dashboard for my Discord Bot named PenguBot on Datadog using Discord.js and Hot-shots (Node.js Library for Datadog)."
datadog,"When I shared it, a lot of people showed interest in how they can do it themselves."
datadog,"So today I‚Äôll go step by step and tell you how to replicate my results which look something like this:

Okay so let‚Äôs get started!"
datadog,"Create a Free Account on Datadog by visiting https://datadoghq.com
Now install their Agent onto your VPS or VM by finding the appropriate instructions at https://app.datadoghq.com/account/settings#agent
Okay once you‚Äôve done that successfully let‚Äôs link Datadog with your Discord Bot."
datadog,"- To do this firstly install hot-shots by doing npm i hot-shots
- Now let‚Äôs setup hot-shots by adding the following code to your client file:
const { StatsD } = require(‚Äúhot-shots‚Äù);
client.on(‚Äúready‚Äù, client => {
client.dogstats = new StatsD(""localhost"", 8125)
});
Note: If you already have a custom client structure where you can define things inside your Client‚Äôs Constructor, just simply add the require statement at the top of the file and this.dogstats = new StatsD(""localhost"", 8125) inside the Constructor itself."
datadog,4.
datadog,Now we‚Äôll refer to yourbot as the main variable that we will use in our code for guildCreate and guildDelete events.
datadog,5.
datadog,Inside guildCreate and guildDelete add the corresponding code.
datadog,"// guildCreate
this.client.dogstats.increment(‚Äúyourbot.guildcreate‚Äù);
// guildDelete
this.client.dogstats.increment(‚Äúyourbot.guilddelete‚Äù);
Note: I will not be going over on adding those fancy graphs, if you want an in-depth tutorial for those, let me know."
datadog,Important: Those variables won‚Äôt show up in Datadog Dashboard if they‚Äôre not emitted at least once.
datadog,6.
datadog,"Now Login to Datadog and click on ‚ÄúDashboards‚Äù, create a new ‚ÄúTimeboard‚Äù and add a ‚ÄúQuery Value‚Äù for Guilds Added
Inside Metric put: yourbot.guildcreate."
datadog,Now change ‚ÄúTake the Average‚Äù below The Metric to ‚ÄúTake the Sum‚Äù.
datadog,"After that under ‚ÄúUnits and formatting‚Äù change Autoscale to Off and Decimal to 0
7."
datadog,Repeat the same by adding another ‚ÄúQuery Value‚Äù for Guilds Removed and follow the 6th step further down but just change the Metric to: yourbot.guilddelete and you‚Äôre done.
datadog,8.
datadog,"To add colors as I have, edit the query value and change ‚ÄúConditional Format‚Äù by removing everything and adding a new Rule which says if metric > 0 then make it green and so on and so forth."
datadog,It‚Äôs easy to figure out from there.
datadog,"If you have confusions or questions, hit me up on my Discord and ask me questions there."
datadog,"Thank you for reading, I‚Äôll keep updating and adding more information to this article but this is about it for now!"
datadog,"Setting up the environment (Mac OS X)
Run the command below in your terminal in order to install Datadog Agent on your system."
datadog,Replace {YOUR API KEY GOES HERE}with your API key.
datadog,"DD_API_KEY={YOUR API KEY GOES HERE} bash -c ‚Äú$(curl -L https://raw.githubusercontent.com/DataDog/datadog-agent/master/cmd/agent/install_mac_os.sh)""

Installing Datadog Agent on Mac OS X
Click here for more details."
datadog,"Collecting Metrics
Set up Datadog Agent and add tags to host
In order to assign tags to your Datadog Agent."
datadog,"follow the steps below:
Edit the file ~/.datadog-agent/datadog.yaml, and add the following to it."
datadog,"tags:
 ‚Äî role:database
 ‚Äî env:prod
After adding the lines above, your config file should look like this."
datadog,"~/.datadog-agent/datadog.yaml after edited
These lines add two tags to the Agent, role:database and env:prod."
datadog,2.
datadog,Restart the Agent.
datadog,3.
datadog,Navigate to https://app.datadoghq.com/infrastructure/map in order to see your host map.
datadog,"Click one of your hosts to see more details about, i.e., running services, tags, etc."
datadog,First host listed on the dashboard.
datadog,"How to install a Datadog integration (PostgreSQL)
Open your terminal and run the following command to install PostgreSQL."
datadog,"brew install postgresql
2."
datadog,"After installing postgres, run the following commands to create a read-only user for datadog in the database."
datadog,"create user datadog with password ‚ÄòZIIg1Upoe9x5KhLrhfRLjx66‚Äô;
grant SELECT ON pg_stat_database to datadog;
psql -h localhost -U datadog postgres -c ‚Äúselect * from pg_stat_database LIMIT(1);‚Äù && \
echo -e ‚Äú\e[0;32mPostgres connection ‚Äî OK\e[0m‚Äù || \
echo -e ‚Äú\e[0;31mCannot connect to Postgres\e[0m‚Äù
```
When prompted for a password, enter: ZIIg1Upoe9x5KhLrhfRLjx66 or any other password you have picked."
datadog,3.
datadog,Configure the Agent to connect to the PostgreSQL server.
datadog,Edit ~/.datadog-agent/conf.d/postgres.d/conf.yaml and add the lines below to it.
datadog,"init_config:
instances:
    ‚Äî host: localhost
      port: 5432
      username: datadog
      password: ZIIg1Upoe9x5KhLrhfRLjx66
      tags:
          ‚Äî postgresql
4."
datadog,Restart the Agent.
datadog,5.
datadog,Go to datadog settings and install the PostgreSQL integration.
datadog,Click the button install and follow instructions.
datadog,After you installed the integration you will have access to it on the dashboard.
datadog,Click here for more details.
datadog,How to create custom metrics: my_metric sends a metric with a random value between 0 and 1000.
datadog,You need to create a script file and a config file in order to create a custom metric and send it to datadog servers through the Agent.
datadog,1.
datadog,Create ~/.datadog-agent/checks.d/mymetric.py and add the following to the file.
datadog,"import random
from checks import AgentCheck
class RandomCheck(AgentCheck):
 def check(self, instance):
   self.gauge('my_metric', random.randint(0, 1000))
2."
datadog,Create ~/.datadog-agent/conf.d/mymetric.yaml and add the code below.
datadog,"init_config:
instances:
 [{}]
3."
datadog,Restart the Agent.
datadog,"On your Datadog dashboard, go to Metrics > Explorer, and search for your custom metric."
datadog,The Agent is going to run the collector in intervals of 15‚Äì20 seconds.
datadog,How to change your check‚Äôs collection interval so that it only submits the metric once every 45 seconds.
datadog,1.
datadog,Edit the config file ~/.datadog-agent/conf.d/mymetric.yaml and change the min_collection_interval globally to the interval you want the agent to collect data.
datadog,"init_config:
 min_collection_interval: 45
instances:
 [{}]
2."
datadog,Restart the Agent.
datadog,"The versions used here are DataDog Agent 6.4.2 and Kubernetes 1.10.3
In this article I‚Äôm going to show you how to deploy the DataDog agent to your Kubernetes cluster as a DaemonSet
First we need to make a Kubernetes Secret so that we dont have the API key in plaintext in our datadog-ds.yml."
datadog,Kubernetes secrets use the base64 encoded value.
datadog,"So lets get that
$ echo -n ""my_datadog_api_key"" | base64
( notice the -n flag passed to echo."
datadog,"If you leave that off, a trailing newline \n will be added and your secret wont work)
Now we setup our datadog-api-key-secret.yml (Do Not commit this to source control!!)"
datadog,"Add the secret to your cluster:
$ kubectl create -f datadog-api-key-secret.yml
If it was successful you‚Äôll see:
secret/datadog-api-key created
You can now delete datadog-api-key-secret.yml
$ rm datadog-api-key-secret.yml
Next we have to setup the RBAC ServiceAccount, ClusterRole and ClusterRoleBinding that datadog needs to function properly."
datadog,"were going to make 3 files here:
clusterrole.yml
serviceaccount.yml
clusterrolebinding.yml
First we make clusterrole.yml

Next, create the serviceaccount.yml

And finally the clusterrolebinding.yml

Now lets apply them to our cluster
$ kubectl create -f clusterrole.yml
$ kubectl create -f serviceaccount.yml
$ kubectl create -f clusterrolebinding.yml
Finally we make our datadog daemonset (datadog-ds.yml)

Finally, launch the daemonset into your cluster:
$ kubectl create -f datadog-ds.yml
Thats it!!"
datadog,Hope you found this post useful :)
datadog,"As I was recently finishing up a NodeJS application running on Heroku, I finally bit the bullet and figured out how to use DataDog for monitoring and logging the service."
datadog,"There are a lot of great articles and NPM packages out there to help, but for the sake of simplicity, I will only discuss the basics to get started with the essentials."
datadog,"Setup Monitoring
The first we‚Äôll do is to install a Datadog Agent on our Heroku application so that Datadog can begin collecting the necessary metrics we need for setting up our dashboards."
datadog,"Inside Datadog, navigate to Integrations > Heroku

Now the steps are listed on the page, however you may need to slightly modify them in order to work."
datadog,I will describe the same commands along with the changes I had to make in order to make them work properly.
datadog,Step 1.
datadog,"Enable Heroku Labs Dyno Metadata
Assuming you already have a project setup and the NodeJS buildpack installed, we can start by enabling the metadata."
datadog,This step will ensure that the Heroku Dyno will have access to the metadata about the app and environment to share with Datadog.
datadog,It‚Äôs important to add the -a followed by your app name in Heroku that you would like to setup with Datadog.
datadog,"$ heroku labs:enable runtime-dyno-metadata -a <app-name>
Step 2."
datadog,"Add the Datadog Heroku buildpack
$ heroku buildpacks:add https://github.com/DataDog/heroku-buildpack-datadog.git -a <app-name>
Step 3."
datadog,"Set the Agent version to install
$ heroku config:add DD_AGENT_MAJOR_VERSION=7 -a <app-name>
Step 4."
datadog,"Set your Datadog API key
$ heroku config:add DD_API_KEY=<datadog-api-key> -a <app-name>
Step 5."
datadog,"Set the Datadog site
$ heroku config:add DD_SITE=datadoghq.com -a <app-name>
Step 6."
datadog,"Deploy to Heroku
$ git push heroku master
Now we can see our metrics and setup any dashboards we like to monitor and track our Heroku Dyno performance."
datadog,Here you can see how to see the new dashboard that Datadog automatically has setup for us.
datadog,At this point we can setup more metrics to capture manually within your app for greater clarity.
datadog,One example is that we may want to track how long each function takes to execute in our code which we could easily do with a package like https://github.com/brightcove/hot-shots.
datadog,Then in Datadog we could build dashboards from the metrics the app is sending.
datadog,However for the sake of simplicity this article is just to get us up and running with the basics in place.
datadog,Congrats!
datadog,The hardest part is over and now we‚Äôre on to setting up our logging in Datadog.
datadog,"Setup Logging
Now the last part we would like to do is to setup the logging that occurs in our application to send the messages over to Datadog so that we can use the UI to quickly search, find, and live tail all the events occurring in the application."
datadog,"The important is to provide a valid name for the service, I used the app name again in this case as recommended by Heroku."
datadog,I used the domain name for the host.
datadog,"$ heroku drains:add 'https://http-intake.logs.datadoghq.com/v1/input/<datadog-api-key>?ddsource=heroku&service=<service>&host=<host>' -a <app-name>
If everything correctly you should see a confirmation output similar to the following:
Successfully added drain https://http-intake.logs.datadoghq.com..."
datadog,Cheers now the logs are connected to Datadog!
datadog,Let‚Äôs explore this a bit and show how the two systems work together.
datadog,"First, I recommend using a dedicated logging package such as Winston to capture, format, and pass the logs along."
datadog,"The documentation can be found https://github.com/winstonjs/winston
With Winston or any other logger, we can simply write to the console and have the logs processed and sent to Datadog."
datadog,"import winston from 'winston';
// Configure Winston
const logger = winston.createLogger({
  level: 'info',
  transports: [new winston.transports.Console()]
});
// Send a log
logger.info('Hello from Heroku NodeJS app!"
datadog,"');
Now that we sent a log in our app, we can go into Datadog and find the messages showing up under ‚ÄòLogs‚Äô."
datadog,Note that the host and service provided in the drain is the same as should show in Datadog.
datadog,Now go forth and prosper!
datadog,"The possibilities of monitoring your app are endless, but never the less crucial for ensuring critical issues are caught early."
datadog,Good logs are worth their weight in gold as issues arise and you need to debug quickly.
datadog,This story was written by Priya Matpadi.
datadog,"This post is the third in the series to get an AWS EMR cluster, running spark streaming application, ready for deploying in the production environment by enabling monitoring."
datadog,In the first part in this series we looked at how to enable EMR specific metrics to be published to Datadog service.
datadog,"In the second post, I explained how to install Datadog agent, then configure it on each node of a Spark cluster automatically either at the time of cluster launch, or when auto-scaling up the cluster on the AWS EMR service."
datadog,"This enables Datadog agent to periodically execute spark check that publishes spark driver, executor and rdd metrics which can be plotted on Datadog dashboard."
datadog,"In my view, the most important metrics are the ones that give you an insight into how your particular application is responding to events."
datadog,"Some useful measures are:
How often are you receiving events?"
datadog,Are their peaks and troughs?
datadog,Is your spark streaming application able to process the events within the specified batch interval.
datadog,Are the downstream dependencies able to keep pace?
datadog,"Were there errors, retries, failures during event processing?"
datadog,"Does your application demand lots of memory, is it compute intensive or does it demand lots of storage?"
datadog,"At a high level, answers to the above questions are available on the Spark UI."
datadog,"However, as the application developer, you have the best picture of your application‚Äôs function, its business logic, and its downstream dependencies, whether it be a database, an API server, or a message bus."
datadog,"Therefore, you have the best idea of what metrics will be useful to monitor the health and performance of your spark streaming application."
datadog,"Once you have figured out the list of application metrics, the implementation is quite straightforward."
datadog,"If you already have a spark cluster with the Datadog agent running on the master and executor nodes described in the second post, all that is left is to implement code to:
Launch a reporter thread in the initialization phase of your spark streaming application, and
Publish metrics as events are processed by the application."
datadog,"Couple of open source library options available:
https://github.com/coursera/metrics-datadog
http://kamon.io/documentation/1.x/reporters/datadog/
If all goes well, the published application metrics should become available in Datadog in few minutes of setting this up."
datadog,"The next step is to create a beautiful data dog dashboard of combined EMR, Spark, and application metrics to give you visibility into the health of your Spark Streaming application."
datadog,"Finally, you want to create monitors based on these metrics, and integrate with alerting services like Pagerduty to ensure 24X7 availability of your real time spark streaming application."
datadog,"Summary
As I wrap up this series of posts detailing how to publish Spark Streaming System and Application Metrics deployed on AWS EMR cluster to Datadog, let‚Äôs summarize the steps:
Enable Datadog integration with AWS Elastic Mapreduce Service."
datadog,"Bootstrap EMR cluster launch with script to install Datadog agent, and configure spark check."
datadog,Setup spark streaming application to publish metrics relevant to data ingestion and processing.
datadog,"If you have questions or suggestions, please leave a comment below."
datadog,"Trace Search and Analytics by 
Datadog HQ
 is a fantastic tool for performance analysis and capacity planning."
datadog,Trace Search has been in Beta over the past year and was announced for General Availability at Dashcon.io.
datadog,"Please see the keynote, related workshop and also its Github repo."
datadog,"In this blogpost we will cover how to set it up, enhance it with custom attributes and demonstrate some advanced syntax."
datadog,"This will help to illustrate the place Trace Search fits, as well as how to employ Analytics to better understand capacity and performance characteristics of a multi-tenant system."
datadog,Datadog is a very well known product for observability and system metrics monitoring.
datadog,It helps track instrumented elements as well as monitor key performance metrics.
datadog,It can help us visualize this data in a beautiful and professional manner.
datadog,The visual reporting function is where we feel Datadog excels.
datadog,One graph is worth a thousand words.
datadog,How does APM improve on Datadog‚Äôs already strong offering?
datadog,Today‚Äôs applications are complex and multi-tenant.
datadog,What appears to be performant and reliable for most accounts may not be sufficient for another set of accounts whose traffic pattern and/or dataset is very different.
datadog,For example: The N+1 problem can be seen where we think N is large enough.
datadog,"The answer to that problem is APM, it stands for Application Performance Monitoring."
datadog,This product is designed for infinite cardinality (as opposed to Datadog‚Äôs usual 1000 max distinct value limit).
datadog,This allows us to look at large dataset with a high level of granularity.
datadog,"It gives us the capability to monitor throughput and response time (median, 90/95/99 percentile) per individual account."
datadog,This has never been possible before APM.
datadog,The key observability element that APM gives us is the time an individual account spends in the system.
datadog,"From a capacity planning perspective high throughput multiplied by a fast response time can be equal to a low throughput multiplied by slow response time, hence taking throughput or duration for an analysis individually may lead to incorrect decisions because it may not give enough information."
datadog,"Tracing Ruby Applications
Official documentation is the starting point."
datadog,We chose Ruby On Rails as platform to demonstrate the integration.
datadog,"These are some trace search keys that are available by default:
@duration
@http.method
@http.status_code
@http.url
@request_ip
Among different methods to instrument the code with custom metrics, the one we use is the following:
class ApplicationController < ActionController::Base
  before_action :datadog_trace_extend
  private
  def datadog_trace_extend
    current_span = Datadog.tracer.active_span
    if current_span
      current_span.set_tag('account.id', 1)
      current_span.set_tag('account.user_id', 100)
      current_span.set_tag('http.source', 'api')
    end
  end
end
Trace Search Demo
Let‚Äôs jump to our demonstrations followed by a detailed explanation of how to setup and adjust it to your multi-tenant environment."
datadog,First demo covers traffic pattern represented by two accounts.
datadog,The first account causes the system to generate HTTP 200 (OK) while the second account‚Äôs traffic solely results in HTTP 304 (Not Modified).
datadog,"Take a closer look at requests duration, it‚Äôs no different although high number of HTTP 304‚Äôs shows that we spend resources generating a response even though the client already has the most up to date data."
datadog,A traffic pattern like this is usually a sign of inefficient API communication.
datadog,With Trace Search we can identify that account in the multi-tenant environment.
datadog,This demo was part of our presentation at Dashcon.io on 12th of July 2018.
datadog,"See the demo below:

The second demonstration covers traffic from the same account that enters our system from different endpoints."
datadog,This example illustrates a situation where an unexpected number requests may come from an API client.
datadog,This type of analysis is useful when traffic growth needs to be factored into a capacity plan.
datadog,"We demonstrated that it is possible to free up a large portion of capacity by analysing traffic, determining what was excessive, and taking action on it."
datadog,"We have examples where an API client consumes more resources than expected by hitting the same endpoint, all due to a misconfiguration or not respecting HTTP Retry-After headers."
datadog,"See more details in the presentation but the demo is below:

The third and final demo is an example of taking action on an unexpected traffic pattern; specifically public API endpoints which can be cached on the intermediate proxies."
datadog,This prevents the backend from having to receive these requests and respond to them.
datadog,The main intention is to visualise the throughput change before/after the changes are applied.
datadog,"Trace Search can help to determine if the changes you made to your system have the expected effect:

APM Trace Search and Analytics fills the gap between both set of Dev and Ops monitoring and visualisation tools, what was difficult to visualise became easy."
datadog,"With its rich UI and powerful syntax, Trace Search can help to take an action on traffic reduction in order to filter signal out of noise, and efficiently plan capacity in a multi-tenant environment."
datadog,"Before the internship began, my brain had already started awaiting it."
datadog,The internship is just 4 months away.
datadog,"Okay, it‚Äôs 2 months to go now."
datadog,A month!
datadog,And then it began‚Ä¶ and ended!
datadog,Just like that.
datadog,4 months were over.
datadog,I had interned at Kayako for 2 and a half months the entire summer.
datadog,"Phew, time flies!"
datadog,Scary.
datadog,Yet I‚Äôm happy.
datadog,My SRE internship at Kayako in Gurgaon has gone from an impossibility to a possibility; to an actuality and now a memory.
datadog,I‚Äôve had enough experiences over the last 2 and half months to fill a lifetime and I‚Äôll try to recollect a few of those in the next few paragraphs.
datadog,"The Hiring
Let‚Äôs begin at the beginning."
datadog,How did I end up at Kayako?
datadog,My friend Dhruv who was working with Kayako referred me to the opportunity.
datadog,"I started with a small puzzle, which was then transformed into a simple web app creation."
datadog,"After that, I had two interviews, one with Ruhi (HR) and one technical with Kashif (Director of Engineer) over the phone."
datadog,I ultimately received and accepted my offer.
datadog,I was always interested in SRE/DevOps stuff and yet I had only a little experience of how things work in production.
datadog,So I was very relieved that I had found an internship of my interest.
datadog,"Weeks 1‚Äì2: Arriving at Kayako
Upon arrival, I received the latest and most powerful MacBook Pro, a Thunderbolt monitor, Wireless Keyboard and Wireless Mouse."
datadog,"I was shown my desk and introduced to my mentor, Gufran."
datadog,"On the same day, I had one meeting with Gufran who was working as an SRE and another with Ankit who was a senior product engineer."
datadog,"Gufran told me about various microservices they built, open source projects they were using, distributed system architecture and introduced to my project."
datadog,"Ankit told me about the product, K5 (Kayako 5)."
datadog,"My Kayako Setup
The Project
As our infrastructure was growing, there was a need for monitoring and alerting of each and every component in our infrastructure."
datadog,My project was to implement the same using Datadog which is real-time monitoring platform.
datadog,The project also included writing Chef Recipes to manage these configs/scripts.
datadog,"Monitoring is actually a typical task because of following reasons:
First you need to have knowledge of each and every component like what it does, how it works, how it is deployed etc."
datadog,"After understanding components, you need to think what actually needs to be monitored and then learn how to monitor it."
datadog,"After banging your head with all other stuff, the main task becomes to think when the matrices need to be alerted."
datadog,"For example, Request per second gives alert either value bumps suddenly or value comes down to zero."
datadog,"The first two weeks of my internship were mostly filled with learning, learning, and learning."
datadog,"I read about Datadog, learned how to write Chef recipe, asked questions about different components in the infrastructure."
datadog,"By the end of two weeks, I had a fair knowledge of existing infrastructure, Datadog and Chef to get my project started."
datadog,I should say week 1‚Äì2 had my head in a whirlwind.
datadog,A lot of things were pretty new for me.
datadog,"Though I was a little bit scared, I was happy that I would in the worst case, learn a LOT for sure."
datadog,"Weeks 3‚Äì6: Settling In
The first component which I had to conquer was Nginx."
datadog,Kayako was using nginx both as a load balancer and as an app server.
datadog,Nginx was not very complicated or so I was led to believe .
datadog,There are two ways to monitor nginx.
datadog,"Nginx status page
Nginx status page gives real-time data about Nginx‚Äôs health, but this information was not sufficient."
datadog,An example output for status page.
datadog,"Access logs for nginx
We then decided to parse the log, but to parse the log and submit the corresponding matrices in real time to DatadogHQ was arduous."
datadog,Hail Datadog!
datadog,It provides a feature called Dogstreamer.
datadog,"It helps to graph the log data in real-time, all the time."
datadog,So I wrote a parser for the same.
datadog,This log parsing was providing us with a lot of useful information.
datadog,We were able to graph our error rates (i.e.
datadog,"500s, 502s, 503s), analyze the traffic from various desks, hit rate of our APIs and many more."
datadog,"Similarly, we went through each and every component, analyze the matrices and implemented the same."
datadog,"Some of the important components were PHP-FPM, AWS RDS, Elastic Cache (Redis), Elastic search, Consul, Deployments, Crons etc."
datadog,"By the end of this period, I completed the first phase of my project, i.e., to implement the monitoring."
datadog,Now the second phase was to alert these matrices.
datadog,"Weeks 7‚Äì9: Becoming Useful
The last month of my internship was most exciting maybe because I had gotten used to all the good stuff at Kayako."
datadog,"I was spending even more time in the office, working on the alerting, taking part in discussions, playing PS4."
datadog,I began to realize the importance of what I had built so far.
datadog,The monitoring was helping in identifying issues with the product.
datadog,"We were continuously adding new matrices, new tags for filtration and everything was good so far until we started realizing the issue with nginx log monitoring."
datadog,"The Dogstreamer issue
Issue
As mentioned earlier, we were utilizing Datadog dogstreamer to monitor logs."
datadog,"There was an issue with metric, nginx.net.status."
datadog,This metric was a counter metric.
datadog,We were sending data with tag code: <status:code>.
datadog,Now the issue we came to know was that we were getting the false count in Datadog dashboard.
datadog,"Resolution and Hack
I spent 3 straight sleepless nights in order to debug the issue."
datadog,"At first, I thought that the issue was with the parser, but soon I was convinced that the parser was honest."
datadog,"I was scratching my head, getting frustrated."
datadog,"We tried all the possible hacks possible, but we found nothing."
datadog,"Sometimes you get to the point of frustration, that you just become silent."
datadog,"At last, I decided to read the source code for dd-agent(Datadog agent), where I found something fascinating."
datadog,"Before explaining the issue and solution, I would like to explain the working of dd-agent."
datadog,"Datadog Agent Architecture
The diagram shows the black box architecture of dd-agent."
datadog,"In the diagram:-
The collector is responsible for gathering system and application metrics from the machine."
datadog,The forwarder is responsible for buffering and communicating with Datadog HQ over SSL.
datadog,dogstatsd is responsible for aggregating local metrics sent from your code.
datadog,"The issue was that for the dogstreamer if there are many values per second for a metric, Datadog takes the median without considering the tags attached."
datadog,This resulted in the loss of lots of data which was not acceptable for this kind of metric where each and every line of a log was very precious and hence our dogstreamer broke.
datadog,"Now to quickly fix this issue, I implemented a hack where we were using the complete pipeline of Dogstreamer, i.e., to tail and parse the logs but to submit the final data we used dogstatsd."
datadog,The key feature of dogstatsd is that it submits all the data it gets.
datadog,And that‚Äôs how we resolved this issue.
datadog,"As a programmer, I like challenges."
datadog,This bug is a challenge that I would call life‚Äôs favorite ‚Äî because it involved every stage of development.
datadog,"I learned how to believe in my code, how to approach a problem and a lot of techniques."
datadog,"By the end of this period, I had completed alerting."
datadog,I had also started writing documentation.
datadog,There are no words to describe the happiness and joy you feel when you finally see your code in production.
datadog,"Yes, everything that I built or wrote was in production."
datadog,My whole team was using it.
datadog,Now I was in my final stage to complete the documentation.
datadog,"Weeks 10: Wrapping up
As much as I didn‚Äôt want it to happen, my last week had come."
datadog,"While you would imagine it as the most hectic part of my internship, it really was the most relaxed one, to be honest."
datadog,"Most of my work was done or going through some final (code) reviews, writing documentation so I thankfully didn‚Äôt have as much on my plate as the weeks before."
datadog,"And that was it, my internship was over."
datadog,"I was sad about leaving my team and the Kayako life, but very happy that all the late nights and early mornings paid off in the form of seeing my work in production."
datadog,"On my last day, my team got me a delicious cake and gave me a very sweet farewell card."
datadog,"Farewell Cake

Farewell Card
Life at Kayako
So far I was just talking about work, you must have been bored by now, right?"
datadog,"Now if you are reading this blog and you are about to join Kayako, let me tell me you something that may cheer you up."
datadog,So what‚Äôs so cool about Kayako?
datadog,"The perks
Where do we begin?"
datadog,"From an amazing cafeteria with a fridge loaded with all kinds of beverages, and a great arrangement for the meals to unlimited paid leaves, to my favourite pastime, playing Mortal combat on the PS4."
datadog,The list goes on and on for the incredible perks that Kayako offers its employees.
datadog,"Freedom
Kayako offers complete freedom to its employees including unlimited paid leaves, flexible work timings, unrestricted internet and much more."
datadog,"The office digs and culture
I would describe the work setting and culture as, ‚Äúa fantastic work environment, and a culture that allows you to be yourself.‚Äù If you like fast-paced work environments and opportunities to grow (among all the other awesome perks the company offers) then add Kayako to your list of dream companies to work for."
datadog,"Conclusion
The interesting part of this project is that it never ends."
datadog,"You will always be adding new matrices, tweaking existing, tuning threshold values for alerting, adding new features for filtering and the list goes on and on."
datadog,The most important part of my project was its flexibility and diversity.
datadog,No extra effort was needed to add more hosts to existing matrices.
datadog,"Chef, Datadog and our implementation took cares of everything."
datadog,It was the most interesting project which I‚Äôve ever worked on.
datadog,"No matter what happens next, I want to say thank you to everyone at Kayako who made those two and half months the most exciting part of my life."
datadog,"by Scott Morris

The classic ELK stack
Monitoring and alerting are key components of any well-designed system."
datadog,"Opsline, being an MSP (Managed Service Provider) with many clients, each with many systems to be monitored, needed a solution for managing the vast array of monitors (and their subsequent triggered alerts) across all clients."
datadog,"To this end, we designed and built a system for centralizing all our clients‚Äô alerts in a user-friendly visual dashboard to help Opsline engineers keep tabs on the health of our clients‚Äô systems."
datadog,"How we did it
The primary monitoring & alerting tools used by Opsline are Datadog and AWS Cloudwatch."
datadog,"Fortunately, both these monitoring tools have rich APIs for extracting relevant data about monitors and any triggered alerts."
datadog,"With a little bit of custom Python code, we could pull alert data from each monitoring system, for each client, and output the JSON response data."
datadog,We built the Python script into a Docker image and deployed the container on AWS ECS.
datadog,We setup the ECS Task to output to the default AWS Cloudwatch Logs and created a Cloudwatch Events Rule to schedule the execution of the Task every 5 minutes.
datadog,This resulted in a batch of triggered alert JSON data being regularly pushed to the Cloudwatch Log Group for the Task.
datadog,"From here, it was easy enough to setup a single-task ECS Service running a Logstash container configured to ingest the Python script‚Äôs Cloudwatch log and ship the data to a small Elasticsearch/Kibana cluster hosted on Elastic Cloud."
datadog,"Once the alert data for all clients is stored in Elasticsearch, the power of Kibana can be leveraged to slice and dice the data any way you like."
datadog,"We built several Kibana visualizations to make sense of the data, then put it all together in a Kibana dashboard for a one-stop method of seeing clients‚Äô alert status at a glance (see anonymized screenshot below)."
datadog,"Opsline Kibana Alerts dashboard
We are actively using this Kibana dashboard to identify and prune noisy client alerts, escalate high priority alerts to relevant engineers, and keep our finger on the pulse of our clients‚Äô system health."
datadog,We will discuss the different parameters and k8s configuration to run datadog as deamonset and troubleshooting issues.
datadog,"Over the years, I‚Äôve looked many times at Datadog and asked myself if it could be helpful to us at Signiant."
datadog,"Several times we‚Äôve taken a look and, at the stage we were at, it just wasn‚Äôt a ‚Äúmust have‚Äù."
datadog,Until it was.
datadog,"We found that as we broke down our big monoliths into smaller microservices, it was harder to easily visualize and track down errors."
datadog,"Further, while we had most of the data we needed, we had to mine it from multiple places (Cloudwatch, Papertrail, Jenkins, Bitbucket, Pingdom, Slack, Nagios, Docker, etc.)."
datadog,"Datadog really gives us that great visualization, alerting and a ‚Äúsingle pane of glass‚Äù where we can see what‚Äôs going on with various components."
datadog,"After doing a thorough proof of concept, we purchased Datadog earlier this year and we‚Äôve recently ‚Äúfinished‚Äù implementing Datadog across all our AWS infrastructure, (Elastic Beanstalks, ECS clusters, plain old instances)."
datadog,I say ‚Äúfinished‚Äù because there‚Äôs more we plan to pull in but we have enough there now to start with to get value.
datadog,"It‚Äôs already helped us solve some issues we were seeing just by having better visibility into our environments (the Docker instrumentation on ECS is fantastic)
Secure Your DevOps (i.e."
datadog,"DevSecOps)

While we were implementing Datadog, we started using custom events to mark when we had promoted (released) code to production."
datadog,This led us to ask if there were other events we could be capturing via use of custom events in Datadog.
datadog,We‚Äôre using Deep Security as a service from Trend Micro as our preferred cloud protection platform.
datadog,"It was straightforward to hook into our various AWS deployment models, captures a lot of IDS/IPS/log/filesystem events and pretty well works in the background to protect our environment and our SAAS applications."
datadog,Deep Security works very well as an IDS/IPS system but it can generate rather a lot of events and is yet another console to login to.
datadog,"It turns out though that Deep Security can deliver an event stream to an AWS SNS topic and from there, we can do some processing on it."
datadog,Like send it to Datadog.
datadog,"We came up with a solution that looks like this:

DS->SNS->Lambda->DD
Events come from Deep Security to the SNS topic where we have a Lambda function subscribed."
datadog,This Lambda processes the event and sends it to Datadog while also allowing us to do some event filtering (ie.
datadog,only send events with a rank greater than 50).
datadog,"In Datadog we then see something like:

Like any other events in Datadog, these can be alerted on, placed on dashboards, etc."
datadog,It‚Äôs incredibly helpful to be able to overlay events on time boards within Datadog when looking into what may be happening at a time period.
datadog,"The solution is all packaged up in a nice Cloudformation template and available in a Github repo Signiant/datadog-deepsecurity-event-forwarder
How are you doing DevSecOps with smaller teams?"
datadog,What‚Äôs working (or not working!)
datadog,for you?
datadog,"Datadog Dashboard for AWS Budgets
ServiceRocket (SR) Engineers are unable to make optimal decisions because they do not consider the true cost of services being used."
datadog,"It is easy to see a price tag, but it is difficult to take into account all of the factors that make up a product‚Äôs true cost."
datadog,How can hidden costs be made visible?
datadog,"With a bit of effort, true monetary costs of many services used primarily on Amazon Web Services (AWS) can be calculated and made visible."
datadog,"Cost Allocation Tags
AWS by default allows a tag to be assigned to an AWS resource, i.e EC2, RDS, etc."
datadog,"Tags can be used to organize resources, and cost allocation tags to track AWS costs on a detailed level."
datadog,"AWS has two types of cost allocation tags, an AWS generated tag and user-defined tags."
datadog,"Activating Cost Allocation Tags in AWS
AWS defines, creates, and applies AWS generated tag, and user-defined tags can be defined, created and applied by the user."
datadog,Both types of tags must be activated before they can appear on a cost allocation report or to be used for budgets in the Cost Allocation Tags page under Billing Management Console.
datadog,"SR Engineering has two platforms, Learndot and Apps which is comprised of many teams that develop different products utilizing different environments."
datadog,The image below illustrates the user-defined tags created and applied on AWS resources created by Engineering.
datadog,"User-defined Cost Allocation Tags for AWS Resources
All the teams in Learndot and Apps either use Terraform or Cloudformation with a Jenkins pipeline to provision their infrastructure and deploy their applications, thus implementing the user-defined tags above was fairly straightforward."
datadog,"Cost Allocation Tags Implementation with Terraform

Cost Allocation Tags Implementation with CloudFormation
Budget on AWS

Budgets on AWS
After having the teams implement cost allocation tags as one of the Ops Missions, 
Yuen-Chi Lian
 created some budgets with guesstimated limits for services such as EC2, RDS, CloudWatch, and CDN based on cost usage by Engineering (quarterly) as a whole and by Learndot and Apps (monthly)."
datadog,"Budget Implementations for ServiceRocket Engineering
These budgets were implemented with notifications to the Engineering Operations (Ops) mailing group."
datadog,Ops receives emails in regards to a service for a particular budget in AWS surpassing the limit set.
datadog,"However, this did not provide the ability to visually understand if and when the budget needs to be realigned or if a service was costing way more than it was intended and requires attention."
datadog,"If needed to be done, it would require tremendous manual effort."
datadog,"AWS Budget Email Notifications for Actual & Forecasted Amount
Dashboard on Datadog

Datadog Dashboard for AWS Budgets (Night Mode)
Hence, the Datadog dashboard above was setup to display the budgets from AWS which provides better visibility on a monthly basis and over a longer period of time for each service and platform which otherwise could not have been done via the emails Ops received."
datadog,"Additional continuous efforts include:
Ops to analyze AWS dashboards on a quarterly basis and set close to realistic budget limits on all the AWS services and account."
datadog,"Team to setup similar dashboard for products under Learndot (e.g Moo, Hamburger, and etc) and Apps (e.g."
datadog,"SFJC, SafetyOfficer, and etc) thus taking on cost ownership."
datadog,"AWS Budget Datadog Dashboard for Moo Product under the Learndot Platform

AWS Budget Datadag Dashboard for Hambuger Product under the Learndot Platform"
datadog,"These days, it‚Äôs not uncommon for customers to use Cloud or infrastructure monitoring software across their dev, QA and production environments."
datadog,"Back in February, we announced support for Dynatrace to accompany our AppDynamics and New Relic APM support."
datadog,"Today, our Datadog support is now GA.
Why Harness + Datadog?"
datadog,Harness helps customers master CD so they can deploy new applications and services into production with speed and confidence.
datadog,Datadog helps customers monitor the performance of their cloud applications and infrastructure.
datadog,Customers typically have one or more deployment pipelines for each application/service.
datadog,A typical pipeline has several stages that reflect the environments (e.g.
datadog,"dev, QA, staging, production) which are used to test/validate code before production deployment occurs."
datadog,Integrating Harness with Datadog now allows customers to automatically verify cloud application and infrastructure performance across their deployment pipelines.
datadog,"A Simple Deployment Pipeline Example
Let‚Äôs imagine we have a Docker microservice called ‚ÄòMy Microservice‚Äô and our Continuous Integration (CI) tool Jenkins creates a new build (#101) which results in a new artifact version for us."
datadog,"With Harness, we could pick up that new version and immediately trigger a 4-stage deployment pipeline like this:
Example deployment pipeline
Each pipeline stage deploys our new microservice to a different environment, runs a few tests, verifies everything is good before proceeding to the next stage."
datadog,You can see from the above screenshot that stages 1 thru 3 (dev/QA) succeeded and turned green.
datadog,"This is generally good, it means the artifact passed all tests and is ready for production and customers."
datadog,The bad news it that stage 4: production turned red and our pipeline status is ‚Äòfailed‚Äô.
datadog,"Automating Deployment Health Checks With Harness
At Harness, we take CD one step further with something called Continuous Verification."
datadog,One of our early customers Build.com used to verify production deployments with 5‚Äì6 team leads manually analyzing monitoring data and log files.
datadog,This process took each team lead 60 minutes and occurred 3 times a week.
datadog,"That‚Äôs 1,080 minutes or 18 hours of team lead time spent on verification."
datadog,"With Harness, Build.com reduced verification time to just 15 minutes, and also enabled automatic rollback to occur in production."
datadog,"With Datadog, Harness is able to deploy and verify the performance of cloud application deployments instantly in every environment."
datadog,"The second a new application or service artifact is deployed, Harness will automatically connect to Datadog and start analyzing the application/service/infrastructure performance data to understand the real business impact of each deployment."
datadog,Harness applies unsupervised machine learning (Hidden Markov models & Symbolic Aggregate Representation) to understand whether performance deviated for key services and flags performance regressions accordingly.
datadog,Let‚Äôs take a look at what this verification looks like with Datadog.
datadog,"Continuous Verification With Datadog
The below deployment workflow relates to the above-failed pipeline, and specifically stage 4 in production."
datadog,You can see that phase 1 of the deployment failed.
datadog,"The deployment in terms of deploying the service succeeded, as did the verifications and tests relating to Jenkins."
datadog,"However, the Datadog verification failed which means new performance regressions have been identified."
datadog,"The resulting action, in this case, was an automatic rollback (this is the safety net that Harness provides)."
datadog,"Clicking on the Datadog failed step (red) shows us why the verification failed:
datadog_detail
We can see that one key web transaction ‚Äúget_/todolist/inside/load‚Äù has a request duration regression after our new microservice version was deployed."
datadog,"Mousing over the red dot we can get more details ‚Äî response time actually increased 58% from 840ms to 1330ms post-deployment:
datadog_mouse-ver
The default time period for this verification was 15-minutes but this number can be custom."
datadog,Some deployment pipelines and workflows can take hours to complete because not everything is automated (manual checks/approvals etc.).
datadog,"You can also configure/filter any Datadog metrics by clicking the Metrics Filter:
datadog_metrics_filter
Configuring Datadog Continuous Verification
Our integration was pretty simple to build using the standard Datadog API."
datadog,"The first thing you need to do is Setup > Connectors > ‚ÄòAdd New Verification Provider‚Äô:
Add Verification
Then enter your Datadog URL, API Key, and Application Key:
add_datadog
You can get your API Keys from your Datadog Integrations APIs screen:
Datadog APIs
Adding Datadog Verification To Deployment Workflows
First, add or edit an existing workflow in Harness."
datadog,Simply click ‚ÄòAdd Verification‚Äô and select Datadog from the menu.
datadog,"datadog_workflow_setup
Next, select your Datadog server, enter the service name you want to verify, select the metrics you wish to verify, and enter a verification time period (default is 15 minutes)."
datadog,"datadog_verification_setup
Click submit and your deployment workflow will now automatically verify application performance using Datadog."
datadog,"More To Come with Datadog
As you can probably imagine there are lots more things we can do with Datadog."
datadog,"Here are few things to expect in the future:
Harness deployment markers for Datadog users
Support for Datadog log unstructured event data (similar to our Splunk, ELK and Sumo Logic support)
Special thanks to our customers and engineering team for creating this support."
datadog,Cheers!
datadog,"In my first post Rootless Datadog Containers 6.x, I explain how we worked around our limitations in running containers in OpenShift as non-root users for 6.x."
datadog,We have made some additional changes that take us in a better direction and remove the dependency on supervisord.
datadog,Below is an example datadog.yml having some place holder/replacement variables using %xyz%.
datadog,"When we start Datadog, we use the following commands from our entrypoint script passing along some params to optionally enable or disable APM and Process monitoring

This has proven to be a much better solution than using supervisord."
datadog,"One caveat is that when running the datadog-agent process locally on the Mac, the process agent and trace agent will start automatically."
datadog,"This is also true when using some other operating systems, however due to our installation and our inability to register processes and dependent processes with something like sysctrl, we need to start these separately."
datadog,Here is the link to the official Datadog CentOS docs.
datadog,dlog is a small Go library which makes it easy to get logs from your application in json format that Datadog platform expects.
datadog,"Go to
https://github.com/flow-lab/dlog/blob/master/README.md for more information about the usage."
datadog,"Links
https://github.com/flow-lab/dlog
https://docs.datadoghq.com/logs/#reserved-attributes
https://docs.datadoghq.com/logs/languages/go/"
datadog,COVID19 drastically changed my college plans.
datadog,I planned on graduating from my Bachelor‚Äôs degree a year early in 2021 (instead of 2022) and was accepted into the computer science program at Seoul National University to study abroad in Fall 2020.
datadog,"Due to COVID19, my study abroad was cancelled and my school opted to be completely online."
datadog,"From my experiences in the Spring 2020 semester prior, I knew I could not learn well in an online environment."
datadog,I realized that Zoom University was not worth it and opted to take a gap year to do internships instead.
datadog,"Thus, I did internships in both semesters of my junior year instead of attending university."
datadog,Finding a Fall internship was challenging as many companies do not offer off season internships.
datadog,"Anticipating that the COVID19 situation would worsen, I began my Fall internship search at the end of January 2020 and was able to secure an internship as a Software Engineer Intern at Datadog at the beginning of March."
datadog,"Through my internship, I learned a lot about Datadog, working remotely, and met really amazing people along the way!"
datadog,"The Interview Process
Two weeks after I applied, a university recruiter reached out via email to let me know about next steps."
datadog,"No coding challenge was necessary, I simply applied on their website and submitted my resume."
datadog,What‚Äôs unique about Datadog is that they only do 1 round of interviews while many other companies typically send out a coding challenge and then do two to three rounds of interviews afterwards.
datadog,I really enjoyed Datadog‚Äôs process because it made things a lot less stressful since I could focus on classes and prepare for my interview.
datadog,I replied to the recruiter‚Äôs email to schedule an interview date for a week later.
datadog,The recruiter let me know that interview would be held through Zoom while any coding would be done on Coderpad.
datadog,"He was super helpful and clearly outlined what to expect during the interview:
Duration: 1 hour and 15 minutes
Parts: background, a project you worked on, career interests, 2 coding questions
Coding questions will focus on speed, problem solving, and technical proficiency
The end of the interview is saved for questions
There is no dynamic programming
You will hear back at most one week after the interview
They sent over this video titled ‚ÄúWhy I love being an engineer at Datadog‚Äù to give a better understanding of what it‚Äôs like to work at Datadog!"
datadog,"The first 15 minutes of my interview were spent discussing my background, projects, and career interests."
datadog,"Then, the next 45 minutes were spent on solving two coding questions (Leetcode easy-medium)."
datadog,"One of my questions was somewhat similar to Meeting Rooms II on Leetcode to get a better understanding of the difficulty (it wasn‚Äôt exactly the same as none of the questions I was asked could be found on Leetcode, but in terms of difficulty it was similar)."
datadog,My interviewer was super friendly which helped me relax more and I was able to have a conversation with him while I was doing my interview.
datadog,"Two days afterwards, I received a phone call from my recruiter who then told me I received the internship!"
datadog,"He explained pay details, housing (they would be giving a stipend), and asked me what dates I will be able to work."
datadog,"In his followup email after the phone call, he also provided a list of some really cool perks the company offers such as:
Unlimited snacks and drinks

An image of the Datadog snack area
Frequent company and monthly intern events
Catered lunches on Monday, Wednesday, and Friday
A great location with an amazing view
The recruiter had me at unlimited snacks and drinks!"
datadog,"And so, I began my journey as a Datadog intern."
datadog,"Day -21 (August 10, 2020): Getting Equipment
Due to the worsening COVID19 situation, Datadog decided to make the internship completely remote."
datadog,"As a result, they mailed me work equipment 3 weeks in advanced to prepare for the internship which is pictured below."
datadog,I received a MacBook Pro and an adapter.
datadog,"With this equipment, I began setting up my work laptop and was greeted with a nice ‚ÄúWelcome to Datadog!‚Äù screen once I finished!"
datadog,"Day 1 (August 31, 2020): New Hire Onboarding
The first day of work included different onboarding processes and trainings interleaved with generous break times."
datadog,"It was nice since there were three breaks throughout the day after each session and they were an hour long, so the day didn‚Äôt feel jam packed with back to back Zoom meetings."
datadog,"Online orientation that start off with IT set up
This orientation was for all Datadog new hires and not just interns, as the intern orientation would be the next day."
datadog,"Thus, I didn‚Äôt meet my fellow interns yet."
datadog,"Day 2 (September 1, 2020): Intern Onboarding
I really loved how Datadog had an intern onboarding for all the interns to get to know each other!"
datadog,"Something I realized in previous remote internships was that it was really difficult to get to know other interns and become friends with them, which was something I really missed."
datadog,"Because the Fall 2020 intern class had only ~25 interns (while there were 30 interns total as some Summer interns extended their internships into the Fall), it was definitely a lot easier to get to know everyone because rather than trying to know thousands of interns at perhaps a much larger company, there‚Äôs a smaller group to easily become friends with."
datadog,"For the intern onboarding, all interns were asked to create a Google slide with six images to introduce themselves."
datadog,"Then, our recruiter would compile all these slides together into a big presentation for us to get to know each other."
datadog,My slide (featured below) showed a bunch of different aspects of my life.
datadog,"The top left is a meal I cooked (as I started picking up cooking during quarantine) which consisted of miso soup, salad with ginger dressing, and karage."
datadog,The top middle is a picture of me playing badminton as I compete on my university‚Äôs badminton team!
datadog,Top right is a picture of me getting a super awesome quickscope in Fortnite while my friend was spectating me since I love to play video games.
datadog,Bottom left is my anime keychain collection as I love to watch anime and I collect keychains by ordering them online or buying them at conventions.
datadog,And the bottom middle and bottom right are my two dogs Lieutenant (the tan Shih Tzu) and Curly (the black Pomeranian).
datadog,Having get to know me slides for each intern was super helpful in becoming friends with interns because we could find common ground for us to bond over.
datadog,"For example, many of my co-interns and I found out that we‚Äôre all fans of the manga Berserk, so we could talk about it with each other and discuss recent chapters (albeit, we couldn‚Äôt do this often as Berserk is often on a hiatus‚Ä¶)."
datadog,"After intern onboarding, there was one more onboarding I had to do the next day which was engineering onboarding."
datadog,"This was for all new hire software developers (full time and intern) to learn about joining the Datadog organization on Github, learning more about the Datadog product, etc‚Ä¶ With this completed, I could finally start learn more about my team and what I‚Äôll be working on during my internship!"
datadog,"Day 5 (September 4, 2020): Intern Lunch Event
Datadog has done a great job trying to have remote events during the internship and this was the first of them!"
datadog,They reimbursed all interns $30 for lunch (breakfast for west coast interns or dinner for Paris interns) and scheduled a Zoom call for us all to relax and talk to each other while we eat lunch.
datadog,I was able to get a really nice bowl of Poke with the meal reimbursement and it was a solid 10/10.
datadog,"Poke bowl with tuna, salmon, white rice, edamame, scallions, tobiko (small fish roe), pickled ginger, sesame seeds, furikake (rice seasoning mix), nori (seaweed), onion crisps, tempura crisps, and topped with ginger ponzu and eel sauce
Day 16 (September 15, 2020): Pushing out Code
On Friday September 4 and 11, I actually got to push out code to my team‚Äôs repository."
datadog,"This really shocked me cause I pushed out code in the first two weeks of my internship, which shows how fast paced working at Datadog is."
datadog,"Not only do you work at a faster pace, but interns have a greater impact."
datadog,I saw myself contributing to my teams actual code base instead of spending the duration of my internship working on a project that has nothing to do with what my team does.
datadog,"Pushing out code at Datadog was interesting because my team works on an open source repository, so there were a lot of additional protocols I had to do when pushing out my code."
datadog,"While in my previous intern projects I just had to test my code with one set of testcases, open source projects require you to test code with multiple sets of testcases, as individuals could be using different versions of a library or Python."
datadog,"Thus, you have to test different combinations of Python and library versions to make sure that all of them work with your code."
datadog,"To do this, I had to write the testcases and learn how to use tox to automate the testing process."
datadog,"Then with my code tested, I added the testcases to the CircleCI test pipeline (which tests code whenever you push it to the repository) and then made a pull request to update the repository with my code."
datadog,"For my code to be reflected in the repository, it has to be peer reviewed, pass CircleCI tests, and I have to merge it with the code in the master branch to resolve any overlapping changes."
datadog,"While pushing out code had some similarities to private projects, there were many differences when working with open source projects."
datadog,"Day 17 (September 16, 2020): Escape Quest
I‚Äôm so glad that there were actually intern events during the internship, and unique ones that I didn‚Äôt realize existed."
datadog,Datadog scheduled an escape quest for all of us to do through the company Confetti and it exceeded my expectations.
datadog,An escape quest is basically like an online escape room where you have to solve a series of puzzles and make it to the end.
datadog,Confetti only allows 5 people maximum per team so there were 5 teams with 3 people each.
datadog,We all tried to compete with each other to reach the end of the puzzle the fastest.
datadog,The website for the puzzle had a really nice UI and what was really cool was that the puzzle wasn‚Äôt confined to the Confetti website itself.
datadog,"To find the answers to the puzzle, there were times where you had to surf the web on Google Maps, Instagram, and more."
datadog,"The puzzle was broken up into 8 chapters/levels that we had to solve, with a timer on the top right, and if you were stuck you could request a hint on the bottom right."
datadog,"All of the 5 teams were able to solve the puzzle within the time limit (in fact, many solved it within half that time), except mine which was the only team who had to go over the time limit üòé."
datadog,"It was so much fun and I got to bond with my fellow interns, shoutout to the Datadog intern coordinators for putting this together!"
datadog,"Day 32 (October 1, 2020): 10 Year Anniversary
The 10 day anniversary of Datadog occurred the week before and today there was an All Hands meeting (or as Datadog calls it, ‚ÄúAll Paws‚Äù) through Zoom to commemorate it."
datadog,"It was quite interesting to learn about the development of Datadog as a company, as it started out in 2010 with only 2 employees and now in 2020 there were 2,057 employees and it grew to be a large company."
datadog,"Through this event, I got to learn a lot about the development of Datadog to the company it is today."
datadog,"From how the founders learned the importance of logos (the Datadog logo has changed a lot over time) to how Datadog started off with a capital D in the middle (‚ÄúDataDog‚Äù) to becoming a name with a lowercase d (‚ÄúDatadog‚Äù), Datadog has grown so much in the past 10 years and it was great to see the progress that it made!"
datadog,"The graphics team does a very good job making visuals for Datadog
Day 37 (October 6, 2020): Visiting the NYC Office
On October 1, Datadog reopened their offices for employees to optionally go in."
datadog,"If you do choose to go in, you must wear a mask at all times other than sitting at your desk, socially distance, and follow numerous other safety protocols to prevent the spread of COVID19."
datadog,I really appreciated how Datadog had the option to come into the office while making it as safe as possible.
datadog,Just having that change in environment from home to work every now and then can boost energy and make you less tired.
datadog,"With the office reopened, I knew I wanted to go in and visit to actually see the in person office, which I decided to do on October 6."
datadog,"To get to NYC, I took the Coach community buses from NJ as they stop at Port Authority, which is right across the street from the Datadog office."
datadog,"Datadog‚Äôs office is on the upper floors of the New York Times building in NYC, which was amazing because the view from the office was stunning!"
datadog,When I arrived the reception at the entrance gave me a temporary badge (since I didn‚Äôt receive one yet due to being remote) and then I made my way up to the 45th floor where I‚Äôd be working.
datadog,"Elevator lobby (left), my temporary badge (right)
I really liked the feel the Datadog office gave off, it looked colorful and fun and I was super excited to get situated at my desk."
datadog,"There were only 5 other people in the office, but everyone was so friendly and kind, I definitely loved the office appearance and the Datadog culture I experienced in person and virtually."
datadog,"Datadog reception desk (left), A picture of the office from when you first enter (middle), Variations of the Datadog logo hanging in the office (right)
While I waited for reception to check me in, I looked out the window where I could see so much of NYC and Jersey City!"
datadog,I wish I stayed later at night (but I couldn‚Äôt miss my bus to get home) so I could see the view at night time.
datadog,I could only imagine how beautiful it‚Äôd be to see all the NYC lights at night.
datadog,One of the receptionists took me to my desk when they finished checking me in and they left a Datadog backpack with a ton of swag in it!
datadog,There was also a postcard written with welcoming messages signed by everyone seated in my desk area which I thought was really sweet and cute.
datadog,"I mentioned earlier in my article that Datadog offers a lot of free snacks, so of course once I got situated my next course of action was to check out all the snacks they have :)."
datadog,"Unfortunately, due to COVID19 and the office being relatively empty, there weren‚Äôt many snacks available."
datadog,"However, the snacks they did have were very tasty (I really liked the spicy tempura seaweed snacks they had)."
datadog,The Datadog location is really close to Times Square and is surrounded by a lot of terrific restaurants.
datadog,"Before COVID19, I would travel to NYC from NJ (as it was 40 minutes without traffic and 1 hour with traffic) just to eat food in the area around Datadog!"
datadog,"For lunch, I ordered soba."
datadog,Lunch was so enjoyable because I got to eat good food with a spectacular view.
datadog,"natto with tuna and soba with grated yam + poached egg (to go as indoor dining was not available)
After lunch I worked until 4:40PM and left to go to Port Authority to catch the 5:00PM bus to head home."
datadog,It was great going to the Datadog office since I felt refreshed to continue working at home after having a change of environment for a day.
datadog,"Day 38 (October 8, 2020): ddtrace v0.43.0
The open source library that my team worked on (ddtrace) released version 0.43.0 and some of the changes that I made are included in the changelog!"
datadog,"This was a really new experience for me since I‚Äôve never worked on open source code so I learned how to do code releases, write changelogs, and monitor the performance of different Datadog services to make sure the release doesn‚Äôt drastically affect them."
datadog,"Day 54 (October 23, 2020): Project Artemis
Every month there‚Äôs an event called Party Pups that is company wide game for all employees."
datadog,This game was called Project Artemis and people registered in teams of 4.
datadog,The premise of the game was that your team crash lands on the moon and have to try to survive.
datadog,"Every 5 minutes, a communication comes in from mission control to your landing vessel with updates on what is happening and you have to use this information to make the best survival plan (a video pops up on our screen)."
datadog,Project Artemis screenshots!
datadog,Datadog events are so well made and they always exceed my expectations for virtual events.
datadog,"At the end of the event, all participating teams are ranked against each other based on how well they survived based on their plan."
datadog,My team scored 12th place out of 21 and had a 38% survival rate :(.
datadog,Some teams had hilarious responses.
datadog,One team said they were going to travel through one of the moon craters by riding a life raft down the crater and back up (using rope to tie their teammate to the life raft and drag him because he jokingly disagreed with their plan).
datadog,Another team said they wanted to go explore the crater because there could be chicken nuggies there.
datadog,I loved seeing the silly responses people had and how casual everyone was!
datadog,"Day 68 (November 6, 2020): APM Team Demos
APM Team demos occur bi-weekly and are when people in my department (which is called APM) demo some new products they made."
datadog,This meeting was particularly interesting because the Engineering director said that we will be freezing our code starting with today in anticipation of the Sony PS5 release so that Sony won‚Äôt have to update their product to be compatible with any Datadog changes and to ensure that the release is as smooth as possible.
datadog,"It was really neat to learn how widely used Datadog is (it‚Äôs also used by Airbnb, Facebook, Spotify, Palantir, Hulu, and so many more companies!)."
datadog,"Day 74 (November 12, 2020): AMA w/ Datadog CTO Alexis
A nice thing about Datadog culture is how approachable everyone is, even the CEO and CTO!"
datadog,Interns could talk to them through Slack and the CTO Alexis scheduled time to do an AMA just for interns.
datadog,"Day 85‚Äì86 (November 23‚Äì24, 2020): Team Hackathon & Pie Making
To be honest, this week was a lot due to Thanksgiving break (Thursday and Friday) and so there was a lot of work left to be done and only Monday, Tuesday, and Wednesday to do it."
datadog,There was one project my team had to complete and decided to do a team hackathon to do it during this week.
datadog,"This means that we would be working all day Monday and Tuesday to try to get the project done (like a hackathon), have no meetings on these days other than hackathon related meetings, and we‚Äôd get reimbursed for Monday dinner and Tuesday lunch."
datadog,The project was called riot which is a command line interface meant to generate tests for different Datadog Python tracer integrations (as we have to test different combinations of library versions and Python versions) and then run test files with these different combinations.
datadog,My task was to colorize the command line output of the tests (e.g.
datadog,making success test cases green and error test cases red) which I did using the Python click library.
datadog,"Because my mom cooked dinner on Monday, I used my reimbursement to get cookie delivery instead for my family."
datadog,"For my Tuesday lunch reimbursement, I ordered sushi!"
datadog,"What was challenging this week was working outside of standard 9AM-5PM hours, especially with a four day weekend coming up soon."
datadog,"I felt especially tired at night as I worked past 9:30PM on Monday, and so I didn‚Äôt have much time to relax during the day."
datadog,"On Tuesday I decided to relax more and I did not work outside of work hours, especially because there was an intern pie making class I wanted to attend!"
datadog,"Thus, I finished work early to attend the pie making Zoom class where they reimbursed us for ingredients and I got to make a VERY delicious apple pie."
datadog,"Homemade Apple Pie & Cookies (flavors: birthday cake, smores, apple pie, coconut, cookies and creme, cinnamon roll)
My Projects
To give some context for the work I did at Datadog, I‚Äôll talk about what team I was on first."
datadog,"My department was the Application Performance Management team, which means we develop software to monitor the performance for different apps you program."
datadog,"Because apps can be programmed in different languages from Python to C++, there were different teams for different programming languages."
datadog,"I was on the Python Integrations team, which means that we write Datadog the portion of the APM service compatible with Python applications."
datadog,"My Team‚Äôs Overall Project
As mentioned earlier in my article, I got to work on an open source project which means I can freely talk about my project because the source code is publicly available!"
datadog,ddtrace is Datadog‚Äôs tracing library for Python.
datadog,"It is used to trace requests as they flow across web servers, databases and microservices so that developers have great visiblity into bottlenecks and troublesome requests (taken from ddtrace‚Äôs documentation on Pypi)."
datadog,"Within ddtrace, there are multiple integrations (code that implements Datadog‚Äôs tracer), for different Python libraries, as tracing would occur differently between some libraries (e.g."
datadog,synchronous vs asynchronous libraries).
datadog,"When using a tracer, all a developer has to do is call a single function in their code and the function will add the tracer to their app."
datadog,The tracer then records lots of metrics and metadata which gets sent to Datadog for us to nicely display for the developer in our web app.
datadog,"How a trace is displayed in the Datadog webapp
In the image above, you see a lot of colorful rectangles."
datadog,Each rectangle represents a span and all of the spans form a trace.
datadog,You can think of a span like a unit of work.
datadog,The length of a span is based on how long it took the span to complete.
datadog,At the top of all the spans is a timeline that has tick marks corresponding to different timestamps.
datadog,"To better understand spans and how they work, I‚Äôll use a generic example."
datadog,Let‚Äôs say that you have a web app that allows individuals to get data from it.
datadog,The largest span would be the get request made by someone using the web app.
datadog,"Then, underneath that span would be more spans which are the different function calls that are made following that get request."
datadog,"Think of it as the steps that are taken to get the end result, with each step occurring underneath the one that happened before it."
datadog,"It may be hard to understand without ever using Datadog, but if you do ever try it you will understand what I mean quickly!"
datadog,"My Role
I developed a tracer integration for Starlette and FastAPI."
datadog,"To do so, I had to actually learn what Starlette and FastAPI were (as I never heard or used them before)."
datadog,"Then, I had to go through the source code of each to figure out how to implement the tracing library into it."
datadog,"It was definitely a challenge at first since I‚Äôve never done anything like this before, but I learned a ton from it."
datadog,"Once I had a Starlette and FastAPI integration created in the first month of my internship, I spent the rest of my internship doing the tasks that my teammates were doing and was just like any other employee on the team (so I didn‚Äôt really have an intern project just for myself)."
datadog,"I reviewed pull requests, responded to customer inquiries and requests, sat in on customer calls, and more."
datadog,"This experience was so different compared to what I‚Äôve done in my previous internships and I got to really be a part of my team, though it was very intimidating at first since I had so much responsibility right from the start."
datadog,What was cool was that I was able to create my own project based on what I wanted to do once I became integrated into the team.
datadog,"Thus, I wrote up a project proposal, presented it to my team, and got to work on the project I designed during the remaining quarter of my internship!"
datadog,"Work Culture
COVID19 Response
At the beginning of July (two months before my Fall internship start date), my Datadog recruiter emailed to let interns know that the internship was going to start off remote and stay remote if it is still unsafe to go into the office."
datadog,They‚Äôll be mailing us Macbook pros and providing a stipend for at home office equipment so that we are able to conduct our internship from home.
datadog,"While it was disappointing to know that the internship couldn‚Äôt be in person, it was understandable that this was for the best and I am glad that Datadog has made this decision."
datadog,"On October 1, Datadog officially reopened their office; though coming into work is optional and not recommended unless needed."
datadog,They send out a detailed presentation about all the cleaning protocols as well as some of the benefits traditionally offered wouldn‚Äôt be available in the office (e.g.
datadog,free lunches).
datadog,I appreciate that they gave individuals the option to go into work (as it‚Äôs good to get a change in environment every once in a while since working at home can get draining) while implementing strict protocols to make sure that the office isn‚Äôt too full and that everyone is safe and healthy.
datadog,"Fast Paced
While I got to have a lot of impact just as an intern, there‚Äôs also a lot more pressure because you have more responsibilities."
datadog,This has its pros and cons.
datadog,"I learned an incredible amount through my internship, but I will admit there were times where I did feel stressed."
datadog,"At the beginning of my internship it was a challenge at first getting used to the amount of responsibility I was given, but over time I was able to adapt and no longer feel as stressed."
datadog,"Memes and Dog puns
There are lots of memes and dog puns at Datadog and they are all on point and PUPtastic üëå."
datadog,They even bought out the datadoge.com domain just for the meme :‚Äô).
datadog,"Datadoge meme (left) and Pikachu version of the Datadog logo (right)
Intern Events
Even though the internship was remote, there was still events happening!"
datadog,Below is a list of virtual events that Datadog had for interns.
datadog,"Cooking class (using ingredients in your own kitchen)
Escape Quest
Monthly lunches (September 4, October 2, November 6)
Monthly intern game events (September 16: Escape Quest, October 14: GoGames, December 9: Mini Games)
Monthly Party Pup game events (October 23: Project Artemis, November 19: Race around the World)
Remote interns also got to learn a lot about in person events that happened in previous internships (which all sound so amazing and I‚Äôm really disappointed I couldn‚Äôt experience them :/)
Rented out the entire Natural History Museum for a scavenger hunt
Dinner cruise on the Hudson River
Datadog Annual Unleash Party (photos below are from Josh Pindjak‚Äôs blog."
datadog,"I really wish I had my own photos to share but due to COVID19 there wasn‚Äôt a party)



Photos of the unleash party from Josh Pindjak‚Äôs Blog
Perks/Free Stuff
$30 lunch reimbursement several times throughout the internship
Unlimited drinks and snacks at the office
New hire swag box (with lots of goodies!)"
datadog,"Datadog backpack (it‚Äôs super nice I‚Äôm switching out my current backpack with this), headphones, waterbottle, postcard, sticker, and tshirt
More swag

Sweater, tshirt, Bose Quiet Comfort II headphones, notebook
$30 Amazon Giftcard (for winning intern bingo)

Gaming room in the office (it‚Äôs small and I‚Äôve been told you shouldn‚Äôt really be in there during work hours though)
Free lunch Monday, Wednesday, Friday (in non-COVID times) catered by Zero Cater (they get food from local restaurants such as Empanada Mama, Halal Guys, Mighty Quinn‚Äôs BBQ, and more)
Day 110 (December 18, 2020): My Last Day
I received a card in the mail with a Datadog sticker from the recruiting team to thank me for spending the Fall at Datadog."
datadog,It was such a sweet card to receive and the message inside was handwritten!
datadog,"For the rest of the day, I wrapped up my internship by writing a document with feedback on what went well during the internship, what needed to be improved, as well as some tips for the next intern."
datadog,I also discussed logistics for a full time return offer from Datadog to see how Fall internships differ from Summer.
datadog,My recruiter said that they‚Äôll give me an official offer letter next year in Fall 2021.
datadog,This was really convenient because it gives myself time to complete my other internships and see where I‚Äôm the best fit for.
datadog,"To finish off my last day, my team and I had a final Zoom call and ordered sushi (which we got reimbursed for)!"
datadog,I had a great internship and I‚Äôm glad I got to spend my Fall 2020 at Datadog :).
datadog,"If you liked reading about my internship experience at Datadog, check out my articles about my Amazon, Goldman Sachs, and Colgate intern experience!"
datadog,"Be on the lookout for my articles about my Snapchat, Microsoft, Stripe, and Google intern experience!"
datadog,"Sending GraphQL metrics to Datadog with Apollo Engine

Sashko Stubailo
Open Source Eng Manager
@stubailo
BACKEND
HOW-TO
One of our core tenets on the Apollo team is that we want to enable you to use GraphQL in a way that works with your existing technology investments."
datadog,It‚Äôs much easier to convince your coworkers that the benefits of GraphQL are worth the effort if you can bring your favorite tools with you.
datadog,There are tons of software-as-a-service platforms developers use every day to understand and manage their apps.
datadog,"We see Apollo Engine, our service for GraphQL management and insights, as the natural nexus point between these services and your GraphQL API."
datadog,"Engine handles the GraphQL-specific parts, and can hand off the data to the other tools you use."
datadog,"That‚Äôs why recently, we‚Äôve been working hard on integrating Engine‚Äôs GraphQL-specific features with:

CDNs, like CloudFlare, Fastly, and Akamai,
Slack, with daily overview reports of your API, and
PagerDuty, with custom triggered alerts
Today, we‚Äôre introducing another commonly-requested integration: The ability to pipe metrics into Datadog, a popular monitoring and analytics platform!"
datadog,"Seeing your GraphQL operation latency in Datadog
We‚Äôve been using this feature ourselves and testing it with some early access customers, and it‚Äôs allowed us to easily integrate GraphQL-specific information from our API into our existing backend monitoring dashboard."
datadog,"Datadog integration is one of the newest features of our Engine Standard and Pro plans, which also include benefits like much longer data retention and proactive alerting."
datadog,"If you‚Äôre on Community edition today, you can try it out for two weeks with no credit card required!"
datadog,"If you haven‚Äôt added Engine to your API yet, read the setup directions here or learn more on the website."
datadog,"Information provided to Datadog
Almost all of the performance and error statistics you can see in the Engine UI are exported through the integration."
datadog,"With today‚Äôs integration, you can get:

Request rates,
Error rates,
Cache hit rates, and
Latency histogram statistics
But it‚Äôs much better than just that, since Engine embeds extra information in the data it passes on."
datadog,"GraphQL operation tagging
The data sent to Datadog is tagged with GraphQL-specific information, like the name of the GraphQL operation."
datadog,"That way, you can easily filter down to a specific query or mutation by using the provided tags."
datadog,"Here‚Äôs what it looks like in the Datadog UI:


This allows you to integrate any information you want to know about your GraphQL API‚Äôs specific operations into your existing Datadog dashboards."
datadog,"Here‚Äôs what one of our operations looks like in a chart:


Setting up composite alerts in Datadog
Integrating your GraphQL data into a sophisticated monitoring service lik Datadog has additional benefits beyond just being able to see charts."
datadog,"Even though you can get alerts directly from Engine, you also can get sophisticated alerting based on the data piped into Datadog."
datadog,"In particular, you can use composite alerts to trigger an alert based on a combination of factors, for example to get notified when an operation‚Äôs error rate and latency go up."
datadog,"Setting it up
Setting up Datadog with Engine is easy."
datadog,"Get the full details in the docs, but it‚Äôs just a few steps:

Get a new API key from the Datadog API integrations page
In Engine, go to the settings for your service, and enable Datadog integration
Paste in your API key from Datadog
Since metrics are tagged with the service they came from, you can use the same key for all of your services."
datadog,Think of the satisfaction you‚Äôll get when this button is green and you can see all your metrics coming in!
datadog,"üìà
Engine: Bringing together all your services
When you go into production with a new GraphQL API, you don‚Äôt want to leave all of your existing tooling behind."
datadog,"We all rely on tools like Datadog to bring together our data and operate services, and GraphQL needs these just like any other technology."
datadog,"But usually, these services don‚Äôt integrate directly into a GraphQL API, so you can‚Äôt filter by things like your operation name."
datadog,"Plus, once you identify a problem you might need to dive into specific traces and reports to see what needs to be changed."
datadog,"That‚Äôs why I‚Äôm really excited about Apollo Engine integrating with the world of developer services ‚Äî Engine can handle all of the GraphQL-specific bits, and enable you to keep using the tooling you need to do your work."
datadog,And this is just the beginning; stay tuned for more.
datadog,Let us know on Twitter if you have other ideas for services you‚Äôd like to see integrated with GraphQL and Engine!
datadog,In my previous post I explain how we worked around our limitations in running containers in OpenShift as non-root users.
datadog,Here is an updated version to work with the new version 6.x of the agent.
datadog,Below is an example datadog.yml having some place holder/replacement variables using %xyz%.
datadog,"When we start datadog we use the following command:
supervisord -c /etc/datadog-agent/supervisor-apm.conf
The secret sauce here is that currently the agent and trace-agent need to be started separately."
datadog,"When doing so make sure you add the following environment vars to your application because when using supervisord via the config below the agent tags and properties do not seem to carry over to the trace-agent
- DD_TRACE_SPAN_TAGS=env:bar
- DD_SERVICE_NAME=foo-service
The supervisor-apm.conf looks like the following"
datadog,"‚Äî How Datadog metrics helped us identify and fix a critical production issue
Introduction
There are plenty of monitoring tools (Statsd, Prometheus, Datadog‚Ä¶) that allow engineers to create graphs based on metrics they want to keep an eye on."
datadog,"At SimpleReach, we use Datadog to track system as well as application metrics."
datadog,"For example, something that has a lot of importance for us is the total duration of our main Golang processing pipeline."
datadog,"When the application starts, we call start := time.Now() and just before the application exits, we send time.Now().Sub(start)).Seconds() to Datadog."
datadog,"We can then visualize the duration of the pipeline in Datadog:

a) Pipeline duration in seconds
Importance of key application metrics
Where it becomes a little bit more interesting is when you start sending application metrics that are dependent on other nodes or cluster of nodes."
datadog,Our application depends on a cluster of Cassandra nodes where we issue select and insert queries using the gocql golang package.
datadog,The number of attempts to successfully execute queries as well as the latency of queries become critical application metrics for us.
datadog,"We can get these two metrics directly from the gocql package and send them to Datadog:
q.Attempts() where q is a gocql.Query object gives us the number of attempts per query."
datadog,"If we send this number to Datadog, we can then create a graph like the one below:

b) Number of attempts per request and per type (select vs insert)
q.Latency() where q is a gocql.Query object gives us the latency per query."
datadog,"If we send this number to Datadog, we can then create a graph like the one below:

c) Average request latencies (in seconds) by type (select / insert)
As you can see on fig b, we were seeing 1.3 attempts on average on insert queries to Cassandra."
datadog,Latencies for inserts could go as high as 5 to 6 seconds and averaging around 3 seconds (fig c)!
datadog,These numbers do not reflect great performance as you could guess.
datadog,We would rather have this metric closer to 1 attempt (=0 retries) on insert and select queries.
datadog,"By reducing the number of retries, we would also reduce the average latencies of both operations."
datadog,How do I fix this?
datadog,"Thanks to these graphs, we noticed the problem described above during the first stage of the implementation."
datadog,"However, after we spent a little bit of time investigating the issue, we did not find the root cause."
datadog,"As a consequence, we decided to file a ticket for it to be worked on another sprint."
datadog,This has been now 4 to 5 months that the application runs in production and I have worked on it for the past 3.
datadog,"Unfortunately, my super cool coworker that I was working very closely with decides to leave the company and I am now left out with the software to support by myself."
datadog,"I am a little concerned about the high latencies and the large number of retries to Cassandra as I do not know much about how the cluster was setup and how the application was currently connecting to it‚Ä¶ However, I am excited about finding out the root cause of this issue."
datadog,"Things getting a little bit out of control
Last day of my coworker that I will miss a lot and we receive our first timeout ever experienced to the Cassandra cluster."
datadog,It is only one request so it is definitely not critical but I really need to dig into this issue as it is not only retrying but also timing out now.
datadog,"DataDog event:

d) First timeout from the application to the Cassandra cluster
The investigation
Obviously, logs are one of the first things I started looking at and I was surprised to see a lot of failures to connect to a certain number of nodes."
datadog,"Example:
2018/01/03 08:10:04 error: failed to connect to IP:PORT due to error: gocql: no response to connection startup within timeout
Was the cluster in a good shape when we got these failures to connect?"
datadog,"From what we can tell, yes it was."
datadog,"It is when I started looking at the specific node IPs that the application was failing to connect to, that I realized about 80% of these log messages were coming from only a few IPs."
datadog,I looked their hostnames up and realized they were SOLR nodes and not Cassandra nodes!
datadog,"Wait a minute, why is the application connecting to a couple of SOLR nodes?"
datadog,We tell the application to connect to the Cassandra nodes we pass in as a cli parameter.
datadog,I verify the list that we pass as a cli parameter and the list only contains Cassandra hostnames and absolutely no SOLR hostnames.
datadog,"After asking around and examining our gocql.ClusterConfig, I am finding out that our Cassandra and SOLR nodes belong to the same cluster."
datadog,"Everything starts to make sense as I am looking at the gocql.NewCluster documentation:
The supplied hosts are used to initially connect to the cluster then the rest of the ring will be automatically discovered."
datadog,We obviously have to inform the package that we only want to connect to the Cassandra nodes since Cassandra and SOLR nodes are part of the same cluster‚Ä¶ We need a gocql.HostFilter!
datadog,"The one line fix and the happiness that we already had graphs around the Cassandra integration
The fix to the problem is to use a gocql.HostFilter."
datadog,There are a two ways of creating a gocql.HostFilter.
datadog,The first one is to whitelist all the Cassandra hostnames you want to connect to and use gocql.WhiteListHostFilter.
datadog,It does the job perfectly if you have all your Cassandra hostnames / IPs handy.
datadog,"However, at SimpleReach, we have a good amount of Cassandra nodes and since Cassandra and SOLR nodes are in two separate data centers, we can use a gocql.DataCentreHostFilter which is much more powerful."
datadog,It basically lets gocql discover all the Cassandra nodes that are part of our Cassandra data center and filter out all the other nodes that are not part of this data center but part of the cluster.
datadog,A quick tcpdump -i * dst SOLR_IP on my local computer to verify that the application does not connect to a SOLR node and this is officially ready to get pushed out!
datadog,"Thanks to the graphs we already had, this is what it looks like before and after deploying:

e) Average request latencies (in seconds) by type (select / insert) before / after deploying :)
Average latencies looking much better after deploying."
datadog,"f) Number of attempts per request and per type (select vs insert) before / after deploying :)
The number of attempts per query also looks much better after the deployment as well."
datadog,There is rarely a retry for both operations which is a good sign :).
datadog,The main reason why we saw these two drops is because the application was trying to insert to SOLR for a key space that did not exist on the SOLR nodes resulting in at least an extra roundtrip.
datadog,"Basically, if we were lucky, the next attempt would go to a Cassandra node but it could also go to a SOLR node again."
datadog,The original timeout I shared was probably caused by a serie of ‚Äúunfortunate‚Äù retries to SOLR causing our go application to timeout.
datadog,"Conclusion
I am now thrilled that this is fixed."
datadog,The overall pipeline duration also decreased which we are all happy about and I really do not think I would have been able to identify the performance improvements without application metrics!
datadog,"When I take into consideration the amount of visibility and the relevance of the discussions that open up from analyzing application and system metrics graphs, I truly believe that they should be required when software is pushed out to production."
datadog,Application and system metrics graphs are also a great way to onboard people on a project.
datadog,Only looking at them can help new engineers understand what has already been done as well as potentially enable them to identify existing application bottlenecks.
datadog,"By Pattern Match | March 16, 2018

Introduction
In this short post we would like to share our experiences regarding large systems monitoring."
datadog,The focus however will be put on cooperation between dev/devops and business.
datadog,Why is this important?
datadog,Why should we care?
datadog,Is it worth it?
datadog,Are there any obstacles or pitfalls?
datadog,Let‚Äôs dive into what we think are best practices and see how they finally work out.
datadog,"Best practices distilled
Present data in concise and clear manner, ideally aggregated."
datadog,"Show data aggregated from last hour, day, week or month depending on your needs."
datadog,If possible allow to select time period (timeline) but don‚Äôt overdo it.
datadog,Try to avoid timelines in business dashboards.
datadog,"Timelines are important for your (as developer/operations) daily work: when hunting for bugs, preparing post-mortems, finding correlations or searching for so much desired reasons of change (most probably not expected :) )."
datadog,In some very special cases make an exception and display timeline on business dashboard.
datadog,"When some metric is very dependant on other one and business people know about that relationship and specifically demand it, only then add such graphs."
datadog,Allow to drill down and have more detailed data ready.
datadog,Do not overwhelm on main metrics pages.
datadog,Such more detailed views are crucial to you as well.
datadog,They allow to quickly get more insights about current system performance and potential problems.
datadog,Prepare for questions.
datadog,A lot of questions.
datadog,You will need to work with business people and explain a lot.
datadog,"It works the other way too, you will need to extract details about business needs and goals."
datadog,"If this is not your cup of tea, leave metrics management to someone else."
datadog,"If you can attach documentation for the metrics, do it."
datadog,Create such documentation no matter what ‚Äî you will be asked the same questions over and over again by different people ‚Äî it will be very handy to just open it up and read it or just pass the link.
datadog,You will be creating presentations.
datadog,We are using Datadog for monitoring and there is a concept of Notebooks with which you can combine markup documentation with interactive graphs ‚Äî perfect tool for business dashboards.
datadog,"If you break something ‚Äî take responsibility, mark it clearly on the dashboards (you can label it with text invalid for example, or hide it completely)."
datadog,And most importantly communicate.
datadog,It builds trust and shows that you care.
datadog,Remember ‚Äî invalid data is worse than no data at all.
datadog,"When presenting current value of some metric, so basically taking into account near real time, very recent data, you must be prepared for some spikes."
datadog,"They may be related to spikes in traffic, cluster restart/deployment etc."
datadog,‚Äî just prepare business people for such cases.
datadog,Calm them down as they can get worried unnecessary.
datadog,Keep descriptions clear and simple.
datadog,Do not make anyone to guess what is being presented.
datadog,Plainly describe each value.
datadog,"If you are conducting A/B testing, make sure the two streams are nicely labeled."
datadog,Common trait of good metric?
datadog,You have to be able to explain it within one sentence without ambiguity.
datadog,"It‚Äôs easy to achieve when the metric is a ratio, percent or interest rate."
datadog,"An example showing dashboard with business metrics
Keep technical names away."
datadog,Do not show host or any other infrastructural names.
datadog,"Try to use labels that are being used by business people, even if code uses different ones (We know, it should never happen, but‚Ä¶yeah)."
datadog,In Datadog you can easily name your metric by assigning it an alias.
datadog,Do not hesitate to use it.
datadog,Try to keep relevant and logically connected data together and keep such clusters as a separate dashboards.
datadog,"Of course there are exceptions ‚Äî sometimes two or more clusters together, as overview, must be presented side by side to quickly provide some answers."
datadog,In that case think about what you can remove from clusters to focus on important aspects.
datadog,"Try to understand business needs thoroughly ‚Äî what are the goals, KPIs (Key Performance Indicators), reference point?"
datadog,Does business want to just see some data to know how the system behaves?
datadog,"Or do they want to know some very specific detail, like revenue on particular time of the day in particular region?"
datadog,It is a mistake to just dump all the data you have ‚Äî it quickly loses necessary focus and stops being visited.
datadog,"If there is a need to fish, to skim the data in searching for some relevance, still try to at least distill some top level business goals that are currently strategically executed ‚Äî you will need to talk, maybe talk a lot but it will pay off."
datadog,"Extending previous point, beware of Vanity Metrics (https://fizzle.co/sparkline/vanity-vs-actionable-metrics) ‚Äî try to really understand what is meaningful and actionable."
datadog,It can really be addictive to watch metrics all day long but what if they don‚Äôt matter?
datadog,"Be very careful when you modify, delete or add any new metrics..or just make any code changes in business logic or processing."
datadog,Test the changes well and be the first to monitor metrics after deployment.
datadog,Make sure you have additional technical metrics at hand.
datadog,You do want to quickly react in case of any failures ‚Äî in that case no data is better than incorrect data.
datadog,Create detailed technical metrics.
datadog,They can be invaluable for you and ops.
datadog,They allow fast reaction times to issues and shorten debugging time as usually you can quickly pick out the culprit.
datadog,"Eliminate false positives immediately, modify alarms that create a lot of noise and for which you can see that they quickly get ignored."
datadog,You monitoring system must be actionable.
datadog,An example taken from Datadog blog which shows some more advanced technical metrics dashboard.
datadog,"Invaluable to developers, not so much for business guys
Offer your help with creation of any new dashboards."
datadog,Such need may arise if communication and understanding is at high level.
datadog,And this is good because basically you have created a successful business intelligence platform.
datadog,Do not create and maintain your own monitoring system ‚Äî buy SaaS one.
datadog,"Focus on business value and not on fighting with keeping your own system working, be scalable and up to date."
datadog,You will quickly find out that you would like more and more data and your monitoring system cannot be a bottleneck.
datadog,We are using Datadog to gather data from a couple of thousand applications and it is doing very well.
datadog,Why does it all matter?
datadog,"Well, mainly because it allows business people to make better decisions‚Ä¶or make decisions in general."
datadog,They allow to constantly monitor ROI which can have good psychological effect as well.
datadog,"Moreover, lack of metrics could easily postpone or even make impossible for certain actions to be executed."
datadog,"Good metrics allow to observe changes to the system, to see how they affect revenue or any other important indicator."
datadog,Then proper decisions can be made ‚Äî drop the feature or continue..or modify and reevaluate?
datadog,"Without metrics such features could well be dropped without evaluation, without a try."
datadog,"Most of these best practice points are aimed to create good working relations between devs, ops and business."
datadog,"They help build mutual understanding, trust, respect and communication."
datadog,"You, as a developer don‚Äôt like to hear that something is wrong or something is not working (we all have heard it before) ‚Äî it is much better to hear that such and such metric is at suspicious value and then investigate while being on the same level."
datadog,"Good metrics systems give the feeling of system stability, when everyone interested knows about current system status."
datadog,It doesn‚Äôt matter if you manage 2 or 2000 servers ‚Äî you need to have good metrics and monitoring system in place.
datadog,"Actually, for 2000 servers this is necessary, no questions asked, but if you will think about all of this when you have only 2 servers, then you are perfectly ready for the future."
datadog,You know exactly what is going on and why and it is much easier to upscale.
datadog,Who doesn‚Äôt like to have relevant information at the right time?
datadog,We know we do!
datadog,Here at Pattern Match we are highly experienced with monitoring and keeping tight operations for massive scale distributed enterprise applications.
datadog,The best reference for us is that most of the time we know about problems before client does.
datadog,We can help you write scalable solutions hosted in public cloud.
datadog,We hire only engineers with 8+ year of experience.
datadog,We are experienced in many languages and tech stacks.
datadog,"We are happy to help you architect, prototype, implement and scale your software."
datadog,"We are full-stack employees, not developers."
datadog,"If we gained your attention, and you would be interested in working with us, please drop us a line here."
datadog,"New features
New integration: Rollbar
New integration: Datadog
You can now use SSH keys defined in the environment variables in actions using SSH authorization (SFTP, SSH, Rsync, Git push, etc.)"
datadog,"New version of Sandboxes released for private beta testers
Improvements
Rsync deployments now support Buddy keys
Cloning a pipeline will now clone static files and visibility settings, too
It is now possible to set up the mount path for the pipeline filesystem in build actions with YAML/API
Bugfixes
Fixed browsing in the Rsync action (didn‚Äôt work as Rsync was authorized with an SSH key)
Fixed bug with testing and sending Slack attachments"
datadog,"We live in a time where so many of our tools in software development make our lives so unbelievably easy, but at the same time so !"
datadog,@#$ing miserable.
datadog,Recently we faced a dilema with our PaaS tool OpenShift that created a bunch of friction between our own internal teams and our metrics platform and vendor DataDog.
datadog,"TL;DR
The code to solve your DataDog non-root headache can be found at https://github.com/ctoestreich/datadog-agent-rootless
The Players
DataDog
I won‚Äôt make this a sales pitch for DataDog and keep this more about the issue, but their metrics platform and alerting are amazing."
datadog,"You can read more about their offering at http://www.datadoghq.com
OpenShift
Red Hat built a pretty nice PaaS around kubernetes that is called OpenShift."
datadog,"I will also not pitch this tool and you can, again, read about this on your own if you are unfamiliar with it at https://www.openshift.com/container-platform/index.html
Docker

Containers Though!"
datadog,"The Problem
OpenShift allows ops admins to set a policy that disables running containers using root."
datadog,"I have read their information and other info on security and our operations team has decided, for better or worse, to disable root access globally and only allow running as non-priviledged users."
datadog,I will admit that this is PROBABLY the correct thing do.
datadog,"However, it created a bunch of issues for us running supporting infrastructure containers as many platforms designed their conatiners to run as root whether intentional or otherwise."
datadog,These simply would not start when attempting to deploy to OpenShift.
datadog,The DataDog agent is no exception to this rule as it both uses root to run supervisord and to access the docker socket.
datadog,"Recent changes in Kubernetes would seem to address some of these general concerns about ‚Äúescaping‚Äù containers if running root, but we are merely a consumer of the platform and despite some begging and pleading we were unable to affect these enterprise policies."
datadog,"The Fix
We asked DataDog to help fix this issue and create a non-root runtime."
datadog,They were helpful in their repsonses but creating and maintaining a rootless container wasn‚Äôt a priority for them.
datadog,I finally dove in and made the appropriate changes to get this running.
datadog,It was a combiniation of hacking the supervisor.conf to run as nobody and fixing directory permissions.
datadog,The repo can be found at https://github.com/ctoestreich/datadog-agent-rootless.
datadog,"Github Repo
The github repo contains two docker images; one based on DataDog‚Äôs own docker-dd-base and another that uses a centos base image."
datadog,The reason for both is that we specifically have a custom jdk base image and we needed the ability to have our own base image.
datadog,I tried to reflect installing the agent via the web inside a container using a custom base image in the centos-base directory.
datadog,In the centos-base image I did a bit more modifications as some of the logic that is normally baked into the docker-dd-base needs to be setup manually; very specifically we need to provide our own datadog.conf file as the agent install from the web will provide a default one that doesn‚Äôt contain any of our specific tags or host name.
datadog,Below is the datadog.conf filethat has some place holders that the entrypoint.sh will replace with environment variables of the same name when the container starts.
datadog,"Conclusion
Hopefully if you are root-challenged like we are you will find this post and code useful."
datadog,"If you have faced this same challenge or have another solve for this problem, please let me know."
datadog,The views and opinions expressed in this article are those of the author and do not necessarily reflect the official policy or position of any vendor or employeer associated with the author.
datadog,"Either because it is cost-efficient, gets the organization closer to NoOps, or allows for faster iteration, serverless computing is increasingly relevant for specialized use cases such as powering ETL pipelines or acting as glue for DevOps tools."
datadog,This post summarizes my findings from building WikiRoam ‚Äî a fullstack serverless architecture running on AWS and powered by the Serverless Framework.
datadog,"[Repo]
Disclaimer: WikiRoam is a proof-of-concept built as a week-end project to explore the consequences of serverless computing on monitoring approaches."
datadog,"It is not meant to be pretty, optimized, or secure."
datadog,Use at your own risk.
datadog,":)
Architecture
The application is structured in 5 layers:
A static Angular frontend served directly from S3."
datadog,A Lambda-based API layer exposed through API Gateway.
datadog,An ETL pipeline built on Step Functions and triggered by SNS messages for asynchronous processing.
datadog,A noSQL database layer powered by DynamoDB.
datadog,"A turn-key monitoring infrastructure provided by Datadog, through its AWS integration."
datadog,"The first 4 layers are configured and deployed through the Serverless framework, in YAML files that describe the provider (i.e."
datadog,"AWS only in this case), the functions, and resources."
datadog,"Additionally, the following serverless plugins are used: serverless-client-S3 (to simplify the deployment of the frontend to S3), serverless-step-functions (see 3. above), and serverless-pseudo-parameters (for convenience)."
datadog,Let‚Äôs dive into each layer and discuss takeaways and lessons learned.
datadog,1.
datadog,"Javascript Frontend
The Angular application is hosted directly on S3, in a bucket named www.wikiroam.com (for production), so as to allow the definition of an ‚Äòalias record‚Äô pointed to the S3 bucket in Route 53."
datadog,Note that the serverless-client-S3 plugin takes care of configuring the bucket for website hosting.
datadog,The Angular app simply lets the user search wikipedia (through the MediaWiki action API).
datadog,"It then displays relevant articles as cards, and triggers an ETL workflow that caches articles (reactively) and their backlinks (proactively)."
datadog,Basic styling courtesy of Angular Material.
datadog,"Reactive search provided by RxJS:

debounceTime() ensures the frontend waits for the user to stop typing during 300ms before calling the API."
datadog,distinctUntilChanged() checks that the new keyword is different from the previous one.
datadog,switchMap() ensures only the answer from the latest call is awaited for.
datadog,2.
datadog,"Lambda-based API
The Serverless framework allows to easily publish an API endpoint powered by lambda functions."
datadog,The handler points to the lambda function named ‚Äòget‚Äô exported from the ‚Äòapi/wikipages.js‚Äô module.
datadog,i.e.
datadog,"‚Äòmodule.exports.get = (event, context, callback) => {//do stuff}‚Äô
The API Gateway should ideally be tied to a domain such as api.wikiroam.com but AWS requires a certificate to do so."
datadog,"Due to time constraints, the url for the API is currently hard-coded in the frontend instead."
datadog,"Fortunately, Serverless relies on a single CloudFormation stack (per stage, i.e."
datadog,"environment) to create and update the resources and functions, meaning that the url doesn‚Äôt change."
datadog,3.
datadog,"ETL Pipeline
The caching logic is modeled as a Step Function, where each step is modeled as a lambda function, and the state transitions are guided by the State Machine."
datadog,"While this is obviously overkill for this simple use case, it resulted in cleaner code and logic than invoking lambdas from within each others."
datadog,cacheStart() checks whether a specific article is already cached to decide whether to continue or end the workflow.
datadog,cacheInfo() inserts the article in a DynamoDB table and cacheBacklinks() inserts the corresponding links into another table.
datadog,The workflow itself is triggered by receiving an SNS message.
datadog,"However due to a current limitation of Serverless, the Step Function itself can only be exposed through http, thus requiring a lambda to act as a wrapper (i.e."
datadog,receive the SNS message to trigger the execution of the Step Function).
datadog,4.
datadog,"Managed NoSQL database
The tables and their indexes are configured directly in the ‚Äòserverless.yml‚Äô file, with the TableName being dependent on the stage (i.e."
datadog,the environment).
datadog,The DeletionPolicy setting ensures the data is not scrapped on each update.
datadog,"As of 2017, DynamoDB can auto-scale."
datadog,This setting can be configured through a Serverless plugin.
datadog,Defining indexes is required to maintain acceptable performance if the API is expected to scan based on attributes different from the primary key.
datadog,5.
datadog,"Monitoring-as-a-Service
The integration between Datadog and AWS exposes default AWS metrics, across a wide range of AWS products including API Gateway, Lambda, and DynamoDB."
datadog,"Beyond that, Datadog is able to ingest metrics from specially-crafted CloudWatch log messages."
datadog,This simple script is all that‚Äôs needed to track custom metrics within the lambda functions.
datadog,Datadog has an in-depth guide for how to effectively monitor a serverless stack.
datadog,It includes suggestions for how to track both work metrics (e.g.
datadog,"throughput, latency) and resource metrics (e.g."
datadog,throttles).
datadog,"In my case, the resulting dashboard tells a compelling story despite the decentralized nature of the architecture."
datadog,"Around 10.40pm, the system experienced a spike in database latency above acceptable thresholds due to DynamoDB saturating provisioned write throughput."
datadog,"In turn, the increased response time caused the cacheBacklinks() lambda within the ETL pipeline to timeout on several occasions, likely resulting in gaps in the cache."
datadog,There is no indication that users were affected.
datadog,Pretty neat.
datadog,The next frontier would be to expand the serverless monitoring approach from metrics (timestamp + counter or gauge) to logs (timestamp + message) and traces (timestamp + context).
datadog,I‚Äôm guessing the Logmatic acquisition is meant to answer the first point.
datadog,"For the second, the APM product could be expanded to either:
Provide a library to ‚Äòpatch lambdas‚Äô and cascade traces across invocations,
Import X-Ray traces through the AWS integration, or
Ingest arbitrary opentracing spans through CloudWatch."
datadog,Flynn as an open-source PaaS is easy to use and allows quick and safe release of new version of our software.
datadog,"By extending it with monitoring and analysis from DataDog, we create a fully functional environment."
datadog,"In this article, I would like to share my experience with configuring Flynn app and DataDog agent."
datadog,"Step 1: DataDog agent on server
Agent on server allows analyzing state of our hosts."
datadog,The code to install agent can be found in Agent tab (in Integrations).
datadog,Installation of this code guarantees automatic restart of the agent when restarting the server.
datadog,"Installing agent on Ubuntu ‚Äî view DataDog Integrations
Step 2: Generate API key
To be able to send statistics from our app to DataDog, we must have the API key."
datadog,You can generate new key or use default one (generated automatically when creating account).
datadog,"Generate new or use default API key
Step 3: Set environment variables
Having access to the application from console (e.g."
datadog,flynn -a my_app run bash) we can set necessary environment variables.
datadog,This allows you to set up a safe and verified connection between Flynn app and DataDog HQ (via DataDog agent).
datadog,You can use the code below.
datadog,Just remember to change bold snippets to match your app and API key.
datadog,"flynn -a my_app env set HEROKU_APP_NAME=YOUR_APP_NAME
flynn -a my_app env set DATADOG_API_KEY=API_KEY_FROM_DATADOG
Step 4: Buildpack with DataDog agent
When you push your changes to Flynn git (and create new release), Flynn start buildpacks stored in Procfile."
datadog,Add a new buildpack to your list.
datadog,I recommend setting this Git source as first in Procfile.
datadog,"miketheman/heroku-buildpack-datadog
heroku-buildpack-datadog - Heroku Buildpack to run Datadog DogStatsD in a Dyno
github.com

Step 5: Release
If you have done all the steps above, you should not have any problems with starting DataDog analytics and sending your statistics."
datadog,Push changes to Flynn Git and take advantage of opportunities offered by their analytics for your services.
datadog,"Summary
Analytics is required for detecting weak points in our services (e.g."
datadog,choke points).
datadog,"With this integration, you can identify and fix them."
datadog,It is also a good way to analyze user experience.
datadog,DataDog users already know they have agent checks available for a variety of different products and services.
datadog,But what if there‚Äôs something you need to monitor that‚Äôs not currently supported?
datadog,Then it‚Äôs time to write your own.
datadog,"Complete source from this article available from https://github.com/denniswebb/datadog-openvpn
Use Case
I have multiple customers using OpenVPN AS from the AWS Marketplace for remote access to the AWS VPC."
datadog,"It‚Äôs a great solution because setting up a server requires very little configuration, and the client software is simple to setup on both Windows and Mac clients."
datadog,"When launching an instance, you choose how many licenses you need."
datadog,"Of course as customers grow, so does the number of licenses used."
datadog,Monitoring available licenses is a must because users not being able to connect because they unexpectedly outgrew the connection count is just poor management.
datadog,"To prevent this, I wanted a DataDog alarm setup to warn us when available licenses crossed a threshold."
datadog,"Before We Start Writing Code
The first step was discovering an easy way to get the license statistics."
datadog,The sacli command has a parameter named LicUsage that does that.
datadog,"sacli LicUsage showing 30 of 50 licenses used
The command outputs a string that represents a list."
datadog,"The first element is the number of licenses in use, and the second is the total number of connection licenses."
datadog,That‚Äôs all the info we need as a basic subtraction will give us the number of available licenses.
datadog,"Writing the Code
DataDog Agent Checks are made up of 2 files, <project_name>.py and <project_name>.yaml."
datadog,These files should be saved in /etc/dd-agent/checks.d and /etc/dd-agent/conf.d respectively.
datadog,The first file we‚Äôll create is /etc/dd-agent/conf.d/openvpn.yaml.
datadog,Agent config files have 2 sections: init_config and instances.
datadog,Below is our configuration file where we‚Äôll set 2 parameters in the init_config section.
datadog,metric_prefix will be the prefix for the metric name and sacli_path is the full path to the sacli tool.
datadog,The instances section defines one or more instances to check.
datadog,"If we were reporting file sizes, the ability to specify more than one file would be nice."
datadog,This is what this section is good for.
datadog,"Since it is required, I put a single empty object to satisfy the requirement."
datadog,"init_config:
  metric_prefix: openvpn
  sacli_path: /usr/local/openvpn_as/scripts/sacli

instances:
    [{}]
Now we‚Äôll create the actual agent file in /etc/dd-agent/checks.d/openvpn.py."
datadog,The file extension already tells you this is a Python module.
datadog,Start by adding the imports section and declaring our new class that comes from DataDog‚Äôs AgentCheck module.
datadog,"from checks import AgentCheck
class OpenVPN(AgentCheck):
    def check(self, instance):
if __name__ == '__main__':
    check.check(instance)
This is boilerplate that does nothing yet."
datadog,The class‚Äôs check function is what‚Äôs called by the DataDog service regularly.
datadog,"To use the parameters in our configuration file, we call init_config.get."
datadog,"This returns the stored value, and if none is found, the second parameter is the fallback value."
datadog,"def check(self, instance):
    metric_prefix = self.init_config.get('metric_prefix', 'openvpn')
Next up we‚Äôll add a function to return a dictionary of the various OpenVPN license usage statistics."
datadog,For this we‚Äôll use Pythons ast and subprocess modules.
datadog,Add these import lines to the top of your file.
datadog,"The check_output function will return the output of sacli LicUsage, while ast will be used to convert the stringified list outputted to a real Python list."
datadog,"import ast
from subprocess import check_output
The get_license_usage function is added to the OpenVPN class."
datadog,The function returns a dictionary of the license usage statistics returned by sacli.
datadog,You‚Äôll notice I used sudo to run sacli with elevated permissions.
datadog,Unfortunately the command must be run with root privileges to work.
datadog,Later i will cover adding the dd-agent user to /etc/sudoers to allow this.
datadog,"def get_license_usage(self):
    sacli_path = self.init_config.get('sacli_path', '/usr/local/openvpn_as/scripts/sacli')
    lic_usage = ast.literal_eval(check_output([""sudo"", sacli_path, ""LicUsage""]))
    return {
        'used': lic_usage[0],
        'total': lic_usage[1],
        'available': lic_usage[1] - lic_usage[0]
}
Adding more functionality to our check function, we add a variable to hold the results of the get_license_usage function."
datadog,The final 3 lines call the AgentCheck class‚Äôs gauge function to push the 3 metrics to DataDog.
datadog,"The format is gauge(<metric.name>, <metric-value>)."
datadog,"In addition to gauge type, DataDog also support count and increment."
datadog,"For a complete list of metrics you can send, see this article."
datadog,When submitting metrics you can add tags by using the named parameter tags and passing a list of tags to it.
datadog,"def check(self, instance):
    metric_prefix = self.init_config.get('metric_prefix', 'openvpn')
    license_usage = self.get_license_usage()
    self.gauge('%s.licenses_used' % metric_prefix, license_usage['used'])
    self.gauge('%s.licenses_available' % metric_prefix, license_usage['available'])
    self.gauge('%s.licenses_total' % metric_prefix, license_usage['total'])
The Completed Agent Check
The complete project is available on GitHub at https://github.com/denniswebb/datadog-openvpn
import ast
from checks import AgentCheck
from subprocess import check_output

class OpenVPN(AgentCheck):

    def check(self, instance):
        metric_prefix = self.init_config.get('metric_prefix', 'openvpn')
        license_usage = self.get_license_usage()
        self.gauge('%s.licenses_used' % metric_prefix, license_usage['used'])
        self.gauge('%s.licenses_available' % metric_prefix, license_usage['available'])
        self.gauge('%s.licenses_total' % metric_prefix, license_usage['total'])

    def get_license_usage(self):
        sacli_path = self.init_config.get('sacli_path', '/usr/local/openvpn_as/scripts/sacli')
        lic_usage = ast.literal_eval(check_output([""sudo"", sacli_path, ""LicUsage""]))
        return {
                    'used': lic_usage[0],
                    'total': lic_usage[1],
                    'available': lic_usage[1] - lic_usage[0]
                }

if __name__ == '__main__':
    check.check(instance)
Final Steps
We‚Äôre still not done."
datadog,Remember we need to run sacli with elevated privileges.
datadog,The easiest way to accomplish this is to add the following line to your /etc/sudoers file using the visudo tool.
datadog,This allows dd-agent to run sacli as root without being prompted for a password.
datadog,"dd-agent ALL=NOPASSWD: /usr/local/openvpn_as/scripts/sacli
We need to test that our custom check runs without giving errors."
datadog,The command to test a DataDog check is sudo -u dd-agent dd-agent check openvpn.
datadog,"If no errors are returned, restart the DataDog agent with sudo /etc/init.d/datadog-agent restart."
datadog,"You can find your 3 new metrics in the DataDog app as openvpn.licenses_available, openvpn.licenses_used, and openvpn.licenses_total."
datadog,And that‚Äôs all there is to it.
datadog,I hope this tutorial helps anybody looking to create their own DataDog agent check.
datadog,DataDog has an article titled Writing an Agent Check that has another example.
datadog,Also be sure to discover the different types of metrics you can send along with events.
datadog,"Being a ‚Äúdevops‚Äù kind of person, I have a weird love for graphs."
datadog,"Also, I recently heard a lot of talk about how the ISP I have been using has seen a lot of degradation in performance since it was bought out by another entity."
datadog,"Not being one to blindly believe rumours, I thought I could do some measurements and find out if it was time to switch."
datadog,"Using a combination of speedtest-cli and statsd, and taking some inspiration from the post I co-wrote a few years ago at Redbubble, I put together a small script which I could run on a once-every-ten-minutes cronjob:
#!/bin/bash

STATS=`/usr/local/bin/speedtest-cli --json --server 2169 --bytes | /usr/bin/jq '.ping,.download,.upload'`

PING=`/bin/echo ${STATS} | /usr/bin/awk '{printf ""%d"", $1}'`
DOWNLOAD=`/bin/echo ${STATS} | /usr/bin/awk '{printf ""%d"" ,$2}'`
UPLOAD=`/bin/echo ${STATS} | /usr/bin/awk '{printf ""%d"", $3}'`

/bin/echo ""skymesh.ping:${PING}|g"" | nc -w 1 -u localhost 8125
/bin/echo ""skymesh.download:${DOWNLOAD}|g"" | nc -w 1 -u localhost 8125
/bin/echo ""skymesh.upload:${UPLOAD}|g"" | nc -w 1 -u localhost 8125
Note ‚Äî I already had the datadog agent running on my linux machine at home, and it was set to have dogstatsd listening on the UDP port 8125

Datadog happily graphing values from statsd
Et voil√†!"
datadog,"Once this was running, data started to flow right into Datadog!"
datadog,"Conclusion: At consistently ~96Mbit download and ~30Mbit upload, I‚Äôm pretty happy with my connection."
datadog,"Latency is looking a bit off though, might need to investigate that ;)"
datadog,"In the DevOps lifecycle, Monitoring is one of the major phases."
datadog,It makes sure that all the applications running in your production environments run continuously without any failure.
datadog,"In Bukalapak, we have around ~10400 monitors alerts in our environment."
datadog,"If any failures occur, it will send a notification to on-call personnel so engineers can tackle it as soon as possible."
datadog,"In this article, I will share how we manage to integrate Monitoring and alerting tools: Datadog and also incident management tools: OpsGenie."
datadog,"(Why)
I will start from the first early stages of services migration to the cloud in March 2019."
datadog,"At that time, we are still running our Monitoring and alerting system with Prometheus."
datadog,"As we grow, we realize that we need to improve our monitoring system by implementing Infrastructure as code."
datadog,We need a monitoring system with a complete journey of Monitoring and the alerting system itself.
datadog,"All through code and pipeline Automation, start from onboarding, monitoring agent deployment, delivering metrics, managing dashboard, Integration to ‚ÄúOn-Call‚Äù incident management system, configuring our alerts priorities, alerts Escalation policies, monitoring/alerts deployment."
datadog,"Okay, let‚Äôs start to break them down to tackle them one at a time easily."
datadog,"# Onboarding
Thank god our security team is also adopting the Infrastructure as code and run their pipeline and custom script to onboard and offboard people in this organization."
datadog,Kudos to security team in Bukalapak.
datadog,"# Monitoring Agent Deployment
Our infrastructure ecosystem consists of Kubernetes, VM, and Bare Metal."
datadog,"So here is what we‚Äôve done so far:
Kubernetes: We build our pipeline to deploy a monitoring agent to our k8s cluster as a daemon set
VM: We bake our monitoring agent into the image for VM in our DC, and we execute agent monitoring deployment during instance provisioning in GCP
Baremetal: We include a monitoring agent as part of our Ansible provisioning for our Bare Metal
# Delivering Metrics
Without metrics, we will not be able to create a Dashboard."
datadog,"Metrics delivered by an agent with a pre-installed module, custom scripts that we‚Äôve made, or using custom StatsD by orchestrate code and send important metrics for services into our Monitoring platform and will acknowledge it as ‚ÄúCustom Metrics.‚Äù
Metrics have their type, understand the kind of metrics will make our life easier while creating Dashboards."
datadog,"Please take a look at refs URL
# Managing Dashboard
Although We can create Dashboard through Automation and pipeline, we decided not to do so in this rapid migration and deployment phase."
datadog,"As an alternative, we provide a Dashboard template."
datadog,"The monitoring team created Dashboard templates to support different monitoring levels starting from apps, databases, queues, etc."
datadog,"We provide Automation to Backup our Dashboard; if we accidentally removed or deleted the Dashboard, we can recover it from our Backup in our GCS ( Google Cloud Storage )."
datadog,"# Integration to On-Call Management System
Up to this point, we‚Äôve metrics and Dashboard in Datadog."
datadog,"Now, let‚Äôs start playing around with our on-call management system."
datadog,"It‚Äôs essential to define our alerts monitors priority, alerts monitor routing based on priority, on-call schedule structure, and Escalation structure."
datadog,"To enable or establish a connection between our Monitoring platform with the on-call management system, we need to exchange the API Key, API Key from OpsGenie, stick into Datadog, and API from Datadog need to stick into OpsGenie."
datadog,This process needs full authorities to access a particular part of a page with a list of Integration on both parties.
datadog,We create a pipeline to configure squad (team) in our On-Call management system.
datadog,"We choose ‚ÄúOpsGenie‚Äù as our On-Call management system as it provides us rich API that we can use to automate our process of managing squads (team) such as team members, Escalation, and schedule."
datadog,"# Configure Alerts Priorities
Every company is unique and has it‚Äôs own way and standard on how to determine Alerts of P1, P2, P3 up to P5."
datadog,Some of the company only aware of P1 and P2.
datadog,"So are we, in Bukalapak here it‚Äôs what we define as P1, P2, P3 up to P5
P1: Bukalapak wide incident
P2: Service Critical Down / UnAcceptable Performance
P3: Service Non-Critical Down
P4: Non-SLO Alerts
P5: Non-Production issue
# Alerts Escalation Policies
Monitor alerts escalation policy is a company policy handling escalation based on organization chart ( org chart )."
datadog,"There are two things that we need to define:
Who will be the next person
How long until it goes to the next person
In Bukalapak, we escalate our Alert based on priorities, P1 and P2 Alert escalated up to VP Level."
datadog,P3 Alerts up to P5 will only go to Head of Engineering Level.
datadog,"To give more context, herewith what we‚Äôve implemented so far for P1 and P2."
datadog,Primary will be paged immediately after an alert is fired.
datadog,Expected to ack in 5 minutes.
datadog,Secondary will be paged 5 minutes after an alert is fired.
datadog,Expected to ack in 5 minutes.
datadog,All team members will be paged 10 minutes after an alert is fired.
datadog,Expected to ack in 5 minutes.
datadog,EM and Head will be paged 15 minutes after an alert is fired.
datadog,Expected to ack in 5 minutes.
datadog,VP will be paged 20 minutes after an alert is fired.
datadog,"# Monitor / Alerts Deployment
We have more than 50+ Product Engineering Squad with more than 15+ Tribe."
datadog,We know and are aware of all monitor / alert deployment is managed by the infrastructure monitoring team.
datadog,"It will not scale, and the most likely team will become the blocker."
datadog,"We created a Pipeline to deploy our monitors/alerts, provide the guide on how to submit MR / PR, configure their monitor/alerts, sample query for the monitor, and set priority tags for each Alert."
datadog,This documentation is part of our operational runbook and well maintained by the Monitoring team.
datadog,That‚Äôs all the bold part; details in each item above have their challenges.
datadog,"(How)
Thank God we have a reliable team, understand what they are doing, and have less supervision."
datadog,They‚Äôve done great things for this organization.
datadog,"Okay, let‚Äôs summarize it."
datadog,"First, we list them all down in the note, populate them as Jira‚Äôs story, and break it down and distribute it to the team."
datadog,"Automate your onboarding/offboarding process to the Monitoring platform system
Create Automation to deploy your monitoring agent
Create Template for your Dashboard
Automate your Team creation through Custom script and run it as a Pipeline
Establish Integration from Monitoring platform to On-Call Management
Create a standard for Alerts prioritization
Create a standard for Escalation based on Alerts prioritization
Automate your Monitors/Alerts deployment via pipeline
During the process, we release them bit by bit, we track the progress every Friday as part of weekly meetings, get feedback over here and there, take a note and convert it into a Jira story."
datadog,"The case might be different for each organization, so shipping it bit by bit will make it easier to adopt the changes and fast feedback delivery."
datadog,"(What)
This what have achieved so far
We have our pipeline to deploy alerts monitor ( include synthetics monitors deployment pipeline )."
datadog,We have our pipeline to deploy our on-call schedule into OpsGenie.
datadog,"We have ~10K Alerts Monitors deployed thru our pipeline
We have ~4K Dashboard Monitoring
We have successful ~13K pipelines
We have average pipeline execution within ~15 mins
Our Oncall Schedule Maintain Thru our Automation Pipeline
Our Oncall Schedule Maintain Thru our Automation Pipeline
Our Opsgenie with Alerts Monitors Priority Configured
Our Opsgenie with Alerts Monitors Priority Configured
Datadog Synthetics Monitoring
Datadog Synthetics Monitoring
Datadog Monitors ( Sample )
Datadog Monitors ( Sample )
Our pipeline to deploy alert monitor in Datadog
Our pipeline to deploy alert monitor in Datadog
One of our Datadog Dashboard
One of our Datadog Dashboard
There is always room for improvement."
datadog,Nothing is perfect.
datadog,"We‚Äôre still doing our best to meet our expectations, and again nothing is magic in the Automation by the end of the day."
datadog,"Someone needs to maintain the code and Automation (e.g., pipeline), keep it standard and up to date."
datadog,Originally published in The New Stack Update.
datadog,"Since NGINX is deployed most often on Datadog customers‚Äô Docker containers, we thought it appropriate to use the chart above as a ‚Äúproxy‚Äù for the cloud-native world."
datadog,"From this perspective, all the top technologies are open source, and most of them support data and messaging infrastructure."
datadog,"Interestingly, every single technology is now offered as a service (aaS)."
datadog,"Despite the effort needed to keep distributions up to date, most won‚Äôt let you choose to pay for supported elasticsearch, Redis or MySQL."
datadog,"Moving forward, we know companies are looking forward to selling you services with verified Docker images that contain many of these offerings."
datadog,"Alternatively, most major cloud providers are beginning to offer them, just as they also provide supported Apache servers with web hosting."
datadog,"Is not a secret for all of us working on IT that, an architecture pattern is changing the way we are doing things."
datadog,"Yes, I‚Äôm talking about microservices."
datadog,"But don‚Äôt worry, I am not going to describe this architectures pros and cons."
datadog,"Microservices -combined with cloud and devops- are turning around our way of doing things, and monitoring is not the exception."
datadog,"The fact is that, while applications and dependencies are growing faster than ever, traditional monitoring tools (nagios, ganglia, Ca synthetic monitor, dynatrace,‚Ä¶) are unable to hold the pace."
datadog,"Therefore, a year ago in Hotelbeds Group we decide to move forward and start defining our new monitoring stack."
datadog,"In the following lines, I shall try to explain the definition and selection process ‚Ä¶."
datadog,"The Focus have changed
A year ago on an internal presentation I used the following two images to illustrate our new monitoring approach:

Traditionally we monitor systems by adding alerts based on predictable situations."
datadog,For instance when the critical host CPU goes over a predefined threshold we know that we will face problems.
datadog,In the most critical systems we also add synthetic monitoring that simulate our clients behaviour and measure the response in order to know our platform performance.
datadog,"But at the end, we always think on monitoring focusing on our systems."
datadog,"The problem is that real life is more complicated and probably your environment are mostly like the following image:

But what is the main difference between those two images?"
datadog,"‚Ä¶ Of course, the bulls are the main difference!"
datadog,The bulls represents the clients.
datadog,They are who set the real pace on our systems.
datadog,They are who evaluate our performance (thousand of times per second).
datadog,"By knowing how our client is perceiving our performance, we really know how our systems are working."
datadog,"Therefore we have to change our focus from systems to clients, from synthetic measures to real transaction metrics."
datadog,In fact when we start thinking on our client metrics we also have a better understanding which system metrics really matters.
datadog,Once you start monitoring your client‚Äôs performance you understand how to monitor your systems.
datadog,"Analyze future problems
As an architecture team, we like to start with the analytic part on every problem."
datadog,In this case we were not working on actual problems.
datadog,"Instead, we were facing new challenges that come out as a result of our new architecture patterns and so, moving on a more theoretical approach."
datadog,"From the beginning we saw that we need to be ready for:
Increase of the number of applications and hosts to be monitored
More dependencies between applications
More applications involved by the same ‚Äútransaction‚Äù
Business process even more difficult to model as a linear transaction."
datadog,"More ephemeral infrastructure
Therefore, the new monitoring stack has to adapt to this new situation providing the necessary tools to work on these new scenarios."
datadog,"As-is To-be
When we have a good understanding on what we need, we start challenging our entire monitoring stack."
datadog,"On the very beginning, we try to figure out if Nagios is the best solution."
datadog,"While comparing this so common open source tool with other more powerful -and expensive- tools like zenoss or Patrol, we found a game changer called Datadog."
datadog,They offer a powerful solution to monitor systems based on metrics stored on the cloud.
datadog,Their new monitoring approach introduce more and more doubts on our current one.
datadog,Do we have to select a full stack tool that cover all our needs?
datadog,Does this tool already exist?
datadog,Can we try to se select a combination of best in bread?
datadog,What should include?
datadog,"With those questions in mind, we start drawing what a full monitoring stack have to include."
datadog,Putting all together on a Venn Diagram and introducing our ‚Äúas-is‚Äù technologies give us an eye view on the task we are facing.
datadog,"Monitoring stack (as-is)
Once we have our As-is pretty clear we started working on the To-be, that usually is the hardest but funniest part of the process."
datadog,"Integrations are the key
Very soon during the process, we notice that integration will be the key on our new monitoring stack."
datadog,"Having the possibility to collect metrics from our applications and integrate them with the synthetic monitoring, APM or AWS cloudwatch will move our monitoring tools to a next level."
datadog,The good news are that all the actual monitoring vendors know it and therefore the integrations supported are nowadays an important part of the product functionalities.
datadog,"Three selection Process
Doing a selection process is part of our normal job as Technology architects."
datadog,"We start defining the aim of the selection, then introduce the players, if possible made a short list based on the most obvious and then we try to go deeper on the details on every product trying to understand all the pros and cons."
datadog,"Outsourcing a POC is the same as viewing a demo
In order to do this selections we always try to test the products ourselves with a Proof Of Concept (POC) and we ever do our own POC‚Äôs."
datadog,"Outsourcing a POC is the same as viewing a demo, you will only be the beauty part and lost all the info about how product is installed, maintained, how it performs, etc."
datadog,"Therefore it take some time to do a selection but, when it is about selecting technologies that will sustain your business on the future, it pays off."
datadog,"The three big selection process were:
Metrics system: Datadog, Ganglia, riemman-influxdb-grafana
APM: New Relic, Dynatrace, AppDynamics, AppInternals
Synthetic Monitoring: Pingdom, New Relic, uptrends, monitis,
Probably I will explain these selections on future articles but, just to understand what we are looking for on every selection, common requisites were:
Scalable: as a solution and supporting services that scale up and down."
datadog,Cloud First: We prefer not to increase our own infrastructure with new systems.
datadog,Affordable: We cannot introduce a huge cost to our platform.
datadog,Easy to use and maintain: We want to delegate the use of the monitoring tools to the product teams as we are moving to devops.
datadog,"After doing all the selections and documentation process the resulting monitoring stack were as follow:

Monitoring stack (to-be)
Big Bang or incremental approach
Putting in place a new architecture is even harder than the design process."
datadog,Simplifying it to the maximum you can go for a big bang or a incremental approach.
datadog,"Big bang, in this case, means finding a budget for a big project that aims to change all your current monitoring tools and then start migrating applications until you decommission the older tools."
datadog,"On the incremental approach, we just need to put in place the new tools and give all the other -new projects, product teams, other departments- the information they need to start using it."
datadog,"In our case we go directly to the incremental approach, knowing that it will mean a longer path."
datadog,"Fortunately at that moment, we are reviewing also other parts of our architecture and, the projects needed on that evolution could also include the new monitoring tools."
datadog,I want to close this article by giving thanks to all the Technology Architecture team involved on this process and specially to Alfonso Fernandez (@alfonsof) Hotelbeds Group Chief Architect by those days.
datadog,Without his perpetual questioning and support probably we had not gone so far.
datadog,"(Originally published on Netsil‚Äôs blog)
Most modern application monitoring systems consist of the following 3 core components:
Collector ‚Äî daemon(s) to gather metrics
Time Series database ‚Äî for storage of real-time, high volume metrics
Query & Visualization ‚Äî that enables queries and display charts to understand metrics
We have already covered time series database comparison including InfluxDB, Cassandra and Druid."
datadog,"On the visualization front, the primary shift is from a dashboard-centric approach to more ad-hoc query-centric UIs."
datadog,The Netsil Analytics blog post provides examples of query-centric approach to analyze metrics for monitoring.
datadog,"In this post, we compare the popular collector daemons and present an overview of Netsil collectors."
datadog,"Three Core Components of Modern Application Monitoring
Collector Daemon Comparison
Collectd, Telegraf and dd-agent are among 3 popular collector daemons."
datadog,The table below provides comparison for these collectors across multiple dimensions.
datadog,"While collectd is the oldest and most mature among the three, it is lacking in several key integrations with widely used systems."
datadog,"Some examples of missing collectd integrations include container frameworks such as Kubernetes, Mesos, Consul service discovery and etcd key-value store."
datadog,Most modern applications also heavily utilize tags.
datadog,Collectd doesn‚Äôt offer any good mechanism to ingest tags for the metrics.
datadog,Both Telegraf and dd-agent are relatively new and still maturing compared to collectd.
datadog,"While Telegraf is contributed by folks behind InfluxDB, dd-agent is a fork of sd-agent originally open sourced by Server Density and later forked by Datadog."
datadog,"The implementation language, Python for dd-agent and Go for Telegraf, may incur performance overhead compared to collectd which is implemented in C.
However, both dd-agent and Telegraf offer extensive integrations covering most of the commonly used systems of today."
datadog,dd-agent edges out Telegraf with more than 150 integrations and support for both tags as well as events in custom metrics.
datadog,But dd-agent doesn‚Äôt have good support for any time-series database out-of-the-box whereas Telegraf supports quite a few.
datadog,Figure 2.
datadog,"Comparison of Telegraf vs collectd vs dd-agent
Overview of Netsil Collectors
Netsil Application Operations Center (AOC) collector is a combination of open source dd-agent and an additional pcap based agent."
datadog,"This results in the following data sources generated by AOC collectors:
Data generated by capturing network interactions via pcap or SSLSplit This data is categorized under respective protocols such as HTTP, MySQL, DNS, etc."
datadog,"The data provides valuable insights into the golden signals of latency, throughput and error rates for services."
datadog,"Additionally, all the key application level attributes such as HTTP Status Code, URI paths, or MySQL Query Strings, etc."
datadog,are preserved and available for further analysis of the data.
datadog,"AOC data collectors include open source dd-agent for gathering specific system level insights such as operating system level metrics on cpu, memory, disk i/o; or performance metrics from MySQL/PostgreSQL servers."
datadog,Extensive set of applications are integrated with dd-agent and all of them are supported in the AOC as well.
datadog,"Custom application metrics, tags and events collected using dogstatsd."
datadog,Figure 1.
datadog,"Netsil AOC Auto-discovered Application Map and Golden Signals for Services
As a result of the above rich datasources, the AOC not only provides real-time metrics on all the popular application components but also leverages network interactions to map the dependencies among the services (see figure 1)."
datadog,"The metrics from pcap based packet analysis provide dependency information as well as insights for the golden signals ‚Äî latency, error rates and throughput of services."
datadog,"For Site Reliability Engineers (SREs) and operations teams, the combination of real-time map and metrics is extremely valuable for effectively monitoring health and performance of modern applications."
datadog,And the best part is Netsil doesn‚Äôt require any code change or code instrumentation!
datadog,You can get started free with Netsil map and monitoring today.
datadog,"Also, we would recommend to check out our very popular whitepaper on time-series database comparison which complements this post on collector comparison."
datadog,"The nature of sports media is cyclical, and we need to scale our infrastructure accordingly."
datadog,"Significant savings would come during periods of low activity, but we need to burst during big traffic events ‚Äúlike the NFL Draft, College Football Saturdays, NBA Free Agency, etc.‚Äù In order to achieve autoscaling nirvana, we needed to identify the tipping point of our apps."
datadog,"Out of the box, the AWS monitoring service, Amazon CloudWatch, only provides a cookie-cutter template of performance metrics such as CPU, network traffic, etc."
datadog,This data was not granular enough to allow us to reliably scale our apps up or down.
datadog,"In order to scale, we have to utilize KPIs that give us reliable indicators."
datadog,"As we are a big Datadog customer, we were already shipping numerous custom metrics there."
datadog,It seemed only natural for us to leverage that data and turn it into action.
datadog,"In this instance, we will take a look at scaling an Elastic Beanstalk application environment based on the number of requests per instance."
datadog,"The services utilized in this blog post are Datadog, AWS Elastic Beanstalk (EB), SNS and Lambda."
datadog,"Services we will be using in this post:
AWS Elastic Beanstalk environment ‚Äî
Elastic Beanstalk is a service provided by AWS for deploying, scaling and monitoring web applications and services developed with many languages like Java, .NET, PHP, Node.js, Python, Ruby, Go, etc."
datadog,It also supports Docker with single and multiple containers.
datadog,"Elastic Beanstalk handles the deployment, auto-scaling underline resources, load-balancing, and so on."
datadog,More details here.
datadog,2.
datadog,"Lambda function ‚Äî
AWS Lambda is an event-driven serverless computing platform."
datadog,Users just need to provide the code and set up events to run it.
datadog,AWS manages the provisioning of underlying servers and auto-scaling in response to the running code.
datadog,More details here.
datadog,3.
datadog,"SNS topic ‚Äî
SNS is a push notification service provided by AWS."
datadog,"Notification can be set to come through email, text message and/or various third-party integration like Slack."
datadog,Recipients subscribe to SNS topics to get notifications.
datadog,More details here.
datadog,4.
datadog,"Monitor in Datadog ‚Äî
Monitor in Datadog sends SNS notifications based on a sequence of check statuses, metric threshold or other alerting conditions."
datadog,More details here.
datadog,"Architecture:

Steps -
Step 1: Create an Elastic Beanstalk environment
Instructions are here."
datadog,Step 2: Note down the Auto Scaling Group (ASG) and scaling policies created by the Elastic Beanstalk environment.
datadog,"You will need this info for configuring the Datadog monitor:

Step 3: Create an SNS topic

Step 4: Create a Lambda function
Type: sns-message

Select the SNS topic and Enable trigger checkbox and hit the Next button."
datadog,"Paste the following code in Lambda function (name: autoscaling):
from __future__ import print_function
import json
import boto3
import re
client = boto3.client(‚Äòautoscaling‚Äô)
def lambda_handler(event, context):
    messages = event[‚ÄòRecords‚Äô][0][‚ÄòSns‚Äô][‚ÄòMessage‚Äô]
    message_lines = messages.split(‚Äò\n‚Äô)
    first_line = re.sub(‚Äò +‚Äô, ‚Äò ‚Äò , message_lines[ 0 ])
    number_of_services = first_line.split(‚Äò ‚Äò)
    number = int( number_of_services[1] ) + int( 1 )
    message_array = []
    for i in range(1, number):
        strtemp = re.sub(‚Äò +‚Äô, ‚Äò ‚Äò ,message_lines[i])
        message_array = message_array + strtemp.split(‚Äò ‚Äò)
    number = number ‚Äî 1
    temp = 0
    for j in range(0, number):
        temp = int( temp ) + 1
        asg = message_array[ j + temp ]
        temp = int( temp ) + 1
        scaling_policy = message_array[ j + temp ]
        response = client.execute_policy(
            AutoScalingGroupName=asg,
            PolicyName=scaling_policy
   )
   return ‚Äúok‚Äù
Provide the required information to the Lambda function like memory, VPC, subnets, security group and create the function."
datadog,E.g.
datadog,"Memory

E.g."
datadog,"VPC, subnets and security groups

Step 4: Datadog integration with SNS
Make sure your Amazon SNS integration works."
datadog,"You can follow the instructions here to create an SNS subscription for Datadog
Step 5: Create a Datadog monitor
If you are using Haproxy, use Haproxy.frontend.requests metrics for number of requests."
datadog,"Use a simple alert; in the message body, use the following format:
Sample format for upscaling:
@sns-topic 1
<Appname> <ASG> <upscaling-policy>
E.g:
@sns-autoscaling 1
myapp awseb-e-rtqbsvp3nu-stack-AWSEBAutoScalingGroup-1ML8W8H5O1JCC awseb-e-rtqbsvp3nu-stack-AWSEBAutoScalingScaleDownPolicy-1GI57G0UBJ0YN
Note: 1 indicates that we are scaling up only one service."
datadog,We use this for scaling the dependent services as well.
datadog,"Conclusion:
There are some pros and cons of this approach."
datadog,The pros are you can utilize a lot of metrics available in Datadog in order to scale your application.
datadog,You are not dependent on just the CloudWatch metrics.
datadog,"Also, you can scale up downstream services as soon as an application receives high traffic."
datadog,Using better metrics for autoscaling saves money on EC2 and EBS.
datadog,"The con of the current implementation is that it will constantly trigger scale-down due to breaching the lower threshold, but that is acceptable since it is no-op to an ASG that is at its minimum instance count."
datadog,"A test of the final product, implementing a custom Chromecast splash screen."
datadog,"(Because Google won‚Äôt)
The Concept
Ever since I listened to Cory Watson talk about Stripe‚Äôs observability strategies on the (wonderful) Software Engineering Daily, I‚Äôve gotten a relatively strong itch to incorporate that ‚Äòculture of observability‚Äô into my day-to-day with ScoreShots."
datadog,"So about a month ago I set out to be the change I wanted to see, and part of that for me is the need for the perfect dashboard TV."
datadog,"What then, is the perfect dashboard TV?"
datadog,"For me it was:
A robust hardware solution that‚Äôs low power, low maintenance, and cheaply replaceable, with wi-fi support."
datadog,"Not sacrificing the TV‚Äôs ability to be a TV, allowing for media content and screen sharing directly to it."
datadog,An informative passive state that shows critical information.
datadog,Autonomous enough to never need a remote control.
datadog,"The dream, much like my dreams of the perfect messaging client or the perfect operating system, seemed far out of reach, but close enough to make an attempt."
datadog,"Hardware
So lets source the hardware needed for this little project:
TV: Nothing special here, we just need a TV with basic CEC support."
datadog,"Be aware, half the TVs that support CEC either don‚Äôt say so, or call it something weird and proprietary."
datadog,"In my case we picked up a couple of Insignia 40"" LED TVs @ 209.99
Dashboard: Here we chose the low hanging fruit of the Raspberry Pi 3."
datadog,"With CEC support, low energy usage, and built in wifi, it made sense."
datadog,"Media: Again, a no-brainer of sorts, the Chromecast."
datadog,"Most support, user experience that would work on our network, it has issues (which we‚Äôll talk about later), but it‚Äôs good."
datadog,"Software/Services
To start with, lets write something worth showing."
datadog,"We used Datadog here as it had the right recipe: quick to setup, with integrations for everything under the sun (Cory from Stripe also introduced me to them)."
datadog,"I linked it into the machines running ScoreShots and our AWS account, and wrote some custom views to show latest posts and other stats."
datadog,"The dashboard editor on Datadog is pretty sweet
From there, I needed to figure out how to maintain the Raspberry Pis, update them over the air, and add more screens as we (hopefully) continue to grow."
datadog,I know from experience that the flow of getting new builds to existing devices and provisioning new ones can kill a project like this over time super easily.
datadog,"Rather than try to write my own deployment strategy, we went with Resin.io, a service made almost explicitly for this use scenario."
datadog,"From there, we could provision new builds of the software to a whole fleet of devices, while still providing customization variables to each device to fit its unique scenario."
datadog,It uses Docker containers running in its own slimmed down OS to manage updates and configuration.
datadog,"Getting resinOS running on the Raspberry Pis was easy enough, which means I got fleet management, OTA updates, and the rest for free using git as an interface."
datadog,"Fleet Management via Resin.io
The last missing piece here was someone who had made an easy to adapt system of putting a browser to a screen (which is way harder than it sounds, as it so happens)."
datadog,"The advantage of resin.io is that someone had already done the hard parts for us, enter resin-wpe."
datadog,"Hardware accelerated, webkit, you can even connect it to touchscreens, if that‚Äôs your idea of fun."
datadog,"I setup the project in a cloud9 workspace, and pushed it to resin, which pushed it to the devices."
datadog,"By setting the URL via configuration, we now have the datadog dashboard on the TV."
datadog,"So just with off the shelf libraries and tools, we have 3 out of the 4 of our metrics for the perfect dashboard TV."
datadog,All we‚Äôre missing is the ditching of the remote: right now we have to manually switch between chromecast and the raspberry pi.
datadog,So begins our adventure into CEC.
datadog,"CEC Support and Automation
For those unfamiliar, CEC, or Consumer Electronics Control, is a protocol by which HDMI connected devices can control and command other HDMI connected devices without any other forms of communication."
datadog,"Its primary use is to unify remotes, but it also has applications in cross device control, auto-input-switching, etc."
datadog,"It‚Äôs a protocol with the best of intentions, and often the worst of device implementations."
datadog,But lets try and remain positive.
datadog,Raspberry Pi supports CEC out of the box via libCEC.
datadog,"This means with a little tweaking of our Docker image, we can control the TV over bash or Python."
datadog,Neat!
datadog,Chromecast has some useful CEC features.
datadog,It will turn the TV on and switch to its input when an app is started on it.
datadog,"What it doesn‚Äôt do however is ever hand that input back to anyone else when the app closes, which means it requires a remote if you want to use it secondary to any other content provider (It also never blanks its input on inactivity."
datadog,"This wouldn‚Äôt be useful here, but it‚Äôs still dumb)."
datadog,We‚Äôll need to write our own code to add some sanity here if we want it to work without a remote.
datadog,"So first we need to rebuild the image supplied by resin-wpe if we want to add python, libCEC, and all the required dependencies involved with that (gcc, protobuf, etc)."
datadog,"The image is a yocto build, which is a lightweight linux build system for IoT devices."
datadog,The upside of this is that it runs fantastically and is super lightweight.
datadog,"The downside is that, since it‚Äôs not a real distro, we can‚Äôt sudo apt-get anything."
datadog,"Not being a yocto expert myself, regular co-conspirator Chaz Schlarp helped out here and did the re-building."
datadog,"Be warned if you try and do this yourself, making the new image is a pretty intensive process."
datadog,"Chaz solved this as he usually does, by throwing an absurd amount of compute power at it:

The power
What resin-wpe supplies is a yocto build setup to run the webkit browser, hardware accelerated, to an available HDMI screen."
datadog,"What Chaz did is add to that the libraries necessary to give us a development environment moving forward in python, with libCEC and the ability to talk to Chromecasts."
datadog,"So now we have a python environment and all dependencies, the remaining step is simply to write some python."
datadog,"First, we get the Chromecast attached to the device:

Then, we poll that continuously, and send a CEC as (active source) command when the system detects that the user both started a chromecast app, and then returned to the homescreen:

What this creates is a dashboard TV, that can be Cast to (the Chromecast will switch the input to itself), and then switch back to the dashboard (the Raspberry Pi will switch the input back once it finds the Chromecast idle and showing)."
datadog,"Essentially what we‚Äôve done is written our own Chromecast idle screen (which is actually pretty frustrating, when you consider the fact that the chromecast could technically let us set our own idle screen instead of the default and make this whole project unnecessary)."
datadog,So we‚Äôve effectively satisfied the ‚ÄòNo Remote‚Äô clause of the perfect dashboard TV.
datadog,"We don‚Äôt need a remote for any input switching, volume control (most Chromecast apps will do this for you), the only thing we still need a remote for is On/Off."
datadog,"And really, we can use the physical button for that."
datadog,"I was actually wholeheartedly planning to add auto On/Off for the TV in my office based on my own Google Maps supplied location, but as it turned out the TVs we bought don‚Äôt support CEC standby (I did tell you that the state of CEC support is a mess)."
datadog,"Another day, perhaps!"
datadog,"Repositories:
If you want to deploy/fork this project, it‚Äôs available on github:
Aubron/resin-wpe-chromecast
resin-wpe-chromecast - How to run a fullscreen browser with hardware accelerated CSS, WebGL, and HTML5 video as a‚Ä¶
github.com

If you want the resulting Docker image, it‚Äôs available here: https://hub.docker.com/r/schlarpc/resin-wpe-python/, but the source required to build it is in the repository above."
datadog,"in Slack incoming webhook attachments
Issue
If you are here, you have probably experienced the same issue I did using the Datadog programmatic API v1 to generate PNG snapshot of your metrics."
datadog,"I have integrated Datadog metrics in Slack using snapshots and incoming webhooks as shown below:
Datadog Slack Example
The problem I was facing was that the image was missing or simply not displaying!"
datadog,"But, whenever I opened the URL of the snapshot in the browser or using the Slack Message Builder there!"
datadog,I eventually found out that it was a problem of time.
datadog,"Solution: Delay
Add a delay of few seconds before displaying the image or before calling the Slack API to send the attachment will solve the issue."
datadog,This time is needed for Datadog to generate the actual image file.
datadog,"I am currently using a 60 seconds delay, just to make sure it doesn‚Äôt happen again."
datadog,"A more elegant solution would be requesting the image, checking the size of the document or maybe the content-type and only then using the snapshot URL provided by Datadog."
datadog,"For the moment, the delay just works for me."
datadog,"Sounds stupid, but I wasted at least half an hour on this."
datadog,"Hopefully, you will find this article before wasting any of your time!"
datadog,Happy coding!
datadog,We believe strongly in the microservice paradigm here at Lifion.
datadog,Our platform consists of many specialized services and the infrastructure that supports them.
datadog,These components are complex and usually have much to say about their current state.
datadog,How do you keep track of it all?
datadog,"For us, the ELK stack seemed like the perfect fit!"
datadog,"It allowed us, in near real-time, to collect our noisy logs for aggregation and analysis, which let us take a peek at events across our systems as they occured."
datadog,"When we deployed version 5.1.1 across the stack, we noticed that our data nodes were failing intermittently at first, then more often as the amount of data we indexed increased."
datadog,What was happening?
datadog,"To get started debugging, I first needed data."
datadog,"Looking at only the Elasticsearch data nodes, I graphed over a 36 hour period the average:
~ 1 minute system load
~ Elasticsearch cluster status:
2 is Green."
datadog,All primary and replica shards are available.
datadog,1 is Yellow.
datadog,"All primary shards are available, but some replica shards are missing or unassigned."
datadog,"Indexing can still occur, but search is slower and the possibility for data loss is much higher."
datadog,0 is Red.
datadog,1 more primary shards are unavailable and 0 or more replica shards are also unavailable.
datadog,Search will be missing data and indexing may fail.
datadog,"~ The total time spent on GET requests
~ The number of data nodes in the cluster

We see immediately that within an hour of the cluster being deployed, overall health fluctuated from Green to Yellow for around 12 hours, with additional churn in processing load."
datadog,"This did not affect search significantly, but we can see that the cumulative time spent waiting was increasing steadily."
datadog,"This was obviously not good, but in this state, there was no data loss."
datadog,"We think that because there was not a relatively significant amount of data during this time, data node failures were resolved quickly enough to not be deemed complete failures."
datadog,"Unfortunately, we ran out of luck."
datadog,"For the next 12 hours, the cluster fluctuated from Yellow to Red."
datadog,The cluster seemed to have hit a critical amount of data.
datadog,"Once this point was reached, recovery started to take too long."
datadog,"At this point, even if a data node recovered, the master considered it as a new joiner."
datadog,"Because of this, the master node quickly started to reshuffle shards that were originally assigned to the data node it believed to have failed."
datadog,This explains the more sporadic processing pattern we see in the latter half of the system load graph.
datadog,How severe were the failures?
datadog,"For that, we turn to a graph of the minimum data nodes reported for a given period (which has been enlarged to where the global minimums occured):

At worst, 2 out of the 5 data nodes were lost at the same time."
datadog,"Because of our replication factor of 3, we theoretically had no data loss, but because of continuous node failures, the cluster did not have enough breathing room to recover enough shards to reach a Green state."
datadog,Why was this happening?
datadog,"To find out, we need to dig through the torrent of logs that Elasticsearch helpfully spits out."
datadog,"From the master node, we get our first clue:

The connection was being closed by Netty, the underlying non-blocking I/O (NIO) library that Elasticsearch makes use of."
datadog,But why?
datadog,Are the data nodes actually failing?
datadog,"Lets see what they have to say:

From the data node‚Äôs perspective, the master node has experienced a network partition."
datadog,It will valiantly continue trying to rejoin the cluster.
datadog,"If it doesn‚Äôt rejoin quickly, the master node will deem it a failure; even if it does manage to rejoin, it will be considered a new node."
datadog,"We now know that the data node was not experiencing legitimate failures, so clearly the master node is mistaken!"
datadog,"If we continue digging in the master logs, maybe we can find a reason‚Ä¶
Bingo!"
datadog,"A stack trace:

How was this fixed?"
datadog,"After some digging, this turned out to be an issue with an internal stats endpoint not serializing data correctly."
datadog,"(Ironically, this endpoint is used by X-Pack, the built in monitoring plugin."
datadog,This means that the tool tasked with tracking failures was causing the failures itself!)
datadog,It would return garbage data which Netty believed to be corrupt.
datadog,"Netty closes the connection, but surprise!"
datadog,"This connection is also used for other inter-node communication, so once this connection is lost, the master node believes that the node has failed and removes it from the cluster!"
datadog,"This would in turn initiate a shard reshuffle, which is very expensive when you have lots of data to move around."
datadog,This was most likely the cause of increasing latency.
datadog,"Thankfully, Elastic is aware of the issue and has since pushed a fix to versions 5.1.2 and 5.2.0."
datadog,"We were running 5.1.1 and have since upgraded Elasticsearch, Kibana, and X-Pack to 5.2.0."
datadog,What does our monitoring data look like now?
datadog,"At the time of this screenshot, the cluster had collected about 600 GBs worth of logs."
datadog,"Since then, system load has steadied out, time spent on GET requests is consistently under 1 second, there have been no node failures, and Elasticsearch has never been unhealthy since redeploy!"
datadog,"Datadog is great at pulling in large amounts of metrics, and provides a web-based platform to explore, find, and monitor a variety of systems."
datadog,"One such system integration is PostgresQL (aka ‚ÄòPostgres‚Äô, ‚ÄòPG‚Äô) ‚Äî a popular Open Source object-relational database system, ranking #4 in its class (at the time of this writing), with over 15 years of active development, and an impressive list of featured users."
datadog,"It‚Äôs been on an upwards trend for the past couple of years, fueled in part by Heroku Postgres, and has spun up entire companies supporting running Postgres, as well as Amazon Web Services providing PG as one of their engines in their RDS offering."
datadog,"It‚Äôs awesome at a lot of things that I won‚Äôt get into here, but it definitely my go-to choice for relational data."
datadog,"One of the hardest parts of any system is determining whether the current state of the system is better or worse than before, and tracking down the whys, hows and wheres it got to a worse state."
datadog,"That‚Äôs where Datadog comes in ‚Äî the Datadog Agent has included PG support since 2011, and over the past 5 years, has progressively improved and updated the mechanisms by which metrics are collected."
datadog,Read a summary here.
datadog,"Postgres has a large number of metrics associated with it, and there‚Äôs much to learn from each."
datadog,The one metric that I‚Äôm focusing on today is the ‚Äúconnections‚Äù metric.
datadog,"By establishing a periodic collection of the count of connections, we can examine the data points over time and draw lines to show the values."
datadog,"This is built-in to the current Agent code, named postgresql.connections in Datadog, by selecting the value of the numbackends column from the pg_stat_database table."
datadog,"Another two metrics exist, introduced into the code around 2014, that assist with using the counts reported with alerting."
datadog,These are postgresql.max_connections and postgresql.percent_usage_connections.
datadog,( Note: Changing PG‚Äôs max_connections value requires a server restart and in a replication cluster has other implications.)
datadog,"The latter, percent_usage_connections, is a calculated value, returning 'current / max', which you could compute yourself in an alert definition if you wanted to account for other variables."
datadog,It is normally sufficient for these purposes.
datadog,A value of postgresql.percent_usage_connections:0.15 tells us that we're using 15% of our maximum allowable connections.
datadog,"If this hits 1, then we will receive this kind of response from PG:
FATAL: too many connections for role...
And you likely have a Sad Day for a bit after that."
datadog,Setting an alert threshold at 0.85 ‚Äî or a Change Alert to watch the percent change in the values over the previous time window ‚Äî should prompt an operator to investigate the cause of the connections increase.
datadog,"This can happen for a variety of reasons such as configuration errors, SQL queries with too-long timeouts, and a host of other possibilities, but at least we‚Äôll know before that Sad Day hits."
datadog,"If you‚Äôve launched your application, and nobody uses it, you‚Äôll have very low connection counts, you‚Äôll be fine."
datadog,"#dadjoke
If your application is scaling up, you are probably running more instances of said application, and if it uses the database (which is likely), the increase in connections to the database is typically linear with the count of running applications."
datadog,"Some PG drivers offer connection pooling to the app layer, so as methods execute, instead of opening a fresh connection to the database (which is an expensive operation), the app maintains some amount of ‚Äúpersistent connections‚Äù to the database, and the methods can use one of the existing connections to communicate with PG."
datadog,"This works for a while, especially if the driver can handle application concurrency, and if the overall count of application servers remains low."
datadog,"The Postgres Wiki has an article on handling the number of database connections, in which the topic of a connection pooler comes up."
datadog,"An excerpt:
If you look at any graph of PostgreSQL performance with number of connections on the x axis and tps on the y access [sic] (with nothing else changing), you will see performance climb as connections rise until you hit saturation, and then you have a ‚Äúknee‚Äù after which performance falls off."
datadog,"The need for connection pooling is well established, and the decision to not have this part of core is spelled out in the article."
datadog,"So we install a PG connection pooler, like PGBouncer (or pgpool, or something else), configure it to connect to PG, and point our apps at the pooler."
datadog,"In doing so, we configure the pooler to establish some amount of connections to PG, so that when an application requests a connection, it can receive one speedily."
datadog,Interlude: Is Idle a Problem?
datadog,"Over the past 4 years, I‚Äôve heard the topic raised again and again:
If the max_connections is set in the thousands, and the majority of them are in idle state, is that bad?"
datadog,"Let‚Äôs say that we have 10 poolers, and each establishes 100 connections to PG, for a max of 1000."
datadog,"These poolers serve some large number of application servers, but have the 1000 connections at-the-ready for any application request."
datadog,"It is entirely possible that most of the time, a significant portion of these established connections are idle."
datadog,"You can see a given connection‚Äôs state in the pg_stat_activity table, with a query like this:
SELECT datname, state, COUNT(state)
FROM pg_stat_activity
GROUP BY datname, state
HAVING COUNT(state) > 0;
A sample output from my local dev database that‚Äôs not doing much:
datname  | state  | count
---------+--------+-------
postgres | active |     1
postgres | idle   |     2
(2 rows)
We can see that there is a single active connection to the postgres database (that's me!)"
datadog,and two idle connections from a recent application interaction.
datadog,"If it‚Äôs idle, is it harming anyone?"
datadog,"A similar question was asked on the PG Mailing List in 2015, to which Tom Lane responds to the topic of idle: (see link for full quote):
Those connections have to be examined when gathering snapshot information, since you don‚Äôt know that they‚Äôre idle until you look."
datadog,"So the cost of taking a snapshot is proportional to the total number of connections, even when most are idle."
datadog,"This sort of situation is known to aggravate contention for the ProcArrayLock, which is a performance bottleneck if you‚Äôve got lots of CPUs."
datadog,"So we now know why idling connections can impact performance, despite not doing anything, especially with modern DBs that we scale up to multi-CPU instances."
datadog,Back to the show!
datadog,"Now that we know that high connection counts are bad, and we are able to cut the total count of connections with pooling strategies, we must ask ourselves ‚Äî how many connections do we actually need to have established, yet not have a high count of idling connections that impact performance."
datadog,"We could log in, run the SELECT statement from before, and inspect the output, or we could add this to our Datadog monitoring, and trend it over time."
datadog,"The Agent docs show how to write an Agent Check, and you could follow the current postgres.py to write another custom check, or you could use the nifty custom_metrics syntax in the default postgres.yaml to extend the check to perform more checks."
datadog,"Here‚Äôs an example:
custom_metrics:
  - # Postgres Connection state
    descriptors:
      - [datname, database]
      - [state, state]
    metrics:
      COUNT(state): [postgresql.connection_state, GAUGE]
    query: >
      SELECT datname, state, %s FROM pg_stat_activity
      GROUP BY datname, state HAVING COUNT(state) > 0;
    relation: false
Wait, what was that?"
datadog,"Let me explain each key in this, in an order that made sense to me, instead of alphabetically."
datadog,"relation: false informs the check to perform this once per collection, not against each of any specified tables (relations) that are part of this database entry in the configuration."
datadog,"query: This is pretty similar to our manual SELECT, with one key differentiation - the %s informs the query to replace this with the contents of the metrics key."
datadog,"metrics: For each entry in here, the query will be run, substituting the key into the query."
datadog,The metric name and type are specified in the value.
datadog,"descriptors: Each column returned has a name, and here's how we convert the returned name to a tag on the metric."
datadog,"Placing this config section in our postgres.yaml file and restarting the Agent gives us the ability to define a query like this in a graph:
sum:postgresql.connection_state{*} by {state}

As can be seen in this graph, the majority of my connections are idling, so I might want to re-examine my configuration settings on application or pooler configuration."
datadog,"Let‚Äôs take this one step further, and ask ourselves ‚Äî now that we know the state of each connection, how might we determine which of our many applications connecting to PG is idling, and target our efforts?"
datadog,"As luck would have it, back in PG 8.5, a change was added to allow for clients to set an application_name value during the connection, and this value would be available in our pg_stat_activity table, as well as in logs."
datadog,This typically involves setting a configuration value at connection startup.
datadog,"In Django, this might be done with:
DATABASES = {
  'default': {
    'ENGINE': 'django.db.backends.postgresql',
    ...
    'OPTIONS': {
      'application_name': 'myapp',
    }
    ...
No matter what client library you‚Äôre using, most have the facility to pass extra arguments along, some in the form of a database connection URI, so this might look like:
postgresql://other@localhost/otherdb?application_name=myapp
Again, this all depends on your client library."
datadog,"I can see clearly now
So now that we have the configuration in place, and have restarted all of our apps, a modification to our earlier Agent configuration code for postgres.yaml would look like:
custom_metrics:
  - # Postgres Connection state
    descriptors:
      - [datname, database]
      - [application_name, application_name]
      - [state, state]
    metrics:
      COUNT(state): [postgresql.connection_state, GAUGE]
    query: >
      SELECT datname, application_name, state, %s FROM pg_stat_activity
      GROUP BY datname, application_name, state HAVING COUNT(state) > 0;
    relation: false
With this extra dimension in place, we can craft queries like this:
sum:postgresql.connection_state{state:idle} by {application_name}

So now I can see that my worker-medium application has the most idling connections, so there's some tuning to be done here - either I open too many connections for the application, or it's not doing much."
datadog,"I can confirm this with refining the query structure to narrow in on a single application_name:
sum:postgresql.connection_state{application_name:worker-medium} by {state}

So now that I‚Äôve applied methodology of surfacing connection states, and increased visibility into what‚Äôs going on, before making any changes to resolve."
datadog,"Go forth, measure, and learn how your systems evolve!"
datadog,I discovered DataDog monitoring services while I was working at Citrix as part of the DevOps team.
datadog,"We needed a system monitoring solution that was flexible and easy to use, one where anyone could add or remove hosts or alerts."
datadog,"The department that was supposed to provide us with such an infrastructure kind of service failed to provide one so we looked around and ended up picking a hosted service, DataDog."
datadog,"DataDog provided excellent support, and the overall user experience with their platform was a pleasure too."
datadog,"It would be impossible to compare it with Nagios, Zabbix and the other similar solutions born in the dark ages of the system administration."
datadog,"Still, there was a problem with DataDog, its price tag: $15/host/month."
datadog,If you use it to monitor critical services running on expensive machines that would be ok but we are talking about times where VMs can make it very expensive.
datadog,"So, we limited its usage to only a few sensitive hosts."
datadog,"Yep, due to its costs, DataDog was not able to entirely replace other monitoring systems."
datadog,"As at the beginning of 2016, I decided to try the startup life, and I ended up working for a promising startup in London."
datadog,It took just one day to deploy it there entirely.
datadog,Everyone was happy.
datadog,"After getting a quite expensive bill from DataDog in August and September, we decided that we need to identify a less expensive solution."
datadog,I don‚Äôt want to have to disable monitoring on some hosts or environment to keep costs under control.
datadog,"That‚Äôs how I found Librato, a service that is remarkably similar to DataDog but that has better pricing model: they charge you per metric monitored."
datadog,"Instead of paying a fixed fee per host, you pay for the amount of data you store on their servers."
datadog,This model allows you to tune your monitoring to your needs.
datadog,"With the default deployment settings, Librato was only about 20% less expensive per host than DataDog, but this was before I started to filter out the noise (monitored metrics that we didn‚Äôt need)."
datadog,"Two weeks later, the costs were approximative only 1/5 of the DataDog ones, yes 80% less!"
datadog,I am still surprised about this; my target was to cut monitoring costs per host to only about 50%.
datadog,I need to mention that it took me less than two days of work to learn how to stop measuring some metrics twice as many of them can be recorded using AWS integration instead of using the agent.
datadog,"As a result, we had a complete Ansible role for deploying the tuned monitoring agent to our hosts."
datadog,In case you were wondering why we were just using CloudWatch for monitoring AWS.
datadog,"CloudWatch is cool and really useful but is not a full monitoring solutions, is more like a half baked one."
datadog,Librato is able to get data from CloudWatch but you cannot really do monitoring with only CloudWatch.
datadog,"Well, AWS will tell you that you can but they fail to tell you that you would have to hire a team of developers for writing and maintaining the missing bits."
datadog,Another benefit of using Librato is that their agent is collectd which is entirely open source.
datadog,"Collectd can be used to report data to any other monitoring platform, meaning that you are not locked-in by Librato."
datadog,I like the idea that the time invested in adding monitors for additional metrics would not be wasted if we decide to switch to another service.
datadog,While DataDog has its agent written in Python and open source you will not be able to use without their platform.
datadog,"I have to say that I observed that unless you are a key customer (massive monthly bills), you will not be able to get much attention from DataDog team."
datadog,"In fact, the usual answer is that they may get your contributions if you make them."
datadog,"Sorry guys but even if I still have your stickers on my laptop, I would not be very keen to spend my time coding for free for growing your business."
datadog,"Librato, being a challenger in the monitoring market, seems to be considerably more open to implementing missing features."
datadog,"I was pleased to be able to get an estimate regarding when they think they will implement a particular feature, something I was never able to get from DataDog."
datadog,One thing that I like about DataDog is that they have an open issue tracker for their agent on GitHub.
datadog,Librato also has one open issue tracker.
datadog,Before making a decision you may want to have a look at both of them and see how fast they are dealing with bugs and feature requests.
datadog,"For those that are already using DataDog, I should mention that their service is clearly more feature rich and more polished than Librato."
datadog,"Still, if I would have to put a price on the additional functionality, it would not be more than 20% and is the kind of bells and whistles that are not deal-breakers."
datadog,"The reality is I would probably enable Librato even for my personal ‚Äúinfrastructure‚Äù, seems to be too cool not to do so."
datadog,I hope that the DataDog guys will not hate me for writing this article.
datadog,Both of these services are wonderful and if you are not using one of them you are probably making a big mistake.
datadog,"If you still have nightmares about having to deal with Nagios, Zabbix or raising a ticket for making a minor change on monitoring maybe is time to make your old-school sysadmin‚Ä¶ less confident about his future ;)"
datadog,With a site this size and a team this small knowing where to invest time is crucial.
datadog,We‚Äôve been benchmarking the new infrastructure for the past few days and the numbers aren‚Äôt quite what we‚Äôd like to see.
datadog,"Since we‚Äôre moving quick I don‚Äôt quite have time to setup things like Prometheus, Nagios, or other monitoring tools."
datadog,I also don‚Äôt want to have to manage more infrastructure than we already are.
datadog,That‚Äôs what ultimately lead me to the choice of Datadog a tool I‚Äôve seen demos for at a few conferences but never really had a reason to use.
datadog,Getting going with Datadog was way easier than I anticipated.
datadog,I decided to play around with it first on a single machine.
datadog,"I broke the cardinal rule of juju deployments and ssh‚Äôd onto a unit of silph-road and installed datadog:

They have a one-liner, but curl | bash is never a real good install method."
datadog,Above is the ‚Äúmanual‚Äù installation steps which really aren‚Äôt that bad.
datadog,"Once the agent was installed, data showed up instantly."
datadog,Something I like a lot is how integrations work.
datadog,"There are a lot of integrations out of the box, with a quick tweak to some config files I was able to get metric data from NGINX and PHP-FPM streaming in along-side machine metrics."
datadog,There‚Äôs also a series of dashboards that make visualizing data really sweet.
datadog,"So, I quickly pieced together a Datadog agent charm and bolted it onto all of the applications in the deployment."
datadog,"From there, I held my breath as data started pouring in."
datadog,"I know there are still problem areas, people not getting pages to load and the app preforming sluggishly under load."
datadog,"All of these are a problematic for people using the app, especially considering the number of mobile users."
datadog,I used the default HAProxy dashboard and NGINX dashboard and started creating our operational dashboard to help watch for problem areas.
datadog,"Diving right in, one thing is clear: there‚Äôs is a lot of traffic hitting the loadbalancer, and a lot of traffic drilling down to NGINX."
datadog,"At first I figured this is just PHP being PHP, slow and arduous."
datadog,"After building out a few dashboards it became clear that while PHP was the bottle neck, it wasn‚Äôt the sole bottle neck."
datadog,"In fact the thing most in common was slow response times from NGINX directly, returning things like .png and .js files."
datadog,As well as PHP taking a long time to load.
datadog,What was actually happneing was long IO wait times as NGINX was reading from disk and PHP was reading and writing session data to disk.
datadog,It‚Äôs clear that EBS volumes in Amazon are not up to the task.
datadog,We‚Äôre formulating plans on how to alleviate the stress to the disks on Amazon.
datadog,"One thing is clear, adding more units of silph-road won‚Äôt scale for our budget and we‚Äôre going to have be smarter about the resources we have."
datadog,"Now that we have metrics, stream real-time data, we can be much smarter with where we focus our time."
datadog,"From improving the charms and infrastructure, to tuning the application, to produce a much more cost and performance efficient site that loads quick and reliable."
datadog,In an attempt to further open our operations we‚Äôve setup a public Datadog dashboard which is our starting point for monitoring the infrastructure.
datadog,"The built-in RabbitMQ check included with Datadog doesn‚Äôt work well when RabbitMQ has a lot of queues; in our experience, at 10,000+ queues the metrics become pretty much impossible to gather and in fact actively harm the instances by polling the RabbitMQ Management API frequently."
datadog,"For example, here‚Äôs our cluster memory usage at the moment we turned off the Datadog check:

The bad performance isn‚Äôt the check‚Äôs fault, exactly: the Management API does not perform well with many thousands of queues."
datadog,This is evident to anyone who has tried to use the Web UI; the overview page works but as soon as you try to view the list of queues for a busy vhost things get very slow.
datadog,"As an alternative to the Datadog check, RabbitMQ added first-class Prometheus metrics in version 3.8 and we can route these to Datadog to get high-level, aggregate metrics with minimal performance impact."
datadog,"Then, for queue-level metrics, we can implement our own checks using the rabbitmqctl tool, which is considerably more performant than the Management API."
datadog,"Prometheus metrics
First, ensure that RabbitMQ is publishing Prometheus metrics by enabling the plugin, then we can send them to Datadog using an OpenMetrics check similar to the following:
---
instances:
- prometheus_url: http://localhost:15692/metrics
  namespace: rabbitmq
  metrics:
  - rabbitmq*
init_config: {}
This will send all of RabbitMQ‚Äôs Prometheus metrics to Datadog with names like rabbitmq.rabbitmq_queue_messages."
datadog,It‚Äôs possible to rename these metrics (see the docs above) but there‚Äôs a lot of them so it‚Äôs probably easier to just keep them as is and put up with the rabbitmq duplication in the names.
datadog,"Collecting queue metrics
By default, the Prometheus metrics are aggregated."
datadog,"It‚Äôs possible to enable per-object metrics, but the docs advise against this for large deployments."
datadog,"Instead, we‚Äôll use the rabbitmqctl tool, which is much faster, even with thousands of queues."
datadog,The basic idea is to run a recurring script which pulls queue information and sends their metrics to Datadog via the statsd daemon.
datadog,"At LoyaltyLion, we have a lot of dynamic queues so we‚Äôre particularly interested in knowing which queues are full of messages to help identify issues such as orphaned queues or slow consumers."
datadog,"To do this, we created a small Ruby script using the rabbitmqctl list_queues command, which returns metrics for each queue."
datadog,"With ~15k queues, this still takes less than a second to run; to pull the same information via the Management API would take upwards of a minute or more."
datadog,Feel free to use and adapt the code below for your own script.
datadog,"A few things of note:
The --local flag fetches metrics only for queues whose master is the current node."
datadog,"This is ideal if you‚Äôre running this script on every member of a cluster as it‚Äôll reduce network traffic
Additional queue fields can be returned by passing them as arguments."
datadog,"Check the docs for a complete list
We run this script every 30s, as a systemd timer service

The result: per-queue metrics with minimal performance impact:"
datadog,Note: Do read the Dynatrace vs Datadog: basics article first.
datadog,What are agents?
datadog,Agents are the software tools that sends data from the instrumented component.
datadog,"Most of the time, the agents are installed on servers or deployed as operators if the scope of monitoring is Kubernetes and the containers within it."
datadog,To compare products lets have a baseline operating system and install application in a later point.
datadog,"Setting the stage:
Firstly, Let‚Äôs ensure we have identical servers and thus in this case I have the latest Ubuntu version released in 2021 April (21.04)."
datadog,Both of them are running in the same Cloud Provider and has the same specifications.
datadog,The hostnames have been modified to reflect the tool that is being compared.
datadog,"In the below case, we are going to deploy Dynatrace."
datadog,"Similarly, I have another instance named datadog where we would use Datadog to instrument the apps."
datadog,"Dynatrace: Installing agent:
After signing up, you would be asked to install the Dynatrace OneAgent available in the Dynatrace Hub section."
datadog,"Dynatrace OneAgent can be installed on variety of host platforms like shown in the below list:
Linux
Unix
Windows
AIX
z/OS
Solaris
In addition, it can be installed through orchestration tools like Ansible and Kubernetes as well through the OneAgent operator."
datadog,"In our case, I choose Linux and I get to see the instructions."
datadog,Note that the command includes the unique tenant(masked for security reasons) of Dynatrace associated with my personal account.
datadog,This means Dynatrace isolates the environment dedicated for my account in the backend.
datadog,"Installing OneAgent on the server:
In this case, I logged into the server where we will have Dynatrace and tried to run the commands as instructed above."
datadog,"Its a simple process, download a shell script that contains the installation instruction, optionally verify the integrity of the package and finally run the script to install."
datadog,"See screenshots where I run these commands(yellow) and the resulting output(red)

Downloading OneAgent and Verifying the file integrity

Installing OneAgent
You can confirm if the installation is successful by clicking ‚ÄòCheck deployment status‚Äô

Click on the Show deployment status to see if the agent started to report to Dynatrace

The host now appears in the deployment status page
Installing Datadog agent on Ubuntu 21.04
Datadog offers multiple options but the simplest is the one line command."
datadog,"The full command is pasted below:
DD_AGENT_MAJOR_VERSION=7 DD_API_KEY=‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà DD_SITE=""datadoghq.com"" bash -c ""$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)""
In short, it sets few variables first which includes the Version, API Key and the datadog site details which are injected into the configuration files when the shell script runs which is downloaded from S3

DataDog agent installation options

One Line Datadog Agent installation

The script would elevate itself during installation and will prompt for password if the user does not have enough permissions."
datadog,"Once installed, you should see the agent running within minutes."
datadog,"Datadog agent reporting to Datadog
Conclusion:
Installing the Dynatrace and Datadog agent on a Linux server is very similar and very simple."
datadog,Dynatrace appears to deploy additional resources to isolate a tenants environment whereas Datadog appears to isolate in a separate way.
datadog,"Datadog shows the various flavours of Linux with separate sections for Debian, Ubuntu, Amazon Linux, CentOS/Red Hat, Fedora and SUSE."
datadog,If you look closely they all download the same script and I wonder why they don‚Äôt brand that together as Linux.
datadog,"Nevertheless, it makes it appear as though Datadog can be installed in more agents but if you take a closer look Dynatrace can even be installed on z/OS."
datadog,"Overall, both can be easily installed in popular operating systems."
datadog,Dynatrace OneAgent can be installed on z/OS based Mainframes as well.
datadog,"In this blog series, I will go through Dynatrace and Datadog and compare them on some important aspects."
datadog,One of them is a leader in this space and it is very important to understand how they are different and why customers trust one over the other.
datadog,"Personally, I find both products are absolutely phenomenal but as with anything in life its the little things that makes a difference."
datadog,Developing software today is all about speed and quality.
datadog,"You have to release your software faster, fail faster and reinvent faster than your competition."
datadog,Speed requires eliminating Toil.
datadog,"Toil is that manual, repetitive tasks that are done which are devoid of enduring value and scale up as demands grow which is why developers and operators should focus on their primary duties."
datadog,The job of a developer and an operator is to develop and operate the application.
datadog,Both need to observe how the application responds to various situations.
datadog,Why Monitor or Observe?
datadog,Software is about experience.
datadog,How do you know the software that has been shipped is performing in the real world and used by your customer?
datadog,Is it too slow or loads incorrectly?
datadog,Does it have errors?
datadog,Did the most important button work seamlessly?
datadog,Why is my website down?
datadog,The goal of a monitoring tool is to observe how an application responds throughout its life cycle.
datadog,"To observe, the first step is to get the monitoring agent installed, configure the required metrics that you would like to monitor because you don‚Äôt want to measure everything."
datadog,You do want to measure the key metrics that define the user experience and also resources and components whose unavailability could potentially alter the user experience.
datadog,Least amount of efforts should be invested when configuring any of the below activities.
datadog,"The more time you invest in configuring a tool or an agent that the tool use, the more toil you are creating."
datadog,"Steps:
Install: Install the agent with most seamless fashion that sends the metrics to a monitoring system
Configure: You may have to configure the agent or the tool if the monitoring application needs to be told on what to be monitored
Monitor: Monitoring is the process of setting thresholds when a metric crosses a defined value to trigger a notification."
datadog,"Configuring and Monitoring are two of the hardest things
What metric to monitor?"
datadog,It is hard to determine which metric is important and which is not.
datadog,For E.g.
datadog,You may think that requests per second is an important metric and start to monitor a website if the requests(also referred as queries- QPS) per second crosses 1000 RPS and ignore response times which defines the time taken for the website respond to a request.
datadog,"In this example, even if there were more than 1000 RPS the website performance was acceptable because users were able to load the website quickly."
datadog,So the correct measure could be to check the response times of the page load if it loaded in less than 4 seconds.
datadog,If the answer to this is positive we can be confident that requests per second could not impact performance until a given point.
datadog,RPS(or QPS) is an important aspect of course as a unexpected increase could mean a potential Denial of Service(DOS) attack.
datadog,It gets only harder when we split all the various components between the user and the application.
datadog,"Between the web browser and the data downloaded through the web browser, there may be many components like a CDN, Load Balancers, Web Server fleet, Application server fleet, Micro services, Processes, Functions and Databases."
datadog,Now imagine monitoring metrics across all these a components.
datadog,It would get only hard to work out what to monitor and when.
datadog,Remember the December 2020 Google outage?
datadog,"On 14th December, Google suffered from an outage which brought down their authentication service."
datadog,"An excerpt of the root cause stated ‚Äú‚Ä¶Existing safety checks exist to prevent many unintended quota changes, but at the time they did not cover the scenario of zero reported load for a single service.‚Äù
Working out all the scenarios is one of the hardest task and it isan important criteria in evaluating a monitoring tool."
datadog,Can a monitoring tool automatically measure and monitor?
datadog,Lets find out.
datadog,Dynatrace(DT) and Datadog(DD) are two amazing monitoring products that are very popular in the industry.
datadog,As a user it gets really hard to determine which product meets all the needs you need and thus it is always best to see how they perform on simple use cases.
datadog,"To do so, lets try to install them and monitor a server and potentially a micro service."
datadog,"Dynatrace: Signing up
Signing up Dynatrace was super easy."
datadog,"In addition, I was able to choose the Sydney region which is closer to me as I live in Melbourne."
datadog,"This was asked in my previous screen:

Datadog: Signing up
Signing up for Datadog was very quick and required just an email address."
datadog,I went again to see if I can find a Sydney region because DT had this but I could find only US and EU regions.
datadog,Data sovereignty can be a big topic for variety of industries depending on data classification.
datadog,"Typically, the Chief security officer can advise if monitored data, end user application monitoring data can reside in country or not."
datadog,"In the next blogs, we would take a look at the three stages of monitoring closely on the two products."
datadog,"For those who are in a rush, read this(place holder) blog that summarises both the products."
datadog,Fargate is an amazing tool to develop container applications without having to manage the infrastructure underlying the containers.
datadog,"However, there are some limitations on the monitoring side in that ‚Äî we can only monitor CPU/RAM utilizations at the Cluster, Service and TaskDefinition levels, but not at the container level."
datadog,"AWS confirmed that there is an existing feature request for this requirement, but gave no timelines on when this feature would be released."
datadog,"In order to bridge this gap, we can use Datadog to track CPU/IO utilizations at the container level."
datadog,"Datadog uses a side-car container approach which accesses the Docker container stats, and ships those stats to Datadog ."
datadog,Add the following code snippet to your Fargate task definition file.
datadog,"1) Add your DataDog API key in AWS secrets manager, and update the ""valueFrom‚Äù: ‚Äúarn:aws:secretsmanager:us-east‚Äù part of the following snippet accordingly, with the arn of the AWS secret."
datadog,"[
  {
    ""name"": ""app"",
    ""image"": ""${image_url}"",
    ""essential"": true,
    ""networkMode"" : ""awsvpc"",
    ""portMappings"": [{
      ""containerPort"": 9000,
      ""hostPort"": 9000
    }],
    ""dockerLabels"": {""container_type"": ""app""}
  },
  {
    ""name"": ""datadog-agent"",
    ""image"": ""datadog/agent:latest"",
    ""essential"": true,
    ""cpu"": 256,
    ""memory"": 512,
    ""secrets"": [
      {
        ""name"": ""DD_API_KEY"",
        ""valueFrom"": ""arn:aws:secretsmanager:us-east-****""
      }
    ],
    ""environment"": [
      {
        ""name"": ""ECS_FARGATE"",
        ""value"": ""true""
      },
      {
        ""name"": ""DD_DOCKER_LABELS_AS_TAGS"",
        ""value"": ""{\""container_type\"":\""container_type\""}""
      }
    ],
    ""dockerLabels"": {""container_type"": ""datadog-agent""}
  }
]
Deploy the updated task-defintion in Fargate."
datadog,"That‚Äôs it, DataDog will start showing the CPU/RAM metrics."
datadog,This article was originally published on the HashiCorp blog.
datadog,"Introduction
In this post, we will provide an overview of Observability and demonstrate how to apply one of the three pillars (distributed tracing) of Observability with Consul Service Mesh."
datadog,"In control theory, observability (o11y) is a measure of how well internal states of a system can be inferred from knowledge of its external outputs."
datadog,"In more practical terms, observability consists of tools and techniques to makes sense of complex systems."
datadog,These systems range from applications to infrastructure.
datadog,"The Three Pillars of Observability
A robust observability program focuses on three key areas:
Metrics: Numeric representations of data measured over intervals of time."
datadog,"Metrics provide data about your services that help you troubleshoot issues, gauge system health, and test hypotheses."
datadog,"Metrics can be technical such as requests per second, error rate, or CPU utilization."
datadog,"Metrics can also be business-specific, for example, the sum of goods sold per hour, average order value (AOV), or click-through-rate (CTR)."
datadog,"A Grafana Metrics dashboard example
Logs: Immutable, timestamped records of discrete events that happened over time."
datadog,"Logs are the most common resource that developers use to collect data and quickly debug their code, as they provide more detailed data than metrics."
datadog,Traces: Representations of a series of related distributed events that encode the end-to-end request flow through a distributed system.
datadog,"Traces represent the lifecycle of a request through various services and help pinpoint problematic services, such as ones with high latency."
datadog,"While achieving observability for your systems, there are generally three approaches: DIY or Buy, or in some cases a hybrid of both."
datadog,"DIY or Buy
Observability tools come in two varieties."
datadog,Open-source DIY tools and commercial offerings.
datadog,"DIY (left) or Buy (right)
There are pros and cons to both approaches."
datadog,Open-source (OSS) tools provide users a simple way to start monitoring their applications and services.
datadog,There are plenty to choose from.
datadog,One can build a reasonable monitoring stack with Prometheus and Grafana for metrics and dashboards.
datadog,One important question to ask while planning for observability is how does your o11y strategy align with the overall goals of your organization.
datadog,"For example, whether your organization is a video game startup or a well-regarded financial services firm, the value of the products your company sells depends on the quality of experience those products deliver."
datadog,"As such, one should consider prioritizing engineering resources on creating differentiated experiences for your customers ‚Äî instead of maintaining an o11y stack."
datadog,"OSS Benefits and Implications
There are long term implications for those considering the OSS route."
datadog,"While OSS tools are freely available and easy to get started with, OSS tools require dedicated engineers to maintain, update, and support them in the long run."
datadog,The long term costs of upkeep may be significant and should be considered while developing an observability strategy.
datadog,"Why Organizations Choose SaaS
Commercial offerings are typically SaaS products that alleviate engineering teams from building and maintaining their own observability stack."
datadog,"In addition, commercial products typically provide OOTB dashboards with contextual information for your applications and services."
datadog,"For extremely high traffic applications and services, highly ephemeral workloads, or workloads that generate highly-cardinal data, commercial products are often the only observability solution able to capture the complex data generated by these workloads."
datadog,"New compute primitives require new observability methods

Evolving application delivery
The progression of the compute stack from bare metal hosts to VMs to containers has led to an evolution of the application delivery model from monolithic apps to microservices."
datadog,Monolithic apps can easily be monitored by applying agents to the application.
datadog,"For example, a monolithic Java application can be monitored by instrumenting the application with a Java agent that is passed as a JVM argument while running the app."
datadog,Most monitoring platforms provide agents for a wide variety of languages.
datadog,We replaced our monolith with microservices so that every outage could be more like a murder mystery.
datadog,"‚Äî @honest_update
While microservices provide many benefits over monolithic apps, there are also tradeoffs."
datadog,"Since microservices decouple an app‚Äôs functions into many discrete components, a microservices app is inherently more complex than a monolith."
datadog,"Fortunately, distributed tracing solves the challenge of observability for microservices applications."
datadog,The span is the primary building block of a distributed trace.
datadog,A span represents an individual unit of work done in a distributed system.
datadog,"Spans generally contain references to other spans, which allows multiple spans to be assembled into one complete trace."
datadog,A trace is a visualization of the life of a request as it moves through a distributed system.
datadog,"Example of a trace in Jaeger
Consul Service Mesh
Consul Service Mesh provides service-to-service connection authorization and encryption using mutual TLS."
datadog,Applications can use sidecar proxies in a service mesh configuration to establish TLS connections for inbound and outbound connections without being Consul aware.
datadog,Consul Service Mesh helps you secure your services and provide data about service-to-service communications.
datadog,"Consul Envoy Proxy
There are two basic methods to implement distributed tracing for your services."
datadog,"You can either
Instrument your code directly, or
Leverage the observability hooks of your service mesh."
datadog,Consul has first-class support for using Envoy as a proxy.
datadog,"With Consul, we can configure its Envoy sidecars to enable distributed tracing."
datadog,"Direct Instrumentation
Below, we will demonstrate how to instrument two services written in Go for distributed tracing with Datadog."
datadog,"If you don‚Äôt have an existing Datadog account, feel free to register for a trial."
datadog,"The 2 services are the:
Counting Service
Dashboard Service
In main.go of the Counting Service
import (
	""encoding/json""
	""fmt""
	""log""
	""net/http""
	""os""
	""sync/atomic""
	""github.com/gorilla/mux""
)
We replace github.com/gorilla/mux with the following Datadog go tracing libraries."
datadog,"import (
	""encoding/json""
	""fmt""
	""log""
	""net/http""
	""os""
	""sync/atomic""

	muxtrace ""gopkg.in/DataDog/dd-trace-go.v1/contrib/gorilla/mux""
        ""gopkg.in/DataDog/dd-trace-go.v1/ddtrace/tracer""
)
and add a tracer.Start()
func main() {
    //adding a tracer    tracer.Start(
    tracer.WithService(""counting-service""),
    tracer.WithEnv(""dev""),
)
....
//replacing router
//router := mux.NewRouter()
router := muxtrace.NewRouter()
.....
//adding defer tracer.Stop()
fmt.Printf(""Serving at http://localhost:%s\n(Pass as PORT environment variable)\n"", port)
log.Fatal(http.ListenAndServe(portWithColon, router))
defer tracer.Stop()
Now that we‚Äôve instrumented the Counting service, we also need to instrument the Dashboard‚Äôs service main.go (instrumented version)."
datadog,"See the updated main.go (Counting), main.go (Dashboard) for both services by cloning my forked repo."
datadog,"Following the instructions to install the Datadog agent with APM enabled and running main.go for both services, we‚Äôve successfully instrumented both services for distributed tracing."
datadog,"Install Datadog agent
docker run -d -v /var/run/docker.sock:/var/run/docker.sock:ro \
-v /proc/:/host/proc/:ro \
-v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro \
-p 127.0.0.1:8126:8126/tcp \
-e DD_API_KEY=<YOUR_API_KEY> \
-e DD_APM_ENABLED=true \
datadog/agent:latest
Install the Go tracer
go get gopkg.in/DataDog/dd-trace-go.v1/ddtrace
After starting both services by running both main.go, go to http://localhost:9002/ in your browser to access the Dashboard Service

Dashboard Service
Access Datadog APM to see your traces:

Trace List
Consul Service Mesh Envoy Proxy Traces
This repo demonstrates how we can leverage the existing observability features of the Envoy proxy to generate traces to Jaeger and Datadog."
datadog,"> export DD_API_KEY=<YOUR_DD_API_KEY>
> docker-compose up
> curl localhost:9090

Traces rendered in Datadog
Conclusion
In a world of heterogeneous technologies and complexity, observability should be a vital component of your organization‚Äôs digital transformation program."
datadog,This blog post has demonstrated how we can apply distributed tracing with Consul Service Mesh to achieve one of the Three Pillars of Observability.
datadog,"In addition, we have some exciting news, Consul 1.9 will offer service mesh visualization natively."
datadog,"To get started with Consul, please visit HashiCorp‚Äôs Consul Learn site."
datadog,"Roku
Roku (NASDAQ: ROKU) reported Q3 earnings on Nov. 5."
datadog,The 73% year-over-year revenue growth the company announced was 23% above consensus expectations.
datadog,Gross profit rose 81% YoY while gross margin rose 216 basis points in total to 47.6%.
datadog,Roku added 2.9M active accounts in the quarter (+43% YoY).
datadog,"Total streaming hours increased by 0.2 billion hours over the last quarter to 14.8B (+54% YoY), while ARPU grew 20% YoY to $27."
datadog,Roku was a beneficiary of the rebound in ad spend as the company saw Q3 monetized video ad impressions grow 90% YoY vs. 50% YoY growth last quarter.
datadog,"Roku is anticipating that Q4 revenue growth will likely be in the mid-40% range, similar to the growth rate seen in the last few holiday seasons."
datadog,"Per the earnings call, the company is being cautious about holiday spending with this forecasted guidance."
datadog,ROKU shares briefly hit all-time highs immediately following the announcement of these results.
datadog,Brands like DraftKings (NASDAQ: DKNG) are shifting budgets especially as TV sports have been canceled and delayed.
datadog,Roku also pointed toward CPG brands as a large driver for ad revenue in the current quarter.
datadog,"We have got brands like DraftKings, for example, which is a big sports spender, had to shift budgets out of TV as sports were canceled and delayed."
datadog,Has moved a significant portion of their budget into OTT.
datadog,"In the earnings call, management felt confident the migration from linear TV would be a long-lasting trend after COVID-19."
datadog,We are not going back to the way it was to be clear.
datadog,"I mean, I think, COVID did ‚Äî COVID triggered a lasting durable change in how CMOs and marketers are thinking about their TV ad spend."
datadog,"In Q3, we saw a 17% drop in linear viewing, Roku was up 54%, 92% of Roku cord-cutters are very satisfied with their decision to cut the cord and aren‚Äôt planning to go back."
datadog,So I really think this is a one-way transfer function.
datadog,"We don‚Äôt go back to the older spending patterns, because the audience isn‚Äôt there, marketers need to follow the audience into OTT."
datadog,"And they stay, they stay because of the enhanced capabilities."
datadog,Roku also tackled the question of Walmart (NYSE:WMT) and Comcast (NASDAQ:CMCSA) partnering.
datadog,The CEO reiterated that Roku is the ‚Ññ1 TV operating system and software operating system in the United States and now Canada with a world-class team of software engineers.
datadog,"He also emphasized that Walmart is a large partner with Roku and has carried many Roku OEMs:
In terms of Walmart, I will just say a few words."
datadog,"I mean, Walmart is a big retailer, a very strong partner of Roku‚Äôs."
datadog,We have a great relationship with them.
datadog,They sell millions of Roku players a year.
datadog,"They sell millions of Roku TVs for various Roku OEMs, including TCL, Hisense, RCA, Philips, JVC."
datadog,"We build ‚Äî we help them build on branded, which is their house brand, Roku TVs, smart TVs, and that‚Äôs a business that‚Äôs been growing extremely well for them."
datadog,"So, it‚Äôs a great partnership and it‚Äôs a long-standing partnership, and we have put a lot of work into making sure that it stays strong."
datadog,"Square
Square (NYSE: SQ) announced blowout Q3 results with huge beats on both the top and bottom lines."
datadog,Non-GAAP EPS of $0.34 beat consensus expectations by $0.18.
datadog,"The company saw revenue grow 140% YoY to $3.03B, beating the consensus estimate by $950M or 46%."
datadog,Gross payment volume of $31.7B was 6% above expectations.
datadog,"In total, Square saw gross profit rise 59% YoY, while Cash App gross profit soared 212% YoY."
datadog,"In the quarter, the number of average daily transacting Cash App customers nearly doubled from the same period last year."
datadog,"Square did not provide guidance for Q4, but noted in its shareholder letter that the trends they observed in Q3 remained strong through October."
datadog,Square‚Äôs Seller Ecosystem revenue grew 5% YoY as regions began to reopen.
datadog,"More impressive was the growth of Square‚Äôs Cash App Ecosystem, which saw an increase of 23% in daily active users and 574% YoY growth in revenue."
datadog,"Bitcoin revenue for Square grew 11x last year‚Äôs total, but even excluding Bitcoin transactions, Square grew Cash App revenue 174% YoY this quarter."
datadog,"This is an acceleration from the 140% Cash App growth (excluding bitcoin revenue) Square recorded last quarter, and 98% growth previous to that."
datadog,"Square is focused on expanding Cash App‚Äôs utility beyond peer-to-peer payments, CEO Jack Dorsey remarked in the company‚Äôs shareholder letter: ‚ÄúWe remain focused on increasing daily utility for our Cash App customers to products beyond peer-to-peer payments, which helps drive higher engagement and monetization.‚Äù
Square‚Äôs investments into increasing Cash App engagement continue to pay off as the company‚Äôs Cash App Ecosystem displayed an acceleration in growth across the board this quarter."
datadog,"Beth.Technology
Jack Dorsey noted that Square is positioned to benefit in both segments moving forward:
‚ÄúWe continue to believe that our Seller and Cash App ecosystems are well positioned to benefit from the acceleration of secular shifts, such as omnichannel commerce, contactless payments, and digital wallets for consumers.‚Äù
The company did not give Q4 guidance due to uncertainties yet did discuss what they have seen so far through Q4."
datadog,"Square‚Äôs Seller Ecosystem saw a modest acceleration from Q3 in October:
‚ÄúSeller GPV was up 8% year over year, which improved modestly compared to year-over-year results in the third quarter.‚Äù
Cash App has seen a modest decrease in transaction volume in October, which management attributes to the end of government stimulus programs and unemployment benefits:
‚ÄúGross profit growth in October moderated compared to the third quarter, driven by a decrease in transaction volume per active customer."
datadog,"We believe this was partly a result of the end of government stimulus programs and unemployment benefits at the end of July, as stored funds in Cash App have decreased since July.‚Äù
The Trade Desk
The Trade Desk (NASDAQ: TTD) announced Q3 results that easily cleared analysts‚Äô expectations."
datadog,"Revenue grew 32% YoY, beating consensus estimates by 19%."
datadog,Non-GAAP EPS of $1.27 was a big beat on the consensus bottom-line expectation of $0.45.
datadog,"The company noted that it saw Connected TV grow over 100%, Mobile video spend grow 70% and Audio spend grow 70%."
datadog,"Management issued an upbeat outlook for Q4, expecting $289M in revenue at the midpoint vs. expectations of $255.1M."
datadog,"At the midpoint of this estimate, The Trade Desk is expecting roughly 34% YoY revenue growth in Q4."
datadog,TTD shares traded over $700 for the first time immediately following the announcement of these results.
datadog,Most impressive from TTD‚Äôs report was exceeding 100% YoY growth in their Connected TV segment.
datadog,"CEO Jeff Green remarked in the company‚Äôs press release that COVID-19 has accelerated advertising innovation across the board:
‚ÄúSo far in 2020, we‚Äôve seen several years of advertising disruption and innovation compressed into a few months."
datadog,"As a result, advertisers have become more deliberate and data-driven with every advertising dollar.‚Äù
In the Q3 earnings call, Green talked more about how companies are adapting data-driven measurement strategies for justifying marketing budgets:
‚ÄúWe recently surveyed more than 200 top advertisers, around 85% of them said they are under new pressure from CFOs to justify marketing spend and to measure against business goals.‚Äù
Despite The Trade Desk‚Äôs beat, the company did not report the numbers that Snap or Pinterest did (32% growth versus 50‚Äì60% growth)."
datadog,TTD‚Äôs stock is trading at a valuation that has been historically very hard to sustain in ad-tech.
datadog,Rarely does ad-tech trade over 20 forward price-to-sales even during high-growth periods.
datadog,"Not only is The Trade Desk well exceeding the mean but is trading roughly 200% higher than peers even though Roku, Pinterest and Snap had a better current quarter and are forecasting stronger forward guidance."
datadog,The Trade Desk stock trading 2x more expensive than ad-tech peers that reported much higher revenue growth.
datadog,"Ycharts
TTD‚Äôs forward PE Ratios (not pictured) is also outsized at 168 compared to Facebook‚Äôs 30 forward PE Ratio."
datadog,Facebook‚Äôs PE Ratio has never exceeded 119 even during its high-growth quarters of 100%+ growth and/or with low EPS (law of large numbers).
datadog,Facebook‚Äôs current P/S has also never exceeded 20 even during its high-growth quarters.
datadog,This is despite The Trade Desk facing headwinds with Apple‚Äôs changes to IDFA.
datadog,"Apple (NASDAQ:AAPL) extended the iOS update from September to an undetermined time ‚Äúearly next year.‚Äù

On Sept. 3, Apple delays IDFA changes until early next year @Beth Kindig
Although the risks are hard to quantify right now, most advertising experts are in agreement this will affect the entire mobile ad industry on iOS."
datadog,Facebook has stated they would shut down Audience Network as most ad exchanges need some kind of identifier for targeting and attribution.
datadog,Here‚Äôs a great write-up from mobile analyst Eric Seufert on how this could affect ad prices.
datadog,"The Trade Desk has stated only 10% of its inventory uses the IDFA but has made no clarifications on how it will run mobile attribution and measurement without an identifier, whether that‚Äôs Apple‚Äôs or their own."
datadog,"There are efforts from a collective federation of ad companies to use encrypted emails, although there‚Äôs no guarantee Apple would allow this on iOS and Safari even if the ad industry agrees to pursue this method."
datadog,ATS requires users to authenticate which is another unproven factor in the work flow.
datadog,"Overall, the risk is an unknown and we will get real answers it looks like ‚Äúearly next year.‚Äù For The Trade Desk, it‚Äôs a risk investors need to be aware of."
datadog,"Notably, publisher segments can help augment targeting but this will come from the supply-side."
datadog,"Datadog
Datadog (NASDAQ: DDOG) announced strong Q3 results and an upside outlook that cleared analyst expectations."
datadog,"The company grew revenue 61% YoY to $155M, representing a 7% beat above consensus estimates."
datadog,"The company grew customer count by 38% in the quarter vs. consensus expectations of 32% and added 92 new customers with over $100K ARR (+52% YoY), slightly above the consensus estimate of 90."
datadog,"In Q3, Datadog recorded its 13th consecutive quarter with a dollar-based net retention rate exceeding 130%."
datadog,"Operating margin improved to 9% in the quarter versus expectations of 0.6%, while gross margin improved 3% to 79%."
datadog,Q4 guidance was issued for $163M in revenue at the midpoint (+43% YoY) which was 5% above the consensus outlook.
datadog,"Datadog shares initially sold off as much as 14% on these results, but the stock pared its losses to close trade on Wednesday."
datadog,The stock rebounded Thursday and is now up over 11% off Wednesday‚Äôs lows.
datadog,"In its Q3 earnings call, Datadog‚Äôs CEO Olivier Pomel commented on the recovery in usage trends the company observed after a weak Q2."
datadog,"‚ÄúThroughout the quarter, usage growth of existing customers was robust which was a return to more normalized levels after slower usage expansion in Q2‚Ä¶ the pace of usage growth in Q3 was broadly in line with pre-COVID historical levels.‚Äù
After a period of cloud spend conservation among Datadog‚Äôs enterprise customers in Q2, the company added a record amount of ARR in the quarter."
datadog,"The company managed to do so profitably, as operating income, cash flow and FCF all came in above expectations."
datadog,"Notably, Datadog‚Äôs CAC payback period decreased to ~12 months from ~18 months sequentially despite adding over 400 more customers in Q3 versus Q2."
datadog,"The ~12 month payback period recorded in Q3 is more in line with pre COVID-19 levels, as last quarter is looking more like an outlier given the aforementioned headwinds the company faced in Q2."
datadog,"Datadog‚Äôs platform has proven to be easily adaptable and sticky for enterprise customers migrating to the cloud, as evidenced by the increasing number of existing customers using more Datadog products."
datadog,CEO Olivier Pomel remarked on this in the company‚Äôs earnings call when he said: ‚ÄúOur platform strategy continues to resonate and win in the market.
datadog,"As of the end of Q3, 71% of customers are using two or more products, which is up from 50% last year."
datadog,"Approximately 20% of customers are using four or more products which is up from only 7% a year ago.‚Äù
CEO Olivier Pomel also commented on the partnerships Datadog announced in Q3 with Microsoft Azure (NASDAQ:MSFT) and Google Cloud Platform (NASDAQ:GOOG) (NASDAQ:GOOGL), noting that the flow of revenue from these partnerships will not be immediate: ‚ÄúThere‚Äôs not going to be an immediate impact, but we see that as being potentially meaningful contribution in the mid to long term.‚Äù
The partnerships with Microsoft Azure and Google Cloud Platform that Datadog announced in the quarter, along with the existing alliance with Amazon Web Services (NASDAQ:AMZN), validates the company‚Äôs leadership in cloud-native-observability and establishes its collaborative relationship with the world‚Äôs top public hyperscalers."
datadog,"Over the long term, Datadog expects that these partnerships will become meaningful sources of revenue growth."
datadog,"Looking ahead to Q4, Datadog is confident the rebound in usage trends the company observed in Q3 will continue."
datadog,"CFO, David Obstler alluded to this expectation in the conference call: ‚ÄúThroughout the quarter, we saw usage growth that was more in line with pre-pandemic historical levels."
datadog,The trend was broad-based and sustained throughout the quarter.
datadog,"This provides us with confidence that what we experienced in Q2 was a transitory optimization effort that were related to the challenging macro environment.‚Äù
With the normalization of customer usage trends and secular tailwinds related to digital transformation and cloud migration, management continues to believe that Datadog is very well positioned to capture a ‚Äúlarge and growing long-term market opportunity.‚Äù
JFrog
JFrog (NASDAQ: FROG) announced earnings for Q3 in its first quarter as a public company."
datadog,"The company grew revenue 40% YoY, beating consensus expectations by 3%."
datadog,"JFrog also announced Non-GAAP EPS of $0.05, beating expectations by 5 cents."
datadog,Gross margins came in at an impressive 83% while FCF margin improved to 25% in Q3.
datadog,"For Q4, JFrog expects $41.4M in revenue at the midpoint vs. consensus of $40.52M."
datadog,"The stock has initially sold off up to 10% on the results, as the 40% revenue growth represents a deceleration from the 46% growth recorded last quarter."
datadog,"Even after today‚Äôs sell-off, FROG still trades at approximately 30x 2021 revenue, which remains among the highest valuations in the software industry."
datadog,"Here‚Äôs what the Analysts ratings for the recent string of IPOs and where JFrog ranks:

Beth.Technology
When factoring in how fast some software names are growing, we see that JFrog still remains relatively expensive."
datadog,"With the deceleration, it‚Äôs likely we see an adjustment to JFrog‚Äôs valuation over the next quarter."
datadog,My team (Episource‚Äôs EpiAnalyst) needed a solution for logging and monitoring our applications to be able to better react to and research the issues that our users were running into.
datadog,"We had our application logs being stored on CloudWatch, but they were flat files separated by ECS task instance and we had to hunt those files down before doing our own search through those files to find the logs of interest."
datadog,We explored options that would allow us to filter and find logs of interest with more ease.
datadog,One of our previous Senior Developers suggested looking into DataDog and that is exactly what we ended up choosing.
datadog,DataDog offers a robust filtering system that allows us to easily (which was very important) find logs for a certain service during a particular window of time.
datadog,But it also offers so much more.
datadog,"I‚Äôd like to explore some of DataDog‚Äôs main features, provide a high level overview of what they do (along with links for the curious reader), and touch on some of the cool things we can accomplish if we commit to using DataDog properly."
datadog,What is DataDog?
datadog,"DataDog is a monitoring platform for our application services, particularly built for monitoring an ecosystem of cloud services."
datadog,"We integrate our services (like PostgreSQL, Redis, AWS services, etc.)"
datadog,"and can then observe a bunch of metrics, funnel application logging to DataDog to filter through, and set up alerts, among other things."
datadog,How does it work?
datadog,Every instance of the services we deploy has to run the DataDog Agent.
datadog,The DataDog Agent is the program that allows DataDog to collect metrics on our machines.
datadog,It can be downloaded and installed on a Virtual Machine or a physical machine.
datadog,What we (and most people) have done is to configure our cloud services to install the DataDog agent on deploy.
datadog,"We can then configure it to monitor certain metrics, or use one of DataDog‚Äôs 400+ built-in Integrations to auto-discover and collect metrics."
datadog,"The Features
Integrations
Integrations is more of a shortcut than a feature."
datadog,The team at DataDog has already put in a lot of the work necessary for determining what metrics are crucial for a certain service and how to retrieve them.
datadog,Deploying services onto AWS ECS clusters?
datadog,DataDog has an integration for that so we can quickly start gathering the metrics we need to improve the observability of our application.
datadog,More on Integrations.
datadog,"Logging
We can funnel our application logs over to DataDog."
datadog,"DataDog will save our logs, line by line, with timestamps, tags, and metrics."
datadog,We can then easily filter to find logs for exact situations.
datadog,Say we get a screenshot from an EpiAnalyst user in Los Angeles that there was a server error at 1:15pm.
datadog,"We can filter by service (EpiAnalyst API), by env (production), status (Error), and time (1:10pm to 1:20pm PST) and DataDog will retrieve and display the appropriate logs."
datadog,"We no longer have to dig through a directory for the right file, nor search the file for the right timestamps."
datadog,The logging feature also allows setting up parsing so that the string messages that get recorded to DataDog also get converted to JSON.
datadog,We can also use the parsing to set up pattern recognition to group our logs into clusters with similarities.
datadog,"The pattern clusters allow us to see bigger picture stories, like which API endpoints are our users hitting the most, or which error messages keep coming up."
datadog,More on Logging.
datadog,"Application Performance Monitoring (APM)
DataDog‚Äôs APM feature is a hub for observing and monitoring our services‚Äô performance metrics."
datadog,"The metrics are different depending on the type of service, but as an example, if we were looking at a Web (API) service then we would see metrics like: number of requests, number of errors, latency, as well as further drill down into deployments and endpoints."
datadog,"If all of our services are integrated with DataDog, then we can also check out the Service Map feature which allows us to visualize the relationships between the services."
datadog,One of the most amazing features DataDog offers is the Distributed Traces feature in the APM.
datadog,This allows us to drill down in to each request and gather more insight.
datadog,"With the right configuration, this could allow us to view which functions were called within our application, which other services were used to fulfill the request, how long our request spent in each function or other service, and more metrics during each portion of a request."
datadog,More on APM.
datadog,"Monitors
With all of these different metrics and different ways to observe them, it might be tempting to look often, but we probably don‚Äôt want to be looking at DataDog all day long."
datadog,"Actually, we probably don‚Äôt even want to have to check in periodically."
datadog,We can set up Monitors where we set certain thresholds for metrics and have DataDog send us an alert or notification whenever the metrics suggest our application may be in an undesirable state.
datadog,"For example, if we know that our application is expected to have an average latency of 1 second, then we can set a Monitor to check that metric and send us an email or text if the average latency is above 2s for over 5 minutes."
datadog,The person or team who gets notified then knows they have to check the application and investigate the cause of the irregularity.
datadog,"We would also be saved from the need to check this metric periodically, because DataDog Monitors would do that job for us."
datadog,More on Monitors.
datadog,"Dashboards
Dashboards allow us to use all of the metrics available to us to create a board where we can create a number of different types of charts and graphs and combine them all together to tell a story."
datadog,If we have non-technical users that would like to know how well we are doing to fulfill our Service-level agreements.
datadog,"We can create a dashboard that shows our application‚Äôs uptime/downtime, a board that shows a percentage to represent the percentage of time our services are available and have that number be green when the percentage is within our Service-level agreement and have it turn red if it goes below that threshold."
datadog,You can get creative and combine literally any number of metrics from all of your services to display them in a number of different visual formats to tell any story you may need to communicate.
datadog,More on Dashboards.
datadog,"UX Monitoring (or Real User Monitoring or RUM)
The UX Monitoring feature allows us to create tests based off common behavior we expect from our users in order to periodically test and confirm our application is working as expected."
datadog,We can create API Tests which are web requests DataDog will send off to our API and confirm that the response is what we expect.
datadog,We can even create complex API tests where we chain a few requests together for certain functionality that can‚Äôt be tested by a single web request.
datadog,Or we can create Browser Tests.
datadog,For these tests we will need to download a special Google Chrome plugin tool for DataDog which will allow us to ‚Äúrecord‚Äù a workflow on our website.
datadog,"DataDog will then repeat that workflow periodically, based on the configuration we set."
datadog,"For either test, we can set up Monitors to alert us whenever any of these tests begin to fail (on any environment)."
datadog,More on UX Monitoring.
datadog,"Conclusion
DataDog has a lot of useful features, but a lot of them can‚Äôt be taken advantage of to the fullest extent unless our services are properly integrated and tagged well."
datadog,"If you‚Äôd like to learn more about DataDog, the offer courses and extensive documentation."
datadog,"If you‚Äôre responsible for monitoring, chances are you‚Äôve heard of Datadog."
datadog,"Like InfluxDB, Datadog is a monitoring platform for cloud applications, bringing together data from containers, servers, databases and third-party services."
datadog,InfluxData and Datadog approach monitoring from different starting points.
datadog,"InfluxDB is an open-source time series data platform that can be used for a range of use cases, one of which is monitoring."
datadog,"Datadog started out as an application purpose-built for infrastructure monitoring, and from there created purpose-built offerings for monitoring application performance, logs, security, and more."
datadog,Both companies focus on making things easier for engineering teams.
datadog,"For instance, today on review site G2, ‚Äúeasy to use‚Äù is in the headline of both companies‚Äô lead reviews."
datadog,"Given this ease of use, a number of our customers use both ‚Äî InfluxDB for infrastructure monitoring, and Datadog for other types of monitoring."
datadog,But that led us to ask: why are these customers using InfluxDB in addition to Datadog?
datadog,"After all, Datadog aims to be a place where you can ‚Äúsee it all in one place.‚Äù
So, we decided to investigate."
datadog,Here‚Äôs what we found.
datadog,How are InfluxDB and Datadog used?
datadog,"Among customers that use both, we heard that they prefer InfluxDB for infrastructure monitoring and storing performance metrics for things like servers, containers, virtual machines and databases, and that they prefer Datadog for application performance management (APM) metrics."
datadog,We asked them why they used two different vendors.
datadog,"After all, Single Pane of Glass ‚Äî seeing all your logs, metrics, and traces in one place in order to find and fix problems faster ‚Äî is an essential goal for any team managing production systems."
datadog,This is because these teams continually need to reduce mean time to resolution (MTTR) in order to meet their SLAs and SLOs.
datadog,"Overwhelmingly, we heard about two key areas where they run into problems with Datadog: price and flexibility."
datadog,Let‚Äôs review each in turn.
datadog,How much does DataDog cost?
datadog,"While Datadog‚Äôs per-server, per-month pricing for infrastructure monitoring is easy to understand, customers tell us that it becomes very expensive at scale."
datadog,"For example, suppose you‚Äôre an enterprise with 2,000 hosts to monitor."
datadog,"That‚Äôs actually a small number by today‚Äôs standards, given microservice architectures where many specialized backend components work together to power an application."
datadog,"(Note that, for billing purposes, Datadog counts virtual machines running on AWS, Google Cloud, Azure, or VMware vSphere as individual hosts.)"
datadog,"At $23 per monitored host per month, Datadog Enterprise will have a list price of over $500,000."
datadog,"Even with a discount, that‚Äôs not a number to sneeze at."
datadog,"On top of that, Datadog charges extra for:
Serverless tasks ‚Äî $1 each
Serverless function ‚Äî $5 each per month
Custom metrics (list pricing not available on website)
Individual containers beyond specified limits
Usage spikes (Datadog excludes the top 1% of usage ‚Äî much different from billing on average use.)"
datadog,How much does InfluxDB cost?
datadog,"InfluxData doesn‚Äôt price by monitored host or metric, but by the size of the server or cluster that stores your monitoring data."
datadog,This is a critical difference that means InfluxDB is only 30% the cost of Datadog for most real-world infrastructure monitoring use cases.
datadog,"For our pricing analysis, we looked at pricing for the fully managed InfluxDB Cloud product, since this is closest to Datadog‚Äôs offering."
datadog,"Like Datadog, InfluxDB Cloud is fully managed 24/7 by our in-house site reliability engineering (SRE) team."
datadog,"This is in contrast to InfluxDB Enterprise, which customers manage on their own infrastructure."
datadog,"After looking at prices paid by InfluxDB Cloud customers, we found that the median price is $6.75 per monitored host per month."
datadog,"Slash your infrastructure monitoring costs by 70%
When you compare InfluxDB‚Äôs $6.75 price point to Datadog‚Äôs $23, you see savings of 70%."
datadog,"Your mileage might vary, but put us to the test!"
datadog,Talk to one of our specialists to see how much we can reduce your infrastructure monitoring bill.
datadog,"To be clear, we‚Äôre talking about pricing for infrastructure monitoring."
datadog,"Datadog charges extra for its APM, log, security, and other monitoring products, which wasn‚Äôt included in the above analysis."
datadog,Why does InfluxDB cost less than Datadog?
datadog,"You might ask, why can‚Äôt Datadog simply match InfluxData‚Äôs price?"
datadog,We don‚Äôt believe it‚Äôs that simple.
datadog,One reason InfluxDB is typically less expensive is our lower cost structure.
datadog,"InfluxDB Cloud is based on an open-source product ‚Äî InfluxDB, along with some closed source functionality like clustering and role-based access control (RBAC)."
datadog,"A global community of engineers freely contributes code to InfluxDB, Telegraf, and our Flux language, as shown below."
datadog,This lets us deliver features at a lower cost ‚Äî and we pass those savings on to our customers.
datadog,"In contrast, Datadog‚Äôs product is largely proprietary software it builds itself, leading to a higher cost structure that it passes on to its customers."
datadog,"You can see for yourself on Datadog‚Äôs GitHub repository; while some of its agents and libraries are open source, its core product is not."
datadog,Now you might be thinking: InfluxDB is lower-cost ‚Äî but is it as good?
datadog,"Read on‚Ä¶
Datadog vs. InfluxDB flexibility
The second difference our joint customers brought up was flexibility."
datadog,"Specifically, they mentioned the ability for developers to tailor infrastructure monitoring to their exact needs, and make it manageable using GitOps (storing operations configurations in repositories like GitHub)."
datadog,Let‚Äôs dive in.
datadog,"Broader observability
On its website, Datadog states that they monitor 400 different technologies."
datadog,"While that‚Äôs not bad, it‚Äôs less than half of the 735 FluentD plugins plus 181 Telegraf input plugins that can send data to InfluxDB."
datadog,"Maybe Datadog‚Äôs 400 plugins will cover your needs today, and maybe they won‚Äôt."
datadog,"But if you want to ensure that your future needs are covered, it makes sense to go with a product that taps into both the Telegraf and FluentD communities."
datadog,"By doing so, you can ensure the broadest possible observability to detect problems sooner and fix them faster ‚Äî now and going forward."
datadog,"One customer also told us that Datadog agents can get overwhelmed, crash, and send duplicates of data ‚Äî none of which happens with Telegraf."
datadog,"Your mileage may vary, but at the very least, agent stress testing is something you might want to incorporate into your Datadog and Telegraf evaluations."
datadog,"Unleash your monitoring data
Another challenge our customers told us about is getting data out of Datadog."
datadog,"Datadog‚Äôs documentation states that, by default, it rate-limits its output API to 100 requests per hour."
datadog,InfluxData‚Äôs stance is the complete opposite; we don‚Äôt artificially rate-limit our output.
datadog,We realize that no monitoring platform is an island.
datadog,"It needs to integrate with a broad set of vendors: visualization, alerting, ML/AI, and more."
datadog,So we can‚Äôt be stingy around data export.
datadog,"Because of this, InfluxData provides first-class outbound integrations across your DevOps and monitoring toolchain:
Grafana for visualization
PagerDuty, Slack, and many other alerting tools
AWS Kinesis, Google Cloud Pub/Sub, Azure Monitor ‚Äî to send to those clouds‚Äô AI/ML engines
Jupyter and Zeppelin notebooks for machine learning and AI-powered analysis
30+ Telegraf output plugins
8 client libraries in popular languages
Our philosophy is: this is your data."
datadog,You paid to collect it.
datadog,You should be free to use it to drive further efficiencies in your monitoring and better experiences for your customers.
datadog,"Efficiency through analytics
Datadog query filters and query language let you do min, max, and average, and counts."
datadog,But that‚Äôs a small fraction of the dozens of functions in InfluxDB‚Äôs Flux data scripting language.
datadog,"These InfluxDB functions streamline common tasks for teams running production systems, such as:
Calculate percentiles to track SLA compliance, which are often measured at the 90th, 95th, or 98th percentile."
datadog,Window and aggregate data to pick out trends from noisy data sets.
datadog,"Enrich monitoring data with data in SQL databases, like account data, to facilitate customer outreach during outages."
datadog,Forecast with Holt-Winters to predict outages and capacity issues.
datadog,Geographically track your monitoring metrics to better determine which regions are experiencing problems.
datadog,We built all of this flexibility into InfluxDB to make it a complete time series data platform.
datadog,"This lets you give your developers the monitoring flexibility they crave, so they can quickly find and fix problems fast to keep critical systems running 24/7."
datadog,"Deployment flexibility
Datadog is deployed only on AWS."
datadog,"In contrast, you can deploy InfluxDB on dozens of AWS, Microsoft Azure, and Google Cloud regions, as well as on your own servers."
datadog,This is especially significant given customer privacy regulations such as GDPR and CCPA that might have business implications for where you host your data.
datadog,"Datadog vs. InfluxDB features
Take a look at this detailed comparison of Datadog vs. InfluxDB."
datadog,You‚Äôll see that InfluxDB matches Datadog in many areas and surpasses it in others.
datadog,How to migrate off Datadog?
datadog,"If you‚Äôd like to migrate off Datadog, we‚Äôve made it easy and low-risk by allowing you to migrate gradually, and on your own timeline."
datadog,Here‚Äôs an overview of what that looks like.
datadog,Let‚Äôs walk through this diagram.
datadog,"Telegraf, our data integration agent, can ingest metrics from StatsD format used by the Datadog DogStatsD plugin."
datadog,"Just set the datadog_extensions flag to true in your telegraf.conf file, as shown below, and Telegraf will be able to ingest Datadog metrics:
## Parses extensions to statsd in the datadog statsd format
 ## currently supports metrics and datadog tags."
datadog,"## http://docs.datadoghq.com/guides/dogstatsd/
 datadog_extensions = true
And, Telegraf lets you dual-write monitoring metrics to both Datadog and InfluxDB."
datadog,"For Datadog, you simply put the following into your telegraf.conf file:
[[outputs.datadog]]
apikey = ""<datadog api key>""
This lets you verify that your monitoring metrics are coming into InfluxDB; explore our query capabilities and outbound integrations; and eventually, migrate with no monitoring outages."
datadog,"Dual-write also means that, if you can‚Äôt get monitoring data out of Datadog due to their 100 output API requests/hour limit, you can use both InfluxDB and Datadog for a period of time until you no longer need your Datadog monitoring data."
datadog,"At that point, you can fully switch over to InfluxDB."
datadog,"Summary
So, if you‚Äôre looking for a Datadog alternative that lets you:
Slash your infrastructure monitoring budget by up to 70%
Increase observability for your developers, engineers, and SREs
Unlock monitoring data so it can be used across your DevOps toolchain
Increase DevOps and SRE team efficiency using a broad range of analytics
Store data wherever business needs dictate
‚Ä¶ then speak with one of our monitoring specialists for a free consultation to learn how we can help you transition off of Datadog."
datadog,"Wastes of cloud spend
With the public and hybrid cloud adoption rapidly growing, enterprises and organizations continue to increase their spending on cloud infrastructure."
datadog,"However, most of the increased spending is not turning into business revenue."
datadog,"In the recent survey of 2020 State of the Cloud Report [1] by Flexera over 750 technical professionals worldwide, respondents self-estimate organizations waste 30 percent of cloud spend."
datadog,Flexera has found that actual waste is 35 percent or even higher.
datadog,The significant wasted cloud spend drives organizations to focus on cost savings.
datadog,About 73 percent of the organizations surveyed plan to optimize their existing cloud resources to achieve better cost savings.
datadog,"However, most organizations struggle to handle the growing cloud spend due to a lack of resources or expertise [2]."
datadog,Let‚Äôs do some calculations on the 35 percent waste of cloud spend.
datadog,"Gartner recently predicted [3] that the Cloud System Infrastructure Services (IaaS) spending will reach $50 billion in 2020, an increase of 13% from 2019."
datadog,"That means about $17.5 billion of wasted cloud spending in 2020 alone, and this number will keep increasing, given the growth of the cloud."
datadog,Another study [4] from ParkMyCloud also arrives at a similar conclusion that the Wasted Cloud Spend would exceed $17.6 Billion in 2020.
datadog,"Just as the title of article [5] by Larry Dignan (Editor in Chief of ZDNet), cloud cost control is becoming a leading issue for businesses."
datadog,Figure 1.
datadog,"Percentage of Cloud Spend Wasted

Table 1."
datadog,Worldwide Public Cloud Service Revenue Forecast (Millions of U.S.
datadog,"Dollars)
BPaaS = business process as a service; IaaS = infrastructure as a service; PaaS = platform as a service; SaaS = software as a service
Source: Gartner (July 2020)
Challenges of reducing cloud spend waste
The pay-as-you-go pricing model of cloud infrastructure services claims that you only pay for what you use."
datadog,But this is not entirely accurate.
datadog,"To be more precise, you pay for what you allocate."
datadog,All the resources you allocate for your applications during the period are charged no matter whether you use them or not.
datadog,The wasted cloud spend comes from the idle resources and the idle resources are from the over-provisioning.
datadog,It is almost impossible for most organizations to understand their workload requirements and estimate the needed infrastructure resources before migrating the applications to the public cloud.
datadog,The easiest and safest way is to take an over-provisioning strategy.
datadog,"In the beginning, an IT department allocates a huge and fixed amount of resources to prevent applications from running out of resources."
datadog,"That leads to a large number of idle resources, which means a significant wasted cloud spend."
datadog,"On the other hand, if an IT department periodically reviews their cloud spend and tries to allocate fewer resources, the lack of visibility and capability to predict the needed resources might lead to under-provisioning."
datadog,"It is futile to allocate a fixed amount of resources to meet a dynamically changing workload, as shown in the figure below."
datadog,Figure 2.
datadog,"Over-provisioning leads to wasted spending,
and under-provisioning leads to performance degradation."
datadog,Right-sizing is one way to reduce cloud spending.
datadog,"We consider other methods, including running workloads on a cheaper cloud provider or region with the same SLA maintained, selecting low-priced instance types with similar performance, and taking advantage of reserved instances and SPOT instances when possible."
datadog,"However, most organizations don‚Äôt have the needed expertise to apply these methods, and the right solution is required to optimize the cost of operation."
datadog,A well-designed solution can significantly help with cost optimization if it offers visibility and projection of the workload costs and continuously engages and recommends the right environment to run the workloads.
datadog,"Why Federator.ai can help reducing cloud spend
Federator.ai is an Artificial Intelligence for IT Operations (AIOps) platform that provides intelligence to orchestrate container resources in environments like Kubernetes/OpenShift clusters, either on-premises or in public clouds."
datadog,"Using Machine Learning and other data analytical tools, Federator.ai predicts clusters‚Äô resource usages based on past observations."
datadog,It captures resource utilization‚Äôs dynamic nature throughout the cluster deployment lifecycle and provides the visibility of usage patterns for cluster resource planning.
datadog,"Using this resource usage prediction in conjunction with the price plans of the major public cloud providers (AWS, Azure, and GCP), Federator.ai translates cluster resource usage metrics and forecasts into the most cost-effective and actionable recommendations for right-sizing a cluster."
datadog,"Fedemeter, the patent-pending cost analysis module of Federator.ai, takes the input of current cluster configuration and workload prediction to produce a recommendation of the most cost-optimized cluster configuration for users."
datadog,The recommendation output is a time series of Just-in-Time Fitted instance size to support application workloads without resource wastes.
datadog,"The most cost-effective instance types with the best purchasing options are recommended, including the possibilities of either switching over to different cloud providers and regions or remaining in the same provider depending on the user‚Äôs preference."
datadog,Figure 3.
datadog,"How Federator.ai Optimizes Cloud Cost Savings
Figure 3 shows three main considerations when deciding the recommended cluster configuration."
datadog,The first is to exam how much idle resources could be reduced.
datadog,The second is to search for cost-effective instances that meet the expected workloads.
datadog,The last is to weigh different purchasing options from the users to finalize the recommendation.
datadog,"Reducing Idle Resources
The observed resource usage metrics (CPU/memory) of application workloads are gathered and classified according to their characteristics, such as SLAs (evictable/unevictable) or their lifetimes (continuous/scheduled/batch)."
datadog,Then Federator.ai‚Äôs machine learning algorithms are applied to generate workload predictions in different time granularity.
datadog,"Based on these predicted resource usage metrics, Federator.ai reduces over-provisioned idle resources in the current cluster configuration and translates the metrics into a time series of Just-in-Time Fitted instance size."
datadog,"Using Most Cost-Effective Instance Types
A cluster configuration is a set of metadata of the underlying instances running on the cloud; it includes cloud provider, region, instance type, storage, size, and purchasing model of each instance."
datadog,Instances having similar specifications and performance could have very different prices between providers or regions of the same provider.
datadog,All cloud providers have their pricing strategies and pricing models.
datadog,The cost calculation includes complicated formulas and is all different between providers.
datadog,"Also, in other regions, the instance with other specifications, with operating systems and software installed, combing different storage types all have different prices."
datadog,That makes it a difficult task to determine the most cost-effective instance type and region.
datadog,"The frequent changes in pricing databases‚Äô release due to new deals and new instances, families, or data centers make the situation worse."
datadog,"Federator.ai automatically and continuously compiles the price books from AWS, Azure, and GCP cloud providers and intelligently searches for the most cost-effective instance types and user region."
datadog,The typical cost savings from choosing the right instance type in the appropriate region is up to 40%.
datadog,"Choosing Best Purchasing Models
To maximize the utilization of infrastructure resources, cloud providers usually offer different pricing models for different types of workloads."
datadog,"For example, providers offer a ‚Äúreserved instance‚Äù purchasing option in which users commit to purchasing a fixed amount of resources over one year, whether or not the resources are utilized by the users."
datadog,"Compared to the on-demand purchasing model, the reserved instance price discount typically ranges from 30% to 70%."
datadog,"Also, providers offer ‚Äúspot‚Äù purchasing options for selling their spare infrastructure resources."
datadog,"The discount is even larger, up to 90%, with the risk of the resource being reclaimed on short notice."
datadog,Using reserved and spot instances can significantly reduce costs.
datadog,But not all application workloads are suitable for running on SPOT and reserved instances.
datadog,"By understanding the characteristics (SLA, lifetime, etc.)"
datadog,"of application workloads, Federator.ai uses classified workload predictions to recommend the best combination of purchasing models of cluster instances."
datadog,"For example, the application workloads that are evictable will be aggregated and translate into spot instances."
datadog,"On the other hand, the continuous workloads and scheduled workloads in different time frames can be aggregated and supported using reserved instances."
datadog,"For the unevictable workloads with dynamically changing utilization, they are more suitable for using on-demand instances."
datadog,"Considering predicted idle resources, cost-effective instance types, and different purchasing options based on user preference and application workload characteristics, Federator.ai makes the most optimized recommendations with the best cost savings."
datadog,"Using Federator.ai for MultiCloud cost savings
There are several use cases where Federator.ai can help customers reduce their cloud spend."
datadog,"Day-1 recommendation for application workload deployment
For customers planning to migrate their application workloads from on-premises clusters to the public cloud, Federator.ai recommends the most cost-effective cluster configuration based on the workload prediction and comparison of prices from different cloud providers and regions."
datadog,The recommended instances included in the cluster configuration are also optimized to provide Just-in-Time Fitted resources for supporting application workloads.
datadog,This recommendation offers organizations excellent visibility about the estimated cost when migrating their applications from on-premises to a public cloud service provider or from one public cloud provider to another.
datadog,"Also, the recommended cluster configuration provides organizations an optimized and executable plan for allocating proper infrastructure resources on the new public cloud."
datadog,"Day-2 Operation recommendation for cost savings in existing public cloud deployment
If users are already running applications in the public cloud, they can also benefit from Federator.ai‚Äôs recommendation for cost savings."
datadog,"With workload prediction, Federator.ai recommends cost-optimized configuration with the same provider and region, and thus the users could consider changing their current configuration and optimize the current cluster."
datadog,"Users can also explore the purchasing options like reserved instance and spot instance, which can significantly reduce the cost."
datadog,"Also, combing with the Federator.ai Horizontal Pod Autoscaling and Cluster Optimizer features, Federator.ai intelligently and automatically maintains the most cost-effective cluster configuration and delivers the most optimized application performance for Kubernetes/OpenShift users."
datadog,"Cost breakdown for cluster namespaces and applications
Each department in an organization can understand its hourly cost of resource usage and the whole cluster‚Äôs cost percentage in real-time."
datadog,The cost already spent in the past and projected costs in the future are presented in the same chart for better illustrating the cost trend.
datadog,"Using Federator.ai‚Äôs public APIs, users can integrate with their own systems for alert notification of potential cost overrun to proper departments."
datadog,"Conclusion
Reducing wasted cloud spend is an essential task for any enterprise and organization that are running mission-critical applications in a public cloud or considering moving to a public cloud."
datadog,Federator.ai‚Äôs AI-enabled intelligent cost analysis capability simplifies the cumbersome and complicated process of deciding the right cluster configuration with workload prediction.
datadog,Continuous analysis of ongoing workloads and prediction of future workloads with new recommendations allows users to maintain their cost objectives throughout the deployment lifecycle.
datadog,"#kubernetes #datadog #ai #multicloud #aiops #redhat #openshift #cloudcostsavings #aws #gcp #azure #rackspace #costoptimization #ProphetStor
References
Flexera, 2020 State of the Cloud Report (launched initially by RightScale)."
datadog,"The Cost of Cloud Expertise report, by John Engates, CTO, Rackspace."
datadog,"Gartner, Forecasts Worldwide Public Cloud Revenue to Grow 6.3% in 2020
ParkMyCloud, Wasted Cloud Spend to Exceed $17.6 Billion in 2020, Fueled by Cloud Computing Growth
Cloud cost control becoming a leading issue for businesses, by Larry Dignan, Editor in Chief of ZDNet and Editorial Director of TechRepublic."
datadog,"Follow ProphetStor on Twitter and Facebook
Connect with ProphetStor on LinkedIn
For more information, please visit https://www.prophetstor.com"
datadog,"Source
Azure resources generally have good integration with App Insights for logs and APM (Application performance monitoring)."
datadog,"But sometimes your monitoring stack is with a 3rd Party company, like New Relic, Zabbix or Datadog."
datadog,"In this guide, we are going to how to log every single request hitting an Azure API management into Datadog."
datadog,What is Datadog?
datadog,"Datadog is a monitoring service for cloud-scale applications, providing monitoring of servers, databases, tools, and services, through a SaaS-based data analytics platform."
datadog,"[Wikipedia]
Logging from API Management
The base documentation where I learned this logging flow."
datadog,"The steps

Diagram: Azure API management > Event Hub > Function App > Datadog
This integration requires a few components, so let‚Äôs go over configuring this manually:
* Make sure you are adding the resources to the same region
1."
datadog,"Add the event hub namespace

Create Event hub namespace Azure page
2."
datadog,"Create the event hub in the namespace:

Create Event hub Azure page
3."
datadog,"Enable the diagnostic logging:
Azure seems to be moving towards this model, where every resource is going to expose diagnostic settings, so this tutorial could be used for other resource types to have Datadog integration."
datadog,"Enable diagnostic in the API management

Enable diagnostic settings for log ‚ÄúGatewayLogs‚Äù into the event hub we created
So up to this point, we have half the integration:

Diagram: Azure API management > Event Hub > other components disabled
4."
datadog,"Create the Function app:

5."
datadog,"Add the configuration:

DD_API_KEY ‚Äî The API key for Datadog
DD_SITE ‚Äî The function bellow uses it to decide to which Datadog site to use."
datadog,"(US by default)
The function bellow uses for metadata: DD_SERVICE, DD_SOUCE, DD_TAGS, DD_SOURCE_CATEGORY
6."
datadog,"Deploy the function code:
Create an app function with an Event Hub Trigger

Make sure the connection is pointing to the event hub we created previously:

Deploy this code:

Source
7."
datadog,"Test the function in isolation

8."
datadog,"Confirm the logs arrive into Datadog
Test the entire flow by making API calls in the API management instance."
datadog,"Datadog logs page

Datadog logs
Terraform automation:
And of course, I wouldn‚Äôt leave you with a manual setup, here are the Terraform scripts:

Terraform script, creating all the steps and linking them together."
datadog,"On Github
I haven‚Äôt automated the Node.js Function deployment at this point, as it was the least complicated bit, but that won‚Äôt be too hard to do if needed."
datadog,"Conclusion
That isn‚Äôt a straight forward integration, but hopefully, I showed that is possible to integrate API management logs with Datadog, and that a complex manual setup like this can be automated using Terraform."
datadog,Honeycomb markers of your datadog alerts.
datadog,Observability and monitoring is a key tool to know how your product is going.
datadog,"There are thousands of good products to get this data and to evaluate these, but my favorites are datadog and honeycomb.io they are both super great in their expertise domain."
datadog,"We are using datadog to monitor our infrastructure and to collect our logs and we are using honeycomb for tracing, so honeycomb has the user vision when datadog has the infrastructure vision."
datadog,"We have one problem here is that these 2 visions are not connected, so sometimes it is hard to understand what we see in the user vision if we have no context of what happened in the infrastructure."
datadog,So what we want is that when an alert is triggered by datadog we need to see it in honeycomb.
datadog,"Honeycomb Markers
Markers are for indicating points in time on your graphs where interesting things happen, such as deploys or outages."
datadog,We will use markers to have a visual way to see the datadog alert in our timeline.
datadog,How to create these datadog alert markers?
datadog,"Create a Honeycomb API key
First, what we need to do is to create an API key to be able to create a marker with an API call."
datadog,"Connect to your honeycomb.io account
Go on your team settings
Under section API Keys section, create a new key with the following params."
datadog,"Create a webhook in Datadog
Now that we have a Honeycomb API key we can create a custom webhook integration in datadog to call markers API."
datadog,"Connect to your datadog account
Go in Integrations > Integrations > webhooks

3."
datadog,"Inside the webhooks integration, add a new webhook."
datadog,"In your configuration, you should have:
URL: https://api.honeycomb.io/1/markers/<YOUR_DATASET>
Payload:
{
    ""message"":""DD #$ALERT_ID ($ALERT_TRANSITION)"",
    ""type"":""$EVENT_TYPE"",
    ""url"":""$LINK""
}
Now that everything is set, the last thing is to call this webhook on your monitor in datadog."
datadog,That part works exactly the same way that you set up your monitors in datadog.
datadog,"{
    ""X-Honeycomb-Team"":""YOUR_HONEYCOMB_API_KEY""
}

Call the wehook
Now that everything is set, the last thing is to call this webhook on your monitor in datadog."
datadog,That part works exactly the same way that you set up your monitors in datadog.
datadog,"How it looks
Now that you have everything setup, your next alert will appear in your honeycomb.io timeline, and it will be way easier to understand your user behavior."
datadog,"As you can see below, we have a new marker that links us directly to the datadog alert so, it is easy to have the information that something happens and, you can click on it to see directly the datadog‚Äôs alert."
datadog,"So as you can see now, we have a cross vision from user to infrastructure, and let me tell you that it will help you a lot to debug your next incident."
datadog,"Collect Kubernetes and Docker metrics
First, you will need to deploy the Datadog Agent [https://github.com/DataDog/datadog-agent] to collect key resource metrics and events from Kubernetes and Docker for monitoring in Datadog."
datadog,"In this section, we will show you one way to install the containerized Datadog Agent as a DaemonSet on every node in your Kubernetes cluster."
datadog,"Or, if you only want to install it on a specific subset of nodes, you can add a nodeSelector field to your pod configuration."
datadog,"If your Kubernetes cluster uses role-based access control (RBAC), you can deploy the Datadog Agent‚Äôs RBAC manifest (rbac-agent.yaml) to grant it the necessary permissions to operate in your cluster."
datadog,"Doing this creates a ClusterRole, ClusterRoleBinding, and ServiceAccount for the Agent."
datadog,"kubectl create -f ""https://raw.githubusercontent.com/DataDog/datadog-agent/master/Dockerfiles/manifests/cluster-agent/rbac/rbac-agent.yaml""
Next, copy the following manifest to a local file and save it as datadog-agent.yaml."
datadog,"apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: datadog-agent
  namespace: default
spec:
  selector:
    matchLabels:
      app: datadog-agent
  template:
    metadata:
      labels:
        app: datadog-agent
      name: datadog-agent
    spec:
      serviceAccountName: datadog-agent
      containers:
      - image: datadog/agent:latest
        imagePullPolicy: Always
        name: datadog-agent
        ports:
          - containerPort: 3919
            name: dogstatsdport
            protocol: UDP
          - containerPort: 3920
            name: traceport
            protocol: TCP
        env:
          - name: DD_API_KEY
            value: <YOUR_API_KEY>
          - name: DD_COLLECT_KUBERNETES_EVENTS
            value: ""true""
          - name: DD_LEADER_ELECTION
            value: ""true""
          - name: KUBERNETES
            value: ""true""
          - name: DD_HEALTH_PORT
            value: ""5555""
          - name: DD_KUBELET_TLS_VERIFY
            value: ""false""
          - name: DD_KUBERNETES_KUBELET_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: DD_APM_ENABLED
            value: ""true""
        resources:
          requests:
            memory: ""256Mi""
            cpu: ""200m""
          limits:
            memory: ""256Mi""
            cpu: ""200m""
        volumeMounts:
          - name: dockersocket
            mountPath: /var/run/docker.sock
          - name: procdir
            mountPath: /host/proc
            readOnly: true
          - name: cgroups
            mountPath: /host/sys/fs/cgroup
            readOnly: true
        livenessProbe:
          httpGet:
            path: /health
            port: 5555
          initialDelaySeconds: 15
          periodSeconds: 15
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
      volumes:
        - hostPath:
            path: /var/run/docker.sock
          name: dockersocket
        - hostPath:
            path: /proc
          name: procdir
        - hostPath:
            path: /sys/fs/cgroup
          name: cgroups
Replace <YOUR_API_KEY> with an API key from your Datadog account."
datadog,"Then run the following command to deploy the Agent as a DaemonSet:
kubectl create -f datadog-agent.yaml
Now you can verify that the Agent is collecting Docker and Kubernetes metrics by running the Agent‚Äôs status command."
datadog,"To do that, you first need to get the list of running pods so you can run the command on one of the Datadog Agent pods:
# Get the list of running pods
$ kubectl get pods
NAME             READY     STATUS    RESTARTS   AGE
datadog-agent-krrmd   1/1       Running   0          17d
...

# Use the pod name returned above to run the Agent's 'status' command
$ kubectl exec -it datadog-agent-krrmd agent status
In the output you should see sections resembling the following, indicating that Kubernetes and Docker metrics are being collected:
kubelet (4.1.0)
---------------
  Instance ID: kubelet:d884b5186b651429 [OK]
  Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default
  Total Runs: 35
  Metric Samples: Last Run: 378, Total: 14,191
  Events: Last Run: 0, Total: 0
  Service Checks: Last Run: 4, Total: 140
  Average Execution Time : 817ms
  Last Execution Date : 2020-10-22 15:20:37.000000 UTC
  Last Successful Execution Date : 2020-10-22 15:20:37.000000 UTC

docker
------
  Instance ID: docker [OK]
  Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default
  Total Runs: 35
  Metric Samples: Last Run: 290, Total: 15,537
  Events: Last Run: 1, Total: 4
  Service Checks: Last Run: 1, Total: 35
  Average Execution Time : 101ms
  Last Execution Date : 2020-10-22 15:20:30.000000 UTC
  Last Successful Execution Date : 2020-10-22 15:20:30.000000 UTC
Now you can glance at your built-in Datadog dashboards for Kubernetes and Docker to see what those metrics look like."
datadog,"And, if you‚Äôre running a large-scale production deployment, you can also install the Datadog Cluster Agent ‚Äî in addition to the node-based Agent ‚Äî as a centralized and streamlined way to collect cluster-data for deep visibility into your infrastructure."
datadog,"Add more Kubernetes metrics with kube-state-metrics
By default, the Kubernetes Agent check reports a handful of basic system metrics to Datadog, covering CPU, network, disk, and memory usage."
datadog,"You can easily expand on the data collected from Kubernetes by deploying the kube-state-metrics [https://github.com/kubernetes/kube-state-metrics] add-on to your cluster, which provides much more detailed metrics on the state of the cluster itself."
datadog,"kube-state-metrics listens to the Kubernetes API and generates metrics about the state of Kubernetes logical objects: node status, node capacity (CPU and memory), number of desired/available/unavailable/updated replicas per deployment, pod status (e.g., waiting, running, ready), and so on."
datadog,You can see the full list of metrics that Datadog collects from kube-state-metrics here.
datadog,"To deploy kube-state-metrics as a Kubernetes service, copy the manifest here [https://github.com/kubernetes/kube-state-metrics/blob/master/examples/standard/service.yaml], paste it into a kube-state-metrics.yaml file, and deploy the service to your cluster:
kubectl create -f kube-state-metrics.yaml
Within minutes, you should see metrics with the prefix kubernetes_state."
datadog,streaming into your Datadog account.
datadog,I am a Site Reliability Engineer at Fairwinds where we provide both Software and Service offerings that help our clients succeed in the world of Kubernetes.
datadog,In our highest touch offering we will run clusters for you and monitor that infrastructure 24/7.
datadog,"In working with so many clusters and customers with varying needs, it is a necessity to have tools that make us (and our clients) more efficient in our day to day work."
datadog,A lot of this software we create is open sourced to give back to the open source community that we leverage so often.
datadog,"Astro is one of these open source tools, and that‚Äôs the focus today."
datadog,"First, I want to tell you a little about my monitoring journey throughout my career."
datadog,"10 years ago, my first position was for a large company using bare metal servers alongside a few VM‚Äôs, but the VMs were mostly used for dev and QA."
datadog,Most of the monitoring that was done was for the bare metal machines.
datadog,My experience with monitoring and alerts at this point revolved around statically monitoring machines that didn‚Äôt change often.
datadog,We‚Äôre talking hundreds of hours of uptime for some of these machines and applications.
datadog,The shift from bare metal hosts into the world of containers and Kubernetes requires us to rethink some things around monitoring.
datadog,"In a traditional bare metal environment, the number of machines you need to monitor is usually a known quantity with a finite number of processes on each host."
datadog,Easy!
datadog,You set up your monitors once when you‚Äôre provisioning the machine and rely on them from that point forward.
datadog,"When using Kubernetes, development teams are empowered to create and destroy services as necessary which means you need to monitor an unknown number of services."
datadog,"This leaves something to be desired when using manually defined, traditional static monitoring."
datadog,"Depending on SLA and SLO of an application, you will likely want to get alerted if it is misbehaving."
datadog,"On the flipside, you don‚Äôt need to keep monitoring a service once it is removed from the cluster."
datadog,"Granted, this may not be the case depending on how you or your organization manage deployments, but regardless it‚Äôs easier to allow software to manage this process."
datadog,"Monitoring Kubernetes Workloads with Astro
Datadog‚Äôs service is wonderful and removes a lot of toil from our daily lives as Kubernetes operators."
datadog,Most things ‚Äújust work‚Äù when it comes to metrics gathering after you install the datadog-agent.
datadog,We built Astro to complement the Datadog service so that monitoring workloads is automatic in the dynamic world of Kubernetes.
datadog,"Astro is a workload that runs inside your Kubernetes cluster and will create a set of defined monitors based on annotations put on either your workloads, or a namespace that contains multiple workloads."
datadog,"Astro provides three key elements to greatly simplify monitor management:
Automated management of the lifecycle of Datadog monitors for workloads running in Kubernetes: Given configuration parameters, the utility will automatically manage defined monitors for all relevant objects within the Kubernetes cluster."
datadog,"As objects change, monitors are updated to reflect that state."
datadog,Correlation between logically bound objects: Astro has the ability to manage monitors for all objects within a given namespace.
datadog,This ensures greater consistency across monitor configurations.
datadog,Templating of values from Kubernetes objects into managed monitors: Any data from a managed Kubernetes object can be inserted into a managed monitor.
datadog,This makes more informative alerts and can make monitors more context specific.
datadog,"Watch a Demo of Astro

Astro, an open source project by Fairwinds, Automates Kubernetes Monitors in Datadog
Transcript
In this demo, I already have Astro running, which was installed with our provided helm chart."
datadog,We are tailing the logs of Astro in my top pane and also showing the monitors in the Datadog frontend.
datadog,We have configured Astro in this demo to create a set of monitors for any Deployment with the annotation of astro/owner = astro.
datadog,This key value combination can be configured to something else if you desire.
datadog,You can see here that I‚Äôve added this annotation to our nginx deployment.
datadog,We see a log message that the monitor should be created.
datadog,If we refresh the Datadog frontend we can see this is true!
datadog,Now lets remove the annotation and verify that Astro removes the monitor.
datadog,One other feature of note is the idea of a binding monitor.
datadog,"In a binding monitor you configure a set of ‚Äúbound‚Äù resource types, such as a Deployment and then you apply the configured annotation to a namespace, which in this case is astro/admin-bound = astro."
datadog,"Once applied to the namespace, any resources that match the binding type within that namespace will get the set of monitors."
datadog,This gives you flexibility to monitor every Deployment in a given namespace.
datadog,"At this time, Deployment is the only resource type available with the plan to add DaemonSets and StatefulSets."
datadog,"If we remove the annotation from the namespace, the monitors will go away
The Astro project is still young and growing, and the community is growing with it."
datadog,We hope to see you in our community slack and maybe even opening a PR to Astro to help us make this project as useful as can be.
datadog,"https://imgflip.com/
In my last 2 articles about maintenance, we have talked about properly handling exceptions and how to log properly."
datadog,"Both subjects are simple enough, but done improperly will make our application unmaintainable."
datadog,"In this article, I won‚Äôt explain how to configure these log aggregation and analysis tool."
datadog,We rather are going to see the difference between the various tools I have tested.
datadog,This way we can choose which tool we wish to have.
datadog,There is plenty of tutorials on how to set up the tools.
datadog,"Why aggregate logs
If we can‚Äôt find something it is as if we didn‚Äôt have it."
datadog,"It is true for things we own, it‚Äôs also true for logs."
datadog,For most small applications we can search and find logs using a simple grep command on the server.
datadog,Most often this is enough.
datadog,"But when we start having multiple files and multiple servers, with thousands of users, finding the right log might start to become a problem."
datadog,Log aggregation will help us find these logs.
datadog,Errors/Exceptions; are usually easy to find; because we often have one error repeating itself; or a single error log that‚Äôs easy to find.
datadog,"In this case, finding the log and fixing the issue shouldn‚Äôt be hard."
datadog,"But this means that either someone checks our error logs manually, or someone has noticed the error and is complaining."
datadog,Log aggregation will allow us to see if there have been any errors and with some tools even alert us.
datadog,"What aggregation also allows us to do, is statistics."
datadog,"As discussed in a previous article, this will allow us to understand the impact of a particular error or log."
datadog,If our website registers thousands of orders per day and we have a single order in error; even if the error is important the issue is not critical.
datadog,"How to aggregate logs
There are 3 steps to log aggregation:
The first step is to have a storage solution."
datadog,We can‚Äôt just store logs in files anymore; we need something more.
datadog,"In this article, we will discuss 3 solutions."
datadog,"Elasitcsearch, Loki & Datadog
The second step is to tail the logs to send it to our storage of choice."
datadog,This step could be removed if the application sends its logs directly to our storage.
datadog,I have never used this technique as I don‚Äôt think that the application should depend upon another service for logs.
datadog,I rather use a tailing agent that reads the log files written by the application.
datadog,"We are going to talk about 3 solutions for this; Filebeat, Promtail, & Datadog Agent
Finally, we need a visualisation tool, a tool that allows us to easily search the logs, make statistics and even alerts."
datadog,"3 other solutions are present here; Kibana, Grafana & Datadog
Datadog is a SASS tool that takes care of both the visualisation and the storage."
datadog,It is plugged to the Datadog agent that fetches the logs (and other metrics) on the server it is installed on.
datadog,Most of the configuration is done directly in the interface once the agent is installed.
datadog,"Elasticsearch, Filebeat and Kibana are all 3 tools made by Elastic.co."
datadog,"Loki, Promtail and Grafana are all 3 tools made by Grafana."
datadog,We actually can intermix the Grafana & Elastic.co solutions.
datadog,Datadog stands apart as a SASS solution.
datadog,Grafana can use both Loki and Elasticsearch as a data source but some features are more limited when using elastic search.
datadog,Before continuing I would like to point out that I am going to compare these tools from the perspective of a developer and not a DevOps.
datadog,Loki for example has a few compromises that will allow it to be lighter to host compared to an Elasticsearch.
datadog,"Also, for the second step of tailing the logs, there are more generic solutions such as Fluentd that can be used to populate both Loki & Elasticsearch."
datadog,"Our contenders
The software used to tails the logs has little impact on the final results and as we are focusing on the developer aspect we will ignore them."
datadog,"Our contenders are :
Elasticsearch for storage & Kibana for visualisation."
datadog,Elasticsearch for storage & Grafana for visualisation.
datadog,Loki for storage & Grafana for visualisation.
datadog,Datadog.
datadog,"Comparison
Here we can see a list of features and the support for these features by the combination of our tools."
datadog,Let‚Äôs look closer.
datadog,"Parsing context
Logs contain multiple information, a date, a level, a message."
datadog,It also should contain a context.
datadog,This context is what gives meaning to the log.
datadog,If an order can‚Äôt be captured we should log ‚ÄúOrder can‚Äôt be captured‚Äù and put the order id as well as any additional information in the context.
datadog,It is therefore important to be able to read the data but also to parse it so that we can query it and use it instead of it just being a string where all the data is dumped.
datadog,If you use Monolog in php this will be a json at the end of the log.
datadog,All the tools we tested with the proper configuration will allow the information to be accessible.
datadog,For Elasticsearch used file beats we need to add an ingest.
datadog,"For Loki, it needs to be parsed by the tailing agent
For Datadog this is done directly in the applications web page."
datadog,"Dynamically taking context into consideration
Our storage solutions require to be configured to make use of our fields in the context."
datadog,"For example, we need to define ‚Äúorder_id‚Äù as an int."
datadog,For Elasticsearch + Kibana this can be done very easily through the interface.
datadog,A button even allows the mapping to be updated automatically based on the existing data.
datadog,"For Grafana with Elasticsearch, it‚Äôs slightly more complicated."
datadog,We will need to make a query manually to Elasticsearch to update the index configuration.
datadog,"For Loki and Grafana, you need to change the configuration of the tailing tool."
datadog,Which makes it the harder of the 4 to configure.
datadog,To add to the complexity fields extracted from the context can be just ‚Äúvisible‚Äù or filterable depending on the configuration.
datadog,"For Datadog, this can be easily configured on their website."
datadog,"Taking context into consideration for older logs
Does changing the configuration affect older logs?"
datadog,This can an interesting feature if we forgot to update our tool after adding additional data in the context.
datadog,This feature is directly related to the storage solution.
datadog,Both Loki & Datadog will take the new ‚Äúmapping‚Äù into account for new logs only.
datadog,Elasticsearch on the other hand will do the changes on all the logs of the current index.
datadog,This means(depending on your configuration) for logs written the same day.
datadog,"But you can force it on the older indexes if you need it, but that will require you to manually do queries."
datadog,"Searching logs with keyword
All of our tools have dedicated interfaces for searching through logs."
datadog,The only exception is the combination of Grafana with Elasticsearch.
datadog,Grafana‚Äôs log exploration interface is only compatible with Loki.
datadog,Grafana‚Äôs interface is also less practical in my opinion.
datadog,In requires us to have at least one filter element in place.
datadog,It limits the number of results making it difficult to zoom into a particular timeframe.
datadog,The graph‚Äôs in Grafana are ‚Äútruncated‚Äù.
datadog,"In this particular example, we might think that there are nogs logs before 11h45."
datadog,That‚Äôs not true it‚Äôs just that the graphic displays only the last 1000 logs.
datadog,"By comparison, Kibana will show a complete graph."
datadog,Kibana on the log search page showing a complete graph of all logs.
datadog,"Searching logs with precise search terms from the context
Beside our Grafana & Elasticsearch duo; all tools allow us to search in data from the context."
datadog,"For example, we can find all logs concerning a certain order."
datadog,Once again Grafan‚Äôs interface is lacking.
datadog,"Datadog & Kibana, both have facets that make seeing the values that might concern us much easier."
datadog,"The Kibana facet view is very useful
We can quickly see information from our context."
datadog,And can add filters to narrow our search.
datadog,So even though Grafana allows us to filter data it doesn't give us this facet view that makes applying filters easier.
datadog,"Visualizing logs with graphs
Visualising log rates with a graph can be practical to understand the error by bettering visualising its occurrences."
datadog,It can also allow us to better assess the criticity of the error.
datadog,"For example, Magento logs every time it purges a cache from varnish."
datadog,This can allow us to diagnose slowdowns.
datadog,All three of our solutions allows us to make such graphs.
datadog,"Creating graphs from context data
We can visualise the error rate but what if we could use the context data as well for our graphs."
datadog,For example; on an e-commerce website we could visualise the number of errors per country.
datadog,"According to the documentation, it‚Äôs not possible to do this with Loki & Grafana."
datadog,But the feature is currently being developed and it‚Äôs actually possible to use.
datadog,This can be done by configuring the Loki server as a Prometheus data source in Grafana.
datadog,So the Loki data source is configured 2 times.
datadog,"Even though this works; I encountered a lot of issues with the Prometheus queries:
There are different behaviours, valid Prometheus queries don‚Äôt always work."
datadog,All Prometheus aggregations have not been implemented.
datadog,The aggregations don‚Äôt work correctly.
datadog,It gives a good view of what‚Äôs on with the order of magnitude visible.
datadog,But the exact numbers don‚Äôt always match.
datadog,Random errors that go away by re-executing the same query a few seconds later.
datadog,Grafana with Elasticsearch works very well; as well as Kibana.
datadog,Datadog has a few limitations as some graphs can‚Äôt use context data but is still a strong contender.
datadog,"Alerting from aggregations
Now that we have graphs we could use the aggregations to automate alerts."
datadog,This is can be a quick and dirty way of making a critical problem manageable.
datadog,If we have shipping issues for example for 1 order nearly every day.
datadog,"If we can alert the person responsible and give him the necessary information; he can then contact the client, manually fix the order until we fix the issue properly."
datadog,It gives us alternatives; it gives us time.
datadog,Grafana allows us to configure alerts with both Elasticsearch & Loki.
datadog,"When using Loki, as for graphs, we will need to configure it as a Prometheus source for the alerting to work."
datadog,Datadog allows alert‚Äôs as well.
datadog,Kibana has no alerting.
datadog,"User accounts
Finally the possibility to create accounts and limit user privileges."
datadog,This is interesting when we have people of different profiles checking our tools.
datadog,Our client for example might have his own dashboard that he manages and we have our own that he can see but not modify.
datadog,Grafana is the most complete solution; we could even use a single Grafana for multiple clients/websites and separate accesses properly.
datadog,Permissions can be configured per dashboard and also per source.
datadog,With Datadog we will be able to have multiple accounts but we can‚Äôt set up permissions per dashboard.
datadog,So our client would have read-only access and we would need to create graphs and dashboard for him if we wish to prevent him from changing our own dashboards.
datadog,Finally; Kibana.
datadog,Kibana has no user support.
datadog,"By default, it‚Äôs public and everyone can connect to it."
datadog,We can add some privacy by putting it behind a proxy but there won‚Äôt be a per person permission setup.
datadog,"My opinion
If we do not want to use a SASS solution; I think Kibana + Elasticsearch is the easiest to set up and is the most practical."
datadog,"Kibana‚Äôs interface for searching is very good, and creating graphs is easy."
datadog,"Nevertheless, it‚Äôs missing 2 important features:
User accounts
Alerting
Therefore if we need one of these features I would also add a Grafana."
datadog,In which case we would only use Kibana to configure the indexes & to search the logs and use Grafana for the graphs and the alerts.
datadog,If we have the budget and are okay to use a SASS solution; I think that Datadog is very easy to install and it‚Äôs pricing is very reasonable.
datadog,"Screenshoot taken in DataDog integrations console
When you are managing more than 10 Kubernetes (EKS) clusters for your team with some critical applications running on them, you will need to setup a observability stack with monitoring, logging and tracing."
datadog,"In this blog, I will share how we build monitoring system, setup dashboard and monitors for our K8s infrastructure using DataDog."
datadog,Why DataDog?
datadog,"There are many observability tools or platforms, both open-source and subscription, but I chose DataDog for my blog because I found it has widely support for multiple platforms (AWS, Azure, GCP, on-premise, etc.)"
datadog,"and applications, as well as its compatibility with Kubernetes or Prometheus metrics."
datadog,Also the main thing is I‚Äôm a (Data)Dog‚Äôs fan.
datadog,You can check out the list of DataDog built-in integrations or refer to their integrations-core and write your own scripts.
datadog,"Requirements
Basic knowledge about K8s, Docker and DataDog."
datadog,Administrator permission on a running AWS EKS cluster.
datadog,You can visit https://eksworkshop.com to learn how to setup.
datadog,kubectl to manage K8s cluster (https://kubernetes.io/docs/tasks/tools/install-kubectl/).
datadog,helm v2 to install DataDog from Chart.
datadog,"For some reasons, in this blog, I will use DataDog Helm Chart from stable repository and version 1.39.9."
datadog,"Since version 2.x.x, DataDog Helm Chart has refactored and moved to its official repo, but the concepts are same."
datadog,"Deploying
I have generated a sample values.yaml for DataDog deployment as following:

I‚Äôm using EKS cluster for this tutorial, so you can see the tags defined as cloud:aws and distribution:eks, and naming my cluster as following convention <env>-<platform>-<category>-xxx, which is dev-eks-datadog-001."
datadog,"Labels or tags are very important when you design and setup a monitoring system for your core infrastructure, which will help you easily organize, group, filter or focus your data to troubleshoot and understand your environment."
datadog,I will share more examples later in Dashboards and Monitors sections.
datadog,"Deploy DataDog using helm:
‚ûú  ~ helm install --name datadog --namespace monitoring -f datadog-k8s-values.yaml --set datadog.apiKey=<API_KEY> --set datadog.appKey=<APPLICATION_KEY> --version=1.39.9 stable/datadog
When helm command finished, you will see somethings similar as:
‚ûú  ~ kubectl get pods -n monitoring --no-headers | grep datadog
datadog-2tspw                                   1/1   Running   0     2m
datadog-6bd328d579-tj8lp                        1/1   Running   0     2m33s
datadog-cluster-agent-54hv37f8fb-cgp2f          1/1   Running   0     2m23s
datadog-kube-state-metrics-56gre5ft89-lx8e9     1/1   Running   0     1m56s
datadog-pvltl                                   1/1   Running   0     2m55s
datadog-qtlh9                                   1/1   Running   0     3m12s
‚ûú  ~ kubectl get svc --no-headers | grep datadog
datadog                             ClusterIP      172.20.6.24    <none>   8125/UDP     2m
datadog-cluster-agent               ClusterIP      172.20.10.15   <none>   5005/TCP     2m
datadog-cluster-agent-metrics-api   ClusterIP      172.20.12.27   <none>   443/TCP      2m
datadog-kube-state-metrics          ClusterIP      172.20.24.17   <none>   8080/TCP     2m
‚ûú  ~ kubectl get deployments --no-headers | grep datadog
datadog                             1/1   1     1     3m
datadog-cluster-agent               1/1   1     1     3m
datadog-kube-state-metrics          1/1   1     1     3m
‚ûú  ~ kubectl get daemonsets --no-headers | grep datadog
datadog    3     3     3     3     3     <none>   3m
You can see DataDog has been deployed with 3 main components:
DataDog agent daemonSet."
datadog,DataDog cluster-agent.
datadog,"DataDog Kube-state-metrics (KSM): Which is a simple service that listens to the Kubernetes API server and generates metrics about the state of the objects: node status, node capacity (CPU and memory), number of desired/available/unavailable/updated replicas per Deployment, pod status (e.g., waiting, running, ready), and so on."
datadog,"To understand about DataDog agents and cluster-agent, let me explain a bit about old and current DataDog designs, which can be found in their official docs."
datadog,"Without Cluster Agent diagram on DataDog
You can see above diagram, without Cluster Agent, every worker nodes in the cluster ran an agent pod which collected data from two main sources:
kubelet:
By monitoring the kubelet on each worker node, the Datadog Agent gives you insights into how your containers are behaving and helps you keep track of scheduling-related issues."
datadog,The Agent also retrieves system-level data and automatically discovers and monitors applications running on the node.
datadog,"The cluster‚Äôs control plane, which consists of the API server, the scheduler, the controller manager, and etcd."
datadog,"In addition to collecting these node-level metrics, each Datadog Agent individually queries the API server on the master node to collect data about the behavior of specific Kubernetes components, as well as to gather key metadata about the cluster as a whole."
datadog,"Each Agent also retrieves the list of services that target the pods scheduled on that particular node, uses this data to map relevant application metrics to services, and then tags each metric with the appropriate pod name and service."
datadog,Agents can also be configured to elect a leader that queries the API server regularly to collect Kubernetes events.
datadog,"Since the old approach gave your visibility into all the layers of the cluster, it put increasing load on the API server and etcd when the cluster size increased."
datadog,"That‚Äôs why DataDog has developed and introduced Cluster Agent as you can see in below diagram:

With Cluster Agent diagram on DataDog
DataDog Cluster Agent main features:
Provides a streamlined, centralized approach to collecting cluster level monitoring data."
datadog,"By acting as a proxy between the API server and node-based Agents, the Cluster Agent helps to alleviate server load."
datadog,"Relays cluster level metadata to node-based Agents, allowing them to enrich the metadata of locally collected metrics."
datadog,"Using the Datadog Cluster Agent allows you to:
Alleviate the impact of Agents on your infrastructure."
datadog,"Isolate node-based Agents to their respective nodes, reducing RBAC rules to solely read metrics and metadata from the kubelet."
datadog,"Provide cluster level metadata that can only be found in the API server to the Node Agents, in order for them to enrich the metadata of the locally collected metrics."
datadog,"Enable the collection of cluster level data, such as the monitoring of services or SPOF and events."
datadog,Leverage horizontal pod autoscaling with custom Kubernetes metrics.
datadog,"With this setup, DataDog agent don‚Äôt need to elect a leader pod, and cluster-agent will do the K8s events collection instead."
datadog,DataDog cluster-agent also provides External Metrics Provider to define HPA based on DataDog metrics (not limiting to only CPU/Memory utilization).
datadog,"DataDog Events
In this setup, I have enabled the K8s Event Collection, by setting the datadog.leaderElection, datadog.collectEvents and agents.rbac.createoptions to true in datadog-k8s-values.yaml file."
datadog,"That feature tells DataDog Cluster Agent collect the K8s events from Control Plane, and forward them to DataDog."
datadog,"You can easily check what happening to your clusters, why pod can‚Äôt be scheduled or troubleshoot a BackOff container without the need of kubectl get events or kubectl describe nodes|pods."
datadog,"K8s events ‚Äî Backoff
We can easily create dashboards or monitors to watch and notify any K8s events nearly realtime."
datadog,"Dashboards
In this section, I will share my own experience on building a common Dashboard for all running Kubernetes clusters (EKS)."
datadog,"I used to break down the metrics for different layers and group them as following:
Cloud/Cluster infrastructure metrics: EC2, RDS, ElastiCache, etc."
datadog,"System metrics: OS, CPU, Memory, Disk IOps, Network bandwidth, etc."
datadog,"Orchestration (K8s) metrics: Node status, deployments/replicaSet/statefulSet, pods (CPU/Mem), PVC size, etc."
datadog,"Application metrics: HTTP response time, Kafka consumer lag, JVM Heap, Logstash events, Spark job metrics, etc."
datadog,"An example dashboard I created which provides an overview for all running EKS clusters in my team:

Cluster-metrics graphs ‚Äî 1

Cluster-metrics graphs ‚Äî 2
DataDog supports configure template variables to quickly filter or query metrics from specific tags or attributes, e.g subaccount (AWS accounts), k8s_cluster (K8s cluster names), k8s_node (EC2 Worker nodes), k8s_namespace, k8s_deployment, k8s_daemonset and so on."
datadog,"DataDog template variables
You will be noticed why I‚Äôm using 2 different tags to filter same thing, like k8s_namespace and k8s_state_namespace."
datadog,"That is because there are 2 sets of metrics are gathered by DataDog and being tagged differently:
kubernetes."
datadog,* metrics are collected by DataDog agents/cluster-agent.
datadog,kubernetes_state.
datadog,* metrics are gathered from the kube-state-metrics (KSM) API.
datadog,"Beside cluster graphs, I also added system metrics and K8s metrics into the dashboard like this:

System-metrics graphs ‚Äî 1

K8s-metrics graphs ‚Äî 1

K8s-metrics graphs ‚Äî 2
You can add more metrics to your dashboard to have more observations on your infrastructure, but I would recommend we split different layers (Cluster/Orchestrator/System/Application/etc.)"
datadog,to different dashboards.
datadog,It‚Äôs because your dashboard UI will become laggy when you‚Äôre querying a huge metrics subset or huge time range (1 week or 1 month).
datadog,"Monitors
Before creating a monitor, I used to think about some basic information:
What are the things to look out when you pick out the metrics?"
datadog,"(High CPU/Mem, Events drop, error rates, HTTP slow response, p95/p99, etc.)"
datadog,"Calculate metrics and set a threshold (min/max, avg/sum, week/day before, etc.)."
datadog,Metrics tagging/labelling.
datadog,Runbook for troubleshooting steps and link to logs.
datadog,"Alerts notification (Slack, PagerDuty)."
datadog,"As I mentioned above, labels or tags are important, especially when we design and setup common alerts for the core infra."
datadog,"Let me share one example: Creating alert about failed pods on namespace:
Metrics to check: kubernetes_state.pod.status with phase:failed

Failed pods alert ‚Äî 1
sum by: kubernetes_cluster, cluster_env and namespace ‚Äî the idea is when a namespace in the cluster has so many failed pods, oncall engineer need to quickly investigate the root cause."
datadog,"Set Alert and Warning thresholds for the monitor:

Failed pods alert ‚Äî 2
Metrics tagging/labelling: as above I have defined a list of tags in sum by, DataDog allows us to define alert message with those variables:

Failed pods alert ‚Äî 3
Then you can see the alert message as below:

Failed pods alert ‚Äî 4
@slack-k8s-{{cluster_env.name}}-alerts: We can simply diversify the alerts from different environment (dev, stg or prd) to different Slack channels (k8s-dev-alerts or k8s-stg-alerts or k8s-prd-alerts) and only trigger PagerDuty to oncall (@pagerduty-de-infra) if failure happens on production environment."
datadog,"An example alert to Slack will be looked like this:

Failed pods alert ‚Äî 5
What‚Äôs Next
This blog is based on my own experience working with DataDog on existing EKS setup."
datadog,It may or may not work on your existing environment.
datadog,You can visit DataDog official documentation for more information.
datadog,Feel free to leave comments or questions.
datadog,Hope you enjoy reading my blog.
datadog,"In the next one, I will share how we create custom checks and sending custom metrics to DataDog."
datadog,"Photo by Chris Leipelt on Unsplash
Building applications has never been easy as it is today."
datadog,Adopting cloud and the models like serverless have reduced the friction with developing and deploying applications to a great extent.
datadog,"Architectural styles like microservices have been widely embraced by most of the organizations, and as a result of all these movements, the way we design or architect an application also has evolved from one or two components to several components that run on top of different environments like dockers or Lambda like Function as a Service platforms."
datadog,There are several moving parts in a single application.
datadog,The diagram below is an example of modern solution architecture on AWS.
datadog,"Modern Solution Architecture

Ref: https://aws.amazon.com/getting-started/hands-on/build-modern-app-fargate-lambda-dynamodb-python/
As you see above, several layers per application run on different technologies, services, or programming languages."
datadog,"It‚Äôs so cool, huh!"
datadog,"and everything works so well, but is it always?"
datadog,"Not really, because when we are working with distributed applications, we have to expect the unexpected always."
datadog,"The mastermind of AWS cloud says,
Everything will eventually fail over time‚Ä¶ Werner Vogels
So the general truth is no system can guarantee a 100% failure-prone operation."
datadog,"Even though your underline infrastructure is reliable enough to handle its failures, end of the day, you are running your own business logic on top of them, and there can be issues or bugs that you haven‚Äôt even figured out."
datadog,"So having said that, the real challenge in a distributed application like above is when something goes wrong, there are several places to look at to identify where, why, and how it happened."
datadog,"In most cases, the approach to fix the issues is based on hunches and guesses."
datadog,"This is not a good approach at all and would soon collapse, wasting our time and money."
datadog,"Collecting data is cheap, but not having it when you need it can be expensive, so you should instrument everything, and collect all the useful data you reasonably can."
datadog,"‚Äî Datadog
Observability
The best way to tackle the above problem is by having good observability within the applications."
datadog,"Observability is a measure of how well internal states of a system can be inferred from knowledge of its external outputs ‚Äî Wikipedia
Basically, the idea is similar to what we know as monitoring."
datadog,"However, observability is more like a property of a system, and it requires insights from metrics, logs, and tracing, which are known as the three pillars of observability."
datadog,There are several services/tools for gaining visibility into the observability pillars.
datadog,"However, the important thing is that if we need to get the best out of it, we should correlate all three pillars."
datadog,And the monitoring service or the tool we are using should be capable of doing this.
datadog,"Ref: https://www.datadoghq.com/pdf/dd_SolutionsBriefsTemplate_181003_monitoringconsolidation.pdf
Datadog
Datadog comes in handy as a cloud monitoring platform that provides a unified solution to seamlessly combine the three pillars of observability and enable full visibility across our application stack."
datadog,"Other than that, the most important thing is the smooth, frictionless integration process with more than 400 built-in integrations and pre-defined dashboard templates for them."
datadog,There are multiple products within Datadog to support different use cases at each layer of our applications and provide a single pane of glass across different teams within the organization.
datadog,The diagram below compiles what is offered by Datadog.
datadog,"Ref: https://aws.amazon.com/solutionspace/financial-services/solutions/datadog-on-aws/
As shown in the above diagram, Datadog offers a wide variety of services which cover several use-cases."
datadog,And the great thing is they have a well organized and easy to follow documentation to understand how to instrument applications to use those services.
datadog,Anyways let‚Äôs look at a high-level view of how Datadog facilitates the observability pillars.
datadog,"Metrics
Datadog offers to ingest metric data via an Agent or the API with a value and a timestamp and then store it as a time series."
datadog,These time-series data points can be easily queries using the graphical query builder and visualize it in different formats.
datadog,"Metric Query (Ref: https://docs.datadoghq.com/metrics/introduction/)

Chart Visualization(Ref: https://docs.datadoghq.com/metrics/introduction/)
Built-in integrations come with a pre-defined set of metrics, and in most cases, it serves our purpose."
datadog,You can get more details about the metrics from here.
datadog,"Logs
Datadog agent has the capability of tailing log files or listen for logs sent over UDP/TCP."
datadog,"Currently, there are out of the box solutions for collecting logs from these sources."
datadog,"Hosts
Applications
Docker environments
Serverless environments
Cloud providers
Collected logs can then be processed using Pipelines and Processors."
datadog,"A Pipeline takes a filtered subset of incoming logs and applies a list of sequential processors to perform data-structuring actions on logs
Ingested logs can also be used for generating log-based metrics."
datadog,You can refer the Datadog‚Äôs ‚ÄúLogging without Limits‚Äù concept for more details.
datadog,"Tracing
Datadog APM (Application Performance Management) provides a comprehensive solution for collecting, searching, and analyzing traces across fully distributed architectures."
datadog,And the usage is simple as just adding a client library since it can automatically trace requests across many popular libraries and frameworks.
datadog,"The most important feature is that the collected traces seamlessly correlate to browser sessions, logs, synthetic checks, network, processes, and infrastructure metrics across hosts."
datadog,Refer here to learn more about Datadog APM.
datadog,"On a closing note, let me show a quick snap of a Datadog dashboard, which shows a consolidated view of the observability concerns we discussed above."
datadog,"Unified Dashboard for Metrics, Logs, and Traces
Conclusion
Observability is a must-have property for modern applications to gain full visibility across the stack."
datadog,The three pillars of observability are often required to be correlated to get the maximum benefits.
datadog,"Thus, selecting a monitoring platform with a unified view that consolidates all three observability pillars is crucial."
datadog,"[Week 40 | +2.2% vs. +1.6%] $TWLO positive 3Q pre-announcement, $DDOG announces Azure integration, strong Payroll/HCM performance ($PAYC + $PCTY)
Week 40 | Cloud stock performance remained strong, increasing 2.2% for the week ending 10/2, outperforming the S&P 500 (+1.6%) by 60 bps."
datadog,$TWLO positive 3Q pre-announcement.
datadog,$DDOG announces Azure integration.
datadog,"About Breaking SaaS: This article was originally published on BreakingSaaS.com, an industry analysis and intelligence platform curated by top Wall Street and Enterprise SaaS professionals."
datadog,Want more expert analysis straight to your inbox?
datadog,"Visit BreakingSaaS.com/SignUp
saas cloud stock performance
[Week 40 | +2.2% vs. +1.6%]: Cloud stock performance remained strong, increasing 2.2% for the week ending 10/2, outperforming the S&P 500 (+1.6%) by 60 bps."
datadog,Tech (+1.2%) was an overall drag on S&P performance as the Equal-Weight index (+2.4%) outperformed.
datadog,"Likewise, investors continue to be very optimistic of recent IPOs, bidding $IPO up +2.7% for the week."
datadog,SaaS breakouts lead outperformance vs. Tech.
datadog,"SaaS investors were focused on two news-driven breakouts ($TWLO & $DDOG), as well as Payroll/HCM-focused names ‚Äî $PAYC (+16.9%) & $PCTY (+8.5%)."
datadog,$TWLO (+18.5%).
datadog,Investor Day + positive 3Q pre-announcement.
datadog,"After hosting it‚Äôs 2020 investor day Thursday 10/1, Twilio posted an SEC filing stating 3Q revenue ‚Äúwill be ahead of the Company‚Äôs previously issued guidance of $401 million to $406 million.‚Äù See Also: Investor Day Deck
$DDOG (+14.2%)."
datadog,Datadog announces native Azure integration.
datadog,Full read on the Datadog Blog.
datadog,Why are investors so excited?
datadog,The partnership allows new users an easier onboarding process which bypasses the requirement to seek approval for a new third-party tool.
datadog,"saas cloud stock performance
saas cloud IPO performance
üì∞ More Cloud News
$NET (+4.3%)."
datadog,"Cloudflare Launches Radar, Sharing the Latest Internet Trends with the World in One Interactive Public Tool
$WDAY (+1.5%)."
datadog,"Buy Workday Stock as a Play in Cloud Financial Software, Citi Says
With blessings of high NRR and low Churn,
Thomas"
datadog,"Provision your Datadog resources right in Terraform
Tools like Terraform have changed how modern technology companies operate, bringing many of the benefits of code to our infrastructure."
datadog,"Infrastructure can now be versioned like code, packaged up like code, distributed like code, and reused like code."
datadog,But the definition of ‚Äúinfrastructure‚Äù doesn‚Äôt have to stop at databases and EC2 instances.
datadog,"Infrastructure can also include observability tools like New Relic or Datadog ‚Äî tools that help companies get insight into their systems to better diagnose and resolve issues, or even find them before they happen."
datadog,"Since Terraform makes it easy to use third-party providers now, treating your telemetric resources as just another part of your ‚Äúinfrastructure‚Äù is easier than ever."
datadog,"So if you‚Äôre using Terraform and want to provision Datadog resources such as monitors / alerts or dashboards, there are two steps you‚Äôll need to take."
datadog,"Add the Datadog provider to your Terraform
Add the Datadog resources you want to your Terraform
Adding the Datadog Provider
You‚Äôll need to start by pulling in the Datadog provider."
datadog,"This is a little snippet that goes at the top of your main ‚Äúentrypoint‚Äù file in Terraform (‚Äúentrypoint‚Äù being the main.tf file at the top of your module hierarchy ‚Äî it‚Äôs probably in the module you call your terraform commands from, like terraform plan for instance)."
datadog,"That provider block will look like this:
provider ""datadog"" {
  api_key = var.datadog_api_key
  app_key = var.datadog_app_key
}
It only needs to be used in the code once, so don‚Äôt go sticking it all over the place!"
datadog,Any modules created by your top-level Terraform file will use this same provider.
datadog,"You would only need to create a separate provider if you were using multiple Datadog accounts with different API keys, or if you were provisioning for many apps with different app keys."
datadog,"(If that is the case, then I would advise moving each app‚Äôs Datadog resources into its own sub-module, then declaring the provider in that sub-module, so each app has its own provider declaration)."
datadog,Where do the API key and app keys come from?
datadog,"Well, you‚Äôll have to get those from the Datadog web UI."
datadog,Check here for some information about that.
datadog,"To get the secrets into your app, I would recommend passing them in as part of your terraform plan or terraform apply commands (see here) or possibly using the secrets management resource your cloud provider offers."
datadog,"In AWS for instance, you could pull the secrets from SecretsManager like so
data ""aws_secretsmanager_secret_version"" ""datadog_secrets"" {
  secret_id = var.datadog_secrets_id
}
and then use it for your provider by doing something like this:
provider ""datadog"" {
  api_key = jsondecode(data.aws_secretsmanager_secret_version.datadog_secrets.secret_string)[""DATADOG_API_KEY""]
  app_key = jsondecode(data.aws_secretsmanager_secret_version.datadog_secrets.secret_string)[""DATADOG_APP_KEY""]
}
That extracts your keys from the SecretsManager JSON, and assumes they‚Äôre called DATADOG_API_KEY and DATADOG_APP_KEY."
datadog,See here for more.
datadog,"Lastly, if you‚Äôre using Terraform 0.13 or above, you‚Äôll need to specify the source your Datadog provider is coming from (and you can optionally set a version ‚Äî it‚Äôll use the latest if you don‚Äôt)."
datadog,"Typically this will go in a versions.tf file and looks like this:
terraform {
  required_providers {
    datadog = {
      source = ""DataDog/datadog""
    }
  }
}
Adding Datadog Resources
After you‚Äôve gotten the Datadog provider added to your Terraform, the next thing you‚Äôll want to do is actually add some resources."
datadog,"Datadog provides dashboards, third-party integrations, log configuration, monitors, and more all through Terraform."
datadog,You can even provision users and set their permissions!
datadog,There‚Äôs almost no reason to do configuration directly in the UI.
datadog,"Working without the UI might seem a little slow at first, but after building up some modules, it will actually speed you up."
datadog,"In my own experience, it was a pain to write a Terraform module to provision a dozen different database monitors."
datadog,"But after it was done, it was a breeze to put that repo on GitHub and use Terraform‚Äôs module-sourcing magic to reuse that module in all of my services that needed database monitors!"
datadog,A little upfront cost in Terraform saved me many hours of copying and pasting monitors (and spared me all the copy-paste bugs I would‚Äôve had).
datadog,So how do you do it?
datadog,I would recommend starting by making a monitoring module (or something similar) in your Terraform.
datadog,This will just be a new directory containing your terraform files.
datadog,"I normally use
main.tf
variables.tf
versions.tf
in my modules, and add outputs.tf if I need it (you shouldn‚Äôt need one if you‚Äôre just doing monitors and dashboards though)."
datadog,"While you won‚Äôt need to redeclare the Datadog provider block, you will need to set up your versions.tf file again with this code (it‚Äôs the same as what we wrote before):
terraform {
  required_providers {
    datadog = {
      source = ""DataDog/datadog""
    }
  }
}
If you‚Äôre specifying versions in your Terraform, I would advise using a range of acceptable versions in the module itself, and then pinning the version you want in your ‚Äúentrypoint‚Äù module."
datadog,"You can specify a range by doing something like:
version = "">= 2.0.0, < 3""
See more about versioning here."
datadog,Using a range is especially important if you‚Äôre writing a module that‚Äôs going to be reused in other services.
datadog,You want it to work with as many different provider versions as possible.
datadog,Now you‚Äôre ready to actually add some resources!
datadog,"Here is a simple monitor you can put in your main.tf
resource ""datadog_monitor"" ""database_storage_low"" {
  name               = ""${title(var.service)} database storage low""
  type               = ""metric alert""
  message            = ""Monitor triggered."
datadog,"Notify: ${var.notify}""

  query = ""avg(last_1h):avg:aws.rds.free_storage_space{environment:${var.env},service:${var.service}} < ${var.db_storage_critical}""

  monitor_thresholds {
    critical = var.db_storage_critical
    warning  = var.db_storage_warning
  }

  notify_no_data = false

  tags = [
    ""env:${var.env}"", 
    ""service:${var.service}"", 
    ""team:${var.team}
  ]
}
This creates a metric alert that notifies us if our RDS free storage space dips below some threshold on average for an hour."
datadog,"If it recovers, we‚Äôll get notified again (which is useful if you‚Äôre routing alerts through something like PagerDuty ‚Äî it will resolve the issue)."
datadog,"Notice I also tagged the monitor with env , service , and team ."
datadog,"This makes it easier to find and keep track of monitors in the UI, though they‚Äôre certainly not necessary."
datadog,Another note: the query is filtering for RDS instances by service and environment .
datadog,This requires that your RDS instances be tagged with those tags in Datadog.
datadog,"If your tagging is different, make sure to update those filters to match what you have."
datadog,"For more information about the Datadog monitor resource, check out the documentation."
datadog,"Lastly, you‚Äôll need to fill out your variables.tf file."
datadog,"Since we need the variables we specified in our monitor, our variables file will look something like this:
variable ""service"" {
  type        = string
  description = ""Your service name."
datadog,"Should match the service tag on your db""
}
variable ""env"" {
  type        = string
  description = ""The environment we're in."
datadog,"Should match the environment tag on your db""
}
variable ""team"" {
  type        = string
  description = ""Your team's name""
}
variable ""notify"" {
  type        = string
  description = ""Where to route alerts to."
datadog,"Will look something like @pagerduty-<service> or @slack-<channel> etc."""
datadog,"}
variable ""db_storage_critical"" {
  type        = number
  description = ""Lowest acceptable free storage in bytes""
  default     = 10000000000  // ~10 gb
}
variable ""db_storage_warning"" {
  type        = number
  description = ""Low free storage warning threshold in bytes""
  default     = 20000000000  // ~20 gb
}
Providing default values for our thresholds means those variables are optional for users of this module."
datadog,Remove the default if you want to force users to provide values.
datadog,That should do it!
datadog,You are now ready to build out your Datadog infrastructure right in Terraform.
datadog,Add resources to that main.tf file as you need them.
datadog,I‚Äôve found a lot of value creating monitoring modules and putting them on GitHub for reuse.
datadog,Check this out for more info.
datadog,"You can also build out a module for common dashboards that you want services to have, or even lump monitors and dashboards into a single module since you may want to display all the monitor data on your dashboard anyway."
datadog,Take a look at the main Datadog provider page for more documentation and inspiration!
datadog,"In this short post, we‚Äôll see how we can use Datadog API to pull instance utilization data."
datadog,"Pre-requisite: DataDog must be setup, with your EC2 instances metric data being available in DataDog."
datadog,"You will also need DataDog API key and Application key
Step 1: Install datadog package using pip."
datadog,Step 2: Save the given code on your local system.
datadog,"#!/usr/bin/python
import requests, json,sys
from datadog import initialize, api
from time import time

output_file=""instance_utilization.csv""

api_key= ''
app_key= ''

url = ""https://app.datadoghq.com/reports/v2/overview?api_key=""+api_key+""&application_key=""+app_key
headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}

r = requests.get(url,headers=headers)

if r.status_code == 200:
    result= r.json()
    instance_data={}
    for data in result['rows']:
        if 'aws_id' in data and 'host_name' in data:
            instance_data[data['aws_id']]=data['host_name']

            
options = {
'api_key': '',
'app_key': ''
}

hosts=['i-0decf5fb9ebfd270e']

initialize(**options)

end = int(time())
start = end - (3600*24*30)

csv_file = open(output_file,'w+')
csv_file.write(""Instance ID,Hostname,Minimum Avaialble CPU(%),Total Memory(MB),Minimum Usable Memory Available(MB)\n\n"")

for host in hosts:
    if host in instance_data.keys():
        hostname=instance_data[host]
        
        #Fetch toal memory on a server
        query='min:system.mem.total{host:'+hostname+'}'
        results = api.Metric.query(start=start, end=end, query=query)
        if not ""Rate limit of 300 requests in 3600 seconds reached"" in str(results):
            if len(results['series']) > 0:
                total_available_memory=(min(results['series'][0]['pointlist'], key=lambda x: x[1])[1])/(1024*1024)
            else:
                total_available_memory=""Total Memory metrics for ""+host+"" is not available""
        else:
            print(""Rate limit of 300 requests in 3600 seconds reached"")
            sys.exit(1)
        
        #Fetch minimum usable memory on a server
        query='min:system.mem.usable{host:'+hostname+'}'
        results = api.Metric.query(start=start, end=end, query=query)
        if not ""Rate limit of 300 requests in 3600 seconds reached"" in str(results):
            if len(results['series']) > 0:
                minimum_memory_free=(min(results['series'][0]['pointlist'], key=lambda x: x[1])[1])/(1024*1024)
            else:
                minimum_memory_free=""Memory metrics for ""+host+"" is not available""
        else:
            print(""Rate limit of 300 requests in 3600 seconds reached"")
            sys.exit(1)
        
        #Fetch minimum available CPU on a server
        query='min:system.cpu.idle{host:'+hostname+'}'
        results = api.Metric.query(start=start, end=end, query=query)
        if not ""Rate limit of 300 requests in 3600 seconds reached"" in str(results):
            if len(results['series']) > 0:
                minimum_cpu_free=(min(results['series'][0]['pointlist'], key=lambda x: x[1]))[1]
            else:
                minimum_cpu_free=""CPU metrics for ""+host+"" is not available""
        else:
            print(""Rate limit of 300 requests in 3600 seconds reached"")
            sys.exit(1)
        csv_file.write(""%s,%s,%s,%s,%s\n"" %(host,hostname,minimum_cpu_free,total_available_memory,minimum_memory_free))
        csv_file.flush()
    else:
        print(""Hostname for ""+host+"" is not available"")
Step 3: Provide value for api_key and app_key variables."
datadog,Also set the same values for options variable.
datadog,Also provide a list of host ids for which you need metric data.
datadog,Step 4: Execute the script.
datadog,"Once the script is executed successfully, check instance_utilization.csv for your data."
datadog,If needed you can modify the datadog queries used in the code or you can include additional queries based on your requirement.
datadog,"How to define meaningful quality metrics that matter to you and your product, and using App Script to collect them all in Google Sheets
Introduction
In modern software development setup, logs and metrics are all over the place."
datadog,"With Kibana, Datadog, and Grafana easily integratable with any programming language and infrastructure providers, collecting logs is not a problem."
datadog,"As a Quality Assurance expert, what I am interested in are those specific logs, or metrics, that reflects the quality of our product, and finding ways to monitor those metrics on a regular basis and seeing their trends over time."
datadog,"In order to talk about what I exactly do to achieve this goal, we need to break down that last sentence and separate those goals one by one:
‚Äú‚Ä¶ specific logs that reflect the quality‚Ä¶‚Äù
‚Äú‚Ä¶ finding ways to monitor them‚Ä¶‚Äù
And ‚Äú‚Ä¶see how they change over time‚Äù
This is what this article is about."
datadog,"I am going to talk about how I approached these objectives, the lessons I learned from my mistakes, and the final steps that I took to finally have a clear understanding of How is the current state of quality in our product and how it changes over time in a fully automated setup, so my engineering teams can constantly have a clear overview of the product‚Äôs quality and see how the decision they make influences it."
datadog,"What is a ‚ÄúQuality Metric‚Äù
A quality metric is any metric of any given type (size, time, count, etc) that either directly, or indirectly, represents the quality of a product or service."
datadog,Let‚Äôs take a web app as an example.
datadog,What types of metrics can we think of that directly represent its quality?
datadog,"From the most obvious to least, we can name a few:
Page Response Time
This refers to the time calculated from the moment a user interacts with the application until the moment that the interaction results in an effect."
datadog,"For example, the time it takes when you click on someone‚Äôs profile picture in a social media app until the profile page and its content is fully loaded is the Page Response Time."
datadog,"Uptime Status
It shows how often a web page been up and running by showing a percentage of its uptime."
datadog,"If a web app is down too often, then it means there is a chance that at a point in time and when the service was needed, it was unavailable for some users, therefore there is no quality to define for it to begin with."
datadog,"Over a period of time, the average uptime percentage can define the quality of the service, since Quality of Service is directly affected by its availability."
datadog,"Failure Rate
It refers to the relative number of failed interactions that users experience while using a service."
datadog,"While using a web app, or any sort of software for that matter, the more issue, errors, empty screens, and such that users experience, it would be fair to say that the lower product quality is."
datadog,As you might have noticed I stated in the definition of quality metrics ‚Äúeither directly or indirecty‚Äù.
datadog,The three examples above are metrics that directly reflect the quality of a product or software.
datadog,"For instance, in the case of the Page Response Time, it is fair to say that:
The lower the response time is, the higher the quality
‚Ä¶ or in case of the Failure Rate:
The higher failure rate than user experience, the lower the quality."
datadog,But not all metrics can directly be linked to the quality of a product.
datadog,"Sometimes such metrics only play a role, minor or major, and might end up affecting the quality."
datadog,"These metrics usually can be found not so visibly around the product itself, but rather around the resources that are allocated to the product; resources being infrastructural, developing teams, or related to the users‚Äô experience."
datadog,"Two products might have a similar response time and failure rate, but the majority of users might simply claim ‚ÄúIt just feels better when I use one and not the other‚Äù which might be translated in terms of quality."
datadog,"As a couple of examples for metrics that indirectly influence that quality, we can mention a couple:
Bugs count over a period of time
Although detecting failure rate can be easily achieved by looking at your log monitoring service, the number of bugs per week, month, or sprint tells a different story."
datadog,"Simply because of the bugs count in a development team is increasing, that doesn‚Äôt necessarily mean that quality is getting lower since all the other metrics that we have already been through might still be at a good rate, but one conclusion that we can draw is that ‚ÄúSomething‚Äôs wrong and that something might, later on, result in lower quality‚Äù."
datadog,"As an example, the reason behind this increase could be pressure from the product owner to release new features, which down the road, might end up affecting the quality."
datadog,"UX analysis metrics
There are tools out there that capture user‚Äôs interactions with a web app, and run analysis on those measurements to extract meaningful metrics."
datadog,"FullStory and HorJar are two of these tools that enable the developing team to see how happy, unpleased, or frustrated the users were using their product, by showing them metrics such as the number of rage clicks (user spam-clicking a UI element) or dead clicks (Clicks on elements that don‚Äôt trigger an action), which can reflect the possibility that the current UX can benefit from improvements and end up increasing the overall quality."
datadog,Which quality metrics should we aim for?
datadog,"Always choose the metrics that are relevant to your product, not the ones that are often mentioned on the web that you can find on a ‚ÄúTop 10 quality metrics‚Äù articles that a simple Google search leads you to."
datadog,"First of all, many of the quality metrics that were relevant in the olden days of software development are not fitting in today‚Äôs rapid architecture."
datadog,"I would argue that metrics such as Change Failure Percentage, MTBF (Mean Time Between Failures), and MTTR (Mean Time To Recover/Repair) are either not so easy to measure, or they simply are not applicable anymore in today‚Äôs small scrum/vertical developer teams in the tech scene."
datadog,"And secondly, a quality metric that is very valuable to one product, does not necessarily bring the same value when measured for another."
datadog,"Let‚Äôs go over this by comparing two different products: A flight and hotel booking web app, like Kayak, and a social media app, like TikTok, with millions of young and impatient users."
datadog,"For the booking app, the failure rate is the most important quality metric which should be as low as it can be at all times since the booking process is usually a long process and collects users‚Äô info, travel details, and their payment info."
datadog,"Response time though, on the other hand, is not as crucial, since booking processes are usually long ones that people are used to already, and collecting thousands of flight info from other search engines consumes a lot of time anyway."
datadog,"On the other hand and for the social media app, it is the opposite: The response time has to be as low as possible since most users won‚Äôt wait for too long for content to load, and if nothing loads in a short timespan, they simply swipe to the next one, while failure rate, although still important, is not as critical as the booking app."
datadog,"The best way, in my opinion, is to sit with your product owner/manager and iterate over a list of possible candidates for quality metrics and find out which ones are more valuable to spend time on their monitoring and collection."
datadog,"How to measure and monitor the metrics
Depending on the metric you choose, there is usually a tool that is made to collect them."
datadog,"Here is a list of well-known tools for some of the quality metrics that I used in the past or currently use:
For the response time of the backend services and failure rate, there are log collecting tools that can be integrated with your services, like Datadog, Sentry, and Kibana
For the Page Response Time and Uptime Status of the frontend pages, there is StatusCake
And for UX quality, there is Sentry and HotJar
After setting these tools up and integrating it successfully, there are two main ways to monitor the metrics:
One way is to monitor the metrics within the tools."
datadog,"Most of these tools come with visual dashboards, sometimes heavily configurable, like in Datadog, giving you the full power of deciding what metrics you want to monitor and how you want to do it."
datadog,"Here are some of the dashboards that I currently have running for our product:

A custom-made dashboard in Datadog, showing the 5xx error counts

Uptime status percentage, in StatusCake

Average page speed (or page response time) in milliseconds, in StatusCake

UX (User Experience) analysis on FullStory
This looks insightful, doesn‚Äôt it?"
datadog,"weekly or monthly insight over different aspects of the quality of your product can give you not only a good grasp of the current state of quality, but also, showing you their trend and giving an idea of the current path that you‚Äôre on:
If you don‚Äôt change anything, will this current trend lead to a high-quality product or the opposite?"
datadog,"and If you need to make a change, from which areas you have to start."
datadog,"If you want to improve one thing in this current setup of having several dashboards showing different quality metrics, what would it be?"
datadog,For me the answer was easy: Having them all in one place!
datadog,"So I don‚Äôt have to have different links to different dashboards, some of which having a different time frame for displaying the metrics, that unfortunately is not configurable, like StatusCake‚Äôs."
datadog,But where should that single holy place be?
datadog,"The place I chose is a classic one: A tool where accountants since the dawn of the age of computers used to display rows and rows of data, all in one sheet: The spreadsheets!"
datadog,"With Google Sheets available in every browser, this idea is more appealing than ever, but there is another reason that I chose Google Sheets and that‚Äôs Google‚Äôs App Script, which takes us to the second way of collecting and displaying those metrics:
Collection in Google Sheets using App Script
One way of collecting these quality metrics in Google Sheets is, of course, extracting the needed data from those dashboards, and then manually add it to the spreadsheet."
datadog,"While this approach is completely fine and there is nothing wrong with it, but my motto has always been:
‚ÄúIf something can be automated, then it should‚Äù
Google building its App Script as a layer on top of its cloud suite (Sheets, Docs, etc) enable us to read from and write into out Google documents via a .gc script which is basically javascript for the most part:

You can access the Script editor via Tools

This is how the Script editor looks like: you can have multiple files, functions, and all with autocomplete!"
datadog,"Here is a great multi-part step-by-step guide to Using App Scripts with Google Sheets and I won‚Äôt do the introduction here; instead I share some code snippets that I wrote showing you how I retrieve some of my quality metrics using Datadog‚Äôs and StatusCake‚Äôs API, as an example."
datadog,"Before sharing the scripts, I want to show you how the empty sheet looks like:

Quality Metrics sheet, before having any data
As you can see, the two left columns show the metrics and the specific area that the metric was measured for, and the rest of the columns are for every calendar week."
datadog,"Therefore what I want to do in my script is to:
Collect the metrics for every week
Fill the right cell considering the right calendar week
Now that you know what the purpose of the script, let‚Äôs dive into its code."
datadog,"The first example gets the Error Count metrics from Datadog and fills the corresponding cells:
// Gets the error count report from Datadog
function getMetricFromDataDog(query, formData, options, rowPosition) {
  var url = ""https://api.datadoghq.com/api/v2/logs/events/search?api_key=<YOUR_API_KEU>&application_key=<YOU_APP_KEY>""
  // Gets 2 days in ISO fromat: for ""from"" and ""to"" in payload
  var dates = getDatesISO()
  // The corresponding rows that needs to be filled
  // In the sheet, rows #2, #3, & #4 are for error count
  var rowPositions = [2, 3, 4]
  var queries = [ 
    ""<DATADOG_QUERY_1>"",
    ""<DATADOG_QUERY_2>"",
    ""<DATADOG_QUERY_3>"",
    ...
  ]
  // For every query, we call the Datadog query once
  for (var i = 0; i < rowPositions.length; i++) {    
    var formData = {
      ""filter"":
      {
        ""from"": dates[0],
        ""to"": dates[1],
        ""query"": queries[i]
      },
      ""page"":  
      {
        ""limit"": 9999  
      }
    };
    var options = {
      'method' : 'post',
      'payload' : JSON.stringify(formData)
    };
    // Sending the request to Datadog API
    var response = UrlFetchApp.fetch(url, options);
    var responseArr = JSON.parse(response)
    var errorCount = Object.keys(responseArr[""data""]).length;
    
    // Finding the right colomn based on the current calendar week
    var colPosition = getCurrentWeek()
    var sheet = SpreadsheetApp.getActiveSheet();
    // Filling the right Cell (Row x Column)
    sheet.getRange(rowPositions[i], colPosition).setValue([errorCount]);
  }
}
And the second function is for fetching the Page Speed metrics from StatusCake:
// Getspage speed reports form StatusCake
function getPageSpeedReport() {
  // Every test in StatusCake has an ID that you can see in the URL
  var testIds = [<ID_1>, <ID_2>, <ID_3>, <ID_4>, <ID_5>]
  // The corresponding rows that needs to be filled
  // In the sheet, rows #13 to #17 are for error count
  var rowPositions = [13, 14, 15, 16, 17]
  var headers = {
    'API' : '<YOUR_API_KEY>',
    'Username' : '<YOUR_USERNAME>'
  }
  var options = {
    'method': 'get',
    'headers': headers
  };
  
  for (var i = 0; i < testIds.length; i++) {
    var url = 'https://app.statuscake.com/API/Pagespeed/History?id=' + testIds[i] + '&days=7'
    // Sending a request to StatusCake's API
    var response = UrlFetchApp.fetch(url, options);
    var responseArr = JSON.parse(response)
    var avgPageSpeed = responseArr[""data""][""aggregated""][""loadtime_ms""][""avg""];
    // Finding the right colomn based on the current calendar week
    var colPosition = getCurrentWeek()
    // Filling the right Cell (Row x Column)
    var sheet = SpreadsheetApp.getActiveSheet();
    sheet.getRange(rowPositions[i], colPosition).setValue(Math.trunc([avgPageSpeed]));
  }
}
And these are the utility functions, called in these examples:
// Calculates the 'from' and 'to' dates in ISO format for Datadog
function getDatesISO() {
  // Collecting logs on a weekly basis
  var interval = 7
  var d = new Date()
  var endDate = d.toISOString()
  d.setDate(d.getDate() - interval);
  var startDate = d.toISOString()
  return [String(startDate), String(endDate)];
}
// Returns the current calendar week number
function getCurrentWeek() {
  // week columns start from C/3rd
  var weekOffset = 3
  // the first week in the sheet
  var firstWeek = 33
  // the first year in the sheet 
  var firstYear = 2020
  var weekNo = getWeekNumber(new Date())[1]
  var weekNoConsiderYear = (getWeekNumber(new Date())[0] - firstYear) * 52 + weekNo
  var weekColoumPos = weekNoConsiderYear - firstWeek + weekOffset
  
  return weekColoumPos
}
// Returns the current [ year, calendar week number]
function getWeekNumber(d) {
    d = new Date(Date.UTC(d.getFullYear(), d.getMonth(), d.getDate()));
    d.setUTCDate(d.getUTCDate() + 4 - (d.getUTCDay()||7));
    var yearStart = new Date(Date.UTC(d.getUTCFullYear(),0,1));
    var weekNo = Math.ceil(( ( (d - yearStart) / 86400000) + 1)/7);
  
    return [d.getUTCFullYear(), weekNo];
}
And the last step is to define triggers that run your functions:

Clicking the clock takes you to the Triggers page

Modal for Trigger creation

Here you can see the 2 triggers for those two functions that collect metrics from Datadog and StatusCake
And at the end when this is all set‚Ä¶ Viol√†!"
datadog,"All your quality metrics are set and will update automatically:

Quality Metrics sheet, after setting up the App Script and Triggers
Adding visuals
On top of all this, you can also add some visual charts in the same Google Sheet document, to show the changes in the metrics."
datadog,"For example, the chart below visualizes the Error Count metric‚Äôs measurements:

Graphic charts created based on the values for Error Count, Page Speed, and a few more"
datadog,"On August 11th, Datadog has announced its new Marketplace, a platform for third-party application development that provides customers with access to a wide range of tools, integrations, and services from Datadog‚Äôs Partner Network."
datadog,We are excited to be part of the Datadog Marketplace launch!
datadog,"Fairwinds Insights is now available in the Marketplace allowing users to proactively monitor their Kubernetes and container configurations and get recommendations to improve security, efficiency and reliability."
datadog,"Fairwinds Insights findings and recommendations integrate within Datadog, enabling DevOps teams to manage Kubernetes and application containers more productively."
datadog,We are big fans of Datadog at Fairwinds using it across many of our Kubernetes managed services to ensure observability and the ability to discover unknown unknowns.
datadog,"We also have an open source project, Astro , a Kubernetes operator that watches objects in your cluster for defined patterns and manages Datadog monitors based on this state."
datadog,"This integration allows more Datadog customers to benefit from improved security, reduced costs and saved time."
datadog,"About Fairwinds Insights
Fairwinds Insights is 5+ open-source tools in one, single configuration validation platform, all integrated with the tools you use."
datadog,"It combines trusted open source tools, toolchain integrations, and SRE expertise based on hundreds of successful Kubernetes deployments."
datadog,"How it Helps
Fairwinds Insights provides a unified, multi-cluster view into three categories of Kubernetes configuration issues and prioritizes remediation actions around security, efficiency, and reliability."
datadog,Fairwinds Insights makes it easy to deploy multiple open-source tools through a single helm installation.
datadog,This one-time install helps engineers avoid custom work for installing and configuring each tool.
datadog,"Datadog Marketplace
The Datadog Marketplace is available now to all Datadog customers within the Datadog app for a free two-week trial for any application before committing to a purchase."
datadog,You can try Fairwinds Insights in the Marketplace.
datadog,"At Beam, we have a lot of metrics that we collect of which we utilize in pretty standard ways."
datadog,"For instance, we collect CPU and Memory metrics and utilize those for our horizontal pod auto scalers."
datadog,"We also collect custom metrics, like how many claims we‚Äôve processed over a given amount of time so we can alert if the number of claims during a set period drops below an expected amount."
datadog,Beam also utilizes Datadog for our metric and log aggregation so it made sense for us to ship custom metrics to Datadog.
datadog,"Currently, we utilize the prometheus_exporter gem by Discourse to surface our metrics to Prometheus and wanted to continue to surface a subset of those metrics to datadog in the same way."
datadog,"The reasoning behind only surfacing a subset of the metrics to Datadog came down to one thing, cost."
datadog,We have hundreds of metrics that are sent to Prometheus and we just wanted metrics in Datadog to facilitate alerting in our slack channels and bubbling those alerts into Victorops in cases where human intervention needed to happen.
datadog,"To get started with this tutorial, you‚Äôll need a few things:
Working knowledge of Ruby
A Kubernetes cluster and knowledge of how to set up Kubernetes manifests."
datadog,A Datadog account and the Datadog k8s agent installed to your cluster.
datadog,"Installing Prometheus Exporter
To make the tutorial as a whole more visible, I have set this up utilizing the Sinatra Ruby framework."
datadog,The first step of setting this all up is getting the Prometheus exporter gem installed.
datadog,"With bundler this is as simple as running:
bundle add prometheus_exporter and then bundle install
Once installed, you can then create a client registry in your application and bind the metrics server to 0.0.0.0:9394 ."
datadog,"In app.rb:
require 'sinatra'
require 'prometheus_exporter'
require 'prometheus_exporter/server'
# client allows instrumentation to send info to server
require 'prometheus_exporter/client'
require 'prometheus_exporter/instrumentation'
# bind is the address, on which the webserver will listen
# port is the port that will provide the /metrics route
server = PrometheusExporter::Server::WebServer.new bind: '0.0.0.0', port: 9394
server.start
# wire up a default local client
PrometheusExporter::Client.default = PrometheusExporter::LocalClient.new(collector: server.collector)
Once this is all in place, you can then view empty metrics are being served up by running: bundle exec prometheus_exporter -b 0.0.0.0 and then opening your browser to localhost:9394 (we will call this the metrics tab)."
datadog,This should show you an empty metrics page because no metrics have been exported yet.
datadog,"Setting Up Your First Metric
Now that Prometheus exporter is configured, let‚Äôs go ahead and add a metric that will count HTTP requests."
datadog,"Appending to app.rb above, add the following:
http_requests = PrometheusExporter::Metric::Counter.new(""http_requests"", ""A counter of HTTP requests made"")
server.collector.register_metric(http_requests)
get '/' do
  http_requests.observe(1)   
  content_type 'text/html'
  ""hello world""
end
Now you can start up your Sinatra app with the following command: ruby app.rb -p 3000 -o 0.0.0.0
Once the application is started, in a new tab you can open your browser to localhost:3000 (we will call this the app tab) which should print out hello world ."
datadog,"If you switch back to your metrics tab and refresh you will then see
# TYPE http_requests counter
# HELP http_requests A counter of HTTP requests made
http_requests 1.0
The more you refresh your app tab, the higher the http_requests counter will go."
datadog,"Sending To Datadog
Now that we are collecting HTTP request metrics, we will want to ship these metrics to datadog."
datadog,"To do this, set up a pod with two containers."
datadog,"One that will accept your production traffic and one that will handle metrics:
apiVersion: v1
kind: Pod
metadata:
  name: sinatra
  labels:
    app.kubernetes.io/name: sinatra
  annotations:
    ad.datadoghq.com/sinatra.check_names: |
      [""openmetrics""]
    ad.datadoghq.com/sinatra.init_configs: |
      [{}]
    ad.datadoghq.com/sinatra.instances: |
      [
        {
          ""prometheus_url"": ""http://sinatra-metrics.sinatra.svc.cluster.local/metrics"",
          ""namespace"": ""sinatra"",
          ""metrics"": [""http_requests""],
          ""tags"": [
            {""namespace"": ""sinatra""},
            {""app"": ""sinatra""},
            {""environment"": ""production""}
          ],
          ""ssl_verify"": ""false"",
          ""ssl_ignore_warning"": ""true""
        }
      ]
spec:
  containers:
    - name: sinatra-metrics
      image: myawesomesinatrarepo/sinatratutorial
      command:
        - bundle
        - exec
        - prometheus_exporter
        - -b
        - 0.0.0.0
    - name: sinatra-app
      image: myawesomesinatrarepo/sinatratutorial
      command:
        - ruby
        - app.rb
        - -p
        - 3000
        - -o
        - 0.0.0.0
The real magic happens with the pod‚Äôs annotations."
datadog,The Datadog Kubernetes agent is looking for pods that have the ad.datadoghq.com/<podname>.<config_option> annotations and utilizes them for autodiscovery of metrics.
datadog,One thing that I found hard to find when setting this up at Beam was finding all available <config_option>'s which can be found here.
datadog,"The most important part of this piece was the ""metrics"": [""http_requests""] bit, since this is datadogs whitelist of metrics."
datadog,It will only pull metrics that are in this whitelist and it allows you to use * as a wildcard.
datadog,"So you can pull all [""http_requests"", ""ruby*""] metrics or even [""*""] all metrics."
datadog,"The final part of this entire thing is that you will need a service configured so that datadog can hit your metrics endpoint from anywhere within your cluster by utilizing the in-cluster DNS of your service:
apiVersion: v1
kind: Service
metadata:
  name: sinatra-metrics
spec:
  clusterIP: 172.20.20.20
  ports:
  - name: metrics
    port: 80
    protocol: TCP
    targetPort: 9394
  selector:
    app.kubernetes.io/name: sinatra
  sessionAffinity: None
  type: ClusterIP
Once the service is in place, you should now see your custom whitelisted OpenMetrics flowing to Datadog within seconds!"
datadog,We‚Äôre excited to announce that Undefined Labs has been acquired by Datadog!
datadog,"Two years ago, we started Undefined Labs to completely rethink testing in a world rapidly shifting to the cloud."
datadog,"Having experienced firsthand the transition from simple and monolithic web applications to the complex and distributed cloud-native applications of modern days, we‚Äôve encountered organizations of all sizes dealing with the same painful issues around testing and deployment."
datadog,"There‚Äôs been a lack of tooling to debug tests in microservice environments, an absence of historical understanding when it comes to testing, gross inefficiencies that lead to both bottlenecks as well as exorbitant CI costs, and no centralized and automated way to deal with test flakiness."
datadog,"With our latest release of Scope, we‚Äôre proud to have been able to address all of these problems in a meaningful way."
datadog,"After founding Undefined Labs, Datadog was one of the first services we added to our tech stack."
datadog,"We‚Äôve always greatly admired the power of the Datadog platform to provide us with best-in-class production observability, as well as their ability to remain agile and innovative and to continually redefine the monitoring space."
datadog,We‚Äôre excited by the opportunity to extend Datadog‚Äôs industry-leading visibility into the software development and pre-production workflows.
datadog,"We believe joining Datadog will accelerate our vision of helping thousands of engineering organizations operate with a better understanding of the entire software development lifecycle, from git push to production."
datadog,"We‚Äôd like to extend a special thanks to all of our users and customers who have supported us and pushed us, and have provided incredible feedback in shaping our products."
datadog,"In light of the acquisition, we‚Äôll be hard at work creating an even better product and experience within the Datadog platform, with the added benefit of carrying forward all of the lessons learned while building Scope."
datadog,"We know many of our users are already Datadog customers, so we‚Äôll be seeing you again very soon!"
datadog,"We‚Äôre not only excited about the future of what we‚Äôll build as a part of Datadog, but also the chance to make a positive impact in Madrid, Spain."
datadog,"We will maintain our engineering office in Madrid, and we look forward to growing the team over time as part of Datadog."
datadog,"Last but not least, we‚Äôd like to thank our investors, advisors, and friends for all of your support, advice, and mentorship over the past couple of years."
datadog,"The entire team at Undefined Labs will be joining Datadog and we look forward to continuing the journey to build tools that solve challenges in software engineering so development teams can do more, faster."
datadog,"For a peek into what this means for Datadog, you can see their announcement here."
datadog,"Datadog is a monitoring service for monitoring servers, databases, tools, and services."
datadog,This post covers using Puppet Bolt to install Datadog agents.
datadog,"Initialize a New Bolt Project
Ensure that the latest version of Puppet Bolt is installed before getting started."
datadog,Puppet Bolt utilizes Project directories as launching points for running Bolt operations.
datadog,In this post we‚Äôll create a Bolt project for deploying a Datadog agent.
datadog,The following command will create a directory named datadog in the current working directory and install the datadog_agent forge module along with the necessary module dependencies.
datadog,"bolt project init datadog --modules datadog-datadog_agent
The command should generate output similar to that shown below if it ran successfully."
datadog,"Successfully created Bolt project at /system/path/datadog
Successfully created Puppetfile at /system/path/datadog/Puppetfile
Successfully synced modules from /system/path/datadog/Puppetfile to /system/path/datadog/modules
Successfully installed datadog-datadog_agent
There should now be a bolt.yaml file in the datadog directory."
datadog,In the datadog project directory create a file named bolt-project.yaml with the following content.
datadog,"# bolt-project.yaml
name: datadog
Deploy the Datadog Agent
With the Datadog agent module installed all we need to do now is instantiate the module by creating a Bolt plan to run."
datadog,"Encrypt Datadog API Key
In order for our Datadog agent to connect to the Datadog service an API key is required and should be protected."
datadog,We‚Äôll need Puppet Bolt to be able to access the API key but we don‚Äôt want it to be stored in plaintext so we‚Äôll use hiera-eyaml to encrypt the data.
datadog,"Install Hiera-Eyaml Gem
Hiera-Eyaml is a library commonly used by Puppet for encrypting sensitive data."
datadog,It doesn‚Äôt ship with Puppet Bolt so we‚Äôll need to install it first.
datadog,Run the following command to install the hiera-eyaml gem.
datadog,"/opt/puppetlabs/bolt/bin/gem install --user-install hiera-eyaml
The command should have generated output similar to that shown below."
datadog,"Fetching: hiera-eyaml-3.2.0.gem (100%)
Successfully installed hiera-eyaml-3.2.0
Parsing documentation for hiera-eyaml-3.2.0
Installing ri documentation for hiera-eyaml-3.2.0
Done installing documentation for hiera-eyaml after 1 seconds
1 gem installed
Now that hiera-eyaml is installed we need to generate a key pair for the encryption and decryption process."
datadog,Run the following command to generate a new key pair.
datadog,"/opt/puppetlabs//bolt/bin/eyaml createkeys
The command should have generated output similar to that shown below."
datadog,The key pair is by default stored in a keys directory in the current working directory that the command was run in.
datadog,"[hiera-eyaml-core] Created key directory: ./keys
[hiera-eyaml-core] Keys created OK
Setup Hiera
Hiera is a built-in key-value configuration data lookup system."
datadog,This allows us to use a robust lookup system for defining parameters in our Bolt code.
datadog,In addition to yaml files we can use external systems such as a CMDB to provide data to our Bolt code.
datadog,Create a hiera.yaml file in the datadog directory with the content below.
datadog,The hiera configuration defines where and how to find the encrypted API key.
datadog,"---
version: 5
defaults:
  datadir: data
hierarchy:
  - name: ""Secret data""
    lookup_key: eyaml_lookup_key # eyaml backend
    paths:
      - ""common.eyaml""
    options:
      pkcs7_private_key: './keys/private_key.pkcs7.pem'
      pkcs7_public_key: './keys/public_key.pkcs7.pem'
Create a directory named data to store our hiera data files as specified in the hiera configuration file."
datadog,"mkdir data
Encrypt the Datadog API key using hiera-eyaml by running the following command and replacing the value after -s with your API key."
datadog,"/opt/puppetlabs//bolt/bin/eyaml encrypt -s be2qe2676543375deqde8e9fa28424343
The command should have generated output similar to that shown below."
datadog,"string: ENC[PKCS7,MIIBmQYJKoZIhvcNAQcDoIIBijCCAYYCAQAxggEhMIIBHQIBADAFMAACAQEwDQYJKoZIhvcNAQEBBQAEggEASCIWgU8lnyfMSSKIb1Nj/OScH+gJZ2FVc6JWeA1lilAIijyyHNByuswMkZoB+9+Q35MEiRbLLSkmhwchtbmHMe/51AcfF7RxHG0KImoESM9VLPN7juX5wJDIsD7KAbIRAC1OeLUTnk1kS2kHEjuOLA1FU/hnKMFu8Yyy/eXClD+gaXwiryUuCDjiIui6ht28xzEe0H+2RTugggdkdIMvdsUEHSFvAT/oW35ZMTQdway5XF0ro80y/lA0nT2S7DtHPvu/Sy05009Ei/La4MVNlDBln3x8gRk0v/mMsUoiGCs7ZYTOycYYq0LPiNHKIIGrfGrp397ef5zKOKySCryaBTBcBgkqhkiG9w0BBwEwHQYJYIZIAWUDBAEqBBAXv0fhfFThA4j/YN/yJ/4agDC5UW4hNla4JeAZQJyLNqHx9mGJydHQUuYiLOmxW7Sz1P4X2mWlwpsEHplWWEoWBd8=]
OR
block: >
    ENC[PKCS7,MIIBmQYJKoZIhvcNAQcDoIIBijCCAYYCAQAxggEhMIIBHQIBADAFMAACAQEw
    DQYJKoZIhvcNAQEBBQAEggEASCIWgU8lnyfMSSKIb1Nj/OScH+gJZ2FVc6JW
    eA1lilAIijyyHNByuswMkZoB+9+Q35MEiRbLLSkmhwchtbmHMe/51AcfF7Rx
    HG0KImoESM9VLPN7juX5wJDIsD7KAbIRAC1OeLUTnk1kS2kHEjuOLA1FU/hn
    KMFu8Yyy/eXClD+gaXwiryUuCDjiIui6ht28xzEe0H+2RTugggdkdIMvdsUE
    HSFvAT/oW35ZMTQdway5XF0ro80y/lA0nT2S7DtHPvu/Sy05009Ei/La4MVN
    lDBln3x8gRk0v/mMsUoiGCs7ZYTOycYYq0LPiNHKIIGrfGrp397ef5zKOKyS
    CryaBTBcBgkqhkiG9w0BBwEwHQYJYIZIAWUDBAEqBBAXv0fhfFThA4j/YN/y
    J/4agDC5UW4hNla4JeAZQJyLNqHx9mGJydHQUuYiLOmxW7Sz1P4X2mWlwpsE
    HplWWEoWBd8=]
Create a file named common.eyaml in the data directory created in a previous step."
datadog,The file should include an entry for the datadog_agent::api_key and its value should be the block output format generated from the encryption command.
datadog,"---
datadog_agent::api_key: >
    ENC[PKCS7,MIIBmQYJKoZIhvcNAQcDoIIBijCCAYYCAQAxggEhMIIBHQIBADAFMAACAQEw
    DQYJKoZIhvcNAQEBBQAEggEASCIWgU8lnyfMSSKIb1Nj/OScH+gJZ2FVc6JW
    eA1lilAIijyyHNByuswMkZoB+9+Q35MEiRbLLSkmhwchtbmHMe/51AcfF7Rx
    HG0KImoESM9VLPN7juX5wJDIsD7KAbIRAC1OeLUTnk1kS2kHEjuOLA1FU/hn
    KMFu8Yyy/eXClD+gaXwiryUuCDjiIui6ht28xzEe0H+2RTugggdkdIMvdsUE
    HSFvAT/oW35ZMTQdway5XF0ro80y/lA0nT2S7DtHPvu/Sy05009Ei/La4MVN
    lDBln3x8gRk0v/mMsUoiGCs7ZYTOycYYq0LPiNHKIIGrfGrp397ef5zKOKyS
    CryaBTBcBgkqhkiG9w0BBwEwHQYJYIZIAWUDBAEqBBAXv0fhfFThA4j/YN/y
    J/4agDC5UW4hNla4JeAZQJyLNqHx9mGJydHQUuYiLOmxW7Sz1P4X2mWlwpsE
    HplWWEoWBd8=]
Create a Datadog Install Plan
Now that hiera has been configured and the api key has been encrypted, we‚Äôre ready to create a plans directory in the project directory."
datadog,"mkdir plans
Create a plan named install.pp in the plans directory with the following content."
datadog,The following plan preps the remote system with a Puppet agent and installs the DataDog agent.
datadog,The module requires that an api key is provided but instead of specifying it in the plan an automatic parameter lookup is performed to our hiera common.eyaml file for the value.
datadog,"plan datadog::install(
  TargetSpec $targets,
  ) {
      $targets.apply_prep
      apply($targets) {
        class { ""datadog_agent"":
          datadog_site => ""datadoghq.com"",
          agent_major_version => 7,
        }
   }
}
We can now verify that Bolt recognizes our new plan by running the following command that lists registered Bolt plans."
datadog,"bolt plan show
If the plan registers properly the output should include a datadog::install entry."
datadog,"aggregate::count
aggregate::nodes
aggregate::targets
canary
datadog::install
facts
facts::info
puppetdb_fact
reboot
terraform::apply
terraform::destroy
Run the DataDog agent Install
With the plan registered we are ready to run the plan by running the following command."
datadog,Change the target IP address and username for your environment.
datadog,"bolt plan run datadog::install --targets 10.0.0.199 --no-host-key-check --user root
If the plan ran successfully it should have generated output similar to that displayed below."
datadog,"bolt plan run datadog::install --targets 10.0.0.199 --no-host-key-check --user root
Project-level configuration in bolt.yaml is deprecated if using bolt-project.yaml."
datadog,"Transport config should be set in inventory.yaml, all other config should be set in bolt-project.yaml."
datadog,"Starting: plan datadog::install
Starting: install puppet and gather facts on 10.0.0.199
Finished: install puppet and gather facts with 0 failures in 11.14 sec
Starting: apply catalog on 10.0.0.199
Finished: apply catalog with 0 failures in 109.16 sec
Finished: plan datadog::install in 2 min, 1 sec
Plan completed successfully with no result
If our plan ran successfully we should be able to log into our Datadog account and see the newly added node in our inventory."
datadog,We have now successfully deployed a Datadog agent using Puppet Bolt.
datadog,"Puppet Bolt also supports inventory plugins to dynamically target nodes in AWS, Azure, VMware vSphere and others."
datadog,This enables us to quickly rollout agents to hundreds or thousands of nodes in minutes.
datadog,Puppet Bolt can also use facts about the system or cloud tags to dynamically configure Datadog classification information.
datadog,The Puppet Forge has a large amount of existing content that can be utilized to quickly get started with other automation.
datadog,When I came across Apache Kafka and its concept of a streaming platform I asked myself ‚Äî how will I monitor it?
datadog,"SaaS adoption continues to accelerate as the world is moving to services, data streaming, events, messaging frameworks and the like ‚Äî and it‚Äôs not getting any smaller."
datadog,The fact that you don‚Äôt manage the SaaS application doesn‚Äôt mean you‚Äôre exempt from monitoring it.
datadog,It‚Äôs important to have monitoring and management tools designed to identify what‚Äôs happening inside the platforms and help them be a usable tool for business.
datadog,At Natural Intelligence we chose Confluent Cloud Kafka rather than build it on our own.
datadog,"In this post, I‚Äôll explain how we monitor Confluent Cloud Kafka via Datadog."
datadog,"Kafka as a Service with Confluent Cloud
Using the cloud generally means less control of your workload, whereas on-premises solutions enable a more fine-grained control."
datadog,"With Kafka we considered monitoring these three components:
Producers
Consumers
Brokers
But, we had a unique challenge: integrate Confluent Kafka with our own standard monitoring and alerts system ‚Äî Datadog."
datadog,We had to devise a solution that enables monitoring Confluent Kafka with a tool external to Confluent cloud.
datadog,"This is how we did it:
Unfortunately, Kafka metrics are hidden inside the Confluent Cloud and Datadog can‚Äôt access them directly."
datadog,"Therefore, we had to build a ‚ÄúBridge‚Äù that connects Confluent with Datadog."
datadog,"The steps to create this ‚Äúbridge‚Äù:
Step 1- Define a docker compose for the bridge
Step 2 ‚Äî Create an open-metrics config file for Confluent metrics
Step 3 ‚Äî Create a cloud API key
Step 1- Define a docker compose for the bridge
The docker-compose runs a Datadog agent and mounts the config file below and launches it together with the ccloud_exporter in order to be on the same network."
datadog,"ccloudexporterWithDatadog
Step 2- Create an open-metrics config file for Confluent metrics
Here is the baseline config for the container collecting the metrics from Confluent."
datadog,"instances:
  # The prometheus endpoint to query from
  - prometheus_url: http://ccloudexporter_ccloud_exporter_1:2112/metrics
    namespace: ""production""
    metrics:
      - ccloud*
Rather than setting up a full-blown Prometheus, we decided to expose only the same metrics with a similar API."
datadog,"This configuration exposes the Confluent metrics in the configured url:
http://ccloudexporter_ccloud_exporter_1:2112/metrics

Here you will find all the available configuration options."
datadog,"Step 3 ‚Äî Create a Cloud API key
A cloud API key is necessary to reach the Confluent cloud metrics."
datadog,"ccloud login ccloud
kafka cluster use lkc-XXXXX ccloud
api-key create --resource cloud
Once the API key is created, remember to write down your App Key and Secret ‚Äî they will be needed in the docker compose."
datadog,"Finally, we are ready to launch the docker compose
After running the service, it will collect the metrics and send them to Datadog."
datadog,"The essence of the solution is the way the cloud exporter collects the data, and the config file shared here, which defines what to collect, guiding the Datadog agent accordingly."
datadog,Collecting the metrics happens automatically every 60 seconds.
datadog,"Export and launch the docker-compose:
export CCLOUD_USER=<CCLOUD_USER>
export CCLOUD_PASSWORD=<CCLOUD_PASSWORD>
export CCLOUD_CLUSTER=<CCLOUD_CLUSTER>
export DD_API_KEY=<DD_API_KEY>
# Deploy the applications
docker-compose up -d
Metrics
Metrics are standardized across the organization, and tailored to its needs."
datadog,Consider these as the basic metrics for a production environment.
datadog,"Here‚Äôs a simple dashboard to help us monitor our metrics:

Summary
It‚Äôs pretty easy to connect Confluent Cloud to your Datadog monitoring infrastructure."
datadog,"You are now able to monitor your Kafka topics provided by Confluent on your organization‚Äôs Datadog dashboard, and of course add alerts as you do for any internal metrics."
datadog,"The result of a hackday, this post focuses on leveraging native F5 LTM and Nginx logs functionality to gain visibility into the latency breakdown of individual requests."
datadog,"(Super) High level flow diagram
Datadog is a popular observability platform for your entire (cloud native) tech stack, F5 is a powerful gateway to many critical on-premise workloads."
datadog,Nginx is a very popular open source web server and proxy.
datadog,What happens when you have all 3 in your environment?
datadog,Can we get everything to play nicely together with minimum effort (no sweat or iRules)?
datadog,There are many ways to monitor F5 BIG-IP.
datadog,You could procure BIG-IQ or Beacon or use some combination of SNMP or Telemetry Streaming.
datadog,"However, to follow this post, you just need access to:
F5 LTM
Datadog SaaS account (go ahead and create a free trial, it should take no more than 5mins)
https://www.datadoghq.com/free-datadog-trial/
Centralized logging setup or a t2.micro EC2 instance to deploy rsyslog
Aim:
Send HTTP access logs from both the LTM and backend Nginx instance to Datadog."
datadog,This should include response processing time on each tier (F5 and Nginx) so we can tell where any latency occurred.
datadog,Parse the logs to allow us to tease out aggregated views and maybe even drill down to individual requests.
datadog,"Step1: Setup rsyslog
Skip this step if you already have centralized logging setup (eg."
datadog,"fluentd or syslog-ng) and instead follow the documentation below
https://docs.datadoghq.com/logs/log_collection/
Here we use rsyslog as a lightweight centralized logger to send relevant logs over to Datadog."
datadog,Rsyslog is really convenient as it comes preinstalled on most linux images.
datadog,Not much configuration needed here since Datadog accepts logs in any format.
datadog,"If you are starting from scratch on AWS, just spin up a t2.micro with Amazon Linux and follow the instructions below."
datadog,You will need access to a Datadog API key to complete this.
datadog,"https://docs.datadoghq.com/integrations/rsyslog/
Here is what we used to capture the relevant LTM logs in our rsyslog.conf:
$template messages, ‚Äú/var/log/%fromhost-ip%/messages‚Äù
*.info;mail.none;authpriv.none;cron.none;local7.none;local6.none ?messages
Correspondingly, in /etc/rsyslog.d/datadog.conf plug in the following values (in addition to what is stated in the docs):
File=‚Äú/var/log/{f5-ip}/messages‚Äù
[metas ddsource=\""f5\""]
Step2: Setup F5 Request Logging
In this step, we assume that your F5 virtual server is already up and humming."
datadog,"Next, you create a LTM pool pointing to your rsyslog server which you will need in for the ‚ÄúPool Name‚Äù field in your request logging profile."
datadog,"Following this, we create the actual request logging profile (its hidden quite deep in the menus)

Configure the Response logging section (Request logging lacks the logging data we need)."
datadog,Details of the format of the cryptic looking Template string below are in the link below.
datadog,"https://techdocs.f5.com/en-us/bigip-14-0-0/external-monitoring-of-big-ip-systems-implementations-14-0-0/configuring-request-logging.html

Once the request logging profile is created, attach it to the virtual server you wish to log traffic from."
datadog,"Look under the main virtual server config, change the dropdown from basic to advanced, and then look for the field Request Logging Profile (yes its well hidden, almost like an easter egg)

Jul 17 06:11:08 JRESPONSE xx.xx.xx.xx /Common/VS1 req=GET / HTTP/1.1 hrc=200 4174 1575 cookie=_dd_s=rum=1&id={sessionId}&created=yyy&expire=zzz
At this point, you should see logs of the format above hitting your rsyslog server each time you access your virtual server."
datadog,"If you get 1 log per request, you are making good progress!"
datadog,"Step3: Generate Nginx Access logs
For F5, we have to use an agentless collection method."
datadog,"For Nginx, you also have the option to use the agent-based method which is both easier and more powerful."
datadog,"In addition to logs, the agent will also collect a bunch of insightful Nginx health metrics and provide an OOTB dashboard."
datadog,Feel free to explore these on your own.
datadog,"Now, install the Datadog Agent on the Nginx host and follow instructions here to configure logging."
datadog,"https://docs.datadoghq.com/integrations/nginx/
We cheated a bit here and bypassed rsyslog as the agent can send logs directly to Datadog."
datadog,Here is the nginx.conf access log format and sample log line.
datadog,See how easy it is to get request_time?
datadog,Its 0.885 sec in the sample log below.
datadog,"nginx.conf log format
10.0.0.208 - - [17/Jul/2020:06:11:07 +0000] ""GET / HTTP/1.1"" 200 4174 0.885 ""-"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.0.0 Safari/123"" ""-"" ""_dd_s=rum=1&id={sessionID}&created=xxx&expire=yyy"" ""1.2.3.4""
Step4: Jump into Datadog
Now for the fun part!"
datadog,We need to parse the logs that are ingested into Datadog.
datadog,Default Nginx logs are supported out-of-the-box but this needs to be modified to parse the new cookie header we added to the access logs.
datadog,"Modified Nginx Parser
Clone the default Nginx pipeline and add the additional rules below access.combined to handle the additional cookie attributes."
datadog,"Next, we create a parsing pipeline for the custom F5 LTM request logs."
datadog,"F5 Parser
Create a new pipeline for F5, filter to the ddsource we defined in step1, then use the auto-grok parser or the rule below."
datadog,"Step5: Connecting the dots
Lastly, you need a way to connect the logs for each request together."
datadog,You could do this by writing iRules to generate headers with a random ID on your LTM.
datadog,"But let‚Äôs assume we are not familiar with iRules, so here we take a shortcut by simply use Datadog RUM (Real User Monitoring)."
datadog,"https://docs.datadoghq.com/real_user_monitoring/installation/
One quick way to implement this is to just paste the provided code snippet into your html code <head> block."
datadog,"Besides being a pretty cool solution on its own with DNS and resource level breakdown of frontend latency, we now can repurpose the RUM injected cookie header which has a unique session_id!"
datadog,"Once Datadog RUM is setup, go into one of the captured F5 LTM logs in Datadog and create a facet for cookie.id (unique ID) and a measure for duration_ms (attribute that denotes latency in both F5 and Nginx)

cookie.id facet

duration_ms measure
Now you can generate some traffic and visualize the latency breakdown of your incoming requests!"
datadog,"Filter by session ID

Visualization of latency breakdown
You can also slice and dice by URL path, user-agent, and any other attribute that catches your eye."
datadog,"Summary
Turns out with just a basic F5 BIG-IP LTM and a Datadog free trial (or ongoing logs+RUM subscription), you can get this setup in 2‚Äì3 hours."
datadog,Definitely worth your time.
datadog,Thanks to Shigeya-san who worked on this with me and my friends from F5 who inspired and helped this project materialize.
datadog,"The new world of DevOps, platform engineering and Site Reliability Engineering."
datadog,It is brave new world for me.
datadog,"But this is one place where i wanted to be for a long long time, to get my hands dirty in the new wonders of IT world."
datadog,"What i was doing before it, was solution designing, architecting in the telecom OSS software world and it was a very traditional place."
datadog,"There are quite a few off the shelf COTS/Product Suites which were typically big product groups , installed in on-premise setups in Telco Data Centres."
datadog,"There was a different way of working, designing the solutions and language."
datadog,DevOps and SRE are products of the cloud native technical eco-system.
datadog,"They are born in the realms of Clouds (read data centre of AWS‚Äôs, Microsoft‚Äôs etc.)"
datadog,and adapted to system engineering practices by people who are developers at heart.
datadog,Confused ?
datadog,That‚Äôs what i was when i looked at it for the first time.
datadog,It was a transition from SNMP to HTTP for me.
datadog,From the packet inspect in wireshark to request tracing in Postman.So thats the move.
datadog,"Anyways , enough about me."
datadog,"So what is SRE, it stands for Site Reliability Engineering (https://en.wikipedia.org/wiki/Site_Reliability_Engineering) , which in the digital world means that you are (among one of many) responsible for making sure that the Site (read website) for your organisation is reliable, and the fact that you are an engineer and not just a support person on call."
datadog,"Now two key things there, First and foremost , Reliability ‚Äî Which mainly means that your Digital Services (Web Pages, API‚Äôs etc.)"
datadog,"are :
1."
datadog,"Up and available
2. and running with sufficient capacity and latency to ensure your desired customer experience
Note that its not just about making sure that its up and running , but the experience that customer is getting also needs to be factored in, as always !"
datadog,"The second Key bit about SRE is that , it is not a support function but an engineering function primarily."
datadog,"Which means that as an SRE , we need to create engineering solutions for the monitoring, running and improving the customer experience."
datadog,"So the job description comes with a requirement for understanding end-to-end Digital architecture , which are API driven , on the web and are microservices based."
datadog,"You out to understand all the components starting from the CDN hosting the content on the web for you , to the API gateways hosting your API‚Äôs, to the Cloud estate hosting your microservices and then the Databases at the backend NoSQL or SQL storing your data."
datadog,"Also since the speed of deployments is always going to be faster than traditional software system, SRE‚Äôs also need to be on-board the CI/CD systems , IaaC systems and all the new wonders of the DevOps world."
datadog,Another key bit are the APM systems and any supporting systems which facilitate in the observability of the stack!
datadog,"So, thats the trade, now to the key tools :
A) APM Systems : Application Performance Management tools are the ones which monitor your stack and help with the identification of issues as they occur or sometimes even before they occur (predictive insights)."
datadog,"There is a whole array of such systems , but the key is to choose one system suitable to your stack ."
datadog,Maybe you have a big part of your stack On-Prem so you would want a tool which performs good in On-Prem Deployment.
datadog,"or more likely you have most of your stack as Cloud Native , so you want a SaaS APM solution that its more native to your stack."
datadog,"There are systems like Datadog, AppDynamics, Dynatrace, Splunk all of which provides one or more of the services in the APM space."
datadog,"B) Notification Systems : Complementing your APM systems would be notification systems like PagerDuty, XMatters , which need to be efficient and clever enough so that they can identify multiple scenarios and complex team structures and cater to them."
datadog,"And also modern enough so that to be able to integrate with not just email and SMS , but also to the newer ways such as Slack channels etc."
datadog,"C) DevOps CI/CD systems : A large part of the role would be spend in making updates , creating new configurations, code even and pushing it continuously into the different environments."
datadog,"Which means that you would need to be familiar with the CI/CD systems be it Azure devOps, Jenkins/Ansible or any other combination of that."
datadog,"And yes, dont forget Git and the the dream that is GitOps‚Ä¶oh inner peace :) ."
datadog,"D) Infrastructure as a Code Systems : Chances are that as part of an SRE, you would be doing a lot of sysadmin tasks , particularly about creating new cofings , deploying and modifying infrastructure in cloud and SaaS systems."
datadog,For that Terraform is your friend.
datadog,"E) Cloud and Containerisation Systems : And last but not the least by any strech of your imagination Cloud and Container technologies like AWS, Azure, GCP , IBM Cloud etc."
datadog,And Docker and K8S for the containers.
datadog,You would need to understand and work on these techs as per your role demand.
datadog,Chances are that you would need a very good understanding of these techs day in day out.
datadog,"There are quite a few other significant parts like CDN systems, API management systems etc which will be part of the portfolio also and you would learn these depending on the section of the organisation you land in."
datadog,"But the above tools are key part of the SRE trade in my view , which you would do well to learn and well‚Ä¶.master (if you can that is)."
datadog,So thats it for this one from me ‚Ä¶more later ‚Ä¶stay kool and keep monitoring your stacks :)..ciao!
datadog,"Setu Dixit
An engineer on his SRE journey, a budding writer looking to write something genuine , a human looking to stay decent!"
datadog,Follow
datadog,These are exciting times for engineers at CM as many features from our core app (a monolith) are being refactored into microservices.
datadog,"A system which had a request path like below:

now looks like this:

When a system starts to scale in terms of the number of microservices, mapping a request‚Äôs end to end journey becomes harder."
datadog,"Unless you have strict documentation procedures, maintaining architecture diagrams in a wiki is hard as they can become outdated quickly and are then more misleading than useful."
datadog,"For the Site Reliability Engineering (SRE) team who are responsible for the reliability of the platform and emergency response, this means more complexity and chaos."
datadog,"I joined the SRE team at a time where engineers with the most knowledge about the monolith had moved on, so not only did we have to support the newly added microservices but also the giant monolith!"
datadog,We realised that we needed the system to answer a very important question: what is broken and why?
datadog,"For the last year, our main goal has been to make our system answer this question."
datadog,"In this post, we will look at the ways we went about accomplishing this."
datadog,What is observability?
datadog,Observability is a measure of how well internal states of a system can be inferred by knowledge of its external outputs.
datadog,"‚Äî wikipedia
If we can answer questions about an application without having prior knowledge about it, then we can say that the application is observable."
datadog,This is the key to helping us resolve production issues for our system.
datadog,"To make it observable, the app has to be instrumented to expose relevant data."
datadog,Let‚Äôs go through all the different kind of data we expose from our application.
datadog,"Source: https://www.elastic.co/blog/observability-with-the-elastic-stack
Logs
Extensive logging has always been practised by developers at CM but, without structure, it is hard to find and analyze relevant logs."
datadog,We live in an age of distributed microservices and unstructured logs just don‚Äôt cut it.
datadog,"Logs need structure, and by that I mean they need fields and values so that we can search and aggregate on those field values."
datadog,"There are libraries we use to provide structured logging for eg SLF4J for Java, Serilog for C# and Zerolog for GO."
datadog,It is not possible to change all the applications at once but every time we touch a part of a system we ensure the right logging libraries and right formats are used.
datadog,Organically our log data has become significantly more useful!
datadog,"Tools
We send all our application logs to Graylog which stores the data in an Elasticsearch (ES) cluster."
datadog,"Graylog is quite a powerful tool with options to manage ES indexes, alerting, dashboards and many more cool features."
datadog,"Metrics
Our engineers use metrics heavily throughout the application."
datadog,"Different metric types like counts, histograms and gauges are used to give information about a particular process or activity over time."
datadog,"However, these were not standardised."
datadog,"Every application has inputs and outputs like: Amazon Simple Queue Service (SQS), RabbitMQ, Kafka, HTTP/gRPC endpoints etc via which data is ingested, processed and passed on to another application or stored for persistence."
datadog,"For each of these inputs and outputs, it is important to measure all the key metrics."
datadog,This will determine if the issues are with the application itself or its dependencies.
datadog,What are the key metrics we look at?
datadog,"Traffic / Usage
Latency
Errors
Saturation of resources (CPU / Memory/ IO)
An application could use many services like gRPC, Kafka, Redis etc."
datadog,"In order to standardise the metrics we collected for each of these services, we created a list of key metrics."
datadog,We verified that every application or feature which is ready to be released exposed these key metrics.
datadog,This gave the team confidence in being able to find the right metrics to help troubleshoot the issue.
datadog,"Tools
We use Datadog for our metrics and monitors and PagerDuty for event management."
datadog,"We integrated Datadog monitors with PagerDuty, to ensure any metric breaching threshold(s) alerts an engineer."
datadog,Why not just be happy with logs and metrics?
datadog,Logs and metrics are great tools for observability.
datadog,"However, they have gaps like:
With logs, we often struggle with not knowing what log messages to search for (due to the sheer volume of log data)."
datadog,"With metrics, the data is aggregated so it is helpful for a birds-eye view but not to drill down to specific parameters."
datadog,"With Datadog, adding custom metrics helps in performing deeper analyses but that comes with a huge price tag $$$$
We add metrics and logs where we think something might go wrong but what about the unknown unknowns?"
datadog,What about understanding the end to end journey of a request?
datadog,"Traces
Datadog‚Äôs APM has been a game-changer for us in terms of observability."
datadog,We started with a basic set up following the guidelines here.
datadog,"With just the initial traces for HTTP requests, SQL queries and Redis operations we were able to derive more insights into our application."
datadog,The visual appeal of tracing for me was a clear win over logs and metrics.
datadog,"Source: https://docs.datadoghq.com/tracing/visualization/
APM made the dependencies between various services visible with services map."
datadog,Watchdog is another cool feature that will automatically detect anomalies in traces and provide alerts on system performance.
datadog,"Datadog also provides Trace Metrics, which are the following aggregate statistics over all the traces instrumented:
Total requests and requests per second
Total errors and errors per second
Latency
Breakdown of time spent by service/type
Apdex score (web services only)
In order to customise some of the functionality, we created our own wrapper around Datadog‚Äôs library for each language we support: C#, Java and Go."
datadog,This gave us more control over creating traces and how we wanted to serialise the span context.
datadog,We trace distributed calls by adding the span context (traceId and spanId) as a header value from the client.
datadog,"In the server, we could then use that span context as the parent giving visibility into the journey of a request across microservices."
datadog,Datadog samples the traces that are stored in the system.
datadog,"It is important to understand the sampling rules and storage of traces in APM to help set the right sampling priority, especially when dealing with distributed tracing."
datadog,"Baking in APM
Tracing does involve adding more code to the application, this could be a blocker for widespread adoption."
datadog,"In order to make it easier for our engineers, we created libraries that are easy to plug into existing services and in some cases, we added tracing in existing libraries."
datadog,"As of now, services like MSSQL, SQS, Couchbase, Cassandra, Kafka, Redis, gRPC are traced."
datadog,This has significantly increased our visibility into the performance of our entire system.
datadog,"Conclusion
Datadog has been key to our observability journey."
datadog,"We did consider Newrelic, Honeycomb and a few other options but Datadog has achieved a happy medium in terms of features and cost."
datadog,"Knowing that if we get paged in the middle of the night, we have the right information to deal with the issue has helped us sleep better ;)"
datadog,"AWS Data and Analytics services have evolved continuously; recently, I have seen that Amazon Kinesis Data Firehose allows third-party destinations such as Dynatrace, Datadog, and NewRelic, among others."
datadog,This new integration will allow us to take our log and metric flows easily to these providers.
datadog,"Some of the third party integrations
When I saw this new release, I began to work on an architecture that I had previously implemented, which you can see at this link."
datadog,Since we had an on-premise ingest of many logs to AWS through a VPN.
datadog,I decided then to test the new functionalities and implement the integration with datadog to see how it made the logs reach Datadog without taking advantage of what was previously implemented.
datadog,"I made the integration with Datadog to test this new functionality and be able to take the advantages that this tool gives us in:
Log parsing."
datadog,Log enrichment.
datadog,Generation of metrics.
datadog,Filtering and prioritization.
datadog,How does the integration work?
datadog,The integrations with these providers are all done through an API KEY; you have to select the correct endpoint and use the API KEY generated from the service.
datadog,"Datadog Integration
1- Go to the Datadog Configuration page."
datadog,2- Create an API KEY.
datadog,3- Create Amazon Kinesis Data Firehose and select the endpoint for Datadog.
datadog,4- Select the HTTP endpoint URL.
datadog,5- Put the API KEY from step 2.
datadog,"Check the Integration
Check in the Amazon Kinesis Data Firose monitoring tab the Records read from Amazon Kinesis Data Stream (Sum)."
datadog,Check on Datadog logs.
datadog,The logs in the image are generating from the sample KPL.
datadog,"Once you have all the logs in Datadog, you can take advantage of all the functionalities it provides."
datadog,"Final Architecture and conclusions

In the architecture above, Amazon Kinesis Data Streams receive the information from an on-premise application running the KPL."
datadog,This information is transmitted over the VPN and using a VPC endpoint; it reaches the Kinesis data streams.
datadog,It feeds the entire Amazon Kinesis Data Firehose flow to reach the Datadog.
datadog,1- Integrations for managing logs and metrics are easier through Amazon Kinesis Data Firehose.
datadog,2- All integrations must use an API KEY; you must consult third-party provider documentation for this.
datadog,3- These integrations will allow you to take advantage of the functionalities provided by these third-party providers in the management of logs and monitoring.
datadog,4- Data that could not be sent to the third-party provider can be stored in a local bucket.
datadog,5- It will be possible to centralize N amount of log sources in an Amazon Kinesis Data Stream and use Amazon Kinesis Data Firehose to be sent to Datadog; this use case is widespread since many companies that use these tools from other providers as their monitoring and logging core.
datadog,"6- In this post, I talk about Dynatrace, Datadog, and NewRelic."
datadog,"Still, you have to consider other third-party integrations such as LogicMonitor, MongoDB Cloud, Splunk, and Sumo Logic."
datadog,7- Many will wonder why not directly install the Datadog agent on the instance and avoid the use of Kinesis?
datadog,"In this scenario, using Amazon Kinesis Data Stream and Amazon Kinesis Data Firehose allows more flows within AWS that can use the logs, such as a flow that feeds S3 with the logs use Amazon Quicksight and visualize the information."
datadog,"Photo by TheDigitalArtist on PixelBay
Many applications at Disney Streaming Services are built as distributed systems, leveraging a variety of tools on the AWS cloud from Kinesis Data Analytics to ECS to Lambda."
datadog,"With this sort of design, monitoring and observability can be a challenge."
datadog,"AWS CloudWatch Logs Insights is a great tool when logging within the AWS ecosystem, but to solve an arising need for a centralized logging solution we decided to migrate to DataDog."
datadog,This post will detail how we migrated one project and provide a roadmap for migrating your own logs to DataDog.
datadog,"Motivations
Monitoring and observability are paramount to the success of any system."
datadog,"In distributed systems, with core business logic spread among several components, good observability becomes even more crucial."
datadog,"Although CloudWatch Logs Insights provides many benefits to logging on AWS, our distributed system still faced some unsolved pain points."
datadog,CloudWatch Logs Insights allows users to aggregate across multiple log groups through the UI.
datadog,"While this allows a certain amount of centralization, the AWS region still reigns supreme."
datadog,This isn‚Äôt a knock on CloudWatch Logs Insights at all.
datadog,"This is the way AWS is designed, and that‚Äôs totally fine."
datadog,"That said, for our use case, this approach required supplementing."
datadog,We also needed a platform that supported live logs for debugging potential regressions and generating business insights from our production systems.
datadog,"The latter requires a bit of technical and institutional knowledge, so an additional goal for us was to reduce the barrier to entry on this front for product managers and others."
datadog,"Migration
With the decision to use DataDog‚Äôs logging solution made, we moved forward with their documented method for collecting application logs using the DataDog Forwarder Lambda provided on Github."
datadog,"After a few tweaks within our own AWS setup, we were up and running with the forwarding Lambda."
datadog,"If you‚Äôre familiar with CloudFormation deployment, this stack will be extremely easy."
datadog,"If you‚Äôre new to CloudFormation, Amazon‚Äôs Getting Started guide for CloudFormation will help you get familiar with the product and concepts needed to make light working of this step."
datadog,"With the stack deployed and the Lambda running, we set up an index for our project in DataDog, making sure the forwarder Lambda was configured to correctly tag our logs."
datadog,With the baseline infrastructure set up it was time to start adding triggers to the forwarder.
datadog,"We opted to go the manual route to get started, explicitly adding the log groups we cared about as event sources to trigger the Lambda."
datadog,Voila!
datadog,Logs were flowing from our AWS account into DataDog.
datadog,We repeated this process for each region and just like that we had centralized logging.
datadog,"The whole process, from start to finish, took about half a day and was very straight forward."
datadog,"Tuning
As the saying goes, ‚Äúthe devil is in the details.‚Äù With our centralized logging set up, it was time to dig into those details to fine-tune our pipeline."
datadog,"Our apps emit structured JSON logs, which should be parsed automatically."
datadog,"However, with Lambda, the logging agent re-writes the JSON logs as a string along with other logging metadata such as timestamp and log level."
datadog,"This caused a bit of an issue for me on the DataDog side, as our logs were unable to be properly parsed."
datadog,"To address this, I created a processing pipeline scoped to our project index."
datadog,"From there I added a Grok parsing step to parse and reformat our logs from Lambda sources, ensuring these logs could be parsed as proper JSON."
datadog,It took a bit of trial and error to build the correct parsing rule.
datadog,"We landed on something like this for Lambda logs:
parsing_rule \[%{word:status}\]  %{date(""yyyy-MM-dd'T'HH:mm:ss.SSSZ""):timestamp}    %{uuid:execution_id} %{data::json}
If the spacing on this parsing rule looks weird it‚Äôs because it is."
datadog,"The gaps in the string logged by Lambda are tabs, and thus the Grok parsing rule will need to respect that in order to properly parse the logs to JSON."
datadog,"While DataDog maintains a list of reserved attributes that they use for high-level tags like service or status, individual use cases and logging heuristics will vary across teams and companies."
datadog,"DataDog, therefore, allows users to define remapping steps as part of a processing pipeline."
datadog,For us this meant remapping the reserved service attribute to lambda_name for Lambdas and app for non-Lambda applications.
datadog,"It might seem like a minor thing, but there‚Äôs a lot of power in the remapping processors."
datadog,"Adding this step gave us an easier, more concise way to quickly look at our logs and quickly see which component was responsible for a given logline."
datadog,"Remap service attribute to lambda_name attribute
Finally, with the other processing stages in place and our logs looking clean, it was time to check out exclusion filters."
datadog,"At a basic level, exclusion filters allow you to still send logs to DataDog but filter them out of the index."
datadog,"Exclusion filters are easy to toggle on and off, and this is a great way to think about managing cost."
datadog,Our use case for exclusion filters is highly specific.
datadog,We have one particularly chatty logger packaged within a third-party library we‚Äôre using in one of our applications.
datadog,"Rather than eat up index space (and $$$), we created an exclusion filter for this logger."
datadog,"Should we ever need that data, all we have to do is flip the switch."
datadog,"Otherwise, we can shave some cost and keep our logs clean."
datadog,With the exclusion filter added and our processing stages running our logging pipeline from AWS to DataDog is complete.
datadog,"This new setup is already paying dividends, making it much easier to debug feature work in QA while giving the whole team a more detailed look into our production systems."
datadog,"Wrapping Up
If you‚Äôve been exploring a centralized logging solution to supplement AWS CloudWatch Logs Insights, AWS has a deep network of partners (including DataDog, Logz.io, and Sumo Logic) worth checking out."
datadog,"Our team has found great value in utilizing DataDog for our logging needs, and it might be the droid you‚Äôre looking for as well."
datadog,"The lift of getting from zero to sixty was light, and the amount of flexibility built into the logging platform has been appreciated."
datadog,"There‚Äôs plenty to still explore for next steps, and I hope to revisit our current platform solution on this blog again soon!"
datadog,"Recently, I have set up my micro services application onto datadog APM with tracing and logging."
datadog,"something like,

so that we can follow through, for example, any http request or user_id from HTTP request, controller, service, authentication, database, and etc, with the same tracing ID and logs detailed."
datadog,"Here are the steps I have followed:
Set up datadog account and access, so that we will get the datadog API key, which is to be used to upload the data to datadog server
install the datadog agent onto the server, we are using kubernetes on AWS (EKS) here, and have installed it as a daemonset (so that we have one for each node) with terraform."
datadog,"set up the necessary environment variable in the daemonset

and expose the necessary ports

3. from the python services, leverage on libraries, for example, https://pypi.org/project/JSON-log-formatter/0.1.0/, to log the messages into JSON format
format = ""%(asctime)s %(levelname)s [%(name)s]-- '[dd.trace_id=%(dd.trace_id)s dd.span_id=%(dd.span_id)s] ' -- %(message)s""
json = jsonlogger.JsonFormatter(format)
handler = logging.StreamHandler()
handler.setFormatter(json)
so that these logs would be in JSON format, and datadog would be able to parse the logs into tags & attributes."
datadog,"4. then configure the datadog tracing
from ddtrace import config, patch_all, tracer
def setup_datadog():
    tracer.configure(
        hostname=os.environ[""DD_AGENT_HOST""],#set up in the deployment.yaml, the env attribute
    )
    tracer.set_tags({""env"": ""production""})
    config.flask[""service_name""] = ""checkout-service"" #this could also set up in the deployment.yaml, the env attribute
    config.flask[""analytics_enabled""] = True
    config.flask[""extra_error_codes""] = [401, 403]
    patch_all()
5. finally, then annotate the entry point function, with
@tracer.wrap(service=""checkout-service"")
sample configuration in the deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
...
  annotations:
    ad.datadoghq.com/checkout.logs: '[{""source"":""python"", ""service"": ""checkout-service""}]'
spec:
  replicas: 1
...
  template:
    metadata:
    spec:
      containers:
      -  name: checkout
...
        env:
          - name: DD_AGENT_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: DD_SERVICE
            value: checkout-service
          - name: DD_TRACE_ANALYTICS_ENABLED
            value: ""true""
...
      restartPolicy: Always
status: {}"
datadog,"Partnership brings new value to customers by enabling automation, optimizing resource utilization, and enhancing application performance in Kubernetes and OpenShift clusters

PC:DATADOG
MILPITAS, CA, June 24, 2020 ‚Äî ProphetStor Data Services, Inc. today announced that the company has joined Datadog (NASDAQ: DDOG) Partner Network as a Technology Partner, and the integration of Federator.ai with Datadog‚Äôs monitoring services."
datadog,The Federator.ai and Datadog integration will allow customers to get full observability into their applications‚Äô resource utilization along with Federator.ai AI based recommendations for real time Horizontal Pod Autoscaling (HPAs).
datadog,"ProphetStor‚Äôs Federator.ai leverages multi-layer operational data, including the metrics from applications, Kubernetes, cloud service providers, and underlying infrastructure that Datadog collects."
datadog,"The data is adapted, and then processed by the ProphetStor‚Äôs patented and Deep Learning based Data Correlation and Impact Prediction Engine (DCIE) to create intelligent operation plans."
datadog,"When used for Kubernetes platforms, the Federator.ai creates Application-aware, Just-in-Time, and Fitted resource allocation operational plans for Kubernetes Pod Autoscaling."
datadog,"Additionally, Federator.ai enables workload prediction optimization of application and cloud service usage, making it easier and more efficient to deploy containerized applications."
datadog,"Datadog‚Äôs monitoring and security platform helps users collect and analyze infrastructure metrics, distributed traces, and logs, so teams can scale their environments with confidence."
datadog,"Datadog also makes it easy to monitor applications running on Kubernetes with solutions such as Datadog Agent, and Cluster Agent."
datadog,"Furthermore, Datadog published a free open-source software called Watermark Pod Autoscaler (WPA) to extend the features of the HPA, and give users more control over autoscaling their clusters."
datadog,"With the integration of the Federator.ai and Datadog‚Äôs autoscaling solution, ProphetStor brings proactive resource management to the Kubernetes platforms without changing the application/service/cloud agents of Datadog."
datadog,"The integrated solution combines the advantages offered by both products, enables application-aware acceleration with much-improved utilization and operation automation for the existing users, all without the need to change the code or operation of the application."
datadog,Performance enhancement of up to 90% reduction in latency is achievable in some applications such as Kafka.
datadog,‚ÄúContainers and orchestration are becoming a standard practice for organizations seeking to operate efficiently.
datadog,"However, as workloads become more dynamic and complex, effective resource management can become unwieldy,‚Äù said Ilan Rabinovitch, VP of Product and Community, Datadog."
datadog,"‚ÄúProphetStor has combined Federator.ai‚Äôs machine learning capabilities with Datadog‚Äôs full stack monitoring data to simplify management of Kubernetes at scale.‚Äù
‚ÄúProphetStor is delighted to work together with Datadog for the integration of Federator.ai with Datadog‚Äôs autoscaling solution."
datadog,"Datadog has a monitoring and security platform that covers the full stack, from application to cloud services."
datadog,"Federator.ai offers AI-based application-awareness, multi-layer correlation, and causality analysis that complements the Datadog solution to address the challenges of the scaling and orchestration in container workloads managed by Kubernetes platforms."
datadog,"With additional actionable insights through Federator.ai, our customers can enjoy smoother operation and higher efficiency that are essential in the cloud and 5G services,‚Äù added Eric Chen, CEO of ProphetStor Data Services, Inc.
ProphetStor‚Äôs Federator.ai 4.2 is a generally available product from ProphetStor."
datadog,"For a trial of the integrated ProphetStor-Datadog solution, please visit https://www.prophetstor.com/datadog."
datadog,Every month we share what we‚Äôve learned in our team.
datadog,"In May Micha≈Ç and Grzegorz discovered:
how Confluent plans to remove ZooKeeper from Kafka,
how to interpret the metrics in Kamon Prometheus Reporter."
datadog,"Apache Kafka without ZooKeeper by Micha≈Ç
Last month I‚Äôve learned about Apache Kafka KIP-500."
datadog,Currently every Kafka cluster includes also a ZooKeeper cluster.
datadog,ZooKeeper takes part in Kafka Controller election but also stores Kafka-related metadata.
datadog,"This approach has few drawbacks:
Kafka setup is not easy, since additional ZooKeeper cluster is needed."
datadog,"It is not fully efficient to store metadata in an external system ‚Äî some data needs to be kept both in ZooKeeper and in Kafka Controller memory, plus those are of course additional Java processes."
datadog,ZooKeeper state can diverge from the Kafka Controller state.
datadog,Partition leader changes in ZooKeeper can arrive to Kafka Controller after many seconds.
datadog,"When Kafka Controller fails, a new one needs to load a full cluster state from ZooKeeper, which can take a while."
datadog,KIP-500 describes a concept of a total ZooKeeper removal.
datadog,"As a replacement Kafka would maintain a set of controllers, where one of them is active when the remaining ones are in standby."
datadog,They would leverage Raft quorum for the election process.
datadog,"This way Kafka Controller failures can be handled much faster, cluster complexity is lowered and metadata can be managed better."
datadog,Transition to new architecture won‚Äôt be instantaneous.
datadog,Multiple steps and releases are planned before achieving this goal.
datadog,We‚Äôll need to wait a while for Kafka without the ZooKeeper.
datadog,"If you‚Äôd like to learn more, take a look at KIP-500 and other related KIPs, or at the Confluent blogpost: ‚ÄúApache Kafka Needs No Keeper: Removing the Apache ZooKeeper Dependency‚Äù
Metrics in Kamon Prometheus Reporter by Grzegorz
Observability is one of the most important things in modern applications."
datadog,"It‚Äôs crucial to know how the application is performing, how it utilizes the resources, etc."
datadog,In one of our projects we decided to use Kamon library to expose the metrics.
datadog,"The motivation behind this decision was the ability to switch between reporters, so we can switch for example from Prometheus/Grafana to Datadog, without writing a line of code."
datadog,As a start we enabled Prometheus Reporter.
datadog,The setup is easy and is out of scope of this post.
datadog,As a result we got a list of metrics.
datadog,"But the list was a bit confusing‚Ä¶
Let‚Äôs focus on one metric: open connections in JDBC pool."
datadog,"For each pool we got:
jdbc_pool_connections_open_sum
jdbc_pool_connections_open_count
and several
jdbc_pool_connections_open_bucket with le labels (the histogram)."
datadog,But.. where is the actual number of open connections?
datadog,It turns out... You have to compute it!
datadog,"The Kamon measures the value multiple times each second (15 times), and the value is added to jdbc_pool_connections_open_sum."
datadog,Each time the value is retrieved it also increments the jdbc_pool_connections_open_count.
datadog,So to get the current value you have to divide the sum by the count!
datadog,"After several experiments we got better results after dividing not the metrics themselves, but how the metrics were increased over time."
datadog,"Our final formula looks like:
increase(jdbc_pool_connections_open_sum{env=‚Äùdevelop‚Äù, jdbc_pool_name=‚Äùslick.db‚Äù}[1m]) / increase(jdbc_pool_connections_open_count{env=‚Äùdevelop‚Äù, jdbc_pool_name=‚Äùslick.db‚Äù}[1m])
To be honest the Prometheus Reporter is not very intuitive."
datadog,I‚Äôd rather expect a simple metric with the value.
datadog,Another problem was the lack of documentation on how it actually works.
datadog,"It works much better with DataDog and Kamon APM reportes, which are both paid services though."
datadog,Logs are an essential part of understanding what is occurring in our infrastructure and applications.
datadog,"They provide run-time activity for our applications, which makes it easier for us to diagnose problems in the event of a failure or other performance issues."
datadog,"At Bloom & Wild, we rely on Datadog for our infrastructure monitoring and log collection for our applications."
datadog,"In this blog post, I will give a brief overview of how we can use Datadog to collect logs from Rails applications running inside Docker containers."
datadog,"The Rails Application
The application I will be using is a simple Rails API only application with PostgreSQL both running inside Docker as separate services."
datadog,"Additionally, I will use the Datadog Docker Agent to collect logs."
datadog,"The Rails application has a single resource called Orders, which returns a JSON response about the orders in the database."
datadog,I am using Active Model Serializers to serialise the response.
datadog,"Also, I used the Lograge logger to customise the Rails default log format into a JSON format."
datadog,Now let‚Äôs Dockerize the application.
datadog,"Dockerizing Our Rails Application
In order to Dockerize our application, we will need a Dockerfile."
datadog,A Dockerfile contains all of the commands that you would need to install the programs and libraries.
datadog,You should create a Dockerfile in the root of your project or inside a sub-directory.
datadog,"For this application, I have created a containers/app directory inside the config folder which contains our Dockerfile for the application."
datadog,I will include the GitHub repo link for the application at the end of this post.
datadog,"Dockerfile for the Rails Application
Now we need a docker-compose file to orchestrate our containers."
datadog,"docker-compose.yml file for managing our containers
Configuration options
We are passing a few configuration options as environment variables to our Docker Datadog Agent."
datadog,DD_API_KEY=${DD_API_KEY}.
datadog,This is your Datadog API key (required).
datadog,DD_LOGS_ENABLED=true .
datadog,This enables log collection with the Logs Agent.
datadog,I have removed the option DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL=true which enables log collection for all containers.
datadog,"Instead, we will use the DD_AC_INCLUDE option to select the container we want to use for log collection."
datadog,DD_AC_INCLUDE=‚Äùname:rails_api‚Äù.
datadog,I am passing the name of our Rails application container which I set above in the application services section.
datadog,DD_SITE=datadoghq.eu.
datadog,This is the destination site for our logs.
datadog,My account is in the EU region so I have passed the value ‚Äúdatadoghq.eu‚Äù.
datadog,"You can read more about the Docker Agent and configuration options on Datadog Docker Log Collection
In the docker-compose services application section, we leveraged Autodiscovery to activate log integrations."
datadog,Integration templates can be stored as Docker labels.
datadog,"With Autodiscovery, the Agent detects if it‚Äôs running on Docker and automatically searches labels for integration templates."
datadog,"You can read more about on Docker Integrations Autodiscovery
We provided the value of the source and the service we want to target."
datadog,"labels:
 com.datadoghq.ad.logs: ‚Äò[{‚Äúsource‚Äù: ‚Äúruby‚Äù, ‚Äúservice‚Äù: ‚Äúapp‚Äù}]‚Äô
Running Everything
Now we will put everything together and start-up our stack by running the following command:
docker-compose up --build
Testing the Logs collection
Once everything is running locally, you can open the browser and list some orders."
datadog,"http://localhost:3001/orders
{
    ""data"":[
        {
            ""id"":""1"",
            ""type"":""orders"",
            ""attributes"":{
                ""user-id"":""254"",
                ""shipping-address"":""Suite 211 72358 Treutel Pines, South Ieshashire, CT 35385"",
                ""total-cost"":10,
                ""order-number"":""8b3e2268"",
                ""item"":""Spilt Extract"",
                ""state"":""pending""
            }
        },
        {
            ""id"":""2"",
            ""type"":""orders"",
            ""attributes"":{
                ""user-id"":""640"",
                ""shipping-address"":""90174 Feil Grove, East Tamica, WI 50272"",
                ""total-cost"":10,
                ""order-number"":""19dc3db2"",
                ""item"":""Joe Cake"",
                ""state"":""complete""
            }
        },
        {
            ""id"":""3"",
            ""type"":""orders"",
            ""attributes"":{
                ""user-id"":""140"",
                ""shipping-address"":""Suite 889 96552 Davis Circle, Hellerview, CA 60302"",
                ""total-cost"":10,
                ""order-number"":""5dacb493"",
                ""item"":""Caf√© Forrester"",
                ""state"":""complete""
            }
        }
    ]
}
Logs Collection
Now if you log in to the Datadog dashboard and go to the logs section, you should be able to see some activity from your application."
datadog,We will raise an exception in the controller to see the logs for that.
datadog,"Conclusion
Datadog is a great tool for collecting logs from your applications."
datadog,There are a lot of other features in Datadog which can provide you with better insights into your applications.
datadog,"Datadog is the essential monitoring platform for cloud infrastructure, applications, and logs."
datadog,"They bring together data from servers, containers, databases, and third-party services to make your stack entirely observable."
datadog,"By adding this extension, we‚Äôll be able to utilize any monitors in Datadog to stop problematic deployments in their tracks by adding Datadog Monitors as gates in your Azure Pipelines."
datadog,"https://marketplace.visualstudio.com/items?itemName=Datadog.datadog-monitors
How to install and work on Datadog agent :
We need to first register ourself on the Datadog with the details such as email id and name and other details."
datadog,2.
datadog,Then we need to install the agent on our local machine whether we are using Windows or Mac or Linux .
datadog,3.
datadog,"Download the agent and then run the script given below :


4."
datadog,Then we need to start the Datadog agent by running the command and then we can see the agent is running and then we can start configuring the Integrations.
datadog,5.
datadog,Then login to this site (https://app.datadoghq.com/) with the username and password that we will receive over the email .
datadog,6.
datadog,Click on the Integrations section and choose which one we wanted to get integrated with .
datadog,In my case i have choosen the GITHUB and AZURE DEVOPS.
datadog,"There are more than 100+ options available for Azure , AWS , Docker , Ansible, etc etc ."
datadog,We can choose which one we want and based on that we need to do our configurations .
datadog,7.
datadog,"After choosing the GITHUB , we need to click on the configuration tab and see what is the configuration that we need to do on the GITHUB side ."
datadog,"After copying this Webhook from here , i need to go to Github and go to settings and then paste it there so that i can get all the changes done on the GITHUB to the Datadog and i can monitor it as events across."
datadog,8.
datadog,"Now after the above setup , we need to go to the below events and check the items that we are doing on GITHUB will be reflected here ."
datadog,We can choose the Azure Devops and GitHub events from the above checkbox and then we can start seeing the events on what ever is happening on both the tools.
datadog,Then we need to go to the Menu and Dashboards and then choose the Azure Devops Dashboard accordingly.
datadog,"Create a service hook for Azure DevOps Services and TFS with Datadog :
Before we do the above step and above integration , we need to follow this one like we need to setup the service end point ."
datadog,Create events and metrics in Datadog in response to events from Azure DevOps Services.
datadog,"Use these metrics and events in Datadog to create dashboards, troubleshoot issues, and create monitors to alert you of critical issues."
datadog,Accepts all Azure DevOps event types.
datadog,We need to get the Datadog API key and then put it on the service hook of Azure Devops .
datadog,4.
datadog,Test the service hook subscription and finish the wizard.
datadog,5.
datadog,Repeat steps 2‚Äì5 for each event type you want to send to Datadog.
datadog,Datadog accepts and encourages users to send all event types.
datadog,6.
datadog,"Now that the service hooks are configured, go to Datadog to see events and metrics start to flow into your environment."
datadog,"Datadog Monitors as Deployment Gates:
Consider a canary deployment that updates an e-commerce website in stages across different regions."
datadog,"To ensure the update was successful before rolling it out to the next region, you might want to check the status of various health indicators in the recently updated region, such as:
the memory and CPU utilization of hosts in that region
the number of error logs from your shopping cart application
the results of an automated browser check, which verifies that the website‚Äôs regional endpoint loads quickly and responds correctly to simulated user actions
In Datadog, we can create individual monitors for everything you want to know about, and then combine them using a composite monitor, using simple logic statements to specify a desired combination of monitor conditions."
datadog,"Then, we can set that composite monitor as a gate between the two stages of a pipeline to automatically stop a deployment if an unhealthy state is detected in Datadog."
datadog,"We can define the health of our service, using Datadog monitors as gates in Azure DevOps can help you ensure that your deployments go off without a hitch."
datadog,"Once after all the steps are completed , we will be seeing the below Dashboard which is our real time monitoring ."
datadog,"As a Devops Engineer, one might have to monitor various applications, services and endpoints/API."
datadog,There are a lot of tools and services available which can be used to achieve the goal.
datadog,What if you have to monitor a lot of endpoints/API‚Äôs for a number of applications/projects.
datadog,"Creating those API tests manually is a tedious process, time consuming and error prone."
datadog,"In this article, let‚Äôs go over the automation for monitoring API Endpoints using DataDog API Synthetics and Terraform."
datadog,What is Datadog ?
datadog,"Datadog is a monitoring service which can be used to monitor servers, databases, tools, and services, through a SaaS-based data analytics platform."
datadog,What are Synthetics?
datadog,"A service, which can be used to monitor your applications and API endpoints via simulated user requests and browser rendering, Synthetics helps you ensure uptime, identify regional issues, and track application performance."
datadog,How does API Synthetics work?
datadog,Monitoring using Synthetics is based on an API request & response.
datadog,"For example, you have a text parser service, which has an API endpoint."
datadog,And you want to the test whether parser service API is up and running or not.
datadog,"So, at the time of configuring API Synthetics in Datadog, you need to provide an API endpoint, type of request (GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS) and a set of assertions to validate if the response is valid or not."
datadog,"If the assertions defined fail during the API test, that indicates there may be some issue with the API service and the DataDog can notify a person or team or other a third party services like Pager Duty."
datadog,Below is the sample API Synthetic Test.
datadog,"Note- In order for the below test to work, you might have to whitelist the DataDog IP‚Äôs, here is the link (https://ip-ranges.datadoghq.com/synthetics.json) to get the latest list of DatagDog IP‚Äôs."
datadog,"Create DataDog API Synthetics withTerraform
In this section, Lets go through the requirement, configuration which are required to create the DataDog API Synthetics through terraform."
datadog,"Requirements
Configuration
Terraform Script
Requirements
Once the access to DataDog is setup, API and APP Keys need to be generated."
datadog,Which will be used in Terraform to create the API Synthetics.
datadog,"Create API and APP keys :
After login to DataDog, navigate to Integrations ‚Üí API."
datadog,"Under API Keys Section, provide the API Key Name and click Create API Key to generate API Key
Under Application Keys Section, provide Application Key Name and click Create Application Key to generate the Application Key."
datadog,Please find below screenshot for reference.
datadog,"Terraform Configuration
Use Terraform DataDog Provider and configure it to use the API and APP Keys which we have generated in the above section."
datadog,"Below is the code snippet to configure DataDog Provider :
# Configure the Datadog provider
provider ""datadog"" {
  api_key = ""93bc63e0b4f48fbbff568d9fc0dc3def""
  app_key = ""a8be41babf076626874c3ec618e62a84e218f6de""
  api_url = ""<https://api.datadoghq.com/>""
}
Define you monitoring Endpoints
As we are automating the DataDog API Synthetics tests creation, we have to generate a map/dictionary with the services and their endpoints, success messages which define the API is healthy."
datadog,Below is the sample dictionary map.
datadog,"In the below tfvars file, we have defined notify & dd_synthetics (a dictionary)."
datadog,"notify is the notification email address, i.e who should be receive the alert in case the API endpoint isn‚Äôt working."
datadog,"In dd_synthetics dictionary, I‚Äôm monitoring two services api and parser using the endpoints and message (success message)."
datadog,"notify = ""bhasvanth@sandbox.com""
dd_synthetics  = {
    ""api"" = {
        ""message"" = ""API service is working Fine."
datadog,""", 
        ""endpoint"" = ""<http://dev.sandbox.com/api/admin/health>""
    }, 
    ""parser""= {
        ""message"" = ""Parser service is working Fine"", 
        ""endpoint"" = ""<https://dev.sandbox.com/parser/health>""
    }
}
Define terraform variables
variable ""dd_synthetics"" { }
variable ""notify"" { }
variable ""region"" {
    default = ""us-west-2""
}
Create DataDog API Synthetics Resources
Now, in the terraform resource block ‚Äúdatadog_synthetics_test‚Äù, we have to iterate the dd_synthetics dictionary using for_each and generate the datadog_synthetics_test resources for each and every service defined in the dictionary."
datadog,Below is the Terraform resource block.
datadog,"resource ""datadog_synthetics_test"" ""api_synthetics"" {
  for_each = var.dd_synthetics_map
  type = ""api""
  subtype = ""http""
  request = {
    method = ""GET""
    url = ""${each.value.endpoint}""
  }
  assertions = [
    {
      type = ""statusCode""
      operator = ""is""
      target = ""200""
    },
    {
      type = ""body""
      operator = ""contains""
      target = ""${each.value.message}""
    }
  ]
  locations = [ ""aws:${var.region}"" ]
  options = {
    tick_every = 900
  }
  name = ""${each.key}-${var.env_name}""
  message = ""Notify ${var.notify}""
  tags = [""app_name:${each.key}""]
  status = ""live""
}"
datadog,"A black-and-white photograph of a labrador shaking hands with a boy wearing a striped shirt
Photo by Fabian Gieske on Unsplash
Recently, I was tasked with integrating a new project into our infrastructure that was completely different from our usual platform integrations."
datadog,"I found it sufficiently difficult to implement ‚Äúout of the box,‚Äù and I couldn‚Äôt find applicable examples on the Internet."
datadog,I even needed to reach out to Datadog support to figure it out over several days.
datadog,"When I was finished, I decided to write this blog post to describe how to collect server application metrics for an Apache and PHP-FPM project running on an ECS cluster with the Datadog host agent."
datadog,My hope is that it will help anyone else who is struggling with similar projects to complete them more quickly.
datadog,"Introduction to Datadog Autoconfiguration
This journey begins in a promising way."
datadog,Datadog has an autoconfiguration feature that I have been interested in for a long time.
datadog,"Inside of an ECS cluster, there could be dozens of applications running, and I love the concept of saying, ‚ÄúMonitor everything with the ‚ÄòApplication Foo‚Äô tag with the following (possibly custom) checks.‚Äù Typically, Application Foo tags are already present on the ECS services or in their names, and we have already spotted their AWS metrics, logs, and even AWS costs by the existing tags."
datadog,"When presented with this new project, I initially thought, ‚ÄúHow hard can it be?"
datadog,"Take one (or many) docker container task definition(s), deploy a new service in ECS, tag it with some information, and we‚Äôre live and monitoring a production-level application!‚Äù Little did I know the harrowing trek I was about to embark on."
datadog,The link below will help get you started on the autodiscover journey and requires some familiarity with the Datadog Agent and configuration.
datadog,The changes are not very difficult to get ready.
datadog,Take some time to read the documentation and come back when you‚Äôre done.
datadog,"Autoconfiguration Datadog agent preparation and getting started documentation: https://docs.datadoghq.com/getting_started/agent/autodiscovery/?tab=docker
Collecting Metrics with Datadog Autoconfiguration
By now, I had read up on autoconfiguration details on starting the Datadog agent in our ECS clusters and had a pretty solid grasp of how to monitor our docker containers that would be running Apache and PHP-FPM."
datadog,The examples and research seemed to indicate that autoconfiguration for Apache (at least) would be extremely simple and easy.
datadog,"For example, Apache is listed in the supported autoconfiguration checks out of the box."
datadog,There is even a working version of the Apache-specific auto_conf.yaml file already deployed and active with our Datadog agent (v6.19.0 at the time of this writing).
datadog,There is also an extremely useful blog post on how to configure Apache itself to collect metrics and logs.
datadog,"Of course, nothing is ever that easy, and no matter how I tried to restart the agent and look for the metrics, I couldn‚Äôt get anything to show up in Datadog‚Äôs dashboard or metrics explorer."
datadog,"Just for the sake of discussion, I could have enabled a configuration check on a static configuration that said, ‚ÄúMonitor these ECS tasks with this check,‚Äù but we know that isn‚Äôt scalable and would require future work to adapt to new applications or iterations for features I hadn‚Äôt considered yet."
datadog,"If we ever renamed the project or forked the project to adapt it to something else, I wanted the metrics and logs to magically appear."
datadog,"For the purposes of this blog post, I wanted to wade ahead a little bit so that the example is easier to follow and gives a more holistic view of the effort."
datadog,"In this project, Apache by itself is doing very little; the major purpose of Apache is to provide HTTP requests to the application, which is written in PHP."
datadog,"There are several ways to implement PHP applications using Apache (or Nginx), and the most portable way to do so is with the FastCGI Process Manager (or FPM)."
datadog,The main benefit of using FPM for our application is that the PHP interpreter runs in a separate set of processes running in a different container that can allow scaling horizontally (across instances) and manage scaling vertically (with multiple processes running in each instance).
datadog,You can find many examples of this online.
datadog,"If you need time to go read up on that to configure your application, go ahead; I‚Äôll wait here for you to get back."
datadog,"Configuring PHP-FPM for Datadog Autoconfiguration
The first clue to my Apache configuration problems became a lot clearer as I moved onto monitoring the PHP-FPM container with autoconfiguration."
datadog,"Although PHP-FPM is a supported metric integration in Datadog, it does not have autoconfiguration enabled by default as Apache does."
datadog,"In order to apply autoconfiguration settings and templates to PHP-FPM, you must configure your own auto_conf.yaml file and place it in the php_fpm directory to be interpreted by the Datadog agent."
datadog,Here is a good generic guide to creating an autoconfiguration file for an application check.
datadog,"The benefit of configuring a template in this way is the exact thing I‚Äôve been discussing in this post: instead of configuring this application to run these checks, I want to configure an automatic method to monitor any application with these tags to run appropriate checks."
datadog,"For example, if application ‚ÄúA‚Äù is running on host ‚ÄúH1‚Äù with port ‚ÄúP1‚Äù, and another application ‚ÄúB‚Äù is running on host ‚ÄúH2‚Äù with port ‚ÄúP2‚Äù, then I do not want to configure something like:
https://hostH1:portP1/ApplicationA
https://hostH2:portP2/ApplicationB
Instead, I want to configure a generic check that fills in details from a template that is generated every time an application is deployed with the correct tags, like the following example:
https://%%host%%:%%port%%/%%env_APPLICATION%%
What Not to Do with Autoconfiguration
The first mistake I made with the docker LABELs was a simple self‚Äìfoot shooting."
datadog,Notice that all the keys I listed above are plural.
datadog,It‚Äôs easy to type in a singular key like ‚Äúcheck_name‚Äù rather than ‚Äúcheck_names‚Äù or to mistype ‚Äúconfiguration‚Äù instead of ‚Äúconfig‚Äù.
datadog,"I suggest you copy-paste the keys to avoid making mistakes like these, which, if not caught early, can lurk silently for a long time and might be hard to spot without additional review from a colleague or a support person."
datadog,The second mistake I made with the docker LABELs is much easier to make and is due to the typography used all over the documentation.
datadog,"For example, it‚Äôs not clear which parts of the following string are optional, which are meant to be replaced by a string or name, and which are literal parts of the configuration."
datadog,"I‚Äôll quote a line from the official documentation linked above to illustrate this:
LABEL ""com.datadoghq.ad.check_names""='[<INTEGRATION_NAME>]'
Should be filled out as follows:
LABEL ""com.datadoghq.ad.check_names""='[""php-fpm""]'
You can see how it is supposed to look in the documentation for the Redis example (which shows how it works but is very confusing because of the typography of the generic template)."
datadog,"There are several important pieces that are very hard to figure out and will result in silent failure if you are not explicit about each one:
The sections marked with angle brackets ‚Äú<NAME>‚Äù need to be filled in with a string or NAME, and the NAME has to match the check name(s) in the autoconfiguration files."
datadog,There must not be any spaces or tabs in the label except for exactly one space between LABEL and the following double quotation mark.
datadog,"In particular, you cannot put spaces around the equal sign in the LABEL."
datadog,This is probably a limitation of or caused by the syntax of the Dockerfile.
datadog,"The use of double and single quotation marks is inconsistent and generally doesn‚Äôt matter, but you are probably going to use quotation marks inside the key or value because the values expect valid JSON."
datadog,"And if you are forced to use quotation marks of the same type as the outer closing quotation marks, you must escape those with a backslash."
datadog,"Notice the use of square brackets ‚Äò[‚Äúname‚Äù]‚Äô which indicates the JSON syntax for a list, rather than indicating that the parameter is optional."
datadog,"In particular the documentation specifying ‚Äò[<INTEGRATION_NAME>]‚Äô is misleading, because one doesn‚Äôt know if the quotation marks are literal, whether the square brackets indicate a literal or optional parameter, or if the angle brackets indicate a literal bracket or substituted variable name, and the surrounding quotes to generate valid JSON inside the list are missing completely."
datadog,This is an example taken directly from the Datadog documentation.
datadog,"I do not want you to copy this configuration and I have not provided my attempts, for reasons you will see later."
datadog,"Screenshot from Datadog documentation
Figure 1: A copy of documentation from Datadog for configuring Docker LABELs
If you are ultimately successful in applying the LABELs to your docker image, you should go ahead and verify that everything looks correct as follows."
datadog,"This picture only shows the one LABEL that I needed for correctly matching templates from the agent files to the docker containers holding the application:
# docker image inspect abcde
‚Ä¶
""Labels"": {
  ""com.datadoghq.ad.check.check_names"": ""[\""php-fpm\""]""
}
‚Ä¶
After all this detailed instruction, you must now take a deep breath, back up, and STOP."
datadog,"This section is entitled ‚ÄúWhat Not to Do,‚Äù and you should literally not do anything that I have just described, because it‚Äôs a dead end and will result in wailing and suffering and misery for many days."
datadog,"If you would like to troubleshoot this configuration, be my guest."
datadog,There are some hints on the Internet and an official troubleshooting guide in the Datadog docs.
datadog,"I did find this document by seeing the errors presented there, but I could find precious little information on how to fix it."
datadog,The support team at Datadog was eventually able to help me figure things out.
datadog,"I am documenting the results in this post so that you, dear reader, need not follow my painful footsteps."
datadog,"The problem is that although these docker labels seem to indicate that you can tag your docker images with configuration sections that appear to duplicate (or possibly override) the values specified in the configuration files for the agent, you will eventually discover that they actually do not do anything at all."
datadog,"What to Do to Enable Autoconfiguration for ECS Containers
Now that you have enough information and context, I can rewind the tape to avoid all of the false starts and dead ends of a bad configuration."
datadog,The first thing to note is that the automatic configuration files that the Datadog agent requires need several pieces of information to work properly.
datadog,Here is an example of our PHP FPM auto_conf.yaml file that shows what is required.
datadog,"Code Sample 1: Configuring the PHP_FPM auto_conf.yaml file
Notice the parameter for ‚Äúad_identifiers‚Äù."
datadog,This allows the Datadog agent to match up this particular ‚Äúinstances‚Äù configuration with the docker label on your ECS tasks that run with those images.
datadog,"In particular, you only need to add a single LABEL to your docker build file(s):
LABEL ""com.datadoghq.ad.check.id""='php_fpm'
Now the Datadog agent can read the autoconfig file and apply the templates to any docker images containing the label above, and everything should work smoothly."
datadog,"Indeed, by adding the ‚Äòhttpd‚Äô label to the Apache Dockerfile configuration, we can also make the auto_config.yaml file shipped with the Datadog agent start to work seamlessly (or, we could alter the ‚Äúad identifiers‚Äù (note the plural) parameter appropriately and then restart the Datadog agent[s])."
datadog,"For verification, we can see that the configuration is applied and detected by the datadog agent:
# sudo datadog-agent configcheck
~
Auto-discovery IDs:
* httpd
===
=== apache check ===
Configuration provider: file
Configuration source: file:/etc/datadog-agent/conf.d/apache.d/auto_conf.yaml
Instance ID: apache:abcde1234
apache_status_url: http://xxx:yyy/apache-status?auto
tags:
- cluster_name:mycluster
- docker_image:xxx.dkr.ecr.us-west-2.amazonaws.com/application:tag
- task_version:xx
- task_name:application
- task_family:applicationgroup
‚Ä¶
~Auto-discovery IDs:
*php-fpm
===
=== php_fpm check ===
Configuration provider: file
Configuration source: file:/etc/datadog-agent/conf.d/php_fpm.d/auto_conf.yaml
Instance ID: php_fpm:abcdef1234
ping_reply: pong
ping_url: http://xxx:yyy/ping
status_url: http://xxx:yyy/status
tags:
- cluster_name:mycluster
- task_name:application
- task_family:applicationgroup
- docker_image:xxx.dkr.ecr.us-west-2.amazonaws.com/application:tag
- task version:xx
use_fastcgi: false
And even better, we can now view metrics in the standard dashboards provided by the Datadog PHP integration, as you can see in the next screenshot (truncated for clarity):

Figure 2: Part of the Datadog built-in PHP-FPM dashboard
And you can also view the Apache dashboard metrics that come with the Datadog Apache integration:

Figure 3: The Datadog built-in Apache dashboard
A Brief Overview for Apache/PHP-FPM Logging Configuration
Metrics are great, but let me very briefly go over the logging configuration as well."
datadog,"There are some good examples on the Internet for logging configuration, but I ended up having to piece various parts together before I had something I was happy with."
datadog,"Here is how I configured the metrics and logging for Apache and PHP FPM for ingestion into the Datadog logging agent:

Code Sample 2: JSON logging configuration for Apache running in docker/ECS

Code Sample 3: JSON logging configuration for PHP-FPM running in docker/ECS
For completeness, this is what the logs look like in the Datadog Log Explorer:
A screenshot of the Datadog Log Explorer with sample entries
Figure 11: Sample JSON logs from the Datadog Log Explorer
Conclusion
Autoconfiguration is a powerful way to automatically collect metrics and logs for application containers running in ECS."
datadog,"By specifying a template for the Datadog agent and then configuring the correct tag on the docker image, we are able to move quickly in deploying applications with the correct monitoring metrics and log events at scale."
datadog,"With the constant evolution of technology, there are always questions about how to build your application‚Äôs infrastructure."
datadog,Where should the infrastructure live?
datadog,What technologies should we use?
datadog,Should we modernize it?
datadog,"In this post, we‚Äôll be giving an overview of where we were in our earlier days compared to where we are now in the hope that you‚Äôll learn a thing or two."
datadog,"Before
In the world of startups, you never know whether you‚Äôre going to be successful or not."
datadog,A wise decision is to build your initial product fast and deliver value to your client as soon as possible to increase these odds.
datadog,"During the early days of Yaguara, the initial engineers opted to go with Kubernetes hosted on dedicated EC2 machines using AWS."
datadog,"Unfortunately, after the initial deployment, knowledge of how these clusters were managed was forgotten as it was not version controlled."
datadog,"Additionally, many resources on AWS created manually, and only a handful of them was monitored."
datadog,"For our Continuous Integration and Continuous Delivery (CI/CD), it made sense to use the built-in pipeline solution provided by GitLab as it is the version control provider that we used."
datadog,"Unfortunately, even though we‚Äôre using a micro-service architecture design pattern, every service had to be built at once due to inadequate packaging practices."
datadog,The services weren‚Äôt dockerized either.
datadog,"In other words, we couldn‚Äôt just deploy our API service or just front-end assets without building every package, which would be time-consuming."
datadog,"A consequence of the above is that it became tough to see the impact of some infrastructure changes, and often problems arose long after changes were deployed."
datadog,"Going forward, we wanted to be notified when something was behaving abnormally so as to be proactive with our fixes."
datadog,"After we received our initial seed round, we sat down to prioritize solutions that would allow us to improve these pain points."
datadog,"Core Infrastructure
After evaluating other solutions, we opted to stay with AWS as it was the provider that was most widespread within our organization."
datadog,"They‚Äôre also offering a product called ECS that allows you to spin up docker images and scale horizontally and vertically reasonably quickly, which is why we‚Äôve selected it to build the new generation of services offered by Yaguara."
datadog,"If you wish to dive into the subject of ECS, I would recommend this article: A beginner‚Äôs guide to Amazon‚Äôs Elastic Container Service."
datadog,"For instance, our production ECS cluster that hosts our application contains five different services (e.g."
datadog,"our API, WebSockets, Cron Jobs, ‚Ä¶)."
datadog,ECS trivializes the process to have these services live on their own set of EC2 instances in different availability zones.
datadog,Application Load Balancers then enable load balancing across multiple containers within those EC2 machines.
datadog,"Additionally, security and data privacy is something that we hold dear to our hearts at Yaguara."
datadog,It was the number one priority when designing that new infrastructure.
datadog,"For example, each environment is separated into individual VPCs."
datadog,Each resource lives in a private subnet and is only accessible via a load balancer on restricted ports.
datadog,"Also, non-sensitive information is logged for possible consumption to ease debugging processes."
datadog,"Infrastructure as Code
To build said infrastructure, we‚Äôve opted to go with Terraform."
datadog,Terraform allows us to deploy infrastructure by writing code that we version control.
datadog,"Since we‚Äôre using a micro-service architecture for our different services, we‚Äôve created ECS Services modules for each one."
datadog,Spinning up a specific set of resources (i.e.
datadog,"an RDS instance, a Redis Cluster, Networking, ‚Ä¶) then becomes increasingly easy to deploy."
datadog,"Here is an example of how it would look like to build up the required infrastructure that hosts our Staging API
Another strong contestant was AWS CDK, but we‚Äôve opted against it because we wanted to use Terraform also to manage our GitLab, Datadog and DigitalOcean pieces of the infrastructure and CDK only allows managements of AWS resources
Another benefit of going with Terraform is that resources living in their respective domains are deployed by terraform apply."
datadog,They can also very easily be destroyed by terraform destroy.
datadog,That feature allowed us to use multiple test environments and delete them without being afraid of leaving them running and incurring additional fees.
datadog,"While we‚Äôre using a Monorepo for our main application, we‚Äôve opted to go with a brand new repository that would hold all relevant infrastructure code."
datadog,This allows us to encapsulate better infrastructure code of all our different pieces of software that might or might not live in our main application Monorepo.
datadog,"CI/CD
We‚Äôve opted to keep the GitLab pipeline."
datadog,"While there is definite room for improvements, it is still pretty solid and works for most of our use-cases."
datadog,"We‚Äôve redesigned the dependencies between packages, which allows us to now build and deploy them as standalone services."
datadog,"In summary, for every deployment, we create the relevant images using Dockerfiles, we push them onto GitLab container registries, and deploy that image onto ECS using the infrastructure‚Äôs built image of its pipeline."
datadog,"Here is an example of a task to deploy our API infrastructure to staging
GitLab Environments is also a killer feature."
datadog,It allows the user to access the different deployed environments in one place and see their status.
datadog,This significantly helps when you have dozens of environments as we do.
datadog,"Since we‚Äôve decided to go with Terraform, we‚Äôve been able to leverage an existing module that allows us to self-host the job runners for these pipelines and to configure them to our specific needs."
datadog,"Interesting tweaks are:
the instance size of the runners
the number of runners that are always left available
the ‚Äúoutside working hours‚Äù period to reduce the amount of EC2 instances, which significantly reduces our incurred fees when jobs are unlikely to be run."
datadog,"Monitoring
Like we‚Äôve hinted a bit earlier, we‚Äôve opted to go with Datadog for our monitoring platform."
datadog,"Datadog offers a lot of different services, but the main ones that we were interested in were the display of each machine and containers that were spun up, the ability to quickly access and put logs in context and the ability to create easily accessible visualizations."
datadog,It also has a friendly UI.
datadog,"While you can integrate Datadog with CloudWatch and have metrics from your infrastructure instantly accessible, we also have a Datadog container living on every single EC2 instance of our ECS Cluster."
datadog,"This gives us additional metrics coming from our infrastructure, such as Docker Container CPU usage."
datadog,This DataDog Infrastructure view allows us to visualize the different hosts for each service within a specific environment.
datadog,"The hexagon would change colour from green to red the more CPU it uses
That was trivially done by setting our Datadog ECS service scheduling strategy to DAEMON."
datadog,"Conclusion
Ultimately, there are no ‚Äúperfect‚Äù solutions that work for every single use case."
datadog,You have to evaluate what are the things that you want to optimize and what resources are available to find out what‚Äôs best for your organization.
datadog,"In the following post, we‚Äôll be discussing the concept of review apps that were made possible with that new infrastructure."
datadog,It allows engineers to create a dedicated and sharable environment with a click of a button.
datadog,"Additionally, the same concept applies to demo apps, which creates a dedicated environment for every member of our sales team that resets at the end of every day."
datadog,"We‚Äôve love to have a conversation about your experiences with these technologies, don‚Äôt be afraid to comment!"
datadog,"The Problem
We found discrepancies between two datasets and go on a journey to fix those discrepancies."
datadog,"Also, we would like visualize our progress and alert us when production data is bad again."
datadog,"Since we already have custom SQL to BigQuery, and we are already using Datadog, the idea is run the query every once a while and send the query results as custom metrics to Datadog."
datadog,"I was looking for out of box solution, but it turns out there isn‚Äôt any."
datadog,Current BigQuery + Datadog integration documentation is all about collecting system metrics.
datadog,"Datadog has the support to run custom queries against MySQL, but there isn‚Äôt anything like that for BigQuery."
datadog,"Temporary Solution
We ended up using Google Data Studio."
datadog,"Their documentation is a bit concise, and it took me a little time to configure the a simple report to pull data from BigQuery."
datadog,"Manage data source:

Enter custom query (Note the CUSTOM QUERY tab on the left):

It took a little time to adjust to their UI, but essentially it is like building SQL queries:

Closing Thoughts
With Google Data Studio, we can at least visualize the count of records that we are interested in."
datadog,"Also, it allows us to set the refreshness for the data source, or manually refresh it."
datadog,So it satisfies our need in the short term.
datadog,"However, we can‚Äôt set up any alert from there like we do in Datadog."
datadog,It would be nice to see more integration support from Datadog.
datadog,Original post: http://blog.junjizhi.com/all/2020/05/11/bigquery-datadog.html
datadog,We announced our integration with Datadog back in November.
datadog,"With this integration, you can observe all your GraphQL queries and mutations made against your Hasura Cloud project‚Äôs API, and well as query success, failure, errors, and any exceptions that may occur."
datadog,"ICYMI, we also recently announced our integration with New Relic."
datadog,"In this post, we have a quick video guide on adding Datadog to your Hasura Cloud project in a few simple steps."
datadog,"Why add Datadog to Hasura
Monitoring and tracking is a critical component to building robust tech-stacks, and having a native integration for Datadog that can consume your logs and metrics simplifies your APM infrastructure and logging infrastructure in general."
datadog,"What data gets sent to Datadog
At the time of writing, we send logging events across http and ws with the following 5 metrics:
Average number of requests
Average request execution time
Success rate of requests
Active subscriptions
Number of websockets open."
datadog,You can read more in our docs page.
datadog,We will be adding additional metrics in the future.
datadog,"If you have a specific measurement need, let us know!"
datadog,"How to get Started
You can reference the documentation above, or view the following guide that shows how to quickly add Datadog to your Hasura projects and view the exported logs."
datadog,"Saving Dog Owner Money
What is EDC DogData ?"
datadog,DogData is a team of industry experts with over 100 years‚Äô experience.
datadog,"Every week we are producing, working at, supervising or managing parts and aspects of CACIB, CAC, AKC, Kennel Club or FCI dog shows."
datadog,Many of us have more than 20 years in the industry on the ground experience.
datadog,The core team has been explanded with proven functional area experts with experience in building and operating customer focused technology driven businesses in complex market environments.
datadog,What Solution Is Given By DogData?
datadog,"Here DogData provides a very good solution especially for dog owners
there are 9 solutions provided by DogData."
datadog,"International Dog Registration Blockchain
In this solution where Dogdata uses the Blockchain system to record all dogs in the world, this is a good solution where we can know if the dogs we have disappeared or have been stolen by people with this system can be anticipated."
datadog,because if people buy stolen dogs can be caught because it has been in the data by the blockchain.
datadog,"Secure Dog‚Äôs Life Data on Private Blockchain
Almost the same as solution ‚Ññ1 but here is more focused on the dog‚Äôs personal data."
datadog,"Dog Sales & Care Provisions Contract
Dog Sale Smart Contract is a very good solution where when you want to sell your dog you can use SmartContrack where both parties use a written contract or rather we have no doubt whether this buyer likes dogs or not."
datadog,"Dog Mating & Breeding Prediction
Now this is a very good solution because it uses the most experts in analyzing data, machine learning and AI to make better predictions and help eliminate genetic health defects."
datadog,yes all here will be collected data by data and assisted by good machine technology and AI to minimize a genetic defect.
datadog,"Knowledge Exchange
In this solution the owners share knowledge with incentives and create the best exchange of information for the care, health and well-being of the Dog that benefits the entire Canine community."
datadog,"Mobile App
Show more for sharing Where the mobile app works for any dog-related event."
datadog,"Dog Specific Suggestive Marketplace
The market is more focused on the specific types of specialty dogs with a large selection of products and services at low prices with good products, services."
datadog,"Reward & Discount Token
in this solution we will also get prizes for financial activities and dog care which will later be used to purchase discounts at the 4Dogs Marketplace."
datadog,"Funding Mechanism
This solution uses cryptocurrency to raise funds."
datadog,"and Etherbone Coins are bought back from the crypto market, every time the Dog owner doubles the Etherbone Token."
datadog,"‚Äúif you are still curious about the complete solution, please download the Lite White Paper‚Äù https://mydogdata.com/pdf/DogdataLitewhitepaper.pdf
What‚Äôs so special about DogData?"
datadog,"Here, what makes DogData unique is technology
PedigreeChain."
datadog,What is PedigreeChain?
datadog,PedigreeChain is a public reference of Dog‚Äôs ancestors and Dog‚Äôs blockchain international database .uses unchangeable time blockchain technology.
datadog,"This allows easy international registration of Dogs for all Dogs, genealogies, and Dogs that are not pedigree."
datadog,"Dog data also uses the concept of ERC 721 Asset Tokens
Which is where all Dog life data will refer to this registration token in a systematic manner and stored in a secure, timeless and encrypted data record."
datadog,Some key features and data are stored in an enhanced and centralized International Dog registration database.
datadog,DogData Launch ICO?
datadog,"well Dogdata also launched IEO on BitForex

Round 1 starts Round 1 Starts: $0.008 5/18
and round 2 starts Round 2 Starts: $0.010 5/25
You can see it directly on the Dogdata website https://dogdata.io/
How about the team?"
datadog,"The DogData Team is professional and quite expert in their respective fields
DogData is a team of industry experts with over 100 years‚Äô experience."
datadog,"Every week we are producing, working at, supervising or managing parts and aspects of CACIB, CAC, AKC, Kennel Club or FCI dog shows."
datadog,Many of us have more than 20 years in the industry on the ground experience.
datadog,The core team has been explanded with proven functional area experts with experience in building and operating customer focused technology driven businesses in complex market environments.
datadog,What is the allocation of DogData tokens?
datadog,"we can see in the picture below what the allocation is and how much the division is
2.5% Seed Funding
5.0% Marketing
4.7% Round 1
10.0% Team
3.8% Round 2
72.1% Reserve
2.0% Bounty 2020 1% unlocked August 1% unlocked November

What MPVs do DogData already have?"
datadog,"You can see in the picture below what are the existing MVPs

How are you already interested in the DogData project from the conclusions I made above?"
datadog,"if yes please visit the website https://dogdata.io/ and https://mydogdata.com/
And for more info, please visit the website and social media
DogData
Website : https://dogdata.io/
Website : https://mydogdata.com/
Litr Whitepaper : https://mydogdata.com/pdf/DogdataLitewhitepaper.pdf
Facebook :https://www.facebook.com/DogsData
Twitter : https://twitter.com/FaceBook4Dog
Telegram : https://t.me/Dogdata
Medium : https://medium.com/@dogsdata
LinkedIn: https://www.linkedin.com/company/dogdata/
Reddit : https://www.reddit.com/r/MyDogData/
Blockchain : https://mydogdata.com/pdf/Blockchain.pdf
Token Economic : https://mydogdata.com/pdf/TokenEconomics.pdf
PickDeck : https://mydogdata.com/pdf/PitchDeck.pdf
writer by Muhammad Randy Chaniago (copoyes)
Username Bitcointalk : copoyes
Bitcointalk profile link : https://bitcointalk.org/index.php?action=profile;u=1120540
eth addres : 0xcC4b22fFbE19a627505CC1f167258254bB4CCfd3"
datadog,"A variety of tools in play @HMH
A medley of tools and services in a micro-service deployment."
datadog,"As software developers, we are constantly challenged and are expected to stay on top of the performance and monitoring of our applications and infrastructure."
datadog,"With microservice-based architectures, it becomes even more important to track metrics, identify bottlenecks, configure SLA‚Äôs and thresholds consistently across the stack and alerting."
datadog,Based on research data available over public resources we know that a large percentage of developers running microservices at scale or planning to are running into similar challenges.
datadog,There are a number of enterprise and open-source tools available that do a great job for application and infrastructure monitoring.
datadog,"Also, it is quite common for teams to use a number of these tools and technologies across the technology stack."
datadog,Guess what?
datadog,"This mostly results in metrics, event logs, and traces across distributed systems where correlation becomes a manual and therefore time-consuming exercise."
datadog,"Additionally, the process is often error-prone due to differences in the frequency of data collection, units, etc."
datadog,Overall this may neither be effective nor optimized to pinpoint critical issues in the cloud-native and microservices ecosystem.
datadog,"Three Pillars of Observability
Observability is key, with metrics, tracing, and logs being the three main areas of focus."
datadog,At Houghton Mifflin Harcourt we love Spring Boot and Node.JS and develop a lot of microservices that power the K-12 education technology (edTech) services!
datadog,"Starting Spring Boot 2, a big area of focus was production-ready features such as the Actuator."
datadog,"For Metrics, Micrometer is now the default Metrics Collector that does a great job at gathering dimensional metrics with counters, gauges, histograms, etc."
datadog,"and provides a set of management configuration driven attributes to export to a variety of integrations such as Datadog, Prometheus and a dozen others."
datadog,"If you were looking to get started on this you could find a quick-start published here spring-boot-micrometer-datadog-quickstart
Opensource frameworks such as Prometheus, TICK stack and visualization on Grafana are often used together for unifying metrics across microservices."
datadog,They only really solve one of the 3 pillars of observability ‚Äî metrics.
datadog,"A datadog dashboard illustrating the three pillars
source: https://www.datadoghq.com/monitor-openstack/
Traces and logs still have to be correlated/scraped from other tools."
datadog,"As far as Spring Framework goes, you have Spring cloud Sleuth and integration with Zipkin (openTracing) and Brave for a tracing solution."
datadog,"While this works like a charm with spring boot and the java stack, the larger question remains about metrics and tracing on services built on other languages such as Node.js/Go/Ruby/Python/.NET or even Serverless deployments?"
datadog,AWS X-Ray based distributed tracing could provide traces and service maps for Serverless deployments for your microservices or even your Lambda functions.
datadog,Thinking of AWS Appsync as a use-case here where a graph query may result in a bunch of Lambda based resolvers and it becomes critical for a developer to get traces to measure and improve!
datadog,AWS Cloudwatch combines metrics from AWS Services and log groups.
datadog,This is a great combination with API‚Äôs exposed for tools to extract metrics from.
datadog,"In addition, one may write Lambda Functions to forward cloudwatch logs for correlations."
datadog,"A microservices developer's dream would be to inspect slow query logs from your relational databases such as AWS RDS, alongside metrics for troubleshooting why an API may be slow?"
datadog,Good news!
datadog,AWS RDS enabled log shipping to cloudwatch which could then be forwarded along to a centralized tool for correlation alongside metrics.
datadog,We could use a Lambda based Datadog forwarder for cloudwatch log groups.
datadog,"Another project that could help consolidate metrics is Telegraf from the TICK stack which uses a plugin architecture with rich support for a number of integrations such as Cloudwatch, InfluxDB, Datadog, Prometheus, etc."
datadog,"At Houghton Mifflin Harcourt the magic mantra has been to evolve into a single solution (Datadog) that can provide insights into the entire software ecosystem, regardless of where the telemetry data originated from."
datadog,"Rich set of features such as APM, Synthetics, Logs/Metrics/Event Aggregations, Tracing, Real User-Monitoring, Alerting, Cloud Integrations, and more made Datadog an obvious choice for us!"
datadog,"Datadog at HMH
A unified service for application and infrastructure monitoring."
datadog,"Enter OpenTelemetry
Something very exciting coming up is OpenTelemetry, from the Cloud Native Computing Foundation (CNCF), which is the result of a merger between the OpenTracing and OpenCensus projects to standardize how the industry uses metrics, traces, and logs."
datadog,"An excerpt from Wikipedia reads ‚ÄúA complete telemetry system [that is] suitable for monitoring microservices and other types of modern, distributed systems ‚Äî and [is] compatible with most major OSS and commercial backends.‚Äù
Conclusion
OpenTelemetry holds the key and is potentially a game-changer."
datadog,"By integrating tracing and metrics and eventually logging into a single system, OpenTelemetry provides rich correlations between tracing and metrics and help developers effectively conduct root cause analysis in distributed systems."
datadog,It also provides a vendor-neutral SDK across a variety of languages which also introduces uniformity and standards in this space.
datadog,Standardizing data collection patterns and decoupling them from tools that consume them is a great step towards getting both OSS and Commercial tools to adapt to OpenTelemetry.
datadog,The good news is that there is a lot of work already in this space!
datadog,Checkout the OpenTelemetry projects on GitHub and also the Beta Releases that came out recently!
datadog,"It is great to see Datadog already partnering with OpenTelemetry and reinforces our choice at Houghton Mifflin Harcourt to consolidate metrics, logs, and traces over Datadog!"
datadog,"Thanks to 
Darragh Grace
, 
Kenny Wang
, 
Anne-Marie McCullagh
, and 
Craig Hunter
 for their review and feedback on the draft!"
datadog,At Airfordable we employ Uptime Robot as one of the services responsible for monitor our sites.
datadog,"Per dollar spent, Uptime Robot is a very reasonable tool, but while it is a good value, they have not yet managed to create easy integrations with all of the cloud based monitoring tools in the market."
datadog,DataDog is once such monitoring provider that lacks a direct integration with Uptime Robot.
datadog,"As a result, we had to manually integrate Uptime Robot with DataDog using DataDog APIs and Uptime Robot web-hooks."
datadog,This blog post will cover how we did it and what you need to know to make it happen.
datadog,"DataDog
For those who are unfamiliar, DataDog is a cloud service that allows you to monitor your infrastructure using tools they provide and is also capable of ingesting real-time metrics via a StatsD like protocol."
datadog,"They also do a lot more like log ingestion, but that is beyond the scope of this post."
datadog,At Airfordable we use DataDog to monitor all of our infrastructure and centralize all alerts and actions.
datadog,"For this solution, we want DataDog to receive events as they happen from Uptime Robot so we can monitor all important happenings in a central location."
datadog,"These events allow us to not only view what is happening, but also trigger alerts and actions based on event frequency."
datadog,"DataDog has a nice set of HTTP APIs that allow us to interact with their system, and for this project we will use this event API."
datadog,"To create an event using the DataDog Event API, we need to POST a properly formatted JSON object to the /v1/events endpoint."
datadog,"Here is an example from their page of what the JSON blob might look like:
{
 ‚Äútitle‚Äù: ‚ÄúDid you hear the news today?‚Äù,
 ‚Äútext‚Äù: ‚ÄúOh boy!‚Äù,
 ‚Äúpriority‚Äù: ‚Äúnormal‚Äù,
 ‚Äútags‚Äù: [‚Äúenvironment:test‚Äù],
 ‚Äúalert_type‚Äù: ‚Äúinfo‚Äù
}
But before we can do anything with the API, we first must create an API key."
datadog,"This can be done under the DataDog API Keys drop down

With our API key in hand and a basic understanding of what DataDog needs in an event API request, we are ready to move on."
datadog,"Uptime Robot Web-Hooks
Uptime Robot is cloud service whose purpose is to check that your website or service is up and available."
datadog,It does this by making a request or opening a new connection to an endpoint you specify on a regular basis.
datadog,It can also listen for a heartbeat from a service and alert if the heartbeat stops.
datadog,"Since we use Uptime Robot to ensure our site is up, we want to be notified if/when our site goes down (which of course it never does‚Ä¶)."
datadog,Uptime Robot has a few ways of notifying you when one of your services goes down.
datadog,"You can receive a call, receive a text message, get an email, aSlack alert, or have them execute a web-hook."
datadog,The web-hook alert is a great solution for us here since it will allow us to make a call to an arbitrary API endpoint that accepts POST requests in a JSON format.
datadog,This is perfect because this is exactly what the DataDog API does.
datadog,For the web-hook to be effective and interact properly with DataDog we have to format the web hook in a way the DataDog API will be able to parse and understand.
datadog,This can be done by creating a JSON blob and employing the template system that Uptime Robot has implemented.
datadog,The system works by replacing the template strings with corresponding values related to the monitor in Uptime Robot that is alerting.
datadog,"The strings we will make use of are noted as follows:

Uptime Robot Template Variables
With these template strings in mind, and the ability to create and send an arbitrarily formatted JSON object, we are now ready to tie everything together."
datadog,"Tying it all Together
Below is an example JSON object with template strings that we could send to the DataDog event API:
{
 ‚Äútitle‚Äù:‚ÄùUptime_Robot: *monitorFriendlyName* is *alertTypeFriendlyName*‚Äù,
 ‚Äútext‚Äù:‚Äù*monitorFriendlyName* is *alertTypeFriendlyName*: *alertDetails*‚Äù,
 ‚Äúhost‚Äù:‚Äù*monitorURL*‚Äù,
 ‚Äúaggregation_key‚Äù:‚Äù*monitorID*-*alertType*‚Äù,
 ‚Äúalert_type‚Äù: ‚Äúwarning‚Äù
}
As previously noted, Uptime Robot will substitute the strings surrounded with ‚Äò*‚Äô characters with values noted in the table above."
datadog,This allows the alert to work with all of our monitors.
datadog,"A few note about the above JSON blob:
We set the aggregation_key to the *monitorID*-*alertType* so all similar events would be grouped together in the DataDog event stream."
datadog,You can remove the -*alertType* suffix if you want to group up and down events together.
datadog,You may want to set some tags to make categorization easier in DataDog.
datadog,"With this template JSON blob created, we now just need to figure out where to send it."
datadog,As we noted above the The DataDog API endpoint is hosted at https://api.datadoghq.com/api/.
datadog,We just need to append the path we want (/v1/events) and include any required HTTP query parameters (api_key).
datadog,"A full exampleURL might look something like this:
https://api.datadoghq.com/api/v1/events?api_key=A1B2C3D4E5F6G7H8I9K0
With our JSON template object ready and API URL generated, we are ready to create the alert contact in Uptime Robot."
datadog,"Creating the Alert Contact in Uptime Robot
Login to Uptime Robot and do the following:
Navigate to My Settings
Select the ‚ÄúAdd Alert Contact‚Äù button
Once you do that you should see a screen like this:

In the ‚ÄúAlert Contact Type‚Äù field, select ‚ÄúWebhook‚Äù."
datadog,In the ‚ÄúFriendly Name‚Äù field enter a name of your choice.
datadog,In the ‚ÄúURL to Notify‚Äù field enter the URL created in the last section.
datadog,Uptime Robot requires the string to end with a ?
datadog,or & character so they can append values.
datadog,Go ahead and add a trailing & character to the URL we created above.
datadog,In the ‚ÄúPOST Value‚Äù field enter the JSON blob from the last section.
datadog,Ensure the ‚ÄúSend as JSON‚Äù checkbox is selected.
datadog,In the ‚ÄúEnable notification for‚Äù field select ‚ÄúUp & down events‚Äù.
datadog,Click ‚ÄúCreate Alert Contact‚Äù button at the bottom of the window.
datadog,With that done you should now be able to add this alert to any monitor you have and get a corresponding event in DataDog.
datadog,"Wrapping Up
After doing this it would be best that you associate the alert with a test monitor and cause the monitor to fail by mis-configuring it."
datadog,This should send the alert to DataDog and you can verify everything works as expected.
datadog,"Ideally DataDog would have a direct integration with Uptime Robot to save us the trouble here, but for now this is good enough."
datadog,We are living in unprecedented times.
datadog,Our lives have been turned upside down as we all attempt to balance our unique set of circumstances.
datadog,That‚Äôs why our inspiring team at Fairwinds launched the COVID-19 Hackathon.
datadog,"While we are not on the front lines fighting COVID-19, we want to do our part to contribute to the common good by finding solutions that make an impact."
datadog,"Working behind the scenes with the tremendous talent and innovation that exists in the Kubernetes engineering and developer community, Fairwinds, working with AWS, Datadog and GitLab, has announced a competition to encourage innovative thinkers to create Kubernetes-based web application ideas to address the pandemic."
datadog,"Project Proposals
Starting immediately and running through April 10, 2020, people with ideas in the United States can pitch their project proposals for consideration."
datadog,"Proposals can be projects already underway or completely new ideas, though all entries must help address at least one of the following."
datadog,"Reduce the Spread of COVID-19
Find a Cure for the Virus
Educate the Public on COVID-19
Rebuild the Economy
Hackathon Voting and Winners
Representatives from Fairwinds, AWS, GitLab and Datadog will judge the competition and vote on a solution, which will be announced on April 15, 2020."
datadog,Application development will be open to the public to start immediately after.
datadog,"Sponsoring companies will provide the following to the winning project as they move from idea to tangible solution:
AWS will be offering six months of application hosting support*
GitLab will be where the project lives
Datadog will be offering free monitoring for six months*
Fairwinds will be offering free Kubernetes managed services for six months*
Project ideas may be submitted immediately by going to the following GitLab link and following the submission directions: http://covidhack.org/."
datadog,"* Timeframes may adjust depending on variables of winning project
Fairwinds ‚Äî The Kubernetes Enablement Company
ClusterOps Managed Kubernetes ‚Äî ClusterOps is a fully-managed Kubernetes cluster management tool that integrates infrastructure as code, open source software, and SRE expertise as a subscription service."
datadog,"ClusterOps Kubernetes Advisory ‚Äî ClusterOps Advisory integrates Kubernetes expertise and open source software so you can confidently run reliable, scalable, and secure Kubernetes clusters."
datadog,"Fairwinds Insights ‚Äî We integrate trusted tools, collaboration workflows, and expertise into a single monitoring platform, so workloads always stay secure, reliable, and efficient."
datadog,"Datadog APM (Application Performance Monitoring) is a wonderful tool for tracing your applications for performance, errors, etc."
datadog,Adding support to most javascript applications it is as simple as importing the tracing libraries and it it hooks into all supported libraries.
datadog,Unfortunately due to the nature of the way Next.js compiles and pre-renders pages this standard setup does not work.
datadog,Fortunately for us the datadog team wrote APM such that it supports the javascript opentracingspecification.
datadog,And even better is there is an express middleware for called express-opentracing to make it easy to dynamically add opentracing to express and pass a custom tracing library.
datadog,"First, install express-opentracing
npm install express-opentracing dd-trace
Update server.js to import datadog and opentracing
// Import the datadog apm tracing lib
const datadogTracer = require(""dd-trace"").init({analytics: true});
// Import the express-opentracing lib
const OpenTracingMiddleware = require(""express-opentracing"").default;
Finally, add the opentracing middleware w/ datadog tracer
// Enable the express-opentracing with datadog apm
const server = express();
server.use(OpenTracingMiddleware({ tracer: datadogTracer }));
That‚Äôs it!"
datadog,The majority of infrastructure engineers are currently living in the age of Cloud and Devops.
datadog,"New opensource is developed and used on daily basis, agile no longer was transformed from ‚Äúnice to have‚Äù to ‚Äúmust have‚Äù."
datadog,"In order to achieve this level of agility and flexibility on cloud deployment, continuous delivery and deployment pipelines were also a must."
datadog,What tools are integrated in this process?
datadog,"It depends, let me give you some examples: Gitlab for the code, Puppet and r10k for automation code deployment, and of course, good old Jenkins."
datadog,"There are also difficulties, beside new functionalities, the pipeline needs to be up and running with all the changes that happen, and it goes wrong in few cases."
datadog,We were trying the other day to fix a ‚Äúbug‚Äù that consists of installing the apt key on each puppet agent run.
datadog,"The main direction pointed to something in the Datadog module for Puppet, or at least that is what we thought at that moment."
datadog,"Since the code was also used by other teams and we couldn‚Äôt make changes on the master branch, I need to create a separate branch for our project."
datadog,"Unfortunately, I did not pay attention to the fact that we are not using the latest version of code and we have a certain older tag and ended by cloning the master branch with the latest version of code."
datadog,"After everything was done and a tag was created and added to Puppetfile, we started receiving alerts that Zookeeper process monitoring was not working anymore(lots of them)."
datadog,"Check filter from Datadog:
""zookeeper.ruok"".over(""type:kafka"",""type:zookeeper"").exclude(""env:prod"").by(""host"",""port"").last(2).count_by_status()
So it was linked with our error, but how?"
datadog,"Turns out that one of the change that is done in the latest code from Datadog module made our datadog.yaml look like:
Before
#
# MANAGED BY PUPPET
#
---
hostname: [hostname]
api_key: [key]
dd_url: https://app.datadoghq.com
cmd_port: 5001
conf_path: ""/etc/datadog-agent/conf.d""
enable_metadata_collection: true
dogstatsd_port: 8125
dogstatsd_socket: ''
dogstatsd_non_local_traffic: false
log_file: ""/var/log/datadog/agent.log""
log_level: info
tags:
- vertical:kafka
- env:dev
- type:kafka
apm_config:
  apm_enabled: false
process_config:
  process_enabled: disabled
After
#
# MANAGED BY PUPPET
#
---
api_key: [key]
dd_url: https://app.datadoghq.com
cmd_port: 5001
conf_path: ""/etc/datadog-agent/conf.d""
enable_metadata_collection: true
dogstatsd_port: 8125
dogstatsd_socket: ''
dogstatsd_non_local_traffic: false
log_file: ""/var/log/datadog/agent.log""
log_level: info
tags:
- vertical:kafka
- env:dev
- type:kafka
apm_config:
  apm_enabled: false
process_config:
  process_enabled: disabled
No hostname in agent configuration file anymore, but this shoudn‚Äôt be a problem after all, right?"
datadog,Wrong!
datadog,"For internal management and operations purpose, one of the GCP daemon updates each machine with lines in /etc/hosts
[ip] [instance-name].c."
datadog,"[project_name].internal [instance_hostname] # Added by Google
[metadata_ip] metadata.google.internal # Added by Google
And /etc/resolv.conf
domain c.[project_name].internal
search c.[project_name].internal."
datadog,google.internal.
datadog,"nameserver [metadata_ip]
Even if our hosts file have one entry with the correct server hostname, since the .internal record was still present, on a Datadog agent restart, wrong hostname was selected."
datadog,New ‚Äúhostname‚Äù looked like [machine name from GCP].internal instead of [machine name from GCP].
datadog,"[domain]
The outcome was that all the metrics were published on wrong .internal hostnames in Datadog, and it turn out that all of monitoring was affected."
datadog,"We are running our pipeline on Continuous Integration principle and even if there are tests that make sure services are running, it‚Äôs pretty hard to think of such scenarios."
datadog,"This caused for us a small outage of one hour (and it was short since we figured it pretty fast), time that was used to redeploy the reverted code on all of instances that were affected."
datadog,"There are two advises to be taken from this unfortunate event:
Pay attention on the branch you are using as base for another, errors happen and they get ugly at the actual rate in which everything is integrated."
datadog,Create a separate testing setup without direct integration.
datadog,You can not have 100% test coverage for all the scenarios that appear on an ever changing opensource landscape of infrastructure solutions.
datadog,Stay safe!
datadog,"The need for Right Monitoring
What caused my API performance to degrade?"
datadog,Is code the issue or external dependencies?
datadog,Are DB Queries taking too much time?
datadog,Code is very light then why does it take time?
datadog,"Ever been through all these questions where you needed to analyze, monitor, instrument, benchmark your code to come up with answers."
datadog,Thanks to APM(Application Performance Management) tools in the market which are designed to solve all this for you in a matter of few lines of code.
datadog,Good then let's not waste time and start using APM tools !!!
datadog,"Few months later, the code grows, more developers writing modules."
datadog,"With dockerization, more applications/services are running in the same machine, saving cost."
datadog,One hardware serving many applications.
datadog,"For our use case, there is flights, hotels, payments, inventory, booking and so many other modules."
datadog,"More and more code, services, applications."
datadog,"Now all the module owners are trying to improve the performance of their modules, but before improving they need to monitor their performance."
datadog,"Module owners go to APM tool, and guess what there is only one service in APM per host‚Äî named host-1, all APIs are somewhere intermingled with all the other module APIs and there is no commonplace to understand my X module performance(latency, request, errors, dependencies duration), all the alerts are on their on the host-1 level."
datadog,"Hey because of module Y issues, X does not want to be alerted."
datadog,"Now what just to get proper performance monitoring, I need to separate all my modules in a different service hosted in a different host, pay for extra cost both machine wise and APM tool installation per host wise."
datadog,My module is not even that big now to be a service.
datadog,"Well, guess what, this is what we at TravelTriangle were going through until last year."
datadog,"The journey from Scout to Datadog
We needed APM tools to Monitor, instrument, troubleshoot, and optimize our end-to-end application performance."
datadog,We were using Scout earlier and now we have switched to Datadog.
datadog,This article is the journey for the change of choice from Scout to Datadog.
datadog,There are many APM(Application performance management) solutions in the market.
datadog,"While we were using Scout in our Rails application(s), Scout gave us a host-level APM solution."
datadog,One of the major drawbacks of this for us was while using Scout in Sidekiq Machines where multiple processes were running and all process were logically separated as per module ownerships.
datadog,Tech teams could not monitor their sidekiq process based on team ownerships and internally every team was confused about what caused sidekiq machine issues.
datadog,"Similar kind of need was there in our backend services where the code grew with time and a lot of logically different modules e.g flight, inventory etc were written as part of the same service."
datadog,"While we needed to solve team owned queue-based monitoring for sidekiq, Scout was unable to provide the same."
datadog,In Scout we would have to separate our machines as per modules and then Scout would have given us that separation of monitoring.
datadog,We started looking out and came across Datadog APM where the costing was still the same i.e per host but it provided flexibility to write customized code to have multiple services from the same host and monitoring/alerts in Datadog platform can be set at the service level.
datadog,This enabled us to save cost while enabling us to separate monitoring at a service level from the same host.
datadog,Below are the points of difference between Scout and Datadog from my experience and as per my knowledge.
datadog,"Scout Vs Datadog
Setup Multi-Service Monitoring From Same Host using Datadog
We followed up the official documentation to set up Datadog in our hosts."
datadog,While the existing sidekiq integration does not provide process-level separation.
datadog,We wrote our custom sidekiq server middleware where we used process name to identify module and create service accordingly.
datadog,"#process_name = $0
def call(worker, job, queue)
.....
service = get_module_name_using_process_name
Datadog.tracer.trace(SPAN_JOB, service: service, span_type: SPAN_TYPE_WORKER) do |span|
  span.resource = resource
  span.set_tag(TAG_JOB_ID, job['jid'])
  span.set_tag(TAG_JOB_RETRY, job['retry'])
  span.set_tag(TAG_JOB_ARGS, job['args'])
  span.set_tag(TAG_JOB_CLASS, job['class'])
  span.set_tag(TAG_JOB_QUEUE, job['queue'])
  span.set_tag(TAG_JOB_WRAPPER, job['class']) if job['wrapped']
  span.set_tag(TAG_JOB_DELAY, 1000.0 * (Time.now.utc.to_f - job['enqueued_at'].to_f))
  yield
end
.....
end
This enabled us to have per process-based Performance Monitoring and also use Datadog features like Latency/Error Alerts which were configured to raise a alert to the specific team in case of abnormality."
datadog,This made our teams responsible for their modules even in a monolithic service and monitor the live performance of their codebase.
datadog,"All the sidekiq processes from the same machine
Handling backtrace of query and memory per transaction through custom code
While the migration to Datadog had few disadvantages(listed in the difference image above), major disadvantages for us was no backtrace of DB calls and no memory bloat insights."
datadog,We added custom code in span metadata at Database Layer(custom Mysql2Adapter < AbstractMysqlAdapter overriding execute method)to identify backtrace of DB query to get the exact code which triggered this SQL query.
datadog,This enabled us to debug on a code level once few queries in a trace were taking more time.
datadog,"Datadog.tracer.trace(‚Äúmsqylquery‚Äù, options) do |span| (span.set_tag(‚Äúbacktraceofquery‚Äù, caller.select{ |c| c.starts_with?"
datadog,"(root) }))

Enabled memory monitoring per trace level by writing custom code which monitored passenger(process) memory at the start of the transaction and end of the transaction."
datadog,This enabled us to see a graph of memory per transaction and we attached this data per Datadog trace also.
datadog,"Leveraging Datadog features to improve operational excellence
When we used Datadog, we used other features of Datadog to improve operational efficiency."
datadog,We used its dashboard feature to create a oncall dashboard which will help the oncall deep dive in identifying the issue.
datadog,This enabled any new developer to quickly debug outage.
datadog,"In this, we put all the relevant dependencies which could cause outage like (Request bombardment, Database, ElasticSearch, Slow Transactions, Cache, Errors, Memory etc)

We used Datadog live process based alerts to configure if the number of process working for the module was changed."
datadog,This used to happen when some transactions were taking a lot of memory and OS will kill the specific sidekiq process silently.
datadog,"Without alerts, we used to get notified about this hours later when the corresponding business team used to report about the impact."
datadog,We used Errors support in this to setup team specific alerts once the alerts ratio used to increase in service.
datadog,"(Faulty code entering into production)
We used DB specific service layer in Datadog to identify the top queries in times of throughput, time and went on to optimized these calls."
datadog,"We used flame graph to debug large time difference between two DB calls, is it the code issue or RAM/IO issue(load average) that the next line of code is not getting executed."
datadog,We used custom code to separate module based services deployed on the same host.
datadog,"We used Span Summary to understand which type of call is taking more time (AvgSpans/Trace * Avg Duration)

This has good metrics around trends, outliers, relative time comparison graphs, we used these to debug month on month increase in latencies."
datadog,We used the change graph to have a deep analysis with Month Vs Previous Month comparison.
datadog,"All these enabled us to have better insights into our services, quickly do RCA and proactive alerts around the relevant metrics."
datadog,"If you like the article or find it relevant, do clap/share so that others might stumble upon this article."
datadog,"If you need to know more, feel free to reach out to me at LinkedIn."
datadog,Read more about engineering at TravelTriangle here.
datadog,"This time Marcin and Micha≈Ç have shared their discoveries from February:
how to launch a preview window in fzf;
how to automate with Datadog & Terraform."
datadog,"Marcin Baraniecki ‚Äî Frontend Engineer
fzf is a great tool to quickly find a file or autocomplete the command arguments ‚Äî by name or pattern."
datadog,"It‚Äôs quick, it‚Äôs handy and it performs well when you don‚Äôt know the exact filename you‚Äôre looking for (by applying ‚Äúfuzzy‚Äù search, match & completion)."
datadog,"Besides terrific autocomplete feature, one of the greatest use cases I‚Äôve discovered recently is the preview window."
datadog,Say you want to quickly browse contents of all files that match your fuzzy search query.
datadog,"Normally, you do that by applying a cat <filename> command."
datadog,"However, you can join both functionalities:

After issuing a command above (fzf ‚Äî preview ‚Äòcat {}‚Äô), a regular fzf search prompt shows up."
datadog,"This time, however, it additionally comes with a right-hand side preview window!"
datadog,Navigating through a list of files changes the output of the preview window.
datadog,"Additionally, that box can be scrolled independently (by hovering over it with your mouse)!"
datadog,"Preview window is a great feature that can be used with other bash commands, too."
datadog,Displaying contents of a file (cat command) is but a simplest one.
datadog,What will YOU use it for?
datadog,"Micha≈Ç Mat≈Çoka ‚Äî Senior Software Engineer & Architect
It is good to automate."
datadog,"There are things that are just quite obvious ‚Äî deployments ‚Äî CI & CD, environments set up etc."
datadog,However there happen to be some small little things which people tend to omit.
datadog,One of those things are Datadog dashboards.
datadog,"During this month, I‚Äôve learned that it is pretty simple to bring dashboard definition to your codebase and ‚Äúdeploy‚Äù it automatically to Datadog."
datadog,Terraform documentation includes a clean description how you can define your dashboards.
datadog,"The definition format is quite similar to the export you can download, from the Datadog website."
datadog,The main difference is that export is in JSON and terraform uses yaml.
datadog,How does a single-widget dashboard definition look like?
datadog,"It is pretty simple:
provider ‚Äúdatadog‚Äù {
  api_key = ‚Äú${var.datadog_api_key}‚Äù
  app_key = ‚Äú${var.datadog_app_key}‚Äù
}
resource ‚Äúdatadog_dashboard‚Äù ‚Äúordered_dashboard‚Äù {
  title = ‚ÄúPotato service‚Äù
  layout_type = ‚Äúordered‚Äù
  is_read_only = true
  widget {
    timeseries_definition {
      title = ‚Äúavg meal time (ms)‚Äù
      show_legend = false
      request {
        q = ‚Äúavg:patato_service.meals.avg{service:patato_service,$environment}‚Äù
        display_type = line
      }
    }
  }
}
Terrafrom Datadog integration does not offer only support for dashboards."
datadog,"You can define there logs indexes, monitors and a lot of other things."
datadog,"If you are using Datadog, then definitely you should take a look at the Datadog integration."
datadog,And what have you learned in February?
datadog,Let us know!
datadog,":)
BTW, we are always looking for outstanding professionals to join our team!"
datadog,Check out backend and frontend open positions!
datadog,"The Telegraph Datadog SLO Dashboard
This is the concluding part to our first blog on implementing SLIs and SLOs and the benefits they can bring."
datadog,"Now, we‚Äôll discuss three real examples of SLIs in operation today."
datadog,Note that the numbers below are sample data for purposes of illustration; they do not represent the actual availability of Telegraph services.
datadog,"Example 1: Customer Subscription Journey (Availability SLI)
We‚Äôve recently deployed a new React-based application that powers our customer subscription journey."
datadog,"When a user clicks ‚Äúsubscribe‚Äù anywhere on the site, the React application launches this journey."
datadog,"This subscription flow is critical to the revenue of our business, as it allows users to purchase a range of products."
datadog,"Therefore, we knew we wanted to implement an SLI/SLO to measure the availability of this key service."
datadog,"Service Type: Request-driven
SLI Type: Availability
SLI Specification: The proportion of subscription journey requests that return an HTTP status code of 200 (success)
SLI Implementation:
Backend API availability: The proportion of subscription journey requests that return an HTTP status code of 200 as measured from the ‚Äúavailability‚Äù column of metrics from an Apigee ELB."
datadog,"Frontend synthetic user test: The proportion of valid subscription requests that return a status code of 200, as measured from a synthetic test executing every minute."
datadog,"By completing the journey, the synthetic test verifies our customers can successfully purchase a subscription via the website."
datadog,We calculate the SLI as a rollup of these two metrics: the total number of 200 responses for both metrics divided by the total number of valid responses for both metrics.
datadog,SLO: 99.5% of subscription journey requests in the past 28 days served successfully (HTTP status code of 200).
datadog,"After discussions with the Product team, latency was not considered critical to this customer journey."
datadog,Purchasing a subscription requires the customer to fill out a web form with personal information.
datadog,Manually inputting this data takes significantly more time than loading the web page.
datadog,"Our reasoning was that if the form took a few hundred milliseconds ‚Äî or even a couple of seconds ‚Äî to load, it would not significantly impact the customer‚Äôs experience."
datadog,"However, if a customer hits a server error at any point during this journey ‚Äî particularly after inputting all that data ‚Äî they would be unlikely to come back and try again."
datadog,"The SLI/SLO therefore focuses on the successful completion of the customer journey, rather than its latency."
datadog,"Example 2: Content API (Freshness SLI)
In the digital publishing business, readers expect to see the latest news and, in turn, journalists race to get breaking stories to readers."
datadog,"So, it‚Äôs important for us to be able to deliver the content as quickly as possible to readers after our staff have committed the content to our CMS (Content Management System)."
datadog,This means we need to minimise the time between an article being published in the CMS and being available in our Content API.
datadog,"Service Type: Pipeline
SLI Type: Freshness
SLI Specification: Articles published in the CMS should be available in the Content API within 1 minute."
datadog,"SLI Implementation:
Run a query every minute on the CMS to get all articles published in the last 1 minute
Run a query every minute on the Content API and get all articles published in the last 1 minute
Compare the two lists and make sure they contain the same articles and the published_date field is the same on both systems
One challenge with measuring this SLI is that the pace of publication varies over the course of the day."
datadog,"During some periods, nothing gets published, while we might see 100 articles get published in another period."
datadog,"Another challenge is accounting for live articles (articles that get updated after they first publish ‚Äî for example, live football match updates)."
datadog,"For live articles, we are also comparing the last_updated field of the CMS and Content API."
datadog,SLO: 99.9% of the articles published are available in the Content API within 1 minute.
datadog,"For us, content freshness is a very difficult SLO to negotiate because there‚Äôs not much room for negotiation."
datadog,"When journalists publish an article to the CMS, they routinely check their apps and Telegraph web properties to see if the article has shown up."
datadog,If the article isn‚Äôt available immediately they will often raise a ticket or call us.
datadog,When we get that kind of call we have to fix the problem ‚Äî the error budget is practically nonexistent.
datadog,Some content is more important to deliver more quickly than other content.
datadog,"Over time, it may make sense to prioritise different content types by creating tiers."
datadog,"For example, big breaking news would be placed in Tier 1 (requiring the most stringent SLO), while an article on gardening the latest summer blooms would be assigned to a lower tier."
datadog,"That type of scheme might be necessary in the future, but it obviously adds significant complexity."
datadog,"Example 3: Log in using Facebook (Latency SLI)
The Telegraph website allows customers to log in to their accounts using a number of social providers, including Facebook."
datadog,"This journey allows us to verify that our customers can log in using Facebook, but also that they complete the login process in an acceptable amount of time."
datadog,"Service Type: Request-driven
SLI Type: Latency
SLI Specification: Of successful login journeys, 90% are served in less than 3s and 99% are served in less than 5s."
datadog,"SLI Implementation:
Synthetic measurement: The proportion of successful Facebook login journeys served in less than 3s and in less than 5s, as measured by probers (synthetic tests)."
datadog,The tests execute JavaScript in a browser in a virtual machine running every minute.
datadog,Real user measurement: The proportion of login page requests served in less than 3s and less than 5s of successful Facebook login journeys measured by Client Instrumentation (RUM tags).
datadog,SLO: 90% of successful Facebook login page journeys are completed in under 3 seconds and 99% in under 5 seconds.
datadog,"This SLI/SLO validates successful Facebook logins, and also helps us ensure that our customers have an acceptable login experience."
datadog,"In this case, since we depend on Facebook as an authentication provider, we can now use this SLI/SLO to directly measure the impact on our customers, should the external provider experience issues."
datadog,We also implemented the same SLI/SLO for our other login methods (Amazon and Telegraph accounts) so we can directly compare services against each other!
datadog,"Conclusion
Site Reliability Engineering (SRE) practices are more specific and prescriptive than DevOps practices, and the SRE book authors acknowledge that not every SRE practice will apply in all environments."
datadog,"For example, the SRE books recommend that site reliability engineers develop business features at least 50% of the time and spend the other half of their time working on systems and infrastructure."
datadog,"But, for now, SREs of that sort are difficult to find, and so we still have a distinction between developers and systems engineers."
datadog,Systems engineers will do some scripting but they won‚Äôt write Java and Java developers will work on some of the infrastructure but they won‚Äôt do everything.
datadog,"However, one key fact is consistent across all of our teams: If you built it, you run it and you own it."
datadog,We‚Äôre by no means finished on our quest to master the art of SLOs.
datadog,We still have a lot of work to do ‚Äî particularly around managing our error budgets ‚Äî but we feel strongly that this is the right approach for us.
datadog,"We‚Äôve had some quick and early success, and it has already helped us create a collaborative, focused team dynamic across our organisation."
datadog,"Acknowledgments
We‚Äôd like to thank The Telegraph‚Äôs CTO, Toby Wright, for sponsoring the SLI initiative."
datadog,We would also like to thank the SREs at Google for sharing their knowledge and assisting us with our journey.
datadog,Dave Sanders is Head of Technology ‚Äî Newsroom at The Telegraph.
datadog,Lucian Craciun is Head of Technology ‚Äî Platforms at The Telegraph.
datadog,"How to create synthetic perf database, environment and run performance test to give real actionable results."
datadog,Is this a existing customer and they are going to see increase usage by e.g.
datadog,4x?
datadog,Is this a new customer using unlike any other current users e.g.
datadog,"more concurrent user, much more subaccount than current customers?"
datadog,Is there a known rampup for usage?
datadog,Time range when users go from low number to peak e.g.
datadog,"1k to 89k users between 5AM-8AM
Is there a know steady state concurrent user level?"
datadog,e.g.
datadog,"89k users on the system from 8AM-2PM
System architecture."
datadog,"How does Web servers, db servers, redis scale?"
datadog,Are they behind a auto scale group?
datadog,ASG rules?
datadog,Any know scaling issues noticed in the past?
datadog,"Any document concerns
Ask how does a bottleneck on downstream system affect user facing web application?"
datadog,e.g.
datadog,if there db lock/avg query times go up in database server how does that effect user facing web app?
datadog,increase error rates?
datadog,Ask/Find during rampUp or Peak Load what are different load/traffic on the system?
datadog,List of top api endpoints and background jobs?
datadog,Endpoints/Controller handing most load e.g.
datadog,(Most used enndpoint*avg_time of each) order by desc.
datadog,Understand the database schema.
datadog,Look at the rowcount of schema in production.
datadog,Use ratio to seed appropriate data.
datadog,e.g.
datadog,if courses table has 1.2million record and we expect customer to experience 4x usage.
datadog,We should seed 4.8million courses.
datadog,Not just course all related tables.
datadog,Is there a import feature that the system allows?
datadog,e.g.
datadog,sis import.
datadog,Use api to seed data so that it is closer to real use case.
datadog,Using the activerecord is another way(understanding of table/model relation is critical if you decide to go this path).
datadog,Once you have identify the endpoints to seed the data use tool like jmeter to seed data at scale.
datadog,"Before starting the load test, ensure that perf test environment is scale and size to as close to production as possible."
datadog,"atleast 2 application servers under the asg, prod sized db, redis rings
Understand latency breakdown for rails controller, postgres, redis, rails cache e.g."
datadog,"using a flamegraph using APM from Datadog
Any know critical integrations to be aware of?"
datadog,e.g.
datadog,"kinesis stream, service for checking feature flags."
datadog,Does a bottleneck in downstream system have impact of core application performance e.g.
datadog,"user facing web application
Part of performance engineer, knowing about
peak traffic hours
user actions
data size and growth rate
key metrics
We use datadog, splunk and cloudhealth
Think Time

blue bar represents transaction response time + think time(whitespace between individual blue bar)
gaps represents pacing delay between 2 iterations(whitespace before start of next blue bar)
increasing think time and pacing can help achieve max user concurrency and production behavior
Little‚Äôs Law:
The long-term average number of customers in a stable system N is equal to the long-term average effective arrival rate, Œª, multiplied by the average time a customer spends in the system, W; or expressed algebraically: N = ŒªW."
datadog,"For performance testing,
N=Throughtput*(Response time+Think time + Pace Time)
pace time is delay of arrival of next interation
think time is time for user interation
response time is system/api level response time (add multiple api times to simulate a transaction e.g."
datadog,"ordering an item on ecommerce app or navigation to home page+login+performing action)
If we can look at splunk/datadadog or an apm tool to figure out the total concurrent users on the system, avg response time for the transaction,arrival rates(pace time), we can calculate think time
Think time = N/Throughput -(response time +pace time)
e.g."
datadog,Business case: A user logs in and edit a blog which takes around 6secs.
datadog,The total concurrent users at steady state is 80k for 1 hour.
datadog,The total edit blog call is 8.3million an hour.
datadog,"The delay between iteration is 1s
N=80k concurrent users
throughput in s=8.3m/3600=2300/s
Think time=80k/2.3k-(6+1)=34.7‚Äì7=24.7s
Peak Traffic Hours
We use multiple app server clusters(we will focusing on application servers)."
datadog,Each cluster maybe server muliple customers.
datadog,"some cluster have dedicated usually a very large customer
Datadog provides an application server wide dashboard(please check with your SRE team member)."
datadog,"Identify the cluster which has most amount of instances
Look at the cluster level datadog app server dashboard and identify the peak hours of user traffic into the system as well as user leaving the system

Around 4:40am there are 1200 users on the system which rapidly grows to 40k users around 8:00am
In this above example
At around 4:40am there are 1200 users on the system which rapidly grows to 40k users around 8:00am
The peak customer activity is between 8am to 1pm
by around 1pm there are 40k users on the system and 3pm drops down to 5k user
Also look if there is pattern,
weekday, weekend, bank holiday pattern, business related seasonal
From a performance testing and scaling perspective, 4:40am to 8am is the critical customer experience time."
datadog,Your systems should scale up/be ready to service incoming rush of customers.
datadog,"User Action
Understanding what user actions are happening on the system is critical in creating synthetic load, measuring system performance, optimizing cost vs usage."
datadog,"NOTE: underutilized resource burns cash
I used splunk to dig into user actions."
datadog,"index=""myapp_iad"" sourcetype=""_json"" cluster=cluster9974 | eval url=mvindex(split(http_request, ""?"
datadog,"""), 0)| eval url1 = replace(url, ""/\d+"", """")| eval conca=http_method."
datadog,""";"".url1 |stats count, p95(db_time), sum(microseconds), sum(user_cpu), p95(microseconds), p95(user_cpu), median(microseconds), median(user_cpu) by conca
For myapp, use the cluster we had identified in our earlier section."
datadog,i‚Äôm spliting the http_request uri and replacing any id data.
datadog,"Using concatenate to included HTTP_METHOD and evaluated HTTP_REQUEST uri and group them to find
count: count of total requests, use this to identify most common endpoint being used as the users arrive
total user_cpu: our custom apache records user_cpu for each endpoint."
datadog,"I‚Äôm counting the total here to identify the which endpoints are cpu hungry
total microseconds: time to service the request, first byte to last byte."
datadog,I‚Äôm counting the total here to identify the which endpoints took the most time.
datadog,"p95,medians: 95th percentile and medians
Alternative approach: i want to see user action during peak hours
http_method, controller and action
index=""myapp_iad"" sourcetype=""_json"" cluster=cluster9974 | eval conca=http_method."";"".controller."
datadog,""";"".action |stats count, p95(db_time), p95(microseconds), p95(user_cpu), median(microseconds), median(user_cpu) by conca

Visualizing the top 80% of user action during peak hours
Data Size and Growth rate
We use postgres."
datadog,"The infrastructure has read/write, read-only and backup replicas."
datadog,"Each of the above are in different AZ‚Äôs for high availability
SELECT
pgNamespace.nspname as Schema,
pgClass.relname   AS tableName,
pgClass.reltuples::bigint AS rowCount
FROM
pg_class pgClass
LEFT JOIN
pg_namespace pgNamespace ON (pgNamespace.oid = pgClass.relnamespace)
WHERE
pgNamespace.nspname NOT IN ('pg_catalog', 'information_schema') AND
pgClass.relkind='r' and
order by pgClass.reltuples desc;
Identify endpoints that can spun-off as service
can be independently scaled and more granularity in scaling up core system
move to more performant stack(e.g."
datadog,rails to java)
datadog,The method described here is not the recommended way of doing things.
datadog,Read more about this in https://docs.datadoghq.com/serverless/forwarder.
datadog,"Create Datadog API Key
First we need an API key so that the Datadog Forwarder can send logs to Datadog."
datadog,Follow the steps in https://docs.datadoghq.com/account_management/api-app-keys/#api-keys.
datadog,"API keys page ‚Äî https://app.datadoghq.com/account/settings#api
Store this API key as an SSM parameter."
datadog,"Datadog documentation recommends using AWS Secrets Manager, but as of today SSM works just fine and is more cost effective¬π."
datadog,"There is a couple of ways of doing this, either using AWS Console or AWS CLI¬≤."
datadog,"aws ssm put-parameter --name datadog-api-key --value $DD_API_KEY --type SecureString --key-id alias/aws/ssm --tier Standard

Parameter store in Paris ‚Äî https://eu-west-3.console.aws.amazon.com/systems-manager/parameters
Create Datadog Forwarder S3 Cache Bucket
This step is not strictly necessary, but still the unified service tagging¬≥ is a nice to have."
datadog,"Example bucket in Paris ‚Äî https://s3.console.aws.amazon.com/s3/home?region=eu-west-3
Create Datadog Forwarder IAM Role
The following policy document grants basic logging permissions along with a special permission to read the API key created in the previous step."
datadog,"Policy document for DatadogForwarderPolicy
Again both AWS Console and AWS CLI‚Å¥ can be used to create the policy."
datadog,"aws iam create-policy --policy-name DatadogForwarderPolicy --policy-document file://datadog-forwarder-policy-document.json
Then attach this policy to an execution role."
datadog,More on this in https://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html.
datadog,"Trust policy for DatadogForwarderRole
aws iam create-role --role-name DatadogForwarderRole --assume-role-policy-document '{""Version"": ""2012-10-17"",""Statement"": [{ ""Sid"": ""AllowAssumingRoleFromLambda"", ""Effect"": ""Allow"", ""Principal"": {""Service"": ""lambda.amazonaws.com""}, ""Action"": ""sts:AssumeRole""}]}'
aws iam attach-role-policy --role-name DatadogForwarderRole --policy-arn arn:aws:iam::123456789012:policy/DatadogForwarderPolicy

IAM roles with policy attachments ‚Äî https://console.aws.amazon.com/iam/home
Create Datadog Forwarder Lambda
At this point, we are ready to create the lambda itself."
datadog,"The code is available for download in https://github.com/DataDog/datadog-serverless-functions/releases, and the current release 3.30.0 runs on Python 3.7."
datadog,"As usual, either on AWS Console or with AWS CLI‚Åµ."
datadog,"Along with the code, the envvars DD_API_KEY_SSM_NAME and DD_ENHANCED_METRICS must be set."
datadog,"On the other hand, DD_FETCH_LAMBDA_TAGS, DD_LOG_LEVEL and DD_S3_BUCKET_NAME are optional."
datadog,"aws lambda create-function --function-name datadog-forwarder --zip-file fileb://aws-dd-forwarder-3.30.0.zip --role arn:aws:iam::123456789012:role/DatadogForwarderRole --handler lambda_function.lambda_handler --runtime python3.7 --environment 'Variables={DD_API_KEY_SSM_NAME=datadog-api-key,DD_ENHANCED_METRICS=false,DD_FETCH_LAMBDA_TAGS=true,DD_LOG_LEVEL=info,DD_S3_BUCKET_NAME=datadog-forwarder-bucket}'
The lambda needs to be executed upon receiving new logs."
datadog,"This requires specific permissions, as described in https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters.html#LambdaFunctionExample."
datadog,"aws lambda add-permission --function-name datadog-forwarder --statement-id AllowInvokingFunctionFromCloudWatchLogs --principal logs.eu-west-3.amazonaws.com --action lambda:InvokeFunction --source-arn 'arn:aws:logs:eu-west-3:123456789012:log-group:*'

In AWS Console, the resource policy can be created in Lambda > Functions > datadog-forwarder > Configuration > Permissions > Resource-based policy > Add permissions
Do not forget to change the retention of the log group‚Å∂ associated with the Datadog Forwarder since it defaults to unlimited."
datadog,"Configure Triggers
With a one-line configuration‚Å∑, Datadog can automatically create logs subscription filters for all existing and new lambdas."
datadog,This provides an effective way not to worry about this in the future.
datadog,"AWS integration page ‚Äî https://app.datadoghq.com/account/settings#integrations/amazon-web-services
And that‚Äôs pretty much it !"
datadog,"Lambda logs, custom metrics and traces will now smoothly flow along with other Datadog resources."
datadog,The banner to introduce the Nimbella serverless cloud Slack platform that will let users get their Datadob billing info.
datadog,"Contact Nimbella on Twitter, LinkedIn, or Slack
Have you ever wanted a simple way of displaying your Datadog billing info on Slack?"
datadog,"With Nimbella Commander, you can have your current bill and next month‚Äôs projected bill displayed in one command to your Slack workspace."
datadog,"Later, I‚Äôll show you how to restrict who can access this Slack command so it‚Äôs only available to people who need to know."
datadog,"Here‚Äôs how to do it:
Inside your Datadog API settings, Create a Datadog API key and Application key in Datadog‚Äôs UI."
datadog,You must name your API key datadogApiKey and your Application Key datadogApplicationKey.
datadog,Page for Datadogs ApiKey and ApplicationKey which you will need to give Commander permission to displaying your billing info.
datadog,2.
datadog,Add Nimbella Commander to your Slack page.
datadog,You can add it by searching ‚ÄúNimbella‚Äù in the apps tab on Slack.
datadog,You can also add it by going to our official website and clicking the ‚ÄúAdd to Slack‚Äù button.
datadog,"Slack button that you have to click to add Commander to your Slack account
3."
datadog,"In order to get your Datadog billing details, you‚Äôll need to install the billing Command Set."
datadog,"Command Sets are a packaging specification for Slack commands, and a convenient way to share commands via GitHub or open source."
datadog,Command Sets are installed into your Slack teams via the Nimbella Commander by typing the command /nc csm_install billing in your Slack prompt.
datadog,Slack command you run to get the Datadog billing ability.
datadog,"Billing will show you your Datadog billing info
4."
datadog,Next we need to bind some secrets to the billing commands.
datadog,"Specifically, the API keys you generated earlier for the Datadog API will be encrypted (outside of Slack) and attached to the slash command."
datadog,"To do this, type /nc secret_create to bring up the Nimbella Secret Creator."
datadog,We‚Äôre creating the secrets outside of Slack so that Slack will only see encrypted strings and not your API keys.
datadog,"When you run the secrets command, you will see an output that looks like this:
Slack command to get the Datadog secret ApiKey and ApplicationKey
5."
datadog,Click on the Secret Creator link to be redirected to the page which encrypts your API keys.
datadog,6.
datadog,Add your Datadog API Key and Application Key from Step 1 to the fields in the Secret Creator as illustrated in the following figure.
datadog,"Next, click the ‚ÄúMake Secrets‚Äù button to generate the commands you‚Äôll need to copy and paste into your Slack prompt."
datadog,7.
datadog,"After clicking the ‚ÄúMake Secrets‚Äù button, the commands you‚Äôll need to run on your Slack page will appear."
datadog,Copy each command one at a time and paste them into Slack.
datadog,This will take your API Key and Application Key and apply them.
datadog,8.
datadog,"Finally, run the built-in command /nc datadogbill to see your Datadog billing info."
datadog,9.
datadog,"To see more details about your bill, try /nc datadogbill -detail

10."
datadog,You likely don‚Äôt want everyone in your Slack team to run this command.
datadog,Nimbella Commander offers a neat feature to allow only certain users to run specific commands.
datadog,"For example, you can restrict access to the Datadog billing command to specific users using /nc command_runners datadogbill + @user1 + @user2, substituting for ‚Äúuser1‚Äù and ‚Äúuser2‚Äù the Slack names of your teammates that should have access to the Datadog billing details."
datadog,Slack slash command that allows specific members of your Devops team to run your Datadog billing info command.
datadog,11.
datadog,It‚Äôs worth also mentioning that you have access to an audit trail to see who‚Äôs run your commands.
datadog,This is useful for administrators and team oversight where appropriate.
datadog,"Type /nc command_log datadogbill
Slack slash command that shows which Slack users are running your Datadog billing info command on Slack."
datadog,Using Nimbella‚Äôs access control you can also limit who can view and edit the code that implements a particular command as well.
datadog,The built-in Secret Creator means your sensitive data remains outside of Slack and accessible only to the code you run.
datadog,"And with Audit Logs, you have accountability and historical data readily available at your fingertips."
datadog,These are powerful features of the Commander that don‚Äôt exist in Slack otherwise.
datadog,"For more information about Commander, visit our website."
datadog,We‚Äôd also love to hear from you via our community Slack channel or on GitHub.
datadog,"If you wish to add Commander to your Slack account, click this link to get started today!"
datadog,"Video tutorial on how to get your Datadog billing info in Slack with Nimbella Commander:

Originally posted on nimbella.com"
datadog,DataDog APM is fully managed tracing service.
datadog,DataDog APM support OpenCensus as trace format.
datadog,so I challenged use DataDog APM with OpenCensus.
datadog,"# Setup
In distribution tracing, trace sender layer called exporter exists."
datadog,so I select DataDog exporter to use DataDog APM.
datadog,let‚Äôs setup DataDog exporter.
datadog,I use Golang in this time.
datadog,"package main

import (
   ""log""

  ""github.com/DataDog/opencensus-go-exporter-datadog""
  ""go.opencensus.io/trace""
)

func main() {
   opt := datadog.Options{
      Service:   ""your service name"",
      TraceAddr: ""your datadog agent_ip:8126"",
   }

   dd, err := datadog.NewExporter(opt)
   if err != nil {
      log.Fatal(err)
   }

   defer dd.Stop()

   trace.RegisterExporter(dd)
   trace.ApplyConfig(trace.Config{DefaultSampler: trace.AlwaysSample()})
}
# Start Trace
for example tracing, I prepared do function."
datadog,I start tracing in function.
datadog,"func do() {
   ctx := context.Background()
   ctx, span := trace.StartSpan(ctx, ""sleeping..."")
   defer span.End()

   time.Sleep(10 * time.Second)
}
call do func in main func."
datadog,"func main() {
   opt := datadog.Options{
      Service:   ""your_service_name"",
      TraceAddr: ""your_datadog_agent_ip:8126"",
   }

   dd, err := datadog.NewExporter(opt)
   if err != nil {
      log.Fatal(err)
   }

   defer dd.Stop()

   trace.RegisterExporter(dd)
   trace.ApplyConfig(trace.Config{DefaultSampler: trace.AlwaysSample()})

   for {
      do() // <- here
   }
}
this is ok for tracing, next I connect log and trace."
datadog,"# Connect Log and Trace
set up logger."
datadog,look blew.
datadog,"package logger

import (
   ""context""
   ""encoding/binary""
   ""fmt""

   ""go.opencensus.io/trace""

   ""go.uber.org/zap""
   ""go.uber.org/zap/zapcore""
)

//Logger is singleton instance."
datadog,"var Logger *logger

type logger struct {
   logger *zap.Logger
}

func init() {
   cfg := zap.Config{
      Level:       zap.NewAtomicLevelAt(zap.InfoLevel),
      Development: false,
      Sampling: &zap.SamplingConfig{
         Initial:    100,
         Thereafter: 100,
      },
      Encoding: ""json"",
      EncoderConfig: zapcore.EncoderConfig{
         TimeKey:     ""ts"",
         LevelKey:    ""level"",
         MessageKey:  ""msg"",
         LineEnding:  zapcore.DefaultLineEnding,
         EncodeLevel: zapcore.CapitalLevelEncoder,
         EncodeTime:  zapcore.ISO8601TimeEncoder,
      },
      OutputPaths:      []string{""stdout""},
      ErrorOutputPaths: []string{""stdout""},
   }

   zapLogger, err := cfg.Build()
   if err != nil {
      panic(fmt.Errorf(""init logger err: %w"", err))
   }

   Logger = &logger{zapLogger}
}

//Info output log with INFO severity."
datadog,"func (l *logger) Info(ctx context.Context, msg string, fields ...zap.Field) {
   spanCTX := trace.FromContext(ctx).SpanContext()
   fields = append(
      fields,
      zap.Uint64(""dd.trace_id"", binary.BigEndian.Uint64(spanCTX.TraceID[8:])),
      zap.Uint64(""dd.span_id"", binary.BigEndian.Uint64(spanCTX.SpanID[:])),
   )
   l.logger.Info(msg, fields...)
}
follow program is point for connecting log and trace."
datadog,"spanCTX := trace.FromContext(ctx).SpanContext()
   fields = append(
      fields,
      zap.Uint64(""dd.trace_id"", binary.BigEndian.Uint64(spanCTX.TraceID[8:])),
      zap.Uint64(""dd.span_id"", binary.BigEndian.Uint64(spanCTX.SpanID[:])),
   )
   l.logger.Error(msg, fields...)
I add dd.trace_id and dd.span_id to log field."
datadog,dd.trace_id and dd.span_id is automatically tagged in datadog.
datadog,you can check dd.trace_id and dd.span_id in follows document.
datadog,"Connect Logs and Traces
If you prefer to manually correlate your traces with your logs, leverage the Datadog API to retrieve correlation‚Ä¶
docs.datadoghq.com

binary.BigEndian.Uint64(spanCTX.TraceID[8:]))
this process that encoding trace_id refer to github.com/DataDog/opencensusu-go-exporter-datadog/span.go ."
datadog,"https://github.com/DataDog/opencensus-go-exporter-datadog/blob/master/span.go
func (e *traceExporter) convertSpan(s *trace.SpanData) *ddSpan {
    startNano := s.StartTime.UnixNano()
    span := &ddSpan{
        TraceID:  binary.BigEndian.Uint64(s.SpanContext.TraceID[8:]),
        SpanID:   binary.BigEndian.Uint64(s.SpanContext.SpanID[:]),
        Name:     ""opencensus"",
        Resource: s.Name,
        Service:  e.opts.Service,
        Start:    startNano,
        Duration: s.EndTime.UnixNano() - startNano,
        Metrics:  map[string]float64{},
        Meta:     map[string]string{},
    }
        //omit
}
complete log setup."
datadog,so insert logging to do function.
datadog,"func do() {
   ctx := context.Background()
   ctx, span := trace.StartSpan(ctx, ""sleeping..."")
   defer span.End()

   logger.Logger.Info(ctx, ""hello world"") //<- here
   time.Sleep(10 * time.Second)
}
# Conclusion
if connecting trace and log, your debugging process become very easy."
datadog,it is not hard to setup.
datadog,so lets use DataDogAPM with OpenCensus!
datadog,"Integrating Airflow running on Docker + Datadog took way longer than I expected, so I decided to simplify it."
datadog,"Couple of requirements before you get into this guide:
Your Airflow instance is Dockerized
You are familiar with docker-compose
Configuring Airflow to write to Datadog‚Äôs StatsD agent
You can do this a few ways: editing airflow.cfg or by setting configuration options through ENV."
datadog,"I‚Äôm going to outline how to configure statsd on airflow through ENV vars:
Install airflow with statsd packaged in it."
datadog,"This is as easy as updating yourrequirements.txt from apache-airflow==1.10.7 to apache-airflow[statsd]==1.10.7
In your docker-compose.yml environment section add below ENV vars to enable statsd:
environment:
- AIRFLOW__SCHEDULER__STATSD_ON=True
- AIRFLOW__SCHEDULER__STATSD_HOST=datadog
- AIRFLOW__SCHEDULER__STATSD_PORT=8125
- AIRFLOW__SCHEDULER__STATSD_PREFIX=airflow
3."
datadog,Congratulations you are done.
datadog,"Adding Datadog to your docker-compose file
If you follow datadog‚Äôs example for configuring docker-compose.yml integrating datadog to your network is pretty simple."
datadog,But there is a few settings that you (probably) need.
datadog,"You‚Äôll need to expose 8125/udp port
I think you‚Äôll need to enable a couple of other ENV vars: DD_APM_ENABLED, DD_DOGSTATSD_NON_LOCAL_TRAFFIC, DD_DOGSTATSD_ORIGIN_DETECTION, DD_AC_INCLUDE
I‚Äôd recommend also setting your DD_HOSTNAME ENV var as well."
datadog,"I chose AIRFLOW-PROD (don‚Äôt fuck up and use an underscore, that was my rookie mistake)
The datadog section should look like:
datadog:
    image: datadog/agent:latest
    container_name: datadog
    ports:
     - ""8125:8125/udp""
    links:
     - airflow
    environment:
     - DD_API_KEY=
     - DD_HOSTNAME=AIRFLOW-PROD
     - DD_APM_ENABLED=true
     - DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true
     - DD_DOGSTATSD_ORIGIN_DETECTION=true
     - DD_AC_INCLUDE=""image:*""
    volumes:
     - /var/run/docker.sock:/var/run/docker.sock
     - /proc/:/host/proc/:ro
     - /sys/fs/cgroup:/host/sys/fs/cgroup:ro
    networks:
     - main
The finished docker-compose.yml file
version: ""3""
services:
  airflow:
    image: apache/airflow
    container_name: airflow
    restart: unless-stopped
    ports:
     - ""8080:8080""
     - ""8888:8888""
    environment:
     - AIRFLOW__SCHEDULER__STATSD_ON=True
     - AIRFLOW__SCHEDULER__STATSD_HOST=datadog
     - AIRFLOW__SCHEDULER__STATSD_PORT=8125
     - AIRFLOW__SCHEDULER__STATSD_PREFIX=airflow
    networks:
     - main
  # agent section
  datadog:
    image: datadog/agent:latest
    container_name: datadog
    ports:
     - ""8125:8125/udp""
    links:
     - airflow
    environment:
     - DD_API_KEY=
     - DD_HOSTNAME=AIRFLOW-PROD
     - DD_APM_ENABLED=true
     - DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true
     - DD_DOGSTATSD_ORIGIN_DETECTION=true
     - DD_AC_INCLUDE=""image:*""
    volumes:
     - /var/run/docker.sock:/var/run/docker.sock
     - /proc/:/host/proc/:ro
     - /sys/fs/cgroup:/host/sys/fs/cgroup:ro
    networks:
     - main
networks:
   main:
Running it
Run docker-compose and wait to see:
Creating airflow ... done
Creating datadog ... done
Hopefully your dashboard starts populating ‚Äî this was my (shitty) finished product:

Mistakes to avoid
Following this guide for using the datadog airflow-integration ‚Äî the huge issue here is that it‚Äôs aimed at users that are running airflow on the local machine + the datadog agent on that machine."
datadog,If you just have your airflow up on an EC2 box ‚Äî feel free.
datadog,But it looks like most airflow metrics come through to data-dog without it!
datadog,Following the datadog docker-compose guide and trying to use autodiscovery for the airflow integration above.
datadog,Turns out the airflow integration isn‚Äôt in the public catalog and cannot be auto discovered!
datadog,"But I really want to use the airflow integration‚Ä¶
Neither me nor Datadog support recommend this approach ‚Äî but here‚Äôs their response:
Hi Lukas,

I just wanted to follow up with you based on our chat from earlier as it seems like we got disconnected."
datadog,"The airflow integration is viable, but just not available to use with autodiscovery."
datadog,"As a workaround, you could run this Airflow integration as a custom check: https://docs.datadoghq.com/developers/write_agent_check/?tab=agentv6v7#overview."
datadog,This would involve copying the Airflow python code into a file in the agent's checks.d directory.
datadog,"Once this integration has been set up as a custom check, you can mount your custom yaml file using a ConfigMap: https://docs.datadoghq.com/agent/kubernetes/integrations/#configmap."
datadog,Would this suit your use case?
datadog,"Best,
Redacted | Solutions Engineer | Datadog
Good luck in your Airflow adventures."
datadog,"Source: Datadog
Setting up datadog monitoring to Monitor JVMs is one of the interesting tasks that I have come across during my work as a DevOps engineer."
datadog,You can find the step by step guide to configure the datadog agent in your VM to achieve this below.
datadog,Step 1: Install the datadog-agent in the Virtual Machine.
datadog,Use the easy one-step install.
datadog,Run the following command in your VM where the JVM runs.
datadog,"DD_AGENT_MAJOR_VERSION=7 DD_API_KEY=<API_KEY> bash -c ""$(curl -L https://raw.githubusercontent.com/DataDog/datadog-agent/master/cmd/agent/install_script.sh)""
Your Agent should be running and functioning properly."
datadog,It will continue to run in the background and submit metrics to Datadog.
datadog,"If you ever want to stop the Agent, run:
sudo stop datadog-agent
And run it again run:
sudo start datadog-agent
To configure hostname into datadog-agent, Open datadog.yaml
sudo vim /etc/datadog-agent/datadog.yaml
Add the following line (Change the hostname as required)
hostname: matillion-host
Step 2: Install java-agent into the Matillion VM
Next, download dd-java-agent.jar that contains the Agent class files:
sudo wget -O /etc/datadog-agent/dd-java-agent.jar 'https://repository.sonatype.org/service/local/artifact/maven/redirect?r=central-proxy&g=com.datadoghq&a=dd-java-agent&v=LATEST'
Configure java agent in JAVA_OPTS, Open /etc/sysconfig/tomcat8
In older versions of Matillion, JAVA_OPTS is configured in /etc/tomcat8/tomcat8.conf, So make sure you open the correct file."
datadog,"sudo vim /etc/sysconfig/tomcat8
Modify JAVA_OPTS variable adding -javaagent:/etc/datadog-agent/dd-java-agent.jar
It should look like something like below."
datadog,"JAVA_OPTS=""
-Djavax.net.ssl.trustStore=/usr/lib/jvm/jre/lib/security/cacerts \
-Djavax.net.ssl.trustStorePassword=changeit \ 
-Djava.security.egd=file:/dev/./urandom \
-javaagent:/etc/datadog-agent/dd-java-agent.jar \
-XX:+UseG1GC \ 
-XX:OnOutOfMemoryError=/usr/share/emerald/WEB-INF/classes/scripts/oom.sh""
Then restart the datadog-agent
sudo restart datadog-agent
After restarting the datadog-agent it should start sending JVM metrics to datadog."
datadog,The following metrics are collected by default after enabling JVM metrics.
datadog,"Source: Datadog
References:
https://www.datadoghq.com/blog/java-runtime-monitoring-with-jvm-metrics/
https://docs.datadoghq.com/tracing/setup/java/
https://docs.datadoghq.com/tracing/runtime_metrics/?tab=java"
datadog,One of the challenges when running a containerized application is implementing persistent services like logging.
datadog,"With more traditional application architecture you can rely on background processes (daemons) to ensure your persistent services are running across your entire application stack, but the whole point of containers is that they are abstracted from the server layer."
datadog,So how do you manage persistent services inside containers?
datadog,This is where Kubernetes DaemonSets come in.
datadog,A DaemonSet is a Kubernetes object that ensures that a (single) copy of a specific Pod is added to every Node.
datadog,"To illustrate the power of DaemonSets, we‚Äôre going to walk through how to set up DataDog logging for a Kubernetes-powered application using Maestro and a DaemonSet."
datadog,"In order to add DataDog to our application, we need to:
Configure our Kubernetes permissions to allow DataDog to access the application
Add the DataDog agent to the application as a DaemonSet
Re-deploy our application
Configure RBAC permissions
If our Kubernetes has role-based access control (RBAC) enabled we will need to configure RBAC permissions for our Datadog Agent service account."
datadog,"To run these commands we will need to ssh to the server, which can be done by either using the toolbelt command for that, namely:
cx ssh [--gateway-key <<The path to the key of gateway server>>] [-s ""your application name""] ""your server name""|<<server ip>>|<<server role>>
‚Ä¶or by visiting the server overview page on the Cloud 66 dashboard and following the SSH instructions on the right hand-side of the page."
datadog,"Once we are on the server, we need to run the following commands in order to configure the Kubernetes user:
sudo su 
export KUBECONFIG=/etc/kubernetes/admin.conf
Next we need to configure ClusterRole, ServiceAccount, and ClusterRoleBinding permissions for DataDog."
datadog,To do this we need to run curl <<URL>> -O for each of the URLs below.
datadog,This will create local copies of the YAML files on our server for each of the configuration objects needed.
datadog,"When the files have been created we should modify them as specified below:
For ServiceAccount and ClusterRoleBinding we should replace:
namespace: default
‚Ä¶with:
namespace: NAME_OF_NAMESPACE
Once this has been done, we run the following 3 commands on our server:
kubectl create -f clusterrole.yaml 
kubectl create -f serviceaccount.yaml 
kubectl create -f clusterrolebinding.yaml
These commands apply the new YAML files to our Kubernetes configuration."
datadog,"Set up a DaemonSet containing the DataDog configuration
To add the DataDog agent to our application we need to add a new element to our application‚Äôs service.yml file."
datadog,"For example:
service: 
  datadog: 
    image: datadog/agent:latest 
    type: daemon_set 
    service_account_name: datadog-agent
This will ensure that the latest datadog agent is added to every Pod that our application spawns."
datadog,"Note that the type is daemon_set and the service account name is datadog-agent, as set in the permissions that we have just configured."
datadog,"However this configuration is missing a few things:
We need to define the ports that DataDog will use
We need to add environment variables like the DataDog API key
We need to set constraints and health checks
We need to mount the volumes that DataDog will be tracking
Defining ports
DataDog tracing uses port 8126 and DogStatsD is enabled by default over UDP port 8125."
datadog,"We add these ports as follows:
services: 
  datadog: 
      image: datadog/agent:latest 
      type: daemon_set 
      service_account_name: datadog-agent 
      ports: 
      - container: 8126 tcp: 8126 
      - container: 8125 udp: 8125
This binds the external and internal (container) ports to DataDog‚Äôs preferred ports."
datadog,"Environment variables
We need to add the following environment variables:
DD_API_KEY ‚Äî can be found in your Datadog account, under Integrations ‚Üí APIs ‚Üí API Keys
DD_SITE ‚Äî the Datadog site you use (either datadog.com or datadoghq.eu)
DD_COLLECT_KUBERNETES_EVENTS ‚Äî set to true
DD_LEADER_ELECTION ‚Äî set to true
KUBERNETES ‚Äî set to true
DD_HEALTH_PORT ‚Äî set to 5555
DD_APM_ENABLED ‚Äî set to true
DD_LOGS_ENABLED ‚Äî set to true
DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL ‚Äî set to true
DD_AC_EXCLUDE: set to name:datadog-agent - this cuts down on the noise from the DataDog agent itself."
datadog,If you want to see its activity you can remove it from the exclude list.
datadog,"DD_KUBERNETES_KUBELET_HOST ‚Äî you can fetch this dynamically using this variable as a value ‚Äî ""$(CLOUD66_HOST_IP)""
DD_KUBELET_TLS_VERIFY ‚Äî set to false
Our configuration should now look something like this:
services: 
  datadog: 
     image: datadog/agent:latest 
     type: daemon_set 
     service_account_name: datadog-agent 
     ports: 
     - container: 8126 
       tcp: 8126 
     - container: 8125 
       udp: 8125 
     env_vars: 
       DD_API_KEY: 5f86b5d87e41ba1f383a16f60bbd8ea0 
       DD_SITE: datadoghq.eu 
       DD_COLLECT_KUBERNETES_EVENTS: 'true' 
       DD_LEADER_ELECTION: 'true' KUBERNETES: 'true' 
       DD_HEALTH_PORT: '5555' 
       DD_APM_ENABLED: 'true' 
       DD_LOGS_ENABLED: 'true' 
       DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL: 'true' 
       DD_AC_EXCLUDE: name:datadog-agent 
       DD_KUBERNETES_KUBELET_HOST: ""$(CLOUD66_HOST_IP)"" 
       DD_KUBELET_TLS_VERIFY: 'false'
Constraints and health checks
Constraints and health checks should be set as per the DataDog resources limits."
datadog,You can find out more about these settings in the DataDog docs.
datadog,"We‚Äôve used their minimum suggested specs for our example:
services: 
  datadog: 
    image: datadog/agent:latest 
    type: daemon_set 
    service_account_name: datadog-agent 
    ports: 
    - container: 8126 
      tcp: 8126 
  
    - container: 8125 
      udp: 8125 
    env_vars: 
       DD_API_KEY: 5f86b5d87e41ba1f383a16f60bbd8ea0 
       DD_SITE: datadoghq.eu 
       DD_COLLECT_KUBERNETES_EVENTS: 'true' 
       DD_LEADER_ELECTION: 'true' KUBERNETES: 'true' 
       DD_HEALTH_PORT: '5555' 
       DD_APM_ENABLED: 'true' 
       DD_LOGS_ENABLED: 'true' 
       DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL: 'true' 
       DD_AC_EXCLUDE: name:datadog-agent 
       DD_KUBERNETES_KUBELET_HOST: ""$(CLOUD66_HOST_IP)"" 
       DD_KUBELET_TLS_VERIFY: 'false' 
    constraints: 
        resources: 
           memory: 256M 
           cpu: 200 
   health: 
       alive: 
           type: http 
           endpoint: ""/health"" 
           success_threshold: 1 
           failure_threshold: 3 
           timeout: 5 
           initial_delay: 15 
           period: 15 
           port: 5555
Mounting volumes
Finally, we need to mount the volumes that we plan to track."
datadog,We mount volumes by defining them in the service.yml which makes them available to DataDog.
datadog,"The general format for mounting volumes is: /outside/container/path:/inside/container/path
Our final service.yml should look a lot like this:
services: 
  datadog: 
    image: datadog/agent:latest 
    type: daemon_set 
    service_account_name: datadog-agent 
    ports: 
    - container: 8126 
      tcp: 8126 
    - container: 8125 
      udp: 8125 
    env_vars: 
       DD_API_KEY: 5f86b5d87e41ba1f383a16f60bbd8ea0 
       DD_SITE: datadoghq.eu 
       DD_COLLECT_KUBERNETES_EVENTS: 'true' 
       DD_LEADER_ELECTION: 'true' KUBERNETES: 'true' 
       DD_HEALTH_PORT: '5555' 
       DD_APM_ENABLED: 'true' 
       DD_LOGS_ENABLED: 'true' 
       DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL: 'true' 
       DD_AC_EXCLUDE: name:datadog-agent 
       DD_KUBERNETES_KUBELET_HOST: ""$(CLOUD66_HOST_IP)""   
       DD_KUBELET_TLS_VERIFY: 'false' 

    constraints: 
       resources: 
          memory: 256M 
          cpu: 200 
    health: 
       alive: 
          type: http 
          endpoint: ""/health"" 
          success_threshold: 1 
          failure_threshold: 3 
          timeout: 5 
          initial_delay: 15 
          period: 15 
          port: 5555 
       volumes: 
       - ""/proc:/host/proc:ro"" 
       - ""/var/run/docker.sock:/var/run/docker.sock"" 
       - ""/sys/fs/cgroup:/host/sys/fs/cgroup:ro"" 
       - ""/opt/datadog-agent/run:/opt/datadog-agent/run""
Originally published at https://blog.cloud66.com on January 23, 2020."
datadog,"On Observability & Monitoring
Observability is achieved by making health and operational measurements available from within the system that you wish to monitor."
datadog,Monitoring is the actual task of collecting data measurements and displaying this data.
datadog,"After you‚Äôve made the system observable, and after you‚Äôve collected the data using a monitoring tool, Analysis of the data either manually or automatically should yield actionable insights."
datadog,"Without meaningful analysis, one would fall short of the whole purpose of making the system observable and performing monitoring in the first place."
datadog,"The better your analysis capabilities are, the more valuable your investments in observability and monitoring become."
datadog,"Recipe for Kubernetes Security
Knowing which security risks affect your system is the first step toward addressing them."
datadog,"A practical implementation of this paradigm would follow the following recipe:
Security oriented observations exposed as metrics."
datadog,"For example:
Gauge that captures the current number of Critical level vulnerabilities of the Kubernetes Worker Node software (kubelet, container runtime, kube-proxy‚Ä¶)
Gauge that captures the count of Critical CVEs of the presently running envoy sidecars
Gauge that captures the non-whitelisted privileged Daemon Sets
2."
datadog,Collecting security metrics by using existing monitoring pipeline.
datadog,"For example:
Prometheus, a pluggable metrics collection and storage system that can act as a data source for Grafana, a metrics visualization frontend."
datadog,Prometheus requires the collectors to pull metrics from each from security agents that expose such observable metrics.
datadog,"Datadog, NewRelic, Sumo Logic & similar APM solutions that can ingest metrics via the platform APIs
3."
datadog,Monitoring security metrics by using the already existing monitoring stack.
datadog,"For example:
Prometheus enables to monitor the security metrics over time as well as define alerts triggered by specific system behavior
With Datadog, one simple example can be by having the user define custom dashboards that graph metrics, or define a threshold based alert by comparing metric values to a static threshold."
datadog,"Kubernetes Security Observability Companion
Alcide Advisor simplifies the security assessment of the entire Kubernetes cluster, by providing a single window to monitor all the configuration related risks such as Kubernetes software components vulnerability (CVE) scanning, identifying misplaced secrets, excessive API server secret access permissions, pod hardening, application of network policies, as well as Istio security configuration and best practices, Ingress controllers security best practices, Kubernetes API server access privileges scanning and Kubernetes operators security best practices."
datadog,"The entire process is completely API driven, and carried over in the background without having any impact on apps or the cluster itself and expose security insights in a fully observable security metrics."
datadog,"Bridging Ops & Security ‚Äî Seamlessly and Continuously
Ops & Security teams, separately and together, try to reduce and potentially unify the number of tools they use to operate and monitor cloud systems."
datadog,It turns out that Kubernetes and specifically Kubernetes security is no different.
datadog,"Grafana dashboard visualizes and inspects latest security hygiene and risk insights
Alcide Advisor ‚Äî Delivering Security at Ops Comfort Zone
Security stakeholders can define what to scan, scope of the scan, and frequency."
datadog,"Ops teams responsible for deploying the Alcide Advisor ‚Äî to running clusters as part of the standard monitoring stack with prometheus, elastic, datadog and alike."
datadog,"Alcide Advisor reports security scan results through:
Exposed prometheus scraping endpoint, with set of security metrics that captures cluster security hygiene and security risk levels."
datadog,"Alcide Advisor cloud-based central security management dashboard(s)
A convenience Grafana dashboard is available to visualize and inspect latest security hygiene and risk insights

Finally, when security metrics are wired into our telemetry/monitoring stack, we can leverage all the existing tool chains being used to trigger & route alerts and notifications about security related ‚Äúnegative‚Äù drifts or risk degradation."
datadog,"Try Kubernetes Advisor in your comfort zone in 4 simple steps:
Create a Free Alcide Account
Login and deploy Alcide Advisor into your cluster
Enable the metrics endpoint and create prometheus service monitor
Consume findings with the rest of your Grafana dashboards"
datadog,"I had the opportunity to introduce Datadog APM in my work, so I would like to briefly summarize the method."
datadog,"What I want to do with Datadog
Setting custom agent host
Change service name
Switch TraceList page every environment
Link logs such as queries to one request
Install Datadog Tracer
Tracing Go Applications
For configuration instructions and details about using the API, see the Datadog API documentation."
datadog,"For manual‚Ä¶
docs.datadoghq.com

Please install using the following command."
datadog,"$ go get gopkg.in/DataDog/dd-trace-go.v1/ddtrace
At the moment, we use echo as the framework, and use gorm as ORM."
datadog,"Therefore, the target files are as follows."
datadog,"$ cd $GOPATH/pkg/mod/gopkg.in/\!data\!dog/dd-trace-go.v1@v1.18.0
$ tree contrib/jinzhu
contrib/jinzhu
‚îî‚îÄ‚îÄ gorm
    ‚îú‚îÄ‚îÄ example_test.go
    ‚îú‚îÄ‚îÄ gorm.go
    ‚îú‚îÄ‚îÄ gorm_test.go
    ‚îî‚îÄ‚îÄ option.go
$ tree contrib/labstack
contrib/labstack
‚îî‚îÄ‚îÄ echo
    ‚îú‚îÄ‚îÄ echotrace.go
    ‚îú‚îÄ‚îÄ echotrace_test.go
    ‚îú‚îÄ‚îÄ example_test.go
    ‚îî‚îÄ‚îÄ option.go
Looking official documentations
I refer to the following three."
datadog,"Tracing Go Applications
For configuration instructions and details about using the API, see the Datadog API documentation."
datadog,"For manual‚Ä¶
docs.datadoghq.com

Package echo
Package echo provides functions to trace the labstack/echo package (https://github.com/labstack/echo)."
datadog,"godoc.org

Package gorm
import ""gopkg.in/DataDog/dd-trace-go.v1/contrib/jinzhu/gorm"" Package gorm provides helper functions for tracing the‚Ä¶
godoc.org

Implementation
Setting custom agent host and Change service name."
datadog,"func startDatadogTrace() {
    // See: https://docs.datadoghq.com/ja/tracing/setup/go/#change-agent-hostname 
    addr := net.JoinHostPort(  
        os.Getenv(""DD_AGENT_HOST""),   
        os.Getenv(""DD_TRACE_AGENT_PORT""),
    )
    // start the tracer with zero or more options   
    tracer.Start(tracer.WithServiceName(""my-app""), tracer.WithAgentAddr(addr))
}
This completes the implementation of start to trace."
datadog,‚ÄªDon‚Äôt forget to implement `tracer.Stop()` in the caller.
datadog,"Switch TraceList page every environment
With the above implementation alone, TraceList cannot be divided for each environment, so we will make some changes."
datadog,"func startDatadogTrace() {
    // See: https://docs.datadoghq.com/ja/tracing/setup/go/#change-agent-hostname
    addr := net.JoinHostPort(
        os.Getenv(""DD_AGENT_HOST""),
        os.Getenv(""DD_TRACE_AGENT_PORT""),
    )
    var opts []tracer.StartOption
    opts = append(opts, tracer.WithServiceName(""my-app""), tracer.WithAgentAddr(addr))
    datadogEnv := os.Getenv(""DATADOG_ENV"")
    if datadogEnv != """" {
        opts = append(opts, tracer.WithGlobalTag(ext.Environment, datadogEnv))
    }
    // start the tracer with zero or more options
    tracer.Start(opts...)
}
It doesn‚Äôt need to be an environment variable, but you need to pass `tracer.WithGlobalTag(ext.Environment, datadogEnv)` to `tracer.Start`."
datadog,"By doing this, you can switch the environment as shown in the following screenshot."
datadog,"Link logs such as queries to one request
I struggled with this very much."
datadog,The official documentation says to implement as follows.
datadog,"echo
Package echo
Package echo provides functions to trace the labstack/echo package (https://github.com/labstack/echo)."
datadog,"godoc.org

// Create a new instance of echo
r := echo.New()

// Use the tracer middleware with your desired service name."
datadog,"r.Use(Middleware(WithServiceName(""image-encoder"")))

// Set up some endpoints."
datadog,"r.GET(""/image/encode"", func(c echo.Context) error {
    // create a child span to track an operation
    span, _ := tracer.StartSpanFromContext(c.Request().Context(), ""image.encode"")

    // encode an image ...

    // finish the child span
    span.Finish()

    return c.String(200, ""ok!"")"
datadog,"})
gorm
Package gorm
import ""gopkg.in/DataDog/dd-trace-go.v1/contrib/jinzhu/gorm"" Package gorm provides helper functions for tracing the‚Ä¶
godoc.org

// Register augments the provided driver with tracing, enabling it to be loaded by gormtrace.Open."
datadog,"sqltrace.Register(""postgres"", &pq.Driver{}, sqltrace.WithServiceName(""my-service""))

// Open the registered driver, allowing all uses of the returned *gorm.DB to be traced."
datadog,"db, err := gormtrace.Open(""postgres"", ""postgres://pqgotest:password@localhost/pqgotest?sslmode=disable"")
defer db.Close()
if err != nil {
    log.Fatal(err)
}

user := struct {
    gorm.Model
    Name string
}{}

// All calls through gorm.DB are now traced."
datadog,"db.Where(""name = ?"
datadog,""", ""jinzhu"").First(&user)
If this is implemented almost as it is, the query will be linked to one request and displayed, but a separate log of the query will also be transferred."
datadog,"Shamefully, it took me a long time to solve this."
datadog,"(Even if you ask, you can‚Äôt get a clear answer.)"
datadog,So I looked at DatadogTracer‚Äôs grom implementation.
datadog,// Open opens a new (traced) database connection.
datadog,"The used dialect must be formerly registered
// using (gopkg.in/DataDog/dd-trace-go.v1/contrib/database/sql).Register."
datadog,"func Open(dialect, source string, opts ...Option) (*gorm.DB, error) {
    sqldb, err := sqltraced.Open(dialect, source)
    if err != nil {
        return nil, err
    }
    db, err := gorm.Open(dialect, sqldb)
    if err != nil {
        return db, err
    }
    return WithCallbacks(db, opts...), err
}
The important thing is the `gormtrace.WithCallbacks` function."
datadog,// WithCallbacks registers callbacks to the gorm.DB for tracing.
datadog,"// It should be called once, after opening the db."
datadog,"// The callbacks are triggered by Create, Update, Delete,
// Query and RowQuery operations."
datadog,"func WithCallbacks(db *gorm.DB, opts ...Option) *gorm.DB {
    afterFunc := func(operationName string) func(*gorm.Scope) {
        return func(scope *gorm.Scope) {
            after(scope, operationName)
        }
    }

    cb := db.Callback()
    cb.Create().Before(""gorm:before_create"").Register(""dd-trace-go:before_create"", before)
    cb.Create().After(""gorm:after_create"").Register(""dd-trace-go:after_create"", afterFunc(""gorm.create""))
    cb.Update().Before(""gorm:before_update"").Register(""dd-trace-go:before_update"", before)
    cb.Update().After(""gorm:after_update"").Register(""dd-trace-go:after_update"", afterFunc(""gorm.update""))
    cb.Delete().Before(""gorm:before_delete"").Register(""dd-trace-go:before_delete"", before)
    cb.Delete().After(""gorm:after_delete"").Register(""dd-trace-go:after_delete"", afterFunc(""gorm.delete""))
    cb.Query().Before(""gorm:query"").Register(""dd-trace-go:before_query"", before)
    cb.Query().After(""gorm:after_query"").Register(""dd-trace-go:after_query"", afterFunc(""gorm.query""))
    cb.RowQuery().Before(""gorm:row_query"").Register(""dd-trace-go:before_row_query"", before)
    cb.RowQuery().After(""gorm:row_query"").Register(""dd-trace-go:after_row_query"", afterFunc(""gorm.row_query""))

    cfg := new(config)
    defaults(cfg)
    for _, fn := range opts {
        fn(cfg)
    }
    return db.Set(gormConfigKey, cfg)
}
That way, you don‚Äôt need to call `sqltrace.Register` nor `gormtrace.Open`."
datadog,The final implementation is as follows.
datadog,"func connectDB() *gorm.DB {
    connection := os.Getenv(""MYSQL_CONNECTION"")

    db, err := gorm.Open(""mysql"", connection)
    if err != nil {
        panic(err.Error())
    }

    // Add callbacks for Datadog."
datadog,"db = gormtrace.WithCallbacks(db)
    return db
}
Conclusion
Of course, it‚Äôs important to look at the official documentations."
datadog,It‚Äôs also important to look at the implementation of the library and figure out how to implement it right for your application.
datadog,"In recent months, we have been on a mission here at Compass to migrate all our observability tools to Datadog."
datadog,As part of this larger process it had come time to migrate from Pingdom to Datadog Synthetics.
datadog,This is the story of that migration process.
datadog,"Problem Overview
The basic principle of a synthetics monitoring is to regularly send an HTTP request to an endpoint from one or multiple AWS regions and then validate that the responses arrive within a timeout and with the right status."
datadog,"In the case of a failure, the test can send out a notification to the owner of the service."
datadog,"These notifications can be sent to one or many on-call services, Slack channels or email addresses."
datadog,At Compass we have traditionally used Pingdom checks for validating the availability of our services.
datadog,At the time of the migration we had built up a collection of hundreds of Pingdom monitors for our services that all had to be migrated to Datadog.
datadog,Luckily a synthetic user-test in Datadog maps almost perfectly from Pingdom‚Äôs Uptime test so the problem space is fairly clear.
datadog,"What throws a wrench in the machinery are the sometimes small differences between the two systems:
The tag structure in Datadog has a namespace component so a tag like consumer-search in Pingdom can correspond to two separate tags such as team:consumer-search and app:consumer-search in Datadog."
datadog,The Slack and on-call integrations in the two systems both operate on internal IDs such that the on-call service consumer-search-backend has integration ID X in Pingdom and Y in Datadog.
datadog,The default values in each system are different.
datadog,"While the default timeout in Pingdom is 30 seconds, it is 2 seconds in Datadog."
datadog,"Best Practices of Technical Migrations
Before we dive into the details, this is a good time to review some basics for migrating data."
datadog,"Here is the master advice for all migration tasks:
Script it!"
datadog,Always.
datadog,Scripts are not for saving time.
datadog,They are primarily useful for encoding assumptions and maintaining quality in the migrated dataset.
datadog,Write a script that you can run multiple times without creating duplicates or other artifacts.
datadog,As you encode your assumptions you will be testing them and some of them will turn out to need tweaking before the process is over.
datadog,Being able to re-run the process is absolutely essential.
datadog,"Now with that said, here is some lower priority advice that we have found useful:
Do not touch the data in the target environment until you have made a formal decision that the migration is complete and any additional changes will be made in the target environment only."
datadog,Be liberal with error generation whenever an unhandled case shows up.
datadog,This will be your guide to determining when you are done.
datadog,"If need be, write additional validation scripts for any questions that may arise."
datadog,"Implementation
All scripts were written using Python 3.7 using the standard JSON library and the requests library for HTTP."
datadog,"First party integration libraries for Pingdom, the on-call system and Datadog were foregone in favor of using the plain HTTP API endpoints each service provided."
datadog,This helped us in debugging which was preferable to any performance gains of the vendor libraries.
datadog,"Now, ideally you would write a single script that runs the entire process."
datadog,"Read the data from Pingdom, bake it to the Datadog format and upload it to its new home."
datadog,As we shall see this process was not very handy in our case.
datadog,We decided instead to adopt a strategy of creating a set of scripts and caching the in-between results in local JSON files.
datadog,This made each script simpler and provided good ways of reviewing intermediate results as well as providing better support for manually managed mappings such as the ones for tags and integrations.
datadog,"Scope of Data Being Migrated
Test URL
Request headers
Test status (live or paused)
Expected response time
Expected response status
Expected response content-type
Tags
On-call notifications
Slack notifications
Email notifications
Most of these were straightforward so we will focus now on a few of the hands-on problems we ran into."
datadog,"Mapping Tags, One-to-Many
After aggregating all the tags used in Pingdom we could conclude that there were less than 100 tags and the clearest way to proceed was to manually map these tags to tags already used in Datadog."
datadog,"As mentioned before it was not necessarily a 1to1 relation so we ended up with a JSON file with a list of tags and their mapped counterparts in Datadog, such as:
""consumer-search"": [
    ""team:consumer-search"", ""app-search""
]
This JSON file could then be reviewed and updated in case a miss was made."
datadog,"On-call System
The on-call notifications were the trickiest part of the migration."
datadog,Both systems introduced a separate layer of abstraction between the test and the on-call service ID.
datadog,Each has a different notion of an Integration.
datadog,The integration object holds the ID for the on-call service and the test holds only a reference to the integration.
datadog,"Both systems has one level of indirection when integrating with the on-call service
Luckily Pingdom allowed for exporting these integrations together with the corresponding on-call service ID."
datadog,After also exporting all services from the on-call service we could start to create a mapping from Pingdom integrations to services.
datadog,The resulting data looked something like below.
datadog,The main key in the listing is the Pingdom integration ID and the ‚Äúoncall_id‚Äù field is the raw on-call service id.
datadog,"""12345"": {
    ""pingdom‚Äù: ‚Äú[Consumer Search] Critical"",
    ""oncall_id‚Äù: ‚Äúabcdef0123456789"",
    ""oncall_service‚Äù: ‚Äú[Consumer Search] React App""
}
This is where the process hit a snag."
datadog,The natural next step would be to analogously export the integrations from Datadog but this is not possible.
datadog,Only creating new integrations is allowed.
datadog,Here it is worth taking a detour to review how integrations work in Datadog.
datadog,Each notification integration is an @-mention in the message field of the test.
datadog,So to email Jane Doe you add @jane.doe@compass.com to your message field and an email will be sent on test failure.
datadog,Likewise the on-call integrations are @-mentions to the name of the integration.
datadog,"In the end, after reviewing the list of integrations in need of migration, we could manually add the integrations we know are already available in Datadog."
datadog,"The rest we could script an import for, and then amend the mapping file with a final Datadog integration."
datadog,Below is the final entry in the mapping.
datadog,The datadog field is the final Datadog @-mention required in the test message field.
datadog,"""12345"": {
    ""pingdom‚Äù: ‚Äú[Consumer Search] Critical"",
    ""oncall_id‚Äù: ‚Äúabcdef0123456789"",
    ""oncall_service‚Äù: ‚Äú[Consumer Search] React App""
    ""datadog‚Äù: @oncall-ConsumerSearch-ReactApp"",
}
Shhhhh, don‚Äôt tell Mom
Another particular issue with migrating the tests automatically and including the notification settings is that if something goes wrong, everyone and their mother may get a page in the middle of the day, not because the service itself has failed but because our brand new test is not migrated or calibrated properly."
datadog,To reduce the number of unnecessary pages going out we took a two-pronged approach.
datadog,By default we created all new tests as paused and with a single notification policy sending failures to an email address controlled by the migration team.
datadog,"Once the migration of data had been generally validated we could independently validate that first, the test runs successfully and also, while keeping the test paused, add all notifications and validate them in the target environment, all using manually executed scripts."
datadog,When we were satisfied with both; a single final step pushed all tests live with the on-call notifications enabled.
datadog,"Validation
Once we had all tests running in Datadog the question arises, are we done now?"
datadog,This too was answered using a script.
datadog,We re-exported all checks from Pingdom and using the mapping file that was the result of the entire process we could validate that each check had an online running counterpart in Datadog.
datadog,"Future Work
The namespace structure of tags in Datadog allows us to validate that all tests are associated with a team and that the correct team is notified in the on-call service for each test."
datadog,This work is ongoing and will result in more robust on-call notifications being sent out during an incident.
datadog,"Summary
In working to aggregate all observability tools in one place we decided to migrate HTTP ping tests from Pingdom to Datadog Synthetics."
datadog,This was done using scripts.
datadog,The main crux of the process was migrating third-party integrations as these had multiple levels of indirection.
datadog,The solution to these problems was achieved through export and aggregation of integration data from all systems into a migration mapping file between the two systems.
datadog,"In the end, 100% of the tests were migrated from Pingdom to Datadog Synthetics."
datadog,"A major contributor to the project‚Äôs success was the application of some basic principles of data migration and to be honest, the magic of a little bit of python."
datadog,"Overview
Traditional logging solutions require teams to provision and pay for a daily volume of logs, which quickly becomes cost-prohibitive without some form of server-side or agent-level filtering."
datadog,"But filtering logs before sending them inevitably leads to gaps in coverage, and often filters out valuable data."
datadog,"After all, logs constantly change in value based on factors that can‚Äôt be anticipated ahead of time, such as whether the log was generated during normal operations, or during an outage or deployment."
datadog,"Datadog log management (SaaS based solution) removes these limitations by decoupling log ingestion from indexing, which makes it possible to cost-effectively collect, process, and archive all logs."
datadog,Datadog logging without limits enables us to collect all our logs from all sources without the cost or complexity.
datadog,"Datadog can parse, enrich, live tail n archive every log in our environment, generate metric from logs, dynamically choose which log to retain n index for further analysis and detect pattern and anomaly in our data."
datadog,"¬∑ Dynamically choose which logs to index and retain for troubleshooting and analytics (and override these filters as needed)
¬∑ Archive enriched logs in your long-term cloud storage solution at no additional cost
¬∑ Observe and query a Live Tail of all processed logs across your entire infrastructure (even the ones you choose not to index)

Best practice for centralized logging solution

No single tool is capable enough to handle all logging requirement in enterprise level with heterogeneous system."
datadog,Reporting and logging requirement vary with client and each vertical layer.
datadog,"Hence, our solution should be extensible to cope with all kinds of requirements e.g."
datadog,"data compliance, audit, client or management."
datadog,"In above model, all logs from different sources will be collected to centralized location."
datadog,"Centralized location could be anything like S3 and data can be shipped using AWS Kinesis, beat utility or custom solution."
datadog,"Point here is, once have all log data at centralized location, can be viewed by multiple logging and analytical solution in RO mode to have customized visualization and reporting solution."
datadog,"Above, I have integration with Datadog log management solution and second, I have custom solution for specific client who doesn‚Äôt wants to use SaaS service (Datadog) due to regulatory requirement."
datadog,What if there is a need to transform the log?
datadog,This solution is valid for legacy application only.
datadog,Doesn‚Äôt apply for immutable infra or containerized solution where host name doesn‚Äôt matter.
datadog,I am referring AWS Kinesis to collect the data at S3.
datadog,Problem is what if I am having 10 web server (IIS server where we don‚Äôt get server detail in logs) and two server is causing issue to end user.
datadog,Its really difficult to know which two server causing issue and hence transforming the raw data in AWS Kinesis Firehose level.
datadog,Keep one copy of raw data to meet regulatory requirement.
datadog,"Approach to use Datadog for log management in above scenario
Most modern platforms like AWS and Kubernetes create dynamic environments by quickly spinning up instances or containers with significantly shorter lifespans than physical hosts."
datadog,"In these environments, where large-scale applications can be distributed across multiple ephemeral containers or instances, tagging is essential to monitoring services and underlying infrastructure."
datadog,"So, First step is to tag all logs data e.g."
datadog,Product:ABC; Application:IIS; environment:prod; tier:web.
datadog,Will use these tags to use in pipeline to identify the data to data parsing and massaging.
datadog,"For example, app:iis tag will be used in IIS pipeline to collect and parse IIS log."
datadog,"Once have all log data processed by their respective pipelines, it will be stored in index for log search and analytics purpose."
datadog,DD index uses TAG to filter log data to store only selective logs.
datadog,For example.
datadog,Product:app filter at index level will store log that contains this tag.
datadog,Data flow in Datadog
datadog,In my September 2019 post I summarized how we used the monitoring capabilities of Datadog to generate insights into our own backend infrastructure.
datadog,With an environment that has grown over the years investing in the understanding of our own systems was very helpful for our further growth.
datadog,It enabled us to make good decisions about where to invest more in improving the system for instance.
datadog,I called this phase 1 of our Datadog journey in the September post and it ended with ous having a collection of dashboards at our hands showing us all kinds of telemetry on all our backend infrastructure systems and services.
datadog,By then we knew what was going on.
datadog,"But this was not the end of our journey, so allow me to lead you through the next steps we took to set up automated alarming and put an incident response process into place."
datadog,"So our goal was to improve from ""what is going on?"""
datadog,"to ""is it ok?"""
datadog,Phase 2 ‚Äî Is it ok?
datadog,"So let's take a look into one of our dashboard metrics:

This image shows just a small area of one of our operational dashboards, but its enough to discuss a couple of things."
datadog,More specific you see the performance of our so-called TabSync endpoint (which we use to sync information between multiple devices within the same venue) over the course of the last hour.
datadog,"Row one shows the development of incoming requests as a rate (requests/s), row to shows average response times in ms and row three gives us the percentage of error responses (4xx and 5xx) on the total responses."
datadog,"Looking good, isn't it?"
datadog,"Yes, it is!"
datadog,"Though it might be we could more easily draw this conclusion, with some visual guidance on the dashboard."
datadog,"Looking at the time-series chart for the response times, we can add this guidance by adding some colored areas and we can do the same with the query-value widget on the left of the chart."
datadog,There is now a green area on the chart indicating that all values in this area are good.
datadog,And there is a red area indicating that values in this area are considered bad.
datadog,"We also find an orange area, which serves as a ""warning buffer""."
datadog,It is pretty straightforward to add this kind of color-coding to Datadog dashboards.
datadog,The harder part clearly is to decide about the thresholds.
datadog,"In our example, we consider all response times up to 200ms to be good and everything above 400ms to be an issue."
datadog,It took us some weeks of collecting and digesting data and seeing it on the dashboard to understand how our metrics behave over a course of a day and week (seasonalities are big in our market).
datadog,"After that, we could define thresholds for each and every endpoint and metric without fearing to change them too often in the future."
datadog,"Let's take a look at one of our operating system level dashboards, where we find the color-coding all over the place:

Even without knowing the details you can see that all looks good at the operating system level."
datadog,"Automated Alarming
After we have decided on thresholds for all relevant metrics of our system, we moved on to set up automated alarming."
datadog,"It's a good thing to see something red on a dashboard in case of an issue, but since we are not starring at our dashboards all the time, it would be even better, if we get paged in case of an issue."
datadog,"With Dadatog this means creating so-called monitors, where every monitor checks for one metric and alarms in case this metric is out of bounds."
datadog,"We found it to be a good practice to use the exact same metrics, parameters, and thresholds on the dashboards as in the corresponding monitors."
datadog,"So in case, something is red on the dashboard a monitor is triggered and vice versa."
datadog,The next screenshot shows you a subset of the monitors we have created.
datadog,"Whenever a monitor is triggered because of its monitored metric going out of bounds, a notification is sent."
datadog,"In our setup, we always send notifications into a Slack channel and we always forward notifications to PagerDuty, which we use for on-call duty scheduling and paging."
datadog,Depending on the severity of the notification PagerDuty will call the on-call team during day and night or just in our usual office hours.
datadog,We found it beneficial to have a clear understanding of the severity of alarms so that we are able to operate on different SLAs.
datadog,The reason for also posting monitor notifications into a slack channel is mainly for documentation purposes.
datadog,"It is just very convenient to see a stream of monitor notifications in slack, especially as they are shown with a snapshot of the metric in question."
datadog,And this concludes part II of this series on how we created operations monitoring at orderbird.
datadog,Part III will tell you about our approach to automate dashboard and monitor creation using Terraform.
datadog,":Photo by Kaushik Panchal on Unsplash
This article is split into two parts:
Background on CloudFormation and an introduction to Custom Resources."
datadog,Monitoring as Code: Managing Datadog monitors with CloudFormation.
datadog,"If you‚Äôd like to skip ahead, all the code discussed in this post is available on my GitHub HERE."
datadog,"CloudFormation
CloudFormation is a fantastic ‚Äòinfrastructure as code‚Äô offering from AWS which allows you to efficiently model a collection of resources and manage them throughout their lifecycles."
datadog,"The AWS ‚ÄòSpaghetti Bowl‚Äô continues to grow at a rate of knots, meaning even CloudFormation cannot keep up with them all, but do not fear as we‚Äôre able to plug any gaps and more using custom resources."
datadog,"Infrastructure as code is the new normal when it comes to the cloud, it gives you an insight into how your environment came to be and the confidence to update your stack without causing any critical errors."
datadog,Examples include CloudFormation and Terraform.
datadog,"CloudFormation provides a common language to describe and provision all infrastructure in your cloud environment, it provisions resources in a repeatable manner, and since everything is written as code can be version controlled."
datadog,CloudFormation provisions and configures resources by making calls to the AWS services that are described in your template.
datadog,"After all the resources have been created, it reports that your stack has been created and is ready for use."
datadog,"If stack creation fails, CloudFormation rolls back your changes."
datadog,"Sometimes you‚Äôll want to do something that isn‚Äôt supported out of the box by CloudFormation, this could be a manual step post deployment or even provision some infrastructure outside the AWS ecosystem."
datadog,"Fortunately, custom resources make this very easy to do."
datadog,"Custom Resources
Custom resources enable you to write custom provisioning logic in templates that AWS CloudFormation runs anytime you create, update or delete a stack."
datadog,"If a Custom Resource has been defined in your template, CloudFormation will send an external request to the resource provider endpoint during a stack operation and wait for a response."
datadog,Data from the response can subsequently be used to provision and configure other resources.
datadog,"A custom resource can be defined in your Cloudformation template as follows:
CustomResource:
    Type: 'Custom::MyCustomResourceTypeName'
    Properties: 
      ServiceToken: RequestAddress
      var1: variable1
      var2: variable2
Custom resources only require one property: ServiceToken, which will tell Cloudformation where to send the request, however additional properties can also be included."
datadog,For lambda-backed Custom resources the ServiceToken will be the lambda Arn and Cloudformation will send a request in the form of an event.
datadog,"An example request is shown below:
{
    ""RequestType"": ""Create"",
    ""ServiceToken"": ""lambda-arn"",
    ""ResponseURL"": ""http://pre-signed-S3-url-for-response"",
    ""StackId"": ""cloudformation-stack-id"",
    ""RequestId"": ""request-id"",
    ""LogicalResourceId"": ""CustomResource"",
    ""ResourceType"": ""Custom::MyCustomResourceTypeName"",
    ""ResourceProperties"": {
        ""ServiceToken"": ""lambda-arn"",
        ""var1"": ""variable1"",
        ""var2"": ""variable2""
    }
}
Once a request has been sent, Cloudformation will wait for a response in the pre-signed URL: ResponseURL."
datadog,"The RequestType can be either Create, Update or Delete depending on the type of operation."
datadog,"The Custom resource provider will process the request, perform whatever task you require, and return a response of SUCCESS or FAILED to the pre-signed URL."
datadog,If a no response or a Failed status is returned the CloudFormation operation will fail and rollback.
datadog,"{
    ""Status"": ""SUCCESS"",
    ""PhysicalResourceId"": ""function-return-value"",
    ""StackId"": ""cloudformation-stack-id"",
    ""RequestId"": ""request-id"",
    ""LogicalResourceId"": ""CustomResource"",
    ""Data"": {
        ""out1"": ""output1"",
        ""out2"": ""output2""
    }
}
Any values included in the Data field are stored in the pre-signed url location and can be referenced in the template using the !GetAtt function."
datadog,"To retrieve the out1 value from the above output, you would use the following command: !GetAtt CustomResource.out1 ."
datadog,"Lambda-backed Custom Resources
When a lambda is used as a custom resource provider, the function is invoked whenever the custom resource is created, updated or deleted."
datadog,CloudFormation invokes the function with the request data (as above) and waits for a response.
datadog,"Fortunately, there are a number of libraries that make writing custom resources very easy."
datadog,The one I will be using is the custom-resource-helper: a Python-based library provided by AWS that uses decorators.
datadog,The Custom Resource Helper is a wonderful package which drastically reduces the complexity of deploying lambda-backed custom resources.
datadog,The code below can be used as a starting point for lambda development.
datadog,"It can be broken down into the following bullet points:
First the CfnResource class is imported."
datadog,A CfnResource object is instantiated and called helper.
datadog,"The create, update and delete decorators determine which function will be invoked for the difference CloudFormation stack actions."
datadog,"The resource properties, which are defined in the CloudFormation template are available in the ResourceProperties object within the lambda event."
datadog,Anything saved in the Data object in the helper object can be referenced by other resources in the CloudFormation template using the !Get Att intrinsic function.
datadog,"Upon each successful execution of the functions, the helper object takes care of uploading the response to the ResponseUrl as defined in the lambda event."
datadog,"Monitoring as Code: Managing Datadog Monitors with CloudFormation
To truly demonstrate some of the benefits of CloudFormation custom resources, I‚Äôve included a walkthrough of how you might use them to provision monitors in Datadog to send alerts if any of your resources fail."
datadog,The example below only monitor for failed lambda invocations.
datadog,"The prerequisites to this walkthrough are as follows:
All the resources in this post have been deployed using the AWS SAM CLI."
datadog,"To follow along, the CLI must be installed and the config file: samconfig.toml must be defined in the root of your project."
datadog,"version=0.1
 [default.deploy.parameters]
 profile = ""personal""
 stack_name = ""datadog-monitor-dev""
 s3_bucket = ""custom-resources-dev-20200318""
 s3_prefix = ""datadog""
 region = ""eu-west-1""
 capabilities = ""CAPABILITY_IAM""
 confirm_changeset = true
 tags = ""project=\""datadog-monitor-dev\"" stage=\""dev\""""
Setup the AWS Services integration in your Datadog account and ensure that the lambda tile is selected."
datadog,This enables Datadog to collect Amazon lambda metrics.
datadog,Once completed all lambda functions will be available in the Datadog serverless view.
datadog,Retrieve the DataDog API key and create an Application key.
datadog,"These must be stored in AWS secrets manager as follows, you can choose any name for the secrets which is added to the CF template as a parameter:
{
  ""DD_CLIENT_API_KEY"": ""API KEY"",
  ""DD_CLIENT_APP_KEY"": ""APP KEY""
}
The Datadog API
Datadog has a HTTP REST API that allows you to interact with the platform programmatically."
datadog,The API has been used in the code below to create the Monitor class which will be used by the custom resource lambda.
datadog,"The code below has been summarised into the following key points:
The base url of the API is: https://api.datadoghq.eu/api/v1
To authenticate calls to the API, the datadog API key and Application Key must be provided in the request headers."
datadog,The keys are used to initialise the class object.
datadog,"The class has three methods to create, update and delete Datadog monitors, and one helper method to construct a simple monitor query."
datadog,"The create_monitor method takes the following arguments: name, message, priority, functionname and tags."
datadog,The name is simply the name of the monitor as it appears in the Datadog UI.
datadog,The message is what gets sent with each alert.
datadog,The priority indicates the severity of the alert.
datadog,The functionname is used by the _create_query method to construct a simple monitor query and the tags are used to tag the monitor.
datadog,After a monitor is created its monitor_id is returned.
datadog,The _create_query method uses the functionname argument to create a monitor query which checks for any lambda errors within the last hour.
datadog,"The update_monitor method takes all the same arguments as the create_monitor method, except with the addition of the monitor_id so it knows which monitor to update."
datadog,The delete_monitor method uses the monitor_id to delete the monitor.
datadog,"Datadog Python Module
The Datadog custom resource lambda
Using the Datadog Monitor class and also the Custom resource skeleton code defined above, it is now possible to create a Custom resource which can create, update and manage Datadog monitors in tandem with CloudFormation stack operations."
datadog,"As mentioned in the prerequisites, the Datadog API and App keys are stored in AWS secrets manager."
datadog,These are retrieved using the aws_lambda_powertools package.
datadog,The CfnResource and DD_monitor objects are created.
datadog,The create_monitor method is called within the create function which is executed when the stack is first created; as indicated by the @helper.create decorator.
datadog,The required arguments are defined in the CloudFormation template and available in the ResourceProperties field in the event object.
datadog,The update_monitor and delete_monitor methods are called within the update and delete function respectively.
datadog,Both the create and delete functions return the monitor_id which will be assigned as the physical id of the resource.
datadog,"Datadog Custom Resource lambda
The Test Lambda
The test lambda is the lambda which will be monitored in Datadog."
datadog,The lambda will only be used to generate some successful and failed invocation metrics.
datadog,"Test lambda
The CloudFormation Template
With the all the lambdas now defined, the next step is to create the CloudFormation (SAM) template to deploy them all."
datadog,"The template explicitly defines three resources, the DataDogMonitorLambda, aTestLambda, and the TestLambdaDDMonitor ."
datadog,The DataDogMonitorLambda is the lambda function that will be called by the custom resource.
datadog,This is evident as the ServiceToken in the custom resource points to the DataDogMonitorLambda Arn.
datadog,The TestLambda is the lambda that will be monitored.
datadog,The TestLambdaDDMonitor is the Datadog monitor that is created by invoking the DataDogMonitorLambda.
datadog,The arguments required to create the monitor are passed as additional properties.
datadog,"Deploying the Stack
To deploy the stack with SAM, execute the following commands:
sam build --use-container
sam deploy
Check everything looks right in the changeset and press y to continue with the deployment."
datadog,"CloudFormation changeset
Once the stack creation is complete, all the resources will have both Logical and Physical IDs."
datadog,"Since the create function in the Custom Resource lambda returns the monitor_id of the Datadog monitor it just created, this is set as the resource Physical ID."
datadog,The monitor can be viewed in Datadog at the following address: https://datadoghq.eu/monitors/{MonitorID}.
datadog,"CloudFormation Resources
Testing the monitor
Initially the Datadog monitor will have no data as shown below, this is because the monitor requires either successful or failed lambda executions."
datadog,The easiest way to generate some data is to manually invoke the TestLambda in the AWS UI.
datadog,"Since the monitor only checks for failed invocations each hour, its best to invoke the lambda successfully a few times and wait for the data to populate in Datadog and then cause the lambda to fail."
datadog,"Finally, if the monitor is working as expected, after a failed lambda execution, it should remain in an alert state."
datadog,I hope you enjoyed reading this post as much as I enjoyed writing it.
datadog,The simplicity of Lambda Functions and Custom Resources really open up the possibilities of CloudFormation.
datadog,"I‚Äôm planning on writing another article of how you might use Custom Resources to manage your Snowflake account, so watch this space!"
datadog,"Checkout my other engineering posts:
Connecting to an ec2 instance in a private subnet on AWS"
datadog,"A mystery
So, it all started on September 1st, right after our cluster upgrade from 1.11 to 1.12."
datadog,"Almost on the next day, we began to see alerts on kubelet reported by Datadog."
datadog,"On some days we would get a few (3 - 5) of them, other days we would get more than 10 in a single day."
datadog,"The alert monitor is based on a Datadog check - kubernetes.kubelet.check, and it's triggered whenever the kubelet process is down in a node."
datadog,We know kubelet plays an important role in Kubernetes scheduling.
datadog,Not having it running properly in a node would directly remove that node from a functional cluster.
datadog,Having more nodes with problematic kubelet then we get a cluster degradation.
datadog,"Now, Imagine waking up to 16 alerts in the morning."
datadog,It was absolutely terrifying.
datadog,What really puzzled us was all the services running on the problematic nodes seemed to be innocuous.
datadog,"In some cases, there were only a handful of running services, and some high CPU usage right before."
datadog,"It was extremely hard to point the finger on anything when the potential offender might have left the scene, thus leaving no trace for us to diagnose further."
datadog,"Funny enough, there weren‚Äôt any obvious performance impact such as request latency across our services."
datadog,This little fact added even more mystery to the whole thing.
datadog,"This phenomenon continued to start around the same time every day (5:30AM PT), and usually stopped before noon, except for the weekends."
datadog,"To a point, I felt I could use these Datadog alerts for my alarm clock."
datadog,"Not super fun, and I certainly got some grey hair with this challenge."
datadog,"Our investigation
From the start, we knew this was going to be a tough investigation that would require a systematic approach."
datadog,"For brevity, I‚Äôm going to just list out some key experiments we attempted and spare you from the details."
datadog,"As much as they are good investigative steps, I don‚Äôt believe they are important for this post."
datadog,"Here are what we tried
We upgraded the cluster from 1.12 to 1.13
We created some tainted nodes and moved all our cronjobs to them
We created more tainted nodes and moved most CPU consuming workers to them
We scaled up the cluster by almost 20%, from 42 nodes to 50 nodes
We recycled (delete and recreate) all the nodes that previously reported kubelet issue, only to see new nodes followed suit on the next day
Just between you and me, I even theorized the Datadog alert might be broken because there wasn‚Äôt any obvious service performance impact."
datadog,But I couldn‚Äôt bring myself to close the case knowing the culprit might still be at large.
datadog,"With a stroke of luck and a lot of witch-hunting, this piqued my attention

We saw 10 buffer-publish pods were scheduled to a single node for around 10 minutes, only to be terminated shortly."
datadog,"At the same time the CPU usage spiked, kubelet cried out, and the pods disappeared from the node in the next few minutes after termination."
datadog,No wonder we could never find anything after alerts.
datadog,"But what were so special about these pods, I thought?"
datadog,The only fact we had was the high CPU usage.
datadog,"Now, let‚Äôs take a look at the resource requests/limits

CPU/Memory requests parameter tells Kubenetes how much resource should be allocated initially
CPU/Memory limits parameter tells Kubenetes the max resource should be given under all circumstances
Here is a post that does a much better job in explaining this concept."
datadog,I highly recommend reading it in full.
datadog,Kudos to the team at kubecost!
datadog,"Now, back to where we are."
datadog,"The CPU requests/limits ratio is 10, and it should be fine, right?"
datadog,We allocate 0.1 CPU to a pod in the beginning and limit the max usage to 1 CPU.
datadog,"In this way, we have a conservative start while still having some kind of, although arbitrary upper boundary."
datadog,It almost feels like we are following the best practice!
datadog,"Then I thought, this doesn‚Äôt make any sense at all."
datadog,"When 10 pods are scheduled in a single node the total CPU this parameter would allow for is 10 CPUs, but there aren‚Äôt 10 CPUs in a m4.xlarge node."
datadog,"What would happen during our peak-hours, say 5:30AM PT when America wakes up?"
datadog,"Now I can almost visualize a grim picture of these node killing pods taking all CPU, to a point that even kubelet starts to die off, then the whole node just crash and burn."
datadog,"So now, what we can do about it?"
datadog,"The remedy
Obviously the easiest way is to lower the CPU limits so these pods will kill themselves before they kill a node."
datadog,But this doesn‚Äôt feel quite right to me.
datadog,"What if they really need that much CPU for normal operations, so throttling ( more on this) doesn‚Äôt lead to low performance."
datadog,"Okay, how about increasing the CPU requests so these pods are more spread out and don‚Äôt get scheduled into a single node."
datadog,"That sounds like a better plan, and that was the plan we implemented."
datadog,"Here are the details:
Figure out how much you typically need
I used the Datadog metric kubernetes.cpu.usage.total over the past week on the max reported value to give me some point of reference
You could see in general it stays below 200m (0.2 CPU)."
datadog,This tells me it‚Äôs hard to go wrong with this value for CPU requests.
datadog,"Put a limit on it
Now, this was the tricky part, and like most tricky things in life, there isn‚Äôt a simple solution."
datadog,"In my experiences, a good start would be 2x of the requests."
datadog,"In this case, it would be 400m (0.4 CPU)."
datadog,"After the change, I spent some time eyeballing the service performance metrics to make sure the performance wasn‚Äôt impacted by CPU throttling."
datadog,"Chances are if it were, I would need to up it to a more reasonable number."
datadog,This is more of an iterative process until you get right.
datadog,"Pay attention to the ratio
It‚Äôs key not to have low requests tricking Kubernetes into scheduling all pods into one node, only to exhaust all CPU with incredibly high limits."
datadog,"Ideally, the requests/limits should not be too far away from each other, say within 2x to 5x range."
datadog,"Otherwise, an application is considered to be too spiky, or even has some kind of leaks."
datadog,"If this is the case, it‚Äôs prudent to get to the bottom of the application footprints."
datadog,"Review regularly
Applications will undergo changes as long as they are active, so will their footprints."
datadog,Make sure you have some kind of review process that takes you back to Step 1 (Figure out how much it typically needs).
datadog,This is the only way to keep things in tip-top shape.
datadog,"Profit
So, did it work?"
datadog,You bet!
datadog,There were quite a few services in our cluster with disproportional requests/limits.
datadog,"After I adjusted these heavy-duty services, the cluster runs with more stability Here is how it looks now üëá

Wait!"
datadog,How about efficiency promised in the title?
datadog,Please note the band has gotten more constricted after the changes.
datadog,This shows the CPU resource across the cluster is being utilized more uniformly.
datadog,"This subsequently makes scaling up to have a linear effect, which is a lot more effective."
datadog,"Closing words
In contrast with deploying each service on a set of dedicated computing instances, service-oriented architecture allows many services to share a single Kubernetes cluster."
datadog,"Precisely because of this, each service now bears the responsibility of specifying its own resource requirements."
datadog,And this step is not to be taken lightly.
datadog,"An unstable cluster affects all the residing services, and troubleshooting is often challenging."
datadog,"Admittedly, not all of us are experienced with this kind of new configurations."
datadog,"In the good ol‚Äô days all we needed was to deploy our one thing on some servers, and scale up/down to our liking."
datadog,I think this might be why I don‚Äôt see a lot of discussions around the resource parameters in Kubernetes.
datadog,"Through this post, it‚Äôs my hope to help a few people out there who are struggling with this new concept (I know I did)."
datadog,"More importantly, perhaps learn from someone who has some other techniques."
datadog,"If you have any thoughts on this, please feel free to hit me up on Twitter."
datadog,"Among the three pillars of observability (metric, logs, traces), logs might be the most boring part but only until we start using them successfully for performance analysis and troubleshooting."
datadog,How often do we find ourselves parsing through terabytes of logs looking for a needle in a haystack?
datadog,When we find it how do we create a context around this individual log event?
datadog,In this blogpost we will learn how to expose database metadata ‚ÄúProcess List‚Äù via Datadog Logs and cover a new Datadog tracing feature called just ‚ÄúTraces‚Äù.
datadog,This new feature will help to connect database traces and logs together and make database performance troubleshooting easier.
datadog,Let me start with an example to demonstrate what level of detail we will go through.
datadog,"Filter slow SQL queries, get the connection IDs and the states these connections switch through alongside with the performance characteristics of each connection:

I will rely on Datadog Application Performance Monitoring (APM) to describe performance troubleshooting techniques."
datadog,"APM client library is available for Ruby, Python, Golang and many other languages."
datadog,Tracing is not something enabled by default.
datadog,"Additional configuration is required to trace requests and search through them, it will be subject to the tracing quota allocated to your account."
datadog,Not every service is worth indexing though.
datadog,"High volume services like MySQL, Redis, Memcached are often exempt from tracing due to the volume and associated cost."
datadog,It isn‚Äôt financially feasible to trace billions of SQL queries when we only need a sample.
datadog,"Use a workaround with the ‚ÄúSQL Time‚Äù measure attached as a tag, it helps to find HTTP requests with slow SQL queries, its instrumentation is fairly simple:

The Ruby On Rails framework has the ActiveSupport Notifications API publish/subscribe model, that helps to extend Datadog trace span with SQL Time."
datadog,We subscribe to an event when the request is complete and take the DB Runtime value to send as an additional tag.
datadog,"APM Query to filter HTTP requests with total SQL Time above 2 seconds will look like:
@database.sql_time:>2s
It will work with every Analyzed Spans regardless of sampling."
datadog,We can‚Äôt filter an individual slow SQL query.
datadog,Priority sampling can help to increase the number of events with full traces but dataset size makes the same SQL query fast in one scenario and slow in the other.
datadog,"Occasionally traces can be dropped as well:
A trace priority should be manually controlled only before any context propagation."
datadog,"If this happens after the propagation of a context, the system can‚Äôt ensure that the entire trace is kept across services."
datadog,"Manually controlled trace priority is set at tracing client location, the trace can still be dropped by Agent or server location based on the sampling rules."
datadog,"When traces are enabled the data is being indexed and you have searching capabilities, while non-traced services like MySQL are only available via Service page (based on custom metrics)."
datadog,"Search was not possible here‚Ä¶
New Datadog ‚ÄúTraces‚Äù feature makes every service traced, it allows you to have SQL queries being available for search without additional Datadog agent‚Äôs configuration."
datadog,It will happen at no extra cost but with some limitations.
datadog,"Downside is not all events will be traced but only a portion, which can be enough for performance troubleshooting."
datadog,"Now traces split to two types:
Traces: no widgets, sample of events, high volume services at no extra cost
App Analytics: widgets (Histogram, List, Table), Analyzed Spans, subject to tracing quota
Database performance
It‚Äôs a difficult and exciting topic at the same time."
datadog,"Millions of unique SQL queries hit database every hour, leaving the engine to do the best to fairly allocate resources to provide consistent performance to every client and also providing MVCC, row-level locking, full ACID compliance."
datadog,"This is difficult in a multi-tenant environment, sometimes a single SQL query can drag performance down for entire database instance."
datadog,"When database performance is far from what we expect, we don‚Äôt often have the data to see why."
datadog,"Would it be useful to have contextual logs, detect slow SQL query, deep dive into relevant Process List‚Äôs snapshot and connect it to APM in order to find a performance issue?"
datadog,"In order to answer this question we are going use Datadog Logs to store snapshots of database‚Äôs meta data Process List to be able to filter slow SQL queries and see exactly what database engine was doing during the query, investigate each individual connection/thread, its states at a given time, analyse how many rows were scanned and examine how much time it spent sending data back."
datadog,"It‚Äôs very important to instrument SQL query with trace_id in SQL Comment as shown here:

Important to mention that research is based on test dummy data which has nothing to any kind of real production data."
datadog,"I use my own test application, run the benchmark and collect the stats from the local development environment fully independent and isolated from other environments."
datadog,"Query Syntax

Datadog Logs UI is SQL query language driven."
datadog,To learn the query language you can use this resource.
datadog,Let‚Äôs briefly touch relevant query syntax to database performance.
datadog,"A search query may contain a combination of key:value pairs including every facet or even negative condition, for example:
env:test service:(mysql OR backend)
service:mysql @duration:>5s @sql.query:SELECT*
service:mysql @sql.query:(*ORDER* OR -*JOIN*)
It can be extremely helpful to select a set of services to pinpoint each layer by trace id."
datadog,"This id is a part of many independent application layers, trace_id connection brings them together in Datadog UI:

To make Process List be available to Datadog Logs UI, we will use the following script:

MySQL sys Schema
According to MySQL 5.7 documentation
MySQL 5.7.7 and higher includes the sys Schema, a set of objects that helps DBAs and developers interpret data collected by the Performance Schema."
datadog,sys schema objects can be used for typical tuning and diagnosis use cases.
datadog,Objects in this schema that summarize Performance Schema data into more easily understandable form.
datadog,"Now that we have the trace data associated to the log events, let‚Äôs investigate an individual slow SQL query:

We get the data from database internal data structure table sys.processlist, this is how database tracks slow running SQL queries (slow query log is different)."
datadog,A SQL query‚Äôs state changes over time and when we need to get total duration and rows then final is the one to look at.
datadog,"Database engine isn‚Äôt trivial, we can‚Äôt accurately get rows scanned and rows examined until the query is complete and connection switched to another state, see details:
Rows examined column is not updated for each examined row so it does not necessarily show an up-to-date value while the statement is executing."
datadog,It only shows a correct value after the statement has completed.).
datadog,"New ‚ÄúTraces‚Äù functionality is a next generation observability tool, it brings contextual information for high volume service, connect it to an individual request in order to analyse it and ease performance troubleshooting."
datadog,With Process List being available in Datadog Logs we can pinpoint slow SQL queries and find the reasons behind it!
datadog,What next?
datadog,"Let‚Äôs investigate another very important database internal structure Statement Analysis provided by the sys Schema:

You learnt:
How to push MySQL sys Schema to Datadog Logs
How to link App Analytics to Datadog Logs
How to use Logs to troubleshoot database performance issues"
datadog,Hello everyone!
datadog,It has been a little while since I have written here but I thought I would get back to business with a nice little tip for forwarding all kinds of logs to your favorite Log Management software and upgrading the security posture of older appliances that do not necessarily support TLS transport.
datadog,"This is particularly useful in order to forward log data to third parties that might require encryption, which is a best-practice in any case if you want to send data over the Internet."
datadog,"I will show you how you can achieve this using a homemade rsyslog TLS proxy, that I personally deploy using Docker and Fargate but the choice of hosting technology really depends on the context of your organization."
datadog,"The setup I demonstrate has been tested with a Mikrotik RouterOS 6.45.1 sending plaintext logs to the proxy, which in turn sends them encrypted to a Log Managements SaaS software: Datadog."
datadog,The presented setup has also been tested with Logz.io and the same principle works almost as-is.
datadog,"I also don‚Äôt think there would be any problem applying it to providers such as Loggly, Graylog or even Splunk for that matter."
datadog,"The problem
With modern Log Management systems, the best practice is to send your logs using a secure transport such as TLS."
datadog,"But lots of appliances have not been built thinking that in a SaaS world, their logs would be sent over the public Internet: The more traditional model is to just send them via the local network to an aggregator/SIEM and they get analyzed and stored locally without ever leaving the enterprise perimeter."
datadog,"In order to use a log management solution with public endpoints, we need to add a little something to the mix."
datadog,"Proposed solution
In order to send your logs to a SaaS provider in a secure way, the proposed solution is to first send the log stream to a small Docker container that will wrap it in a TLS secure transport layer (with additional metadata if you want) and then forward it to its destination."
datadog,"The proposed solution for securing RSyslog streams
Building the container
I assume here that the base container is a vanilla Ubuntu 18.04."
datadog,"First, we need to install relevant RSyslog packages and its TLS utilities."
datadog,"We will also expose the RSyslog service on the port 514:
FROM ubuntu:18.04
EXPOSE 514/udp
RUN apt-get update
RUN apt-get install -y rsyslog rsyslog-gnutls
Configuring TLS
The next step involves downloading the TLS public certificate from the SaaS provider."
datadog,"In this example, the certificate has been named rsyslog_cert.crt and contains the certificate‚Äôs full chain."
datadog,"RUN mkdir -p /etc/ssl/rsyslog
COPY ./rsyslog_cert.crt /etc/ssl/rsyslog/rsyslog_cert.crt
The configuration file
Then, let‚Äôs create an RSyslog configuration template file in which we will inject the provided API key; This template works with Datadog, but the same principle should apply for most providers."
datadog,"We call it rsyslog.conf.template , and we will use it to generate the final configuration file, rsyslog.conf ."
datadog,"Note that the template line has been splitted, but it should be only one line in the resulting file."
datadog,"# start a UDP listener for the remote router
$ModLoad imudp    # load UDP server plugin
$UDPServerRun 514 # listen on default syslog UDP port 514
# make gtls driver the default
$DefaultNetstreamDriver gtls
$DefaultNetstreamDriverCAFile /etc/ssl/rsyslog/rsyslog_cert.crt
$ActionSendStreamDriver gtls
$ActionSendStreamDriverAuthMode x509/name
$ActionSendStreamDriverPermittedPeer *.logs.datadoghq.com
$ActionSendStreamDriverMode 1 # run driver in TLS-only mode
$template DatadogFormat,""%DATADOG_API_KEY% <%pri%> \
    %protocol-version% %timestamp:::date-rfc3339% %HOSTNAME% \
    %app-name% - - [type=mikrotik] %msg%\n""
# forward everything to remote server
*."
datadog,"* @@intake.logs.datadoghq.com:10516;DatadogFormat
The entrypoint
Notice the %DATADOG_API_KEY% ; We will replace this with the actual value at the start of the container using the entrypoint.sh using the sed command."
datadog,"#!/usr/bin/env bash
set -e
# This resolves the $DATADOG_API_KEY env variable
sed -e ""s/%DATADOG_API_KEY%/$DATADOG_API_KEY/g"" /etc/rsyslog.d \
    /firewall-syslog.conf.template > \
    /etc/rsyslog.d/firewall-syslog.conf
# We can get rid of the template
rm /etc/rsyslog.d/firewall-syslog.conf.template
# Run as-is what's passed."
datadog,"exec ""$@""
This implies that you should start the container with the environment variable DATADOG_API_KEY set to the proper value."
datadog,"In the Dockerfile, just copy the template file, the entrypoint.sh and set it as the Docker‚Äôs entrypoint."
datadog,"COPY ./rsyslog.conf.template \
    /etc/rsyslog.d/firewall-syslog.conf.template
COPY ./entrypoint.sh /entrypoint.sh
ENTRYPOINT [""/entrypoint.sh""]
Putting it all together
The only thing that is left to be done is tell Docker to use rsyslogd with our new config file; It should be something similar to this:
FROM ubuntu:18.04
EXPOSE 514/udp
RUN apt-get update
RUN apt-get install -y rsyslog rsyslog-gnutls
RUN mkdir /etc/ssl
RUN mkdir /etc/ssl/rsyslog
COPY ./rsyslog_cert.crt /etc/ssl/rsyslog/rsyslog_cert.crt
COPY ./rsyslog.conf.template /etc/rsyslog.d/firewall-syslog.conf.template
COPY ./entrypoint.sh /entrypoint.sh
ENTRYPOINT [""/entrypoint.sh""]
CMD [""/usr/sbin/rsyslogd"", ""-n"", ""-f"", ""/etc/rsyslog.d/firewall-syslog.conf""]
Now, the last step is to configure your Mikrotik firewall to send its logs to the Docker container:

In this example, the docker RSyslog proxy is listening at the address 10.0.0.2
If everything went well, you should start to see some logs appear in Datadog:

Yay!"
datadog,"Now we have the Mikrotik plaintext logs sent to Datadog using TLS encryption :-)
Happy hacking!"
datadog,"Introduction:
Datadog is one of the great monitoring tools out there."
datadog,They provide amazing integrations with different cloud providers and open source tools.
datadog,They are supporting kubernetes monitoring from quite some time but control plane monitoring was not yet supported.
datadog,"The various parts of the Kubernetes Control Plane, such as the Kubernetes Master and kubelet processes, govern how Kubernetes communicates with your cluster."
datadog,The Control Plane maintains a record of all of the Kubernetes Objects in the system and runs continuous control loops to manage those objects‚Äô state.
datadog,Issues related to the control plane can lead to cluster-wide outage and hence it‚Äôs important to monitor the control plane.
datadog,"Below are the four components of Kubernetes control plane running on Kubernetes master nodes which datadog can monitor starting June 2019:
kube-apiserver: Front end of kubernetes control plane which acts as a communication hub for all the components to communicate with the cluster."
datadog,etcd: Consistent and highly-available key value store used as Kubernetes‚Äô backing store for all cluster data e.g.
datadog,"cluster configuration, desired state of running components, etc."
datadog,"kube-scheduler: Watches newly created pods that have no node assigned, and selects a node for them to run on."
datadog,kube-controller-manager: It is a daemon that embeds the core control loops shipped with Kubernetes.
datadog,It watches the state of the cluster through API server watch feature and makes changes to move cluster towards the desired state.
datadog,Datadog agents need to be setup for monitoring of your infrastructure.
datadog,Datadog agents ship metrics and logs to your datadog account.
datadog,You can send metrics and logs from multiple clusters to your Datadog organization for which you‚Äôll require an app key and api key.
datadog,Datadog provides multiple options to deploy datadog agents over your kubernetes cluster and the one I like the most is helm.
datadog,You can know more about datadog helm chart from this link.
datadog,You can pass your configurations and checks using helm which creates a Datadog Daemonset containing all your configs.
datadog,"Creating control plane configs for Datadog Agent :
Let‚Äôs get started with basic configurations required to run datadog over Kubernetes master nodes."
datadog,Refer to this link to get all the configurations for kubernetes api server.
datadog,"Below is configuration for api-server which we will use in our helm chart:

For kubernetes scheduler check this link for all the configurations."
datadog,For kubernetes controller manager check this link for all the configurations.
datadog,"etcd3 config and certificates creation:
Starting Kubernetes version 12, etcd3 is being used."
datadog,etcd3 has additional security features.
datadog,We need to provide certificates to datadog config for authentication.
datadog,"I am using KOPS to manage kubernetes and for kops, these certificates are already available on kubernetes master nodes at /etc/kubernetes/pki/kube-apiserver directory."
datadog,If you are a fan of having different certificates for different services then you can create your certificates and provide to datadog.
datadog,KOPS is using etcd manager and it store the certificates at /etc/kubernetes/pki/etcd-manager-main.
datadog,"Use the following commands to create your own set of certificates:
## Run the openssl commands on one of the KOPS master node."
datadog,"## You can run this commands from tmp directory
openssl req -nodes -new -out datadog.csr -keyout datadog.key -subj ""/CN=datadog""
openssl x509 -req -in datadog.csr -CA /etc/kubernetes/pki/etcd-manager-main/etcd-clients-ca.crt -CAkey /etc/kubernetes/pki/etcd-manager-main/etcd-clients-ca.key -CAcreateserial -out datadog.crt -days 365 -sha256
openssl x509 -in datadog.crt -outform PEM -out datadog.pem
openssl x509 -in /etc/kubernetes/pki/etcd-manager-main/etcd-clients-ca.crt -outform PEM -out etcd-ca.pem
## Test your certificates by running below command:
curl --cacert etcd-ca.pem --cert datadog.pem --key datadog.key https://127.0.0.1:4001/metrics
These certificates will have to be mounted on the datadog daemonset."
datadog,"We will get to that later, for now let‚Äôs assume we will mount them on /etc/datadog-agent/certs/ directory."
datadog,"Below is how your etcd config file will look like:

Helm Chart for control plane monitoring
We have all the pieces required to create values file for our helm chart."
datadog,"In addition to that, we will require api key and app key from your Datadog account."
datadog,You can either create new app-api keys or use the existing ones.
datadog,"Below document describes how to get ones:
API and Application Keys
API keys are unique to your organization."
datadog,"An API key is required by the Datadog Agent to submit metrics and events to‚Ä¶
docs.datadoghq.com

Datadog helm chart comes with an option to enable datadog cluster agent."
datadog,"The Datadog Cluster Agent provides a streamlined, centralized approach to collecting cluster-level monitoring data."
datadog,I am enabling cluster agent as it‚Äôs a good feature to have and easy to configure using helm.
datadog,Cluster agent requires a token which can be either provided in plain text or via a secret to your helm chart.
datadog,This article explains more about cluster agent token.
datadog,"Below is how your values.yaml file will look like for datadog helm chart:

We are using tolerations to make sure that control plane configs are running on master nodes."
datadog,Running this on workers will create lot of errors in worker node logs related to control plane services.
datadog,We have to set this tolerations on Daemonset level.
datadog,"Below are the tolerations being used:
tolerations:    
- effect: NoSchedule      
  key: node-role.kubernetes.io/master    
- key: CriticalAddonsOnly      
  operator: Exists
We are enabling logs, apm, processagents and all the good features provided by datadog."
datadog,To know about more features or disable some features check this link.
datadog,"This is a nice article from datadog about using their helm chart:
Deploying Datadog in Kubernetes using Helm
Helm is a package management tool for Kubernetes."
datadog,"For other platforms and methods of installing Helm, refer to the Helm‚Ä¶
docs.datadoghq.com

Last part is to run helm command and finish setup of datadog on control plane."
datadog,"We will name our values file as master-node-datadog-values.yaml:
helm install --name control-plane-ddagent \
    --set datadog.apiKey=<DATADOG_API_KEY> \
    --set datadog.appKey=<DATADOG_APP_KEY \
    --set clusterAgent.token= ""<ThirtyX2XcharactersXlongXtoken>"" \
    -f master-node-datadog-values.yaml \
    stable/datadog
Helm Chart for worker nodes:
All the above mentioned steps will only setup datadog for control plane."
datadog,For running datadog on worker nodes is actually quite easy.
datadog,By removing control plane specific configurations we can get values file for worker nodes.
datadog,"Below is a simple values file let‚Äôs call it worker-node-datadog-values.yaml:

Helm command remains the same and we only change values file and release name:
helm install --name workder-node-ddagent \
    --set datadog.apiKey=<DATADOG_API_KEY> \
    --set datadog.appKey=<DATADOG_APP_KEY \
    --set clusterAgent.token= ""<ThirtyX2XcharactersXlongXtoken>"" \
    -f worker-node-datadog-values.yaml \
    stable/datadog
Enabling Integrations:
So far we have enabled metric and log collection."
datadog,Datadog provides good integration for kubernetes services which can be enabled in a few clicks.
datadog,Just go to the Integrations page: https://app.datadoghq.com/account/settings and search for Kubernetes integrations.
datadog,Enabling integrations will help you get OOTB dashboards from datadog.
datadog,E.g.
datadog,"Controller manager dashboard:

Existing Issues:
Control plane monitoring is a new feature and datadog is currently working on it."
datadog,"There are some issues which may concern you:
There is an issue with etcd integration as it supports api version v2 and etcd3 is using api version v3."
datadog,Due to this the dashboard provided by Datadog will have no data in it.
datadog,If you are datadoghq.eu user then api-server integration will not be available for you.
datadog,I am currently following with their engineers and they are working on it.
datadog,New integration!
datadog,Datadog monitors every log produced by your application and aggregates that data into actionable metrics.
datadog,"You can then search, filter, and analyze your logs for troubleshooting."
datadog,"But like every log management tool, the problem is the amount: there is just too much to sift through."
datadog,"And while metrics are a great way to visualize the issues across your stack, they are not enough the give you an accurate idea of every specific problem that each user experiences."
datadog,A lot of our user use Datadog as their log management tool.
datadog,"To make their lives easier, we have chosen it as our next integration."
datadog,"You can now troubleshoot your Datadog logs in Asayer:
Get the full context behind every issue
Replay any session that has backend errors."
datadog,"See a video of how the user experienced the issue, and how your stack behaved at that very moment (JS Console, Network Activity, Redux State, User Metadata, etc.)."
datadog,"Collaborate in real-time with your team to resolve them
MTTR in a live production environment is critical."
datadog,None of us want to be dealing with too many users struggling to perform a workflow or simply leaving the app with a bad experience.
datadog,Asayer + Datadog makes it easy to collaborate in real-time.
datadog,"In fact, with our Slack and Jira integrations, you can share the sessions that have backend errors to your teammates for debugging, all from within the same application."
datadog,Follow our guide to integrate Datadog with Asayer.
datadog,"As Datadog enters its first days as a public company, we wanted to share one of the things we believe has made Datadog‚Äôs journey so special: Purity."
datadog,Purity begins with a highly authentic founding story.
datadog,"At their prior company, Olivier and Alexis literally stood on opposite sides of the Dev and Ops divide and experienced the difficulty in communication across these silos firsthand."
datadog,"They built Datadog in this image ‚Äî to cut across systems, teams and functions and solve these problems."
datadog,"With this inherent empathy and a careful ear to customers, Datadog focused on the pain points engineers were experiencing with the growing complexity of cloud and hybrid environments and built products to surface strong and actionable insights in a digestible way with rapid time to value."
datadog,Purity also encompasses setting.
datadog,"When Datadog was founded in 2010, the New York City technology scene was mostly known for high growth companies in sectors like ecommerce, marketing technology and financial technology, embedded in legacy industries which once served as pillars in the city."
datadog,"At that time, there were very few infrastructure technology companies."
datadog,"Early investor conversations often encouraged the founders to move to California, but Olivier and Alexis believed in the opportunity to build a significant company in New York City due to the immense surrounding talent pool."
datadog,"While this decision made fundraising more difficult early on, scarcity of capital actually enabled customer centricity with a strong focus on efficient growth, which has become a powerful fabric embedded in the company to this day."
datadog,Purity extends to platform vision.
datadog,"Datadog began its journey with the important architectural decision of building a real-time, common data unification platform."
datadog,"When we spoke with Datadog customers ahead of our initial investment, we heard about the breadth of utilization across all public, private and hybrid cloud environments and ubiquity of engagement across users, ‚ÄúDeployed Everywhere."
datadog,Used By Everyone‚Äù.
datadog,"Even as Datadog has meaningfully expanded its product portfolio, this dedication to a single platform has remained core."
datadog,"Many large traditional software companies have grown through acquisitions, often accruing multiple platforms which can bring encumbering complexity."
datadog,"With the acquisitions of companies such as Mortar Data, Logmatic.io and Madumbo, Datadog has brought on new founders, products, teams and geographies into their exciting journey, but have remained committed to building a single, unified data platform."
datadog,Purity is at the core of Datadog‚Äôs product-led growth.
datadog,"Datadog‚Äôs ease of adoption and self-service, frictionless deployment reinforces its growth as customers increase their cloud workloads and extend the product more deeply into their workflow."
datadog,"Prior to our partnership with Datadog, we heard at length about customers bringing in many data sources and using Datadog for a ‚Äúholistic view of my infrastructure in a single-pane‚Äù."
datadog,Datadog has listened to the problems of its customers and built modern products to deliver transparency and insights to its customers.
datadog,"From launching Application Performance Monitoring (APM) in 2017, to Log Management in 2018 to Network Performance Management (NPM), Real-User Monitoring (RUM), Synthetics in 2019, Datadog‚Äôs core growth strategy has been product innovation."
datadog,"Datadog‚Äôs journey has been marked by Purity from its authentic founding story, to its opening setting in New York, to its single, unified data platform vision and product-led growth strategy."
datadog,We are grateful to have been their partner on this journey for what is approaching the last four years.
datadog,"When we first met Olivier and Alexis over Korean cuisine, it was an ‚ÄúAha!‚Äù moment ‚Äî we immediately connected with the unique opportunity and potential of their vision for the alignment of Dev, Ops and Business."
datadog,"Since then, the partnership has been a hallmark of the ICONIQ family‚Äôs collective experience."
datadog,"This is a major milestone in Datadog‚Äôs history, and we are very excited for the meaningful journey ahead with much great work still to be done!"
datadog,"by Mackey Craven, Partner at OpenView
Startups rarely follow the playbook their founders draw-up and share with early investors."
datadog,"When Olivier and Alexis first introduced Datadog to OV in 2013, they shared that enterprises were transitioning from legacy on-premise infrastructure to the cloud and how this was leading to fundamental changes in the diversity of underlying technologies, infrastructure scale in terms of number of computing units, frequency of software releases and number of people and roles involved in managing those changes."
datadog,"Olivier and Alexis‚Äô insights are even more relevant today than they were in 2013, and stellar execution has allowed them to realize their vision for Datadog of becoming the monitoring and analytics platform for the cloud age."
datadog,Congratulations on reaching a milestone many startups merely dream of: an IPO.
datadog,"Datadog in January 2014 where OV led their Series B round
Thank you Olivier, Alexis, and Amit for putting the foundations in place for what Datadog has become and to the entire Datadog management team for leading the company to this milestone."
datadog,"Thank you to the thousands of current and former Datadog team members whose dedication to the mission, company, and customers has been unparalleled, and to our world class co-investors and board members Sunil, Shardul, Kirill, Dev, Matt, Michael and Julie."
datadog,"As we watch you ring the opening bell of the NASDAQ today, we couldn‚Äôt feel more proud of you and what you‚Äôve built."
datadog,It‚Äôs been an honor to have been a part of your team for the last six years and share in what is a truly special journey.
datadog,Mackey Craven and the entire OV Team
datadog,"By Owen Davis, Managing Director and Founder, NYC Seed and Maria Gotsch, President & CEO, Partnership Fund for New York City

Datadog went public today with an opening market capitalization of nearly $8 billion."
datadog,"Ten years ago, such a milestone for a New York-based company was unthinkable."
datadog,There was limited seed capital for tech ‚Äî even less for enterprise tech.
datadog,And the idea of a formalized seed round was new.
datadog,"Typically, early-stage companies went to angels and individuals until they reached milestones that Series A venture investors required."
datadog,"In early 2008, we sought to answer the lack of seed capital for tech and enterprise tech companies in New York City with NYC Seed, one of the first institutional seed funds in the city."
datadog,The Partnership Fund for New York City partnered with NYU-Polytechnic University in response to a catalytic investment from New York state.
datadog,"When the market collapsed later that year in September 2008, NYC Seed was one of the few groups actively open for business."
datadog,"Datadog got its start at SeedStart, an incubator initiative of NYC Seed with additional backing by venture funds Contour, IA, RRE and Polaris, receiving its first $25,000 investment from our consortium."
datadog,Co-founders Oliver Pomel and Alexis L√™-Qu√¥c spent the summer of 2010 writing some of the initial code for Datadog at SeedStart‚Äôs space at NYU.
datadog,"Smart, focused founders with an answer for a market hungry for solutions to cloud management at scale made them a company worth taking a risk on."
datadog,"Over a decade later, New York now boasts several public enterprise technology companies that call the city home, including Medidata and MongoDB."
datadog,"There is also a robust pipeline of venture-backed companies in New York that are solving hard enterprise problems at scale, such as Dataminr, Digital Ocean, Sisense and UiPath."
datadog,"Close to your customer
In retrospect, it now seems obvious that enterprise technology startups were perfectly suited to New York."
datadog,There are few places in the United States that combine a concentration of large companies in very close proximity and talent experienced in numerous industries.
datadog,"In addition, world class universities in New York and the region provide access to a talent pool with the highest level of training in almost all academic fields."
datadog,"Looking forward
Which came first, the startup or the accelerators and seed funds?"
datadog,The answer to that question doesn‚Äôt really matter in New York‚Äôs enterprise ecosystem.
datadog,"It has moved beyond its infancy, and enterprise technology companies are a regular part of the investment mix of many seed and Series A venture capital firms in New York."
datadog,But there is still much to be done to continue to foster the enterprise ecosystem.
datadog,"Many large corporations, municipalities and public agencies still have onerous procurement processes for startups, making it difficult for early companies to engage."
datadog,"In addition, potential clients could proactively publish priorities and needs to better guide early startups trying to find product-market fit."
datadog,Programs for internal company teams that understand problems up close and dedicated personnel for helping vendors succeed could also be beneficial for maintaining and growing a strong ecosystem.
datadog,Enterprise tech in New York City is gaining momentum and we are on our way to becoming THE most dynamic startup city in the country.
datadog,"There is always more to do, but the pieces necessary to support growth are here in a way that does not exist elsewhere in the U.S.
Congrats to the Datadog team ‚Äî you will no doubt be a major pillar on which we build a deep and robust enterprise tech sector in New York."
datadog,"Over the last two years, we have come a far way in improving our platform stability, our operations processes, our team size and morale, and our delivery capability and we are now in very good shape and stronger than ever."
datadog,"The competence and passion of many people were needed to make that happen and also to a smaller degree, good partners and tools were supporting us in our journey."
datadog,This blog series shares the story of how we used the Datadog monitoring solution in different phases during the last two years to always push us to the next level of operational excellence and organizational maturity.
datadog,Phase 1 ‚Äî What is going on?
datadog,When I joined orderbird in August of 2017 the engineering team was in a challenging situation.
datadog,Many first-day team members had already moved on from orderbird leaving the rest of the team with a rather complex codebase and operational infrastructure.
datadog,One bigger refactoring project was not working out very well for being over-ambitious and we were facing the need to start building features into our legacy product again while improving its stability at the same time.
datadog,And we did not have much time to get things in order.
datadog,"Our 8,000 business customers needed our system running and performing each day (and night)."
datadog,In this situation I was trying to focus the team‚Äôs attention on the most important things by asking some simple questions like: Is our system up and running right now?
datadog,Is it running stable over a day?
datadog,How is our latency?
datadog,How much traffic are we getting and how is traffic distributing over the weekdays?
datadog,What are the trends in all those metrics?
datadog,"Sadly there was no easy way to answer those questions back then, so I was happy to find that orderbird already signed up for a monitoring SaaS solution by Datadog."
datadog,"I took my laptop and started to use the ‚Äúout of the box‚Äù integrations from Datadog to collect high-level metrics and draw some dashboards following this very basic workflow:

My basic workflow to understand our backend and infrastructure
It was very straightforward to enable the AWS and Cloudflare integrations in Datadog, which allowed me to collect all sorts of interesting low-level metrics like disk utilization and CPU load."
datadog,"And at WAF and load-balancer level, I could graph requests, response times and server and client errors."
datadog,"To make sense of what I saw on the dashboards, I started graphing the metrics into columns of timeframes like ‚Äúlast hour‚Äù, ‚Äúlast week‚Äù, ‚Äúlast months‚Äù etc."
datadog,"In the following picture, you can see our Cloudflare dashboard that I was able to set up within a short time."
datadog,"Columns show timeframes, and rows show correlated metrics."
datadog,The dashboard shows requests based metrics at our ordebird.com domain.
datadog,"Just from looking at it, you can see how the request volume follows the business hours of our customers every day."
datadog,You also find that on weekends there is more traffic and Monday is the least active day.
datadog,"Over the months the request volume goes up, which follows our customer growths and you see response times and errors graphed over the timeframes."
datadog,The build-in aggregation and analysis tools of Datadog were very helpful in creating meaningful dashboards.
datadog,"For instance, I made good use of the time-shift function to draw a chart of today‚Äôs metric against yesterday‚Äôs values."
datadog,This allowed me to see if a certain metric was behaving similar to yesterday or was doing something strange.
datadog,"At this point, we were now able to see our backend system at work and start to understand its behavior."
datadog,By adding Datadog Agents into our machines we added application-level metrics.
datadog,"Also, Datadog provided us with machine-level information and network maps."
datadog,"The application-level dashboard of our core backend system

Datadog Infrastructure List showing core metrics of machines running the Datadog Agent."
datadog,Meaningful and standardized tagging our resources and metrics were key to get deeper insights into the system and to see valuable correlations.
datadog,I wish we would have done that from the start.
datadog,It would have saved us a lot of time.
datadog,"Very soon we had built around ten dashboards, which covered most of our core systems and infrastructure."
datadog,Just being able to look at the dashboards every day on the office monitors or from our laptop and mobile phones in the evening increased our understanding of and our confidence in our systems dramatically.
datadog,In Phase 2 I will share how we started to define ‚Äúgood‚Äù and ‚Äúbad‚Äù and implemented monitoring and on-call paging.
datadog,This post originally appeared on Datadog‚Äôs blog.
datadog,This project has been an ongoing collaboration between Datadog and the OpenTelemetry Technical and Governance Committees to bring auto-instrumentation support to OpenTelemetry.
datadog,"At Datadog, we‚Äôve always been committed to ensuring that our libraries and software that run on your systems are open source."
datadog,We believe that transparency into how we collect data and integrate with your applications is key for building trust.
datadog,"We‚Äôre also committed to supporting open standards, from the tried-and-true StatsD protocol to newer projects such as OpenTracing, OpenCensus, and OpenMetrics, all of which make it easier for organizations to improve the observability of their systems."
datadog,"We are pleased that OpenTracing and OpenCensus have merged to provide the community with a standard set of APIs and libraries for instrumenting their systems, in a single project called OpenTelemetry, rather than having to choose between two overlapping projects."
datadog,And we‚Äôre excited to announce that we are contributing our tracing libraries to the OpenTelemetry project to support the merger and provide out-of-the box instrumentation to the community.
datadog,"Datadog + OpenTelemetry
OpenTelemetry is a cross-vendor initiative under the umbrella of the Cloud Native Computing Foundation (CNCF)."
datadog,"The project aims to make ‚Äúrobust, portable telemetry a built-in feature of cloud-native software.‚Äù OpenTelemetry will enable any company ‚Äî with any stack, any infrastructure platform, and any monitoring provider ‚Äî to gather observability data from all their systems, including distributed traces, metrics, and, eventually, logs."
datadog,"Because OpenTelemetry is vendor-neutral, companies will be able to migrate their observability data between monitoring backends more easily, without vendor lock-in."
datadog,"As part of our continued commitment to open source software and open observability standards, we are partnering with the OpenTelemetry community to build the foundation for auto-instrumentation of applications across languages and frameworks."
datadog,"By building on Datadog‚Äôs auto-instrumenting telemetry libraries, the OpenTelemetry project will make it easier for any company to start getting deep visibility into their systems."
datadog,"Datadog‚Äôs instrumentation libraries in Python, Ruby, Java, Go, Node.js, PHP, and .NET are already used by thousands of companies to provide visibility into diverse application architectures and infrastructure environments."
datadog,"Their feedback, requests, and improvements have helped us to deliver a better experience to all our customers, and will soon help the OpenTelemetry project to deliver wide-ranging auto-instrumentation to the rest of the community as well."
datadog,What is auto-instrumentation?
datadog,"Auto-instrumentation is a core feature of Datadog‚Äôs tracing libraries, and it will be a core feature of OpenTelemetry as well."
datadog,The goal of auto-instrumentation is to make it possible to collect comprehensive telemetry data from your application without making manual changes to your code.
datadog,"In a distributed tracing context, auto-instrumentation allows you to trace the path of a request as it traverses different application components, including:
Application frameworks such as Django, Spring, Rails, and Laravel
Communication protocols including HTTP, gRPC, DNS, and AMQP
Data stores such as Redis, MySQL, MongoDB, and PostgreSQL
Automatically tracing all the database queries, API calls, and other operations involved in fulfilling a request provides an end-to-end view of how your application functions."
datadog,"You can then visualize, aggregate, and inspect that data to understand the experience of individual users, identify bottlenecks in your architecture, and map out the dependencies between services."
datadog,"By providing integrations with a wide variety of technologies, auto-instrumenting telemetry libraries make it much simpler to start gathering observability data that provides insights across the stack."
datadog,"Datadog ‚ù§Ô∏è open source
We are excited about the future of OpenTelemetry and are pleased that Datadog‚Äôs open source tracing libraries will provide core instrumentation functionality for the project."
datadog,"We believe that this partnership with OpenTelemetry reinforces the value of open source instrumentation and code, from our distributed tracing libraries to the Datadog Agent that collects infrastructure metrics, distributed traces, logs, network performance data, and more."
datadog,"Our commitment to open source not only enables you to inspect, audit, extend, and improve all of your client-side code as a Datadog customer, but it also can provide benefits to the rest of the industry and community."
datadog,Have you been looking at the docs and been thinking where do I start???
datadog,"Then read on ;)
!!IMPORTANT!!"
datadog,"Be very careful when setting up Datadog, if not done correctly you could occur big unexpected costs!"
datadog,Datadog will charge for usage.
datadog,"For example if you paid for APM and infrastructure but enabled logs, they will still charge you for logs!"
datadog,We fell into this trap and ended up with a large bill!
datadog,"luckily Datadog wavered it, as they could see it was not our error."
datadog,But be so careful and monitor Datadog often and even setup alerts for any anomalies or keep an eye for them!
datadog,"Before I begin remember this‚Ä¶
env:
- name: DD_CONTAINER_EXCLUDE
value: ""name:dd-agent""
Datadog will literally log themselves if you don‚Äôt exclude it, we had over 83 million logs a day as a result of not knowing that."
datadog,"Read this document carefully: https://docs.datadoghq.com/agent/guide/autodiscovery-management/?tab=containerizedagent
you need to understand how the exclude and include works, otherwise it‚Äôs likely that you will end up paying for it."
datadog,"Okay now onto the actual setup :)
In a nutshell you will need to:
Download the Datadog extension
Enable the extension within your app
Composer install the ddtrace package
Init the datadog extension in the entry point to the app
Setup datadog via helm
Add the DD_AGENT_HOST to the env of your php app
1."
datadog,"Download the Datadog extension: I‚Äôve set it up in ubuntu so have downloaded the debian package
jjcallis/datadog
Contribute to jjcallis/datadog development by creating an account on GitHub."
datadog,"github.com

Or download a release here: https://github.com/DataDog/dd-trace-php/releases
2."
datadog,"Enable the extension within your app
Example Dockerfile with php fpm: https://github.com/jjcallis/datadog/blob/main/Dockerfile
Note when the docker image has built and installed the Datadog extension you should see the following:

3."
datadog,"Composer install the ddtrace package
datadog/dd-trace - Packagist
PHP Tracer The Datadog PHP Tracer ( ddtrace) brings APM and distributed tracing to PHP."
datadog,"Visit the PHP tracer‚Ä¶
packagist.org

composer require datadog/dd-trace
This will contain an integration specifically for Laravel (as well as many others)."
datadog,"Which will literally trace the Laravel Router, Response, Dispatcher etc."
datadog,NOTE this package works hand in hand with the extension we enabled in step 2.You need both!
datadog,4.
datadog,"Init the datadog extension in the entry point to the app I.E actually initialise the ddtrace extension
require_once(ini_get('ddtrace.request_init_hook'));

If you exec into your php pod
kubectl exec -ti <pod> -n <namespace> bash
and do
php -r 'var_dump(ini_get(""ddtrace.request_init_hook""));'
You‚Äôll see the extension your going to initialise in index.php

So, that‚Äôs the app sorted!"
datadog,you now need to setup Datadog within your kubernetes cluster.
datadog,5.
datadog,"Setup Datadog via helm
I love to use helm: https://helm.sh when possible, it‚Äôs so good!"
datadog,It handles a good amount for us and benefits from tens or hundreds of individuals maintaining a repository.
datadog,"jjcallis/datadog
Contribute to jjcallis/datadog development by creating an account on GitHub."
datadog,"github.com

Apply this i.e
kubectl apply -f datadog.yaml
Note i‚Äôve disabled logs, as I don‚Äôt require them but if you were to enable logs be sure to check what you need to exclude within
env:
- name: DD_CONTAINER_EXCLUDE
value: ..
Side track: I use flux: https://github.com/fluxcd/flux to automatically apply and disable manifests."
datadog,This allows me to have version control via Github and I can easily disable packages if needed and have a complete audit of everything that is added to the cluster.
datadog,"This will then enable Datadog with dogstatsd, APM, processAgent and clusterAgent etc."
datadog,6.
datadog,"Add the DD_AGENT_HOST to the env of your php app
Within the app you want for the traces to happen you‚Äôll need to set the DD_AGENT_HOST so that the trace is able to emit the traces from the pod to the APM:
Like so:
env:
- name: DD_AGENT_HOST
valueFrom:
fieldRef:
fieldPath: status.hostIP
imagePullPolicy: Always
See example: https://github.com/jjcallis/datadog/blob/main/example%20php%20app%20manifest
End result APM enabled on Datadog :)"
datadog,"At Latitude Financial Services we have been focusing on improving the observability of our distributed systems; to have consistency and reduce time to instrument metrics, tracing, dashboards, monitors and alerts for our appropriately sized services."
datadog,Teams were doing repetitive tasks to set-up observability for their services.
datadog,"Changes were made over time to dashboards, monitors, and alerts but reasons were not being captured anywhere."
datadog,Thoughtworks featured observability as code in their 2018 tech radar highlighting these concerns and how treating these configurations as code can address the issue.
datadog,"At Latitude, we use DataDog for our application and infrastructure monitoring."
datadog,We could not find any suitable tools for managing DataDog dashboards and monitors.
datadog,Hence we decided to build our own tool Growl.
datadog,Growl uses DataDog APIs to manage dashboards and monitors.
datadog,"The first version has the following features:
Create and edit time-boards and monitors."
datadog,CLI interface for CI/CD integration.
datadog,Golang library for dynamically generating dashboards and alerts.
datadog,Primarily used by our cloud team when they provision infrastructure for tenants.
datadog,"Capability to dynamically introduce variables and tags like service name, environment and domain."
datadog,Local developer experience to create changes and export it back as configuration.
datadog,"Dashboard management life cycle
Our service starter kit provides developers standard dashboards and monitors."
datadog,So they are part of the source code from day one.
datadog,"Standard health dashboard created by Growl

Standard monitors created by Growl
Any changes made dashboards or monitors get captured through github commits and pull requests."
datadog,"Github pull request example
To ensure users don‚Äôt edit these dashboards or monitors manually, they are locked to be only modified by the creator i.e."
datadog,Growl.
datadog,"By treating these configurations as code and embracing naming & tagging conventions, we are saving developers hours of effort and introducing better practices and consistency."
datadog,Next steps for us to include relevant infrastructure metrics and potentially look at making Growl open source.
datadog,"We are always on the lookout for good engineers to join our team, please feel free to reach out if you want to know more."
datadog,"Gurnam Madan
Principal Engineer

Follow
100


1


100"
datadog,"8,846 customers across 100+ countries."
datadog,"The company did $198.1M of revenue in 2018, up 97% YoY."
datadog,~24% of their ARR came from customers outside of North America in 2018.
datadog,Their dollar-based gross retention rate has been in the low-to-mid 90% range.
datadog,"~35% of the Fortune 100 were Datadog customers, while only about 20% were customers with ARR of $100K+."
datadog,"Datadog [DDOG], the leader in cloud-based infrastructure and multifunctional service that brings together metrics and events from servers, databases, applications, tools, services to present a unified view of the infrastructure, filed for a $100M IPO."
datadog,Many developers who are closely associated with the development process of HL applications are already well-known Datadog as the company provider for monitoring.
datadog,"It was no secret that Datadog platform was one of the best private SaaS companies, even if compare it with companies that have become public years earlier, their growth is impressive."
datadog,"Offering to IPO
The $100M dollar figure is a placeholder and will almost surely rise significantly in the actual offering."
datadog,Morgan Stanley is leading the IPO and the company plans to trade on the Nasdaq under the ticker [DDOG].
datadog,"The company calls out digital transformation, the move to the cloud, the rapid proliferation of applications and modern tech, and the need for collaboration as core industry trends in their favor."
datadog,"As the amount of software grows within both small and large companies, the need to understand performance and manage this ever-growing and disparate infrastructure ‚Äî whether in the public cloud, private cloud, on-premise or multi-cloud hybrid environments ‚Äî is mission-critical to a company‚Äôs success."
datadog,Datadog platform provides a unified and real-time single pane of glass view into a company‚Äôs entire technology stack.
datadog,"Datadog had the right product at the right time ‚Äî they launched their infrastructure monitoring product in 2012 as the move to the cloud, primarily on AWS, started to accelerate rapidly."
datadog,"The results and efficiency of Datadog‚Äôs growth have been outstanding

Datadog was founded ‚Äúon the premise that the old model of siloed developers and IT operations engineers is broken, and that legacy tools used for monitoring static on-premise architectures do not work in the modern cloud or hybrid environments‚Äù."
datadog,"Their platform enables developers, operations and business teams to collaborate, build and improve software applications and understand business and user performance."
datadog,"Moreover, their product is self-serve in nature and can be easily installed in minutes."
datadog,Datadog was also the first company to combine monitoring across infrastructure and applications as well as offering logging in one solution.
datadog,"In addition, this year they announced products including network performance monitoring and real user monitoring."
datadog,It‚Äôs important to note that each of Datadog‚Äôs products is fully-capable on a stand-alone-basis and customers can choose to deploy one or more of the products at once.
datadog,"When deployed together, the sum is greater than the parts as it offers customers a single pane of glass view across their entire technology stack."
datadog,"In the last 6 months, ~40% of customers use more than one product, up from ~10% only a year ago."
datadog,"Moreover, in the same time period, ~60% of new customers landed with 1 or more products, up from ~15% a year ago."
datadog,It shows Datadog is incredibly proficient at building (and selling) new products.
datadog,"Unlike legacy solutions, which are typically used only by IT, Datadog becomes ubiquitous and in many cases is deployed across a customers‚Äô entire infrastructure environment (including public cloud, private cloud, on-premise, and multi-cloud hybrid)."
datadog,"For the first time, companies are offered a single choke-point of performance in one solution and can consolidate all their needs onto the Datadog platform."
datadog,"Some more information about each of their 5 product offerings is below:
Infrastructure Monitoring: Datadog‚Äôs original and flagship product offering."
datadog,Provides real-time monitoring of IT infrastructure across public/private cloud and hybrid environments ensuring performance/availability of applications.
datadog,"The data is located in one repository with automatic correlation, regardless of environment size or rate of change, to provide a fulsome view of everything that is occurring across a customers‚Äô IT ecosystem."
datadog,"Application Performance Monitoring (APM): Launched in 2017, provides full visibility into the health and functioning of applications regardless of deployment environment."
datadog,"Distributed tracing across microservices, hosts, containers and serverless computing functions enabling customers to gain deep insights into application performance."
datadog,"Log Management: Launched in 2018, offers log management for applications, systems and cloud platforms that ingests data, creates indexes and enables querying of logs with visualizations and alerting."
datadog,Also has machine-learning powered pattern detection of frequently occurring logs for predictive functionality.
datadog,"User Experience Monitoring: Launched in beta in 2019 and now generally available, user experience monitoring brings visibility up the stack to monitor the digital experience of the customer."
datadog,Datadog user experience monitoring includes both the simulation of customers (through Synthetics) and the monitoring of actual users (Real User Monitoring).
datadog,"Network Performance Monitoring: Launched this year and currently in beta, enables the analysis and visualization of the flow of network traffic in cloud-based or hybrid environments."
datadog,"It is very lightweight, allowing customers to monitor the flow of network traffic without sacrificing performance."
datadog,Datadog also enables customers to use the full spectrum of their SaaS and open source products and have 350+ out-of-the-box integrations.
datadog,"As mentioned, customers sign up and can start seeing value in minutes without training or implementation."
datadog,The Datadog platform is scalable and is currently monitoring more than 10 trillion events a day and millions of servers and containers.
datadog,"An output of their many integrations is below:

A few interesting stats Datadog cites from industry research
Global spend on public cloud services, including infrastructure-as-a-service and platform-as-a-service is expected to increase from $60B in 2018 to ~$173 billion in 2022, according to the IDC, representing a 30% compound annual growth rate."
datadog,"Gartner notes the need for companies to trim down the number of monitoring tools used, which in the case of larger enterprises is more than 30, while some smaller organizations have monitoring tools ranging in number from 3 to 10."
datadog,"According to Gartner, enterprises will quadruple their use of APM due to increasingly digitalized business processes from 2018 through 2021 to reach 20% of all business applications."
datadog,"Moreover, according to Gartner, only 5% of applications were monitored as of 2018."
datadog,"Market Opportunity
Datadog‚Äôs market is massive and strategic, but also highly competitive and their suite of products touches many different markets."
datadog,The company believes they can address a large portion of the IT Operations Management market and according to Gartner that market represents a $37B opportunity in 2023.
datadog,Datadog estimates their current market size is $35B by taking a bottoms-up approach and applying their average ARR by customer segment against various company size segments.
datadog,They also believe they‚Äôre still under-penetrated in the base so that number could theoretically be larger.
datadog,"Competition

Given the massive market across its many products, Datadog‚Äôs market is competitive."
datadog,Datadog has a head start as they‚Äôre the only company with a unified platform across these categories ‚Äî a compelling value proposition for customers.
datadog,"The company believes they compete across numerous categories including:
On-premise infrastructure monitoring: They compete with diversified technology companies and systems management vendors including IBM, Microsoft, Micro Focus, BMC Software and CA (Computer Associates)."
datadog,"APM: Cisco, New Relic, Dynatrace and emerging start-ups such as Instanaand LightStep."
datadog,"Log management: Splunk, Elastic [ESTC], and emerging start-ups such as LogDNA and Sumo Logic."
datadog,"It‚Äôs relevant that Splunk just announced the acquisition of SignalFX for $1B, which provides a modern APM solution."
datadog,Competition is heating up and large incumbents are no doubt taking notice of Datadog‚Äôs multi-product success.
datadog,"Cloud infrastructure monitoring: Competes with native solutions from cloud providers such as AWS (Amazon), Google Cloud Platform (Google) and Azure (Microsoft) as well as emerging products from start-ups like Grafana."
datadog,"Real User Monitoring and Network Performance Monitoring:Datadog does not call out competitors here, but New Relic also offers a real user monitoring product as well as emerging companies like LogRocket."
datadog,SolarWinds is a large incumbent on the network monitoring side too.
datadog,Home-grown solutions: Datadog also mentions they compete with internally built products from open-source companies but compete favorably.
datadog,"Acquisitions
Datadog disclosed details around 2 acquisitions."
datadog,"In March of 2017, they acquired Focusmatic for $7.4M ($5.4M in cash), a logging company, and Madumbo, an AI solution, which in September of 2018 for $1.6M in cash."
datadog,"Revenue Run-rate

Valuation
Since Datadog is a fast-growth SaaS company, it‚Äôll likely get valued on a Next-Twelve-Month ARR multiple."
datadog,"The fastest-growing SaaS companies (90%+ YoY) like Zoom, Crowdstrike trade for 20‚Äì25x+ NTM ARR and other fast-growth companies (40‚Äì80% YoY growth) like Zscaler, Alteryx, Twilio, Slack, MongoDB trade between 13‚Äì18x NTM ARR."
datadog,"Using 13‚Äì18x NTM ARR as a rough b/p and assuming Datadog grows 85% (see growth persistence) of its current growth rate of 82% so roughly ~70% YoY, Datadog should be~$560m ARR 12 months from now which implies $7.28b ‚Äî $10b enterprise value."
datadog,"Conclusion
Based on a fundamental analysis of the market for companies that are at different stages of growth ‚Äî Datadog will definitely attract the attention of investors, book subscription is expected to increase up to 12‚Äì16 times."
datadog,"It‚Äôs hard to say currently about a spectacular movement as we‚Äôve seen on Twilio stocks, but already strong S1-numbers will show us a huge demand in [DDOG] shares in the first days after IPO."
datadog,"Simultaneously with an optimistic view of the public offering, all investors must be aware of the risk of political influence between Mr. Trump and Mr. Xi Jinping."
datadog,Pressure and recession indices can significantly reduce income expectations and involve negative factors in the prospect of a dynamic increase in revenue.
datadog,"‚Äî -
The content was collected from various open sources and does not make any one-stop recommendation for the purchase of shares."
datadog,‚Äî -
datadog,Here is a quick recipe on how to setup notifications when SQL queries take more than 300ms.
datadog,"Enable long query logs
In RDS, create or update a parameter group:

Set the value to the parameter ""log_min_duration_statement""

Make sure your database use this parameter group."
datadog,"You can validate this first step by running a test query:
select pg_sleep(1);
Make sure you forward the logs to cloudwatch:

Forward the logs to Datadog
Create a lambda function that forwards the logs to Datadog:
DataDog/datadog-serverless-functions
AWS Lambda function to ship logs and metrics from ELB, S3, CloudTrail, VPC, CloudFront and CloudWatch logs to Datadog‚Ä¶
github.com

Set env variables such as

Create a CloudWatch trigger for this lambda."
datadog,"Create a datadog custom view for these logs
Customize datadog logs to parse postgresql logs:


I wrote this grok rule (I couldn't find an existing rule."
datadog,"If you know how to find an official rule, please let me know):
longqueries %{date(‚Äúyyyy-MM-dd HH:mm:ss‚Äù): timestamp} UTC:%{hostname:userDomain}\(%{integer:unknownInteger1}\):%{word:dbUser}@%{word:database}:\[%{integer:unknownInteger2}\]:%{word:level}: duration: %{number:queryDuration} %{word:durationUnit} statement: %{regex(‚Äú."
datadog,"*‚Äù):statement}
Create a saved view

Then you can create a datadog monitor based on logs and based on this saved view."
datadog,"Company Overview
Datadog, the leader in cloud-based infrastructure monitoring, filed for a $100M IPO."
datadog,The $100M dollar figure is a placeholder and will almost surely rise significantly in the actual offering.
datadog,Morgan Stanley is leading the IPO and the company plans to trade on the Nasdaq under the ticker ‚ÄúDDOG‚Äù.
datadog,"Datadog is an exceptional company in a market that is only beginning to take shape ‚Äî they offer a monitoring and analytics platform for developers, IT, and business teams for what they call the ‚Äúcloud age‚Äù."
datadog,"The company calls out digital transformation, the move to the cloud, the rapid proliferation of applications and modern tech, and the need for collaboration as core industry trends in their favor."
datadog,"As the amount of software grows within both small and large companies, the need to understand performance and manage this ever-growing and disparate infrastructure ‚Äî whether in the public cloud, private cloud, on-premise or multi-cloud hybrid environments ‚Äî is mission-critical to a company‚Äôs success."
datadog,Datadog provides a unified and real-time single pane of glass view into a company‚Äôs entire technology stack.
datadog,"While they got their start in infrastructure monitoring, they now offer a full suite of products across log management and APM (application performance monitoring)."
datadog,They call this the ‚Äúthree pillars of observability‚Äù and were the first company to do so.
datadog,"Datadog had the right product at the right time ‚Äî they launched their infrastructure monitoring product in 2012 as the move to the cloud, primarily on AWS, started to accelerate rapidly."
datadog,The results and efficiency of Datadog‚Äôs growth have been outstanding.
datadog,"The company did $198.1M of revenue in 2018, up 97% YoY."
datadog,"The ended last quarter (30-Jun-2019) with 8,846 customers across 100+ countries."
datadog,The company was founded in 2010 and is based in New York City.
datadog,"Datadog has 1,212 employees across 24 countries."
datadog,"~31% of their full-time employees are located outside of the U.S., 50% of whom are in France."
datadog,"Company Milestones from S-1:
2010: Founded in New York
2012: Launched Datadog Infrastructure Monitoring
2013: Surpassed 100 customers
2014: Began monitoring containers
2015: Expanded research and development to Paris
2015: Surpassed 1,000 customers
2016: Began monitoring serverless environments
2016: Established enterprise sales team
2017: Launched Datadog APM
2017: Opened first international sales office in Dublin
2017: Surpassed 5,000 customers
2018: Launched Datadog Log Management and Analytics
2018: Opened first APAC sales office in Tokyo
2018: Held inaugural DASH user conference in New York
2019: Launched Datadog Synthetics
2019: Established APAC headquarters in Singapore
2019: Announced beta availability of Datadog Network Performance Monitoring and Real User Monitoring
Company timeline graphic:

Source: Company S-1
Product

Source: Company S-1
Datadog was founded ‚Äúon the premise that the old model of siloed developers and IT operations engineers is broken, and that legacy tools used for monitoring static on-premise architectures do not work in modern cloud or hybrid environments‚Äù."
datadog,"Their platform enables developers, operations and business teams to collaborate, build and improve software applications and understand business and user performance."
datadog,"Moreover, their product is self-serve in nature and can be easily installed in minutes."
datadog,Datadog was also the first company to combine monitoring across infrastructure and applications as well as offering logging in one solution.
datadog,"In addition, this year they announced products including network performance monitoring and real user monitoring."
datadog,It‚Äôs important to note that each of Datadog‚Äôs products is fully-capable on a stand-alone-basis and customers can choose to deploy one or more of the products at once.
datadog,"When deployed together, the sum is greater than the parts as it offers customers a single pane of glass view across their entire technology stack."
datadog,"In the last 6 months, ~40% of customers use more than one product, up from ~10% only a year ago."
datadog,"Moreover, in the same time period, ~60% of new customers landed with 1 or more products, up from ~15% a year ago."
datadog,It shows Datadog is incredibly proficient at building (and selling) new products.
datadog,"Unlike legacy solutions, which are typically used only by IT, Datadog becomes ubiquitous and in many cases is deployed across a customers‚Äô entire infrastructure environment (including public cloud, private cloud, on-premise, and multi-cloud hybrid)."
datadog,"For the first time, companies are offered a single choke-point of performance in one solution and can consolidate all their needs onto the Datadog platform."
datadog,"Some more information about each of their 5 product offerings is below:
Infrastructure Monitoring: Datadog‚Äôs original and flagship product offering."
datadog,Provides real-time monitoring of IT infrastructure across public/private cloud and hybrid environments ensuring performance/availability of applications.
datadog,"The data is located in one repository with automatic correlation, regardless of environment size or rate of change, to provide a fulsome view of everything that is occurring across a customers‚Äô IT ecosystem."
datadog,"Application Performance Monitoring (APM): Launched in 2017, provides full visibility into the health and functioning of applications regardless of deployment environment."
datadog,"Distributed tracing across microservices, hosts, containers and serverless computing functions enabling customers to gain deep insights into application performance."
datadog,"Log Management: Launched in 2018, offers log management for applications, systems and cloud platforms that ingests data, creates indexes and enables querying of logs with visualizations and alerting."
datadog,Also has machine-learning powered pattern detection of frequently occurring logs for predictive functionality.
datadog,"User Experience Monitoring: Launched in beta in 2019 and now generally available, user experience monitoring brings visibility up the stack to monitor the digital experience of the customer."
datadog,Datadog user experience monitoring includes both the simulation of customers (through Synthetics) and the monitoring of actual users (Real User Monitoring).
datadog,"Network Performance Monitoring: Launched this year and currently in beta, enables the analysis and visualization of the flow of network traffic in cloud-based or hybrid environments."
datadog,"It is very lightweight, allowing customers to monitor the flow of network traffic without sacrificing performance."
datadog,Datadog also enables customers to use the full spectrum of their SaaS and open source products and have 350+ out-of-the-box integrations.
datadog,"As mentioned, customers sign up and can start seeing value in minutes without training or implementation."
datadog,The Datadog platform is scalable and is currently monitoring more than 10 trillion events a day and millions of servers and containers.
datadog,"An output of their many integrations is below:

Source: Company S-1
Summary Metrics and GTM (Go-to-Market)
Datadog is one of the fastest-growing and efficient software businesses to file for an IPO."
datadog,A combination of their self-serve product adoption and cross-sell has enabled them to generate incredible metrics and growth.
datadog,It‚Äôs clear their relentless focus on creating products that customers love has paid off.
datadog,Datadog uses a land-and-expand business model around products ‚Äúthat are easy to adopt and have a very short time to value‚Äù.
datadog,"The company did $153.3M of revenue in the first 6 months of 2019, up 79% YoY."
datadog,"Almost all their revenue is subscription-based, and they‚Äôre at $332.9M of implied ARR (quarterly subscription * 4), which is up 82% YoY as of their last quarter."
datadog,They‚Äôre doing this with efficiency; essentially free cash flow breakeven for the first 6 months of 2019.
datadog,They are break-even on a non-GAAP basis over the past year.
datadog,"Below are a few relevant stats from their S-1:
Datadog ended last quarter with 8,846 total customers, 594 of which are paying more than $100K+ in ARR and 42 that are paying $1M+ in ARR."
datadog,The top 10 customers represent ~14% of total ARR and no single customer represented more than 5% of ARR.
datadog,"Last quarter the average customer was at $37,631 in implied ACV (implied ARR / total customers)."
datadog,"Most of their ARR, 72% last quarter, comes from those 594 customers paying $100K+."
datadog,"For the first 6 months of 2019, over 35% of new ARR came from Datadog‚Äôs newer platform products, APM and logs, up from over 10% in the same period a year earlier."
datadog,Datadog‚Äôs dollar-based net retention rate was 146% in the first 6 months of 2019 and 2018 and 151% in CY‚Äô18.
datadog,Their dollar-based gross retention rate has been in the low-to-mid 90% range.
datadog,~24% of their ARR came from customers outside of North America in 2018.
datadog,"~35% of the Fortune 100 were Datadog customers, while only about 20% were customers with ARR of $100K+."
datadog,"Subscription agreements are primarily monthly or annual, with some quarterly, semi-annual and multi-year."
datadog,Datadog does experience seasonality and typically wins more new customers and renewals in the fourth quarter.
datadog,"In the first 6 months of 2019, ~60% of Datadog‚Äôs increase in revenue was attributable to growth from existing customers."
datadog,"Datadog‚Äôs customers have many end users of their products ‚Äî they call out a couple of examples: a leading communications software technology provider has almost 800 Datadog users, about half of the company‚Äôs total employee count and greater than the total number of the company‚Äôs engineers."
datadog,"Another company, a Fortune 500 financial services firm, has over 3,000 Datadog users."
datadog,In 2019 Datadog signed an agreement with AWS where they are required to purchase at least $225M of cloud services from AWS through April of 2022.
datadog,"A few interesting stats Datadog cites from industry research:
Global spend on public cloud services, including infrastructure-as-a-service and platform-as-a-service is expected to increase from $60B in 2018 to ~$173 billion in 2022, according to the IDC, representing a 30% compound annual growth rate."
datadog,"Gartner notes the need for companies to trim down the number of monitoring tools used, which in the case of larger enterprises is more than 30, while some smaller organizations have monitoring tools ranging in number from 3 to 10."
datadog,"According to Gartner, enterprises will quadruple their use of APM due to increasingly digitalized business processes from 2018 through 2021 to reach 20% of all business applications."
datadog,"Moreover, according to Gartner, only 5% of applications were monitored as of 2018."
datadog,Datadog‚Äôs GTM is highly efficient.
datadog,"While most customers sign up and start using/paying on a self-serve basis, Datadog segments the GTM team in 4 areas 1) enterprise sales team focused on large business 2) high-velocity inside-sales team focused on new customers 3) a customer success team focused on customer onboarding and expansions in the current base and 4) a partner team that works with resellers, distributors and managed service providers."
datadog,"Datadog mentions their land-and-expand business model is centered around their ability to offer products that are easy to adopt and gain value from, which in turn, allows them to prioritize spend in new product innovation."
datadog,"Given their dollar-based net retention rate was 146% in the first 6 months of the year in both 2019 and 2018, Datadog could theoretically shut off sales to new customers and still grow revenue ~50% YoY."
datadog,"They charge on usage, which is measured primarily by the number of hosts (servers) or by the volume of data indexed."
datadog,"Infrastructure monitoring and APM products are priced per host, while the logs product is priced mostly on per log events indexed and secondarily by events ingested."
datadog,"Datadog doesn‚Äôt disclose the metric, but I suspect most (if not all) of their largest customers started with one user that signed up through self-serve."
datadog,"Datadog‚Äôs website pricing is below:

Source: Company website
Market Opportunity
Datadog‚Äôs market is massive and strategic, but also highly competitive and their suite of products touches many different markets."
datadog,The company believes they can address a large portion of the IT Operations Management market and according to Gartner that market represents a $37B opportunity in 2023.
datadog,Datadog estimates their current market size is $35B by taking a bottoms-up approach and applying their average ARR by customer segment against various company size segments.
datadog,They also believe they‚Äôre still under-penetrated in the base so that number could theoretically be larger.
datadog,"Competition
Given the massive market across its many products, Datadog‚Äôs market is competitive."
datadog,Datadog has a head start as they‚Äôre the only company with a unified platform across these categories ‚Äî a compelling value proposition for customers.
datadog,"The company believes they compete across numerous categories including:
On-premise infrastructure monitoring: They compete with diversified technology companies and systems management vendors including IBM, Microsoft, Micro Focus, BMC Software and CA (Computer Associates)."
datadog,"APM: Cisco, New Relic, Dynatrace and emerging start-ups such as Instana and LightStep."
datadog,"Log management: Splunk, Elastic, and emerging start-ups such as LogDNA and Sumo Logic."
datadog,"It‚Äôs relevant that Splunk just announced the acquisition of SignalFX for $1B, which provides a modern APM solution."
datadog,Competition is heating up and large incumbents are no doubt taking notice of Datadog‚Äôs multi-product success.
datadog,"Cloud infrastructure monitoring: Competes with native solutions from cloud providers such as AWS (Amazon), Google Cloud Platform (Google) and Azure (Microsoft) as well as emerging products from start-ups like Grafana."
datadog,"Real User Monitoring and Network Performance Monitoring: Datadog does not call out competitors here, but New Relic also offers a real user monitoring product as well as emerging companies like LogRocket."
datadog,SolarWinds is a large incumbent on the network monitoring side too.
datadog,Home-grown solutions: Datadog also mentions they compete with internally built products from open-source companies but compete favorably.
datadog,"Acquisitions
Datadog disclosed details around 2 acquisitions."
datadog,"In March of 2017, they acquired Focusmatic for $7.4M ($5.4M in cash), a logging company, and Madumbo, an AI solution, which in September of 2018 for $1.6M in cash."
datadog,"Investors and Ownership
According to Pitchbook, Datadog has raised $147.9M to date from investors including Index, OpenView, Battery, RTP, Dragoneer, Amplify, ICONIQ, Meritech, IVP, T. Rowe Price, and others."
datadog,"5%+ pre-offering institutional investor shareholders include Index (20.1%), OpenView (16.0%), ICONIQ (11.3%) and RTP (8.2%)."
datadog,"Olivier Pomel, CEO and co-founder, is a 14.1% pre-offering stake."
datadog,"Their last primary capital round, a $94.5M Series D led by ICONIQ, was in December of 2015 at a $545M pre-money valuation, according to Pitchbook."
datadog,The company mentions a tender offer that happened in March of 2019 at a $47.75 share price (led by Dragoneer).
datadog,"Moreover, since inception Datadog mentions they have raised $92M of capital (net of share repurchases), so the Pitchbook number likely includes some secondary."
datadog,"Comparing Datadog vs. Other High-growth SaaS IPOs
Given the incredible financial profile of Datadog, I benchmarked them against other SaaS IPOs with regard to subscription revenue-run-rate or implied ARR (indexed), sales efficiency, and LTM operating margins."
datadog,"I did this same analysis for Zoom given their break-out metrics and it shows Datadog is one of the fastest-growing and efficient SaaS companies to ever file ‚Äî see below:
Subscription Revenue Run-rate / Implied ARR Index ($M)
Compares Datadog against all other SaaS/cloud IPOs that had a subscription revenue run-rate (or implied ARR) of close to $100M in their disclosure period (meaning in the 6‚Äì8 quarters that companies disclose in their S-1‚Äôs) indexed to the quarter where they crossed roughly $100M."
datadog,This group includes 25 companies.
datadog,"As you can see, Datadog is the 3rd fast-growing at this scale after Zoom and CrowdStrike."
datadog,"Source: Company S-1's
Here are a few charts comparing Datadog to the 2018 and 2019 cohort (YTD) of SaaS IPOs."
datadog,"IPO Quarter YoY % Growth Rate
Datadog grew revenue 82% YoY in their last quarter compared to a median of 39% for these ~20 companies."
datadog,"Source: Company S-1's
Sales Efficiency: Implied Months to Payback in Disclosure Period
The below looks at payback periods using the inverse of a CAC ratio (net new implied ARR * gross margin/sales and marketing spend of the prior quarter) and compares Datadog to the same set of companies."
datadog,Datadog was at a 9.6-month median over the past 9 quarters ‚Äî the second most efficient behind Zoom.
datadog,"Source: Company S-1's
LTM GAAP Operating Margin
Datadog also has one of the best LTM GAAP operating margins from this group."
datadog,"Datadog was at a (9)% GAAP operating margin over the last 12 months, the 3rd best from the group."
datadog,"Source: Company S-1's
Financials and Other Metrics Outputs
Datadog is a rare company ‚Äî every financial and business metric is best-in-class."
datadog,"They‚Äôre growing revenue 80%+ YoY, have ~10 month payback periods over the past 2 years, dollar-based net retention of ~150% (and a gross revenue retention rate of 90%+), very little to no non-GAAP operating and cash losses, and rapidly growing enterprise logo counts."
datadog,"Moreover, Datadog states they raised $92M in capital (net of share repurchases) and have $63.6M in cash & cash equivalents and restricted cash."
datadog,They also reported $7M of cash spent on 2 acquisitions.
datadog,"This implies they have spent ~$21M to get to $332.9M of implied ARR, a 15.6x ratio, which is incredible."
datadog,The goal for most SaaS companies is to have a 1:1 ratio of ARR/burn at IPO and Datadog is 15x+ that.
datadog,They‚Äôre essentially free cash flow neutral today and generated cash in 2017.
datadog,Outputs of other metrics are below.
datadog,"Historical P&L & Metrics (000's)

Source: Company S-1
Quarterly Subscription Revenue ($M)

Source: Company S-1
Implied Ending ARR ($M)

Source: Company S-1
Quarterly non-GAAP Operating Expenses as a % of Revenue

Source: Company S-1
Quarterly GAAP and Non-GAAP Operating Margins

Source: Company S-1
Customer Cohorts and Dollar-Based Net Retention Rate ($M)
Datadog released a cohort graphic and as you can see, customers expand meaningfully over time."
datadog,"For example, the 2014 cohort includes all customers as of the end of 2014 and this cohort increased their ARR from $4.8M as of 31-Dec-2014 to $19.2M as of 31-Dec-2018, a multiple of 4.0x."
datadog,"Additionally, they disclose that ARR from their top 25 customers as of 31-Dec-2018 increased by a median multiple of 33.9x, as measured from the ARR generated in each such customer‚Äôs first month as a customer."
datadog,"Source: Company S-1
Datadog also exhibits best-in-class dollar-based net retention rates ‚Äî they were at 146% in the first 6 months of 2019 and 2018."
datadog,"I can‚Äôt say this enough; Datadog‚Äôs ability to build, launch, and monetize new products is extremely unique for any company."
datadog,"Sales Efficiency and Payback Periods
As mentioned Datadog doesn‚Äôt release customer counts by every quarter, but the below output plots their implied months to payback using the inverse of a CAC ratio (net new ARR * gross margin/sales and marketing spend of the prior quarter)."
datadog,The magic number is defined as just net new ARR/sales and marketing spend of the prior quarter.
datadog,"As mentioned previously, these are all best-in-class."
datadog,"Source: Company S-1
Cash Flows ($M)

Source: Company S-1
Quarterly P&L / Metrics (000's)

Source: Company S-1
Valuation ($M)
Like all high-growth SaaS IPOs (that have no to little profits), Datadog will be valued on a multiple of forward revenue."
datadog,"The output below uses NTM (next-twelve-months) revenue based on an illustrative range of growth rates and comparable EV (enterprise value)/NTM revenue multiples from other public, high-growth SaaS businesses and calls out a few of the high-growth/multiple companies."
datadog,It also includes an implied ARR multiple range.
datadog,Note that companies do not release forward estimates or guidance in their S-1‚Äôs.
datadog,"The fast-growing SaaS companies (and with strong efficiency) get premium multiples, and Datadog surely fits this group."
datadog,I suspect they trade at a higher EV/NTM revenue multiple than competitors Splunk (6.8x) and Elastic (14.6x).
datadog,Market data as of 23-Aug-2019.
datadog,Note: Enterprise value ranges and growth rates are illustrative.
datadog,"Pricing as of 23‚ÄìAug‚Äì2019
Datadog is one of the fastest-growing and efficient SaaS companies to file publicly."
datadog,"As mentioned previously, they have such high dollar-based net retention they could stop selling to new customers and grow their revenue ~50% YoY (and likely produce a significant amount of free cash flow!)."
datadog,"They‚Äôre sitting in the middle of some of the biggest trends in IT infrastructure ‚Äî the move to the cloud, disparate infrastructure environments and DevOps, digital transformation, and the mission-critical need for companies to understand the performance (and find problems) in their IT/infrastructure stacks."
datadog,"Datadog is the only player that offers a unified and single-pane-of-glass view, all built for the modern, cloud-native world."
datadog,The market opportunity is massive and we‚Äôre still in the early stages of the shift.
datadog,"Lastly, I can‚Äôt think of a company that has executed so flawlessly from a product perspective ‚Äî Datadog got their start in infrastructure monitoring, has moved ‚Äúup‚Äù the stack towards APM and ‚Äúdown‚Äù the stack towards logging, and is continuing to bolt on products that customers are paying for, as evidenced by their high dollar-based net retention rates and multi-product sales growth."
datadog,"Much like Zoom, Datadog is creating a new standard for what it means to have best-in-class SaaS metrics at scale and the public markets will undoubtedly reward them."
datadog,Looking forward to seeing them trade and congrats to Datadog and the team!
datadog,"To sign up to receive these post by email, click here."
datadog,"I also found this letter (from the S-1) by the co-founders , Alexis and Olivier worth calling out:

Source: Company S-1"
datadog,Monitoring and analytics platform Datadog recently filed its S-1 with $100M as a placeholder for the offering.
datadog,"Datadog offers a hybrid cloud application observability solution that provides Dev, Ops, and other teams increased efficiency and end-to-end visibility across the application."
datadog,Currently DataDog has 8.8K customers generating $266M in revenue over the last twelve months.
datadog,"Founded in June 2010, Datadog has ~1,212 employees and is headquartered in New York City, NY."
datadog,Datadog‚Äôs S-1 emphasized that traditional IT Operations Management (ITOM) categories were split between different product lines causing confusion.
datadog,"Datadog brought these categories together by building one platform that integrates the three main components of ITOM: infrastructure monitoring, application monitoring, and logs."
datadog,It also offers user experience monitoring and network performance monitoring (in beta).
datadog,The SaaS platform is cloud-agnostic and empowered by out-of-the box functionality and self-service installation.
datadog,"The platform combines infrastructure monitoring, application performance monitoring, log management, user experience monitoring, and network performance monitoring in one integrated data platform."
datadog,Datadog argues this approach increases efficiency by reducing the challenge of garnering insights across disparate systems.
datadog,"It has machine learning that can cross-correlate metrics, traces and logs to identify outliers and notify users of potential anomalies before they impact the business."
datadog,"It can support dynamic cloud infrastructure including microservices, containers and serverless computing."
datadog,"Functionality includes +350 out-of-the box integrations, customizable drag-and-drop dashboards, real-time visualization, and prioritized alerting."
datadog,"Finally, it brings together developers and operations with a common set of tools to develop a joint understanding."
datadog,"Datadog addresses the IT Operations Management market which represents a $37B opportunity in CY23, according to Gartner."
datadog,"Today, Datadog claims it can service a $35B market, which they calculated by multiplying the number of global companies that are between 200‚Äì999 employees and over 1K employees by the average ARR per customer for each product."
datadog,"There are numerous competitors across IT monitoring, APM, and log management providers."
datadog,"With respect to infrastructure monitoring, they compete with IBM, Microsoft, Micro Focus, BMC, CA, AWS, GCP, and Azure."
datadog,"Regarding APM, Datadog competes with Cisco, New Relic, and Dynatrace."
datadog,In logging they fight for spend against Splunk and Elastic.
datadog,Datadog is growing well.
datadog,"It achieved $198M in CY18 compared to $101M in CY17, 97% YoY growth."
datadog,"For the six months ended June 30, 2018 and 2019, Datadog‚Äôs revenue increased from $85M to $153M, expanding 79% YoY."
datadog,Customers continue to increase at a healthy clip.
datadog,"As of June 30, 2019, Datadog had ~8.8K customers, growing from roughly 7.7K, 5.4K and 3.8K customers as of December 31, 2018, 2017 and 2016, respectively."
datadog,"Approximately 590 as of June 30, 2019 had annual run-rate revenue (ARR) of $100K or more, increasing from approximately 450, 240 and 130 customers as of December 31, 2018, 2017 and 2016, respectively, accounting for approximately 72%, 68%, 60% and 48% of ARR, respectively."
datadog,"Further, as of June 30, 2019, they had 42 customers with ARR of $1M+, up from 29, 12 and two customers as of December 31, 2018, 2017 and 2016, respectively."
datadog,"As of June 30, 2019, its 10 largest customers represented approximately 14% of its ARR and no single customer represented more than 5% of ARR."
datadog,Revenue is derived from both U.S. and international customers.
datadog,International customers represented 24% of revenue the past two years.
datadog,"Other than the United States, no other individual country accounted for 10% or more of total revenue for the years ended December 31, 2017 or 2018."
datadog,The business‚Äô dollar-based net retention rate is strong at 151% in CY18.
datadog,The dollar-based net retention rate (NRR) is total current period ARR divided by the total prior period ARR for the customer cohort.
datadog,Our recent research found that the SaaS businesses achieving 140% net dollar retention are in the top decile.
datadog,"As of June 30, 2019, approximately 40% of Datadog‚Äôs customers were using more than one product, up from ~10% a year earlier."
datadog,"Moreover the six-month period ended June 30, 2019, ~60% of new customers landed with more than one product, up from ~15% for the same period the previous year."
datadog,"Moving on to gross margin, which equals revenue minus the cost of goods sold that includes things like hosting costs and customer support."
datadog,"Datadog achieved an 77% gross margin in CY18, below New Relic‚Äôs 84% for the same period."
datadog,"Of each operating expense item, Datadog spends the most on S&M at 45% in CY18, below New Relic‚Äôs spend of 54% of revenue for the same period."
datadog,"Its GTM motion includes self-service tier, a high velocity inside sales team, and an enterprise sales force."
datadog,The company has a strong magic number of 1.8.
datadog,A magic number over 1 suggests there is S&M efficiency.
datadog,"In terms of net income margin, Datadog achieved -5% in CY18, worsening from -3% for the equivalent period a year earlier."
datadog,Datadog‚Äôs negative net income margin last year was close to New Relic‚Äôs -7%.
datadog,"Datadog has raised $148M in total funding, with its last round (Series D) raising $95M in January 2016."
datadog,"Investors include Iconiq Capital (11% ownership), Index Ventures (20% ownership), and OpenView Venture Partners (16% ownership), among others."
datadog,Datadog‚Äôs IPO registration touches on a few trends.
datadog,First observability continues to be hot with the recent Dynatrace IPO and SignalFx acquisition.
datadog,"Second, when underlying infrastructure emerges (e.g."
datadog,the cloud) there is an opportunity to capture customers as they replatform.
datadog,"Finally, using a single product, in this case infrastructure monitoring, as a Trojan horse for a larger platform play is compelling."
datadog,"After almost a decade of being private, it will be exciting to watch as Datadog goes public."
datadog,Like our articles?
datadog,"Sign up for our Public Comps newsletter here
I worked in venture for 4 years at Insight Partners ($20 billion AUM software focused fund) and Signalfire ($800m AUM) where I focused on investing in growth-stage SaaS companies."
datadog,It was no secret that Datadog was one of the best private SaaS companies.
datadog,Datadog‚Äôs S-1 made me realize what a truly amazing business it is.
datadog,"In this post, we summarize Datadog‚Äôs S-1."
datadog,Our philosophy at PublicComps.com (SaaS metrics for Public Companies) is that numbers don‚Äôt mean anything by themselves.
datadog,"So in this blog post, we benchmark Datadog‚Äôs metrics against its competitors and SaaS peers to contextualize why Datadog is such a phenomenal business."
datadog,Datadog benchmarked against the Public SaaS companies we track.
datadog,"Problem
Prior to Datadog, the co-founders Olivier and Alexis led the development team and the technical operations team respectively at Wireless Generation."
datadog,The database the two had to work with and maintain was called ‚ÄúDatadog‚Äù ‚Äî hence the name of the company.
datadog,Alexis and Olivier realized that there was a lot of friction between the developers who were writing code and the technical operations team who were making sure the code ran properly.
datadog,There wasn‚Äôt a common set of tools or metrics that both the developers and operations team could look at to monitor the health of the same system they were all using.
datadog,Was it the code or was it the test or infrastructure that was to blame when the websites slowed for users?
datadog,"Additionally, in 2010 when Oliver and Alexis started Datadog, companies were just starting to move move from legacy on-premise IT to public & private cloud products like AWS."
datadog,"Because companies were starting to deploy updates to their websites in days instead of months, teams needed a way to observe their cloud infrastructure in real-time (‚Äúobservability‚Äù)."
datadog,"To complicate things further, there was a shift from monolithic code bases to distributed systems that leveraged micro services and containers which made monitoring the thousands of servers and hosts very painful for the IT teams and developers."
datadog,"Product Overview
Datadog is cloud-native software product that allows IT teams, developers, and business teams to collaborate, monitor and analyze the health and performance of cloud infrastructure and applications to make sure their digital products are working properly."
datadog,"Additionally, Datadog claims to be the first company to allow end-to-end monitoring and analytics by providing products across infrastructure & application performance monitoring, log management, user experience monitoring, and network performance monitoring."
datadog,The company focuses on providing a unified view of a company‚Äôs entire tech stack in one product vs metrics living in different dashboards or solutions.
datadog,"Timeline of Datadog‚Äôs various product lines from its S-1
2010: Founded in 2010
2012: Launched Datadog Infrastructure Monitoring
2014: Began monitoring containers
2016: Began monitoring serverless environments
2017: Launched Datadog APM
2018: Launched Datadog Log Management and Analytics
2019: Launched Datadog Synthetics
2019: Announced beta availability of Datadog Network Performance Monitoring and Real User Monitoring
Key Product Highlights
Easy to Integrate: At its core, Datadog integrates seamlessly to the entire tech stack ranging from cloud vendors (AWS, Azure, Google Cloud Platform, Alibaba Cloud), databases (Postgres, MySQL, MongoDB), automation tools/source control (CircleCI, Bitbucket, Gitlab, Github), other monitoring services (New Relic), containers (Docker, Kubernetes, etc), bug tracking (Jira), etc."
datadog,"With the 350+ integrations, Datadog is able to pull and surface all the metrics that matter for the different services that make cloud applications and infrastructure work."
datadog,"The value for customers is that they‚Äôre able to integrate data sources or vendors in minutes versus requiring engineering resources that could take hours to add, say, MongoDB or Kubernetes as services to track."
datadog,Dashboard of Metrics: Datadog allows teams to put the core metrics that matter for their infrastructure & application onto a single dashboard.
datadog,"Instead of having to dig into specific metrics that different vendors spit out, Datadog allows users to see what‚Äôs going on at all times with their entire tech stack."
datadog,The company provides an easy and simple way to drag and drop metrics onto a dashboard.
datadog,"Because of their log management product, Datadog is also powerful enough for developers to drill into specific logs to debug why a specific service became so slow."
datadog,Collaboration: The team at Datadog really emphasize the importance of breaking the traditional silos that Alexis and Olivier dealt with at Wireless Generation between the IT operations and developers.
datadog,"Because Datadog is a single dashboard that integrates across the entire tech stack, developers, IT, business users can investigate collaboratively and have a joint understanding of the health of their application & infrastructure."
datadog,"When there‚Äôs a spike in, say, query latency, someone on the IT team can make a comment and notify a developer and share what the IT team is seeing."
datadog,"Cloud Agnostic: It‚Äôs worth noting that while AWS, Google Cloud Platform, Azure offer some sort of cloud monitoring solutions (e.g AWS has AWS Cloud Watch), Datadog is cloud agnostic and works across cloud vendors."
datadog,Alerts: Datadog integrates with 3rd party issue & incidence response tools like Pagerduty and communication platforms like Slack.
datadog,"In the spirit of collaboration, Datadog can automatically notify a developer or IT team on Slack if there‚Äôs a performance problem and allow users to trigger or resolve problems within Pagerduty or Servicenow."
datadog,"Business Model
Datadog charges a subscription fee for its various products on a monthly or annual contract basis."
datadog,Majority of Datadog‚Äôs revenue is subscription software sales so revenue run rate ~ annual recurring revenue (ARR).
datadog,"It‚Äôs worth noting that because Datadog doesn‚Äôt charge by seat, the company incentivizes companies to add more IT members, developers or business users to the product which drives adoption within organizations."
datadog,"Go-To-Market (GTM)
Datadog has a highly efficient go-to-market model."
datadog,"In its S-1, Datadog talks a lot its land-and-expand business model focusing on a product that‚Äôs easy to adopt (hence the many out-of-the-box integrations Datadog offers) and with a short time to value."
datadog,"Not surprisingly, Datadog has a self-service and free trial model which allows any customer to integrate Datadog into various data sources for 14 days without requiring a credit card ‚Äî reducing the friction of signing up and getting value right away."
datadog,"Additionally, Datadog has an inside sales team and enterprise sales force."
datadog,The customer success team is in charge of renewals and upsells.
datadog,"As we‚Äôll see in the next section, the efficient GTM and land-and-expand nature of its cloud offering has lead to best-in-class payback period and net dollar retention."
datadog,"Business Performance & Financials
In analyzing Datadog, we focus on the metrics that matter most for SaaS companies: Revenue, Revenue Growth Rate, Gross Margin, Retention, Payback Period, and Profitability/Capital Efficiency."
datadog,Check out my article ‚ÄúTop 5 SaaS Metrics that VCs Look At‚Äù to understand the how & why behind the metrics.
datadog,"Revenue: At $332m ARR, Datadog is definitely on the smaller side relative to all Public SaaS companies (e.g Salesforce is $16b annual revenue run rate) but DDOG in the same $300‚Äì500m ARR range as other high growth SaaS companies like Crowdstrike, Zoom, Elastic, Alteryx, MongoDb."
datadog,Datadog added $52.7m in its most recent quarter and in the last 4 quarters its added $150m ARR which is quite impressive.
datadog,"Further, Datadog is seeing an increase in net new ARR in the last 4 quarters ($52.7m net new ARR June ‚Äô19 up from $33.8m Mar ‚Äô19) which is always a positive sign of continued growth."
datadog,"Growth Rate: At 82% year-over-year ARR growth, Datadog is the 4th Fastest-Growing Public SaaS company and fastest growing DevOps company."
datadog,Gross Margin: Datadog has slightly lower gross margins than the typical SaaS company because of the cost of having to pay 3rd party cloud vendors to store all the data that they capture on behalf of their customers.
datadog,Payback Period: Datadog has the lowest payback period (9 months) driven by the self-service model and high-velocity sales motion.
datadog,"And the most recent payback period wasn‚Äôt just an anomaly: if you take the median payback period in the last 8 quarters, it‚Äôs roughly 10 months."
datadog,Retention: Datadog‚Äôs 146% net dollar retention is highest among public SaaS.
datadog,Customers almost never churn (90‚Äì95% gross dollar retention according to their filing) and customers pay more when adding more workloads as customers migrate or add more applications to the cloud.
datadog,"Additionally, because Datadog continues to release new product lines, Datadog can upsell existing customers other products like their APM or Log Management product."
datadog,"That‚Äôs highlighted by 40% of their customers paying for more than one product (as of June 30th, 2019) up from 10% a year prior."
datadog,It‚Äôs impressive how much Datadog‚Äôs cohorts expand even beyond year 1.
datadog,"From their S-1: ‚ÄúFor example, the 2014 cohort includes all customers as of the end of 2014."
datadog,"This cohort increased their ARR from $4.8 million as of December 31, 2014 to $19.2 million as of December 31, 2018, representing a multiple of 4.0x.‚Äù

Customer Cohort Analysis ($MM ARR) from Datadog‚Äôs S-1
Capital Efficiency: Datadog spent $30m of cash to get to $330m ARR."
datadog,That‚Äôs ridiculous capital efficiency ($1 spent for every $10 ARR).
datadog,"In comparison, Slack spent nearly ~$560m in capital to get to $539m ARR which is good and roughly $1 spent for every $1 ARR."
datadog,Datadog is almost 10x more capital efficient than Slack is!
datadog,"While Datadog is still not yet profitable (-5% operating income margins in most recent quarter June 30th, 2019), Datadog is effectively cash flow break-even at ~-4% free cash flow margins and even generated $6m of free cash flow in CY2017."
datadog,"Other Interesting Business Metrics
Average Annual Contract Values (ACVs): With 8,846 customers as of June 30, 2019 (up from 7,676 in December 2018) and a ARR of ~$330m, average ACVs per customer is roughly ~$37,000."
datadog,"Customers of >$100,000 and $1M+ ARR: Datadog‚Äôs growth is coming from customers paying >$100,000 ARR and even $1M+ ARR and its revenue is increasingly driven by these larger customers."
datadog,"‚Äú594, 453, 239 and 126 of our customers had ARR of $100,000 or more as of June 30, 2019 and December 31, 2018, 2017 and 2016, respectively, accounting for approximately 72%, 68%, 60% and 48% of our ARR‚Äù
As of June 30, 2019, we had 42 customers with ARR of $1.0 million or more, up from 29, 12 and two customers as of December 31, 2018, 2017 and 2016, respectively
International Revenue: 24% of ARR is from customers outside of North America."
datadog,International markets seems like a growth opportunity for Datadog.
datadog,"Market Opportunity
Large and Growing Market: Company estimates its market size is $35b based on average contract values and number of customers in its given market."
datadog,Datadog cites an IDC research that infrastructure and platform-as-a-service spend will nearly triple from $60b in 2018 to $173b in 2022.
datadog,It doesn‚Äôt take a huge leap of faith to believe that companies will continue to spend on migrating from on-premise legacy systems to the cloud and will require adopting monitoring solutions like Datadog and its competitors.
datadog,"Competitors

Infrastructure Monitoring:
Datadog claims it competes against on-premise infrastructure monitoring tools that don‚Äôt work quite well in a world of distributed systems and micro-services like CA Technologies, BMC, Microfocus, Microsoft and IBM."
datadog,Company also competes with homegrown solutions that leverage open source solutions like Graphite and Nagios but the downside of these solutions are that engineers are required to integrate with data sources and other vendors and aren‚Äôt built for DevOps colloboration.
datadog,"Other cloud-focused monitoring competitors include Kibana (Elastic), Grafana (open source), and SignalFx (acquired by Splunk for ~$1b)."
datadog,"Grafana, in particular, is quite interesting since its an open-source alternative to Datadog (you fork their repo here and start visualizing logs and metrics) and the visualizations are stunning."
datadog,"Because Grafana is open source, it‚Äôs free and I suspect a phenomenal GTM for Grafana as it acts as a ‚Äúfree trial‚Äù."
datadog,Grafana does have an enterprise product that has ‚Äúpremium plugins‚Äù and ‚Äúenterprise security‚Äù features like locking down sensitive data and clearly states what goes into open source and enterprise product.
datadog,The business just raised its $24m Series A from Lightspeed.
datadog,My guess is Grafana is the biggest threat to Datadog moving forward since its a ‚Äúfree‚Äù open-source alternative to Datadog ‚Äî one of the biggest complaint about Datadog is that it‚Äôs too expensive (see this Reddit thread and this Runnable article).
datadog,Datadog also competes with the cloud vendor‚Äôs own solutions like AWS Cloud Watch and GCP and Azure‚Äôs cloud infrastructure monitoring solutions.
datadog,"Application Performance Monitoring:
It‚Äôs interesting to note that Datadog just got into the Application Performance Monitoring space in 2017 (~2 years ago) and the number of public SaaS competitors."
datadog,"Competitors include Appdynamics (Cisco acquired in early 2017), New Relic (NYSE: NEWR), Dynatrace (NYSE: DT), Solarwinds (NYSE:SWI), and Splunk‚Äôs own APM product."
datadog,"Start up competitors include Lightstep ($70m raised, Microservices and Serverless APM and Observability) and Instana ($57m raised, APM for microservices)
Log Management: Splunk‚Äôs recent acquisition of SignalFx puts Splunk directly competitive with Datadog across all three product verticals."
datadog,It‚Äôs interesting that both are ~$300m ARR growing 80% YoY.
datadog,"Other competitors in the log management market include Elastic (NYSE: ESTC), Splunk, Sumo Logic, and LogDNA."
datadog,"It‚Äôs worth noting that Datadog is growing more quickly than most of its public market SaaS competitors particularly Elastic, Appdynamics (acquired by Cisco), Dynatrace, Splunk, New Relic and Solar Winds."
datadog,"Valuation
Since Datadog is a fast growth SaaS company, it‚Äôll likely get valued on a Next-Twelve-Month ARR multiple."
datadog,"The fastest growing SaaS companies (90%+ YoY) like Zoom, Crowdstrike trade for 20‚Äì25x+ NTM ARR and other fast growth companies (40‚Äì80% YoY growth) like Zscaler, Alteryx, Twilio, Slack, MongoDB trade between 13‚Äì18x NTM ARR."
datadog,"Using 13‚Äì18x NTM ARR as a rough ball park and assuming Datadog grows 85% (see growth persistence) of its currently growth rate of 82% so roughly ~70% YoY, Datadog should be~$560m ARR 12 months from now which implies $7.28b ‚Äî $10b enterprise value."
datadog,"The >5% institutional shareholders are Index Ventures (20%), Openview (16%), ICONIQ (11.3%), and RTP (8.2%)."
datadog,Olivier (Co-founder/CEO) owns 14.1% and Alexis (Co-founder/CTO) owns 8.9%.
datadog,"Conclusion
Datadog is riding the wave of companies moving towards the cloud and is spearheading the best practices of Developers and Technical Operations teams (DevOps) working together within Datadog‚Äôs platform."
datadog,The business continues to grow rapidly with best-in-class sales efficiency and retention.
datadog,We believe Datadog will have a very successful IPO and are excited to see where the business goes.
datadog,"Congratulations to Olivier, Alexis and the Datadog team!"
datadog,"Caveats:
I am not a financial advisor and I‚Äôm also not an investor in Datadog."
datadog,This post is not meant to be investment advice.
datadog,I borrow some of the same graphs that Alex Clayton uses in his S-1 breakdowns because they‚Äôre smart and important.
datadog,Originally posted on https://www.publiccomps.com/blog/datadog-s-1-teardown
datadog,How will monitoring agents know what & how to monitor?
datadog,"(This is part 1 of a multi-part series on modern monitoring system design, considerations, and tradeoffs."
datadog,"Other forthcoming parts include Collection & Transmission, Ingest & Storage, Alerting & Notifications, and Visualizations.)"
datadog,Push vs.
datadog,"Pull is a long-running conflict in monitoring system design, i.e."
datadog,should agents push their data to the monitoring system or should the system pull from the agents?
datadog,"Various systems & vendors are on either side, notably Prometheus pulling & Nagios/Zabbix usually pushing."
datadog,"But that‚Äôs about the metrics themselves, and which way they flow in the system."
datadog,"Equally interesting (to me) is how & where the monitoring configurations are set and then moved around, i.e."
datadog,pushed or pulled.
datadog,"Therein lies complexity, tradeoffs, and possibilities."
datadog,"We‚Äôre building a new version of the underlying monitoring and metric storage systems for our Siglos.io Platform, and are trying to think deeply about the best architectures, paradigms, and methods ‚Äî ideally a blend of traditional & modern DevOps to best serve any & all types of environments & customers."
datadog,"I‚Äôm using my own definitions of pull vs. push, as seen from the central monitoring system storing & acting on the data."
datadog,"Push configs are common in traditional systems like Nagios and our beloved Zabbix, on which we‚Äôve been based for more than 10 years."
datadog,Metrics are defined centrally and PUSHED out to assigned hosts and agents.
datadog,"These systems can often auto-discover, but even that is defined centrally and flows up and back down via the monitoring system."
datadog,"The central system is the boss and the agents follow orders, like an army."
datadog,Stuff never just arrives.
datadog,"Pull, on the other hand, is when the agents themselves contain the monitoring configuration, such as in Datadog, collectd, and Prometheus."
datadog,"The agents somehow know what they need to collect and push the metrics (and often any metadata like units, plus tags) to the central system."
datadog,"From the central monitoring system it‚Äôs getting, or pulling, the configs & metric metadata, from the agents."
datadog,"The agents are the boss, and the central system follows them and what they send, like a magazine with stringers."
datadog,Stuff just arrives.
datadog,"The key difference is that in the Push system, the central monitoring system know all about the metrics, who has them, what they are, and so on."
datadog,"In the Pull system, it knows nothing (or very little) about what‚Äôs coming in, when, or even from who."
datadog,They are left to imply a lot from the names (i.e.
datadog,Prometheus) or from shared knowledge of what the agent sends (Datadog).
datadog,"Push Configs are great ‚Ä¶
Central configuration and pushing metric collection configs down to the agents is a very nice architecture, with at some key benefits:
Everything is centralized, so it‚Äôs very easy to make global & wide or narrow-range changes."
datadog,"We often add (or disable) metrics in our Zabbix system, and they roll out to thousand-host fleets in minutes."
datadog,"Likewise, we can add or change monitoring metrics or frequencies, etc."
datadog,on single groups of hosts that are having issues.
datadog,New information arrives nearly instantly.
datadog,"Push is especially useful with generic monitoring agents such as JMX and MySQL (or CloudWatch), which can get any of hundreds of possible metrics, so all we have to do is specify which we‚Äôd like at any given time on any given set of servers and services."
datadog,"It‚Äôs very flexible & dynamic, in near real-time."
datadog,"Central systems often have templates, allowing new hosts and services to be very quickly & easily defined, inheriting all they need from existing templates."
datadog,"This lets us setup complex new host monitoring in seconds, automatically inheriting our years of approved best practices."
datadog,"Central config allows for well-defined graphs, maps, and alerts, since all the data, types, units, etc."
datadog,"is known in advance, and often defined by service experts such as DBAs."
datadog,"Pull Configs are great ‚Ä¶
Pull (agent-defined configs) are great too, as centralized management pushing configs to agents is not problem-free, nor the perfect solution :
Pull systems usually accept ad hoc and unplanned metrics at any time, or even the ‚Äòsame‚Äô metric with different units, tags, etc."
datadog,"This is a big advantage of Pull, especially in the DevOps world when developers can decide any time to add metrics to the mix."
datadog,"Just send stuff, any time."
datadog,"Pull systems tend to be more ‚Äòmodern‚Äô, and better at accepting tags and additional metadata with the metrics."
datadog,"They are also starting to blur the line between metrics, events, and even logs (which are just semi-structured events), mixing them all together."
datadog,"This allows for much richer querying, visualizations, and problem-solving."
datadog,"A real problem in the Pull world is that the central system has no idea what data it‚Äôs getting, nor how to visualize or alert on it."
datadog,"That info has to be provided somehow, often manually at consumption time, or via a ‚Äòrelease‚Äô process along with code releases."
datadog,Some systems like Datadog avoid this in the standard case by having ‚Äòshared‚Äô knowledge between the agent and the central system.
datadog,"When you add the MySQL or Apache Integration, both sides know what to expect and you get both useful best-practice data and pretty pre-defined dashboards."
datadog,"To some extent, that‚Äôs the best of both worlds, but still very rigid and hard to extend, as it‚Äôs still really a pull system with limited central knowledge."
datadog,"This became painfully obvious to us a couple years ago while testing Datadog‚Äôs API, as we had no way to figure out what metrics it had for any given host; it has no idea, so you just query for a given metric and see what you get."
datadog,"Dynamic, but a tad disorganized (note Datadog is a great system, we‚Äôre just picking on the model a bit)."
datadog,Best of both words?
datadog,"We are left trying to see if we can find a middle path that gives us mostly central control we are used to, with lots of benefits, but flexible dynamic ad hoc behavior everyone would love to have."
datadog,"Note we are well-aware that ‚Äúcloud-native‚Äù folks will tell us to forget the central model, go all-in on DevOps, monitoring-as-code, etc."
datadog,"However, we think this foregoes considerable benefits, plus the vast majority of enterprise and more traditional or mixed-mode IT folks will like central definitions."
datadog,"Thus, we are tending towards a central model that also allows dynamic updates, essentially a Zabbix-like system that accepts, even loves, ad hoc data."
datadog,"Plus, of course, tags and all the extra dimensions users want to send."
datadog,"This gets us central templated and well-defined control, including lots of best-practice standards, alerts and graphs, plus the ability to make large-scale changes, improvements, etc."
datadog,"New host/service discovery would be defined centrally, so as new things are found, the central system adds their templates and monitoring."
datadog,"At the same time, we want to accept ad hoc metrics in the Prometheus or InfluxDB style, finding ways to infer their metadata like type, period, units, etc."
datadog,"We‚Äôll probably do that by creating a definition record on first receipt and then a semi-automated follow-up process to nail down how to deal with them for alerting and other things (ideally the release process will use our API to configure graphs & alerts, but dashboards, etc."
datadog,are still likely issues).
datadog,"Thus dynamic metrics will go through phases from first arrival through fully ‚Äòdefined‚Äô, which is a bit messy and creates overhead, but seems unavoidable for long-term data."
datadog,"Fortunately, we have a large common data platform that already deals with most of this across metric & non-metric sources like configs, billing, governance and more, so we‚Äôll probably handle it there."
datadog,"For developer support, we need to think about how to push changes into the system during DevOps deployments, for ad hoc stuff as noted above, but also ideally for more pre-defined services like nginx."
datadog,"The latter can be discovered, but hopefully ad hoc stuff can have enough hints & metadata to be integrated automatically (and later dropped when users lose interest)."
datadog,"For globally-distributed and on-premise systems, this whole process also has to support proxies, agents, and agent-less systems like our Local Management Server (similar to the ServiceNow MID, which I‚Äôll write about soon.)"
datadog,"Decoupling Metric Configuration & Storage
Future articles will talk more about metric & time series storage, but an important part of all this is the likely decoupling of metric storage from the metric configuration."
datadog,"This means using near-native storage in modern dynamic time series stores such as InfluxDB, Prometheus, ElasticSearch, or even DynamoDB, driven by a flexible keyset of host, metric, tags, etc."
datadog,"Collection, enrichment, ingest, and querying / graphing can be driven by the config system, but storage can flexibly use a variety of diverse choices."
datadog,"Monitoring is an ever-changing area, a mix of many traditional things that work in diverse environments, coupled to new-fangled ideas that provide great value in today‚Äôs fast-moving dynamic, microservice, and serverless worlds."
datadog,We‚Äôre always thinking about how to do both old & new things all along the way.
datadog,Ideas and feedback are most welcome as we work our way along this odyssey.
datadog,"I‚Äôm Steve Mushero, CEO & CTO of Siglos.io ‚Äî Siglos is a Unified Cloud & Operations Platform, built on 10+ years of large-scale global system management experience."
datadog,"Siglos includes Full-Stack Design, Build, Management, Monitoring, Governance, Billing, Automation, Troubleshooting, Tuning, Provisioning, Ticketing and much more."
datadog,For Managed Service Providers and selected end users.
datadog,See www.Siglos.io for more information.
datadog,The result can be seen in this repo or it can be installed from the App Service by going to the Extensions tab within the Azure portal.
datadog,Within that repo is a README that will tell you how to install Datadog in your App Service.
datadog,"Set up the agent host
Set up a host running the Datadog agent, like so: https://docs.datadoghq.com/tracing/send_traces/."
datadog,Grant that host a public IP or otherwise make the host accessible on port 8126 from the Azure app service.
datadog,Make sure the agent has attribute ‚Äúapm_non_local_traffic: true‚Äù (under apm_config).
datadog,"Add the Datadog nuget package to your application
Add the same version as is used in this extension (currently 1.3.0)."
datadog,"See here: https://www.nuget.org/packages/Datadog.Trace.ClrProfiler.Managed
Set the environment variables
Go to your app service and click on ‚ÄúConfiguration.‚Äù Add new variables by clicking ‚ÄúNew application setting‚Äù for the following:
DD_AGENT_HOST pointing to the accessible IP for the machine in the step above (‚ÄúSet up the agent host‚Äù)."
datadog,"DD_API_KEY pointing to your Datadog API key (From the Datadog portal: Integrations -> APIs -> API Keys)
DD_ENV set to the environment name you want to appear in Datadog
DD_SERVICE_NAME pointing to the service name you want to appear in Datadog
Add the extension
From the left pane of the app service, select ‚ÄúExtensions.‚Äù Click on ‚ÄúAdd‚Äù and select the ‚Äú.NET Core Datadog APM x86‚Äù for an app that is running .Net Core in a non-self-contained application."
datadog,Accept the license terms and select ‚ÄúOK‚Äù to install.
datadog,Restart the application for this to take effect (and for any of the above environment variable changes to take effect).
datadog,You probably also need to uninstall any other APM extensions you have installed on the app service.
datadog,"Background
Datadog‚Äôs APM product for .NET and .NET Core graduated from beta in April."
datadog,"We had been eagerly awaiting this release, as we had already been monitoring some of our Node.js applications with Datadog with positive results and we wanted to add our various .NET Core services to the mix."
datadog,Adding these other interleaved services to the same observability platform seemed like an impactful feature to pursue.
datadog,"Currently, we run most of our .NET Core services on Azure App Services."
datadog,This product is a hosted solution for services that abstracts away most of the concern for managing the underlying VMs.
datadog,"As such, Azure allows very limited access to the underlying host(s) and provides extensibility through App Service extensions, an open platform for installing pieces of additional functionality within your App Service."
datadog,"When on the technological edge, one often needs to work through significant ambiguity."
datadog,"While Azure App Services can run with a variety of platforms, it is often natural to see them with .NET and .NET Core applications."
datadog,"Since Datadog‚Äôs support for these types of applications is so new, they have yet to offer official support for an App Service extension, and had no solid timeline for when it would be developed."
datadog,This feature seemed important enough from our perspective to pursue a solution on our own and Datadog support was helpful and impactful through the entire process.
datadog,"Figuring out how to build an extension
This was my first foray into building an App Service extension."
datadog,"The documentation is scattered, and examples were a good start, but didn‚Äôt necessarily cover the requirements for this extension."
datadog,"The primary documentation I found was here, with much of the documentation I found pointing to this ancient example."
datadog,"Since there are other APM products that already exist as extensions, I sought one of these out as an example."
datadog,"The above documentation referred to a site extensions portal as the source of the extensions and I downloaded a few to no avail, but I couldn‚Äôt find, for example, the RayGun APM extension, which I ended up finding through a web search here (this should have been my first clue to a problem I encountered later)."
datadog,"Attempt #1: Manually install agent and APM artifacts on the App Service
With the RayGun extension, it was clear how they were setting many of the environment variables (through applicationHost.xdt), and it seemed like there was an install.cmd and uninstall.cmd which were invoked by convention when the extension was installed and uninstalled, respectively."
datadog,They were taking the RayGun agent and running it through a WebJob on the App Service.
datadog,"OK, this seemed like something I could try to replicate."
datadog,"I installed the Agent and .NET Core APM on my dev machine, and copied the files that resulted from the installation to Azure through Kudu."
datadog,"I set up the environment variables that were needed ‚Äî according to the Datadog documentation ‚Äî through the App Service application settings, which I previously knew to work for this purpose."
datadog,I set up the WebJob to run the agent EXE and restarted the app service to allow the changes to take effect.
datadog,The result: I was able to get the agent running and logging within the WebJob.
datadog,"There were a ton of errors logged, and I added some environment variables to point config files to the right location on these machines."
datadog,"However, there were a number of errors still about loading files and not being able to access various system resources and the like."
datadog,WARN | (pkg/util/log/log.go:482 in func1) | Failed to open registry key: The system cannot find the file specified.
datadog,"‚Ä¶
ERROR | (pkg/util/winutil/pdhutil/pdhhelper.go:85 in pdhEnumObjectItems) | Failed to enumerate windows performance counters (class Processor)
ERROR | (pkg/util/winutil/pdhutil/pdhhelper.go:86 in pdhEnumObjectItems) | This error indicates that the Windows performance counter database may need to be rebuilt
‚Ä¶
ERROR | (pkg/collector/corechecks/loader.go:76 in Load) | core.loader: could not configure check file_handle: Requested counter is a single-instance: Process
ERROR | (pkg/collector/scheduler.go:184 in GetChecksFromConfigs) | Unable to load the check: unable to load any check from config ‚Äòfile_handle‚Äô
But, there were also some promising logs that indicated things were working to some extent:
INFO | (cmd/agent/app/start.go:121 in StartAgent) | Starting Datadog Agent v6.10.1
INFO | (cmd/agent/app/start.go:149 in StartAgent) | Hostname is: ***************
INFO | (cmd/agent/gui/gui.go:81 in StartGUIServer) | GUI server is listening at 127.0.0.1:5002
INFO | (pkg/forwarder/forwarder.go:154 in Start) | Forwarder started, sending to 1 endpoint(s) with 1 worker(s) each: ‚Äúhttps://6-10-1-app.agent.datadoghq.com"" (1 api key(s))
‚Ä¶
INFO | (pkg/forwarder/transaction.go:193 in Process) | Successfully posted payload to ‚Äúhttps://6-10-1-app.agent.datadoghq.com/intake/?api_key=******************************"", the agent will only log transaction success every 20 transactions
Ultimately, I engaged Datadog support at this point with the errors that we were seeing and another possible solution surfaced: to move the Agent to a separate host and have the APM send things to this remote host."
datadog,"Attempt 2: Separate Agent Host
The APM MSI install involved only two files: the Datadog Native DLL and an integrations.json file, so this part seemed pretty straightforward."
datadog,"There were instructions from Datadog for how to install manually, as well."
datadog,"Setting up a machine with the Datadog agent seemed pretty straightforward, too."
datadog,"So I acquired a VM, installed the agent and configured it with the setting ‚Äúapm_non_local_traffic: true,‚Äù per these instructions."
datadog,The host was set up to accept traffic from Azure IPs on port 8126 for the metrics being sent over.
datadog,The first issue we faced was using the x64 version of .NET Core APM files causing the machine to not be instrumented and for no logs to show up from the APM.
datadog,"The application we were instrumenting was not a self-contained x64 application, so it required the x86 APM files."
datadog,"With this change, our first sign of positive results!"
datadog,We were seeing logs that indicated that Datadog was attempting to send messages out.
datadog,"[dotnet.exe] 126944: [info] CorProfiler::JITCompilationStarted() replaced calls from System.Net.Http.HttpClientHandler.SendAsync() to System.Net.Http.HttpMessageHandler.SendAsync() 100663951 with calls to Datadog.Trace.ClrProfiler.Integrations.HttpMessageHandlerIntegration.HttpMessageHandler_SendAsync() 167773341
[dotnet.exe] 126944: [info] CorProfiler::JITCompilationStarted() replaced calls from System.Net.Http.HttpClientHandler.SendAsync() to System.Net.Http.HttpMessageHandler.SendAsync() 100663951 with calls to Datadog.Trace.ClrProfiler.Integrations.HttpMessageHandlerIntegration.HttpMessageHandler_SendAsync() 167773341
[dotnet.exe] 126944: [info] CorProfiler::JITCompilationStarted() replaced calls from System.Net.Http.HttpClientHandler.SendAsync() to System.Net.Http.HttpMessageHandler.SendAsync() 100663951 with calls to Datadog.Trace.ClrProfiler.Integrations.HttpMessageHandlerIntegration.HttpMessageHandler_SendAsync() 167773341
However, on the other side, we were seeing that nothing was being received by the agent."
datadog,"TRACE | INFO | (pkg/trace/api/api.go:147 in Listen) | listening for traces at http://localhost:8126
TRACE | INFO | (pkg/trace/api/api.go:342 in logStats) | no data received
TRACE | INFO | (pkg/trace/agent/service.go:63 in Run) | total number of tracked services: 0
The key here, I would find out later, was ‚Äúlistening for traces at http://localhost:8126‚Äù which indicated that the ‚Äúapm_non_local_traffic‚Äù config setting didn‚Äôt take."
datadog,Looking at an example config showed that the ‚Äúapm_non_local_traffic‚Äù setting should be nested within ‚Äúapm_config.‚Äù Fixing this and we started to receive traces!
datadog,"TRACE | INFO | (pkg/trace/api/api.go:147 in Listen) | listening for traces at http://0.0.0.0:8126
‚Ä¶
TRACE | INFO | (pkg/trace/api/api.go:342 in logStats) | [lang:.NET interpreter:.NET Core 4.6.27617.05 tracer_version:1.2.0.0] -> traces received: 207, traces dropped: 0, traces filtered: 0, traces amount: 107659 bytes, services received: 0, services amount: 0 bytes, events extracted: 0, events sampled: 0
TRACE | INFO | (pkg/trace/agent/service.go:63 in Run) | total number of tracked services: 4
Notice now it says ‚Äúlistening for traces at http://0.0.0.0:8126.‚Äù
Writing the App Service extension
Now came the portion of writing the App Service extension, which can be seen here."
datadog,"I followed the example of the RayGun APM extension and figured out how to get the environment variables and install set up, which you can infer from the content of that repo."
datadog,"However, the site extensions website has been deprecated in favor of uploading the package to Nuget with packageType of ‚ÄúAzureSiteExtension.‚Äù Upload this to nuget.org and wait for it to validate and index the package."
datadog,At this point the extension was available to install to Azure App Services!
datadog,"You can find terraform-aws-cloudwatch-to-syslog-server on GitHub, and in the Terraform Registry."
datadog,AWS CloudWatch is meant for durable and scalable log archiving.
datadog,"It is tightly integrated with ECS and, overall, the AWS ecosystem, which makes it an interesting choice for low-cost, long-term log archiving."
datadog,"However, the browsing experience is poor (AWS CloudWatch logs for Humans, Elasticsearch+Kibana)."
datadog,Many third-party services with better browsing experience for logs offer a syslog server interface.
datadog,"That‚Äôs why we have open sourced a full solution, terraform-aws-cloudwatch-to-syslog-server, written as a Terraform module complete with an example and infrastructure tests (using the excellent Terratest), to pipe CloudWatch Logs to a syslog TCP server."
datadog,terraform-aws-cloudwatch-to-syslog-server subscribes to the AWS CloudWatch Logs put by various AWS services and streams them to third-party services via a TCP syslog server interface.
datadog,The source code for rpc_ts is available on GitHub under the MIT license.
datadog,Feel free to contribute.
datadog,"Image by 200 Degrees from Pixabay
Adobe Experience Manager (AEM) is a popular content management system (CMS) that allows developers to create websites, user interfaces, and experiences for a variety of devices."
datadog,"The AEM platform is rated as a leader in content management systems by major analyst firms, and AEM adoption numbers show its popularity."
datadog,"But the focus of this article is not AEM, but how to make it performant, and how to identify any potential leaks, slowness, breaches, or downtime."
datadog,"Unless we know specifically what the problem is, our teams will not be able to fix it."
datadog,"As a popular quote goes, ‚ÄúYou cannot shoot what you don‚Äôt know you‚Äôre aiming for.‚Äù
We will use Datadog to do the analysis and reporting for us."
datadog,"But before we begin‚Ä¶
Assumptions
This article is for readers with some working knowledge of AEM."
datadog,"Focus of this article
This article is about integrating AEM with Datadog, and how to access the various reports from within Datadog."
datadog,We will not discuss the functionalities AEM and Datadog in detail.
datadog,"Organization of this article
The content of this article is in three parts: 1)What are AEM and Datadog and why do we need them; 2) How to install, configure, and integrate Datadog with AEM; 3) How to access and view the reports."
datadog,"Now that the stage is set, let‚Äôs dive into the abyss."
datadog,"Part 1: The What
Caution: A lot of theory
What is AEM?"
datadog,"To put is simply, Adobe Experience Manager is a platform (more than a tool) that lets enterprises build websites and manage digital assets."
datadog,More.
datadog,What is Datadog?
datadog,"Datadog is a SaaS tool that monitors servers and software applications generating metrics, analysis, and various reports."
datadog,More.
datadog,Why do we need analytics on AEM?
datadog,"While AEM is a popular, comprehensive, and robust platform offering a lot of features, it does not include tools that track, analyze, and report on the platform itself."
datadog,"It does have a few reports, but they are not extensive."
datadog,The focus of Adobe for AEM has been more on enabling teams to develop varied customer experiences.
datadog,"Having said that, AEM gets better with more features and capabilities with each annual release/update."
datadog,Why Datadog?
datadog,"Monitoring a platform like AEM is very valuable, teams have several options to monitor AEM."
datadog,Datadog is in this category but is above and beyond any of the comparable tools.
datadog,"The options, in-depth analysis, and reporting make it unique in the market space."
datadog,Datadog does a really good job at all of this.
datadog,"In the next section we will cover how to install and configure Datadog, and how to integrate it with AEM."
datadog,"Part 2: How
Caution: This gets very technical
Step 1: Installing Datadog
Log in to your Datadog account to see instructions on how to install."
datadog,"Screenshot of Datadog Installation Instructions
Step 2: Configuration
You will see something like this if Datadog is running successfully on your machine."
datadog,"Screenshot of Datadog Agent Manager Running Successfully
Step 3: Running AEM
AEM can be set up to run as a service (servers) or we can run it from a command (developer machines) like below:
$ java -jar cq-quickstart-version-p4502.jar

Adobe Experience Manager Home Page
Step 4: Integrating AEM with Datadog
Following the instructions from Datadog‚Äôs documentation site."
datadog,Enable logs in datadog.yml file under /opt/datadog-agent/etc/datadog.yaml file.
datadog,"vi /opt/datadog-agent/etc/datadog.yaml
Find and change from ""# logs_enbaled: false"" to ""logs_enabled: true""
Create
$ cd /opt/datadog-agent/etc/conf.d
$ mkdir adobe.experience.manager.d
$ cd adobe.experience.manager.d
$ vi conf.yaml
<add the below lines>
logs:
  - type: file
    path: /Users/Software/aem65/author/crx-quickstart/logs/*.log
    service: aem
    source: adobe.experience.manager
Restart datadog-agent
Get the status of the Agent 
$ launchctl list com.datadoghq.agent
Stop the agent
$ datadog-agent stop
Start the agent
$ datadog-agent start
That‚Äôs it."
datadog,We are done setting up Datadog and AEM.
datadog,In the next section we will see how to access the analytics and read them.
datadog,"Part 3: Reading the analysis and reports
Caution: Get your reading glasses ‚Äî we will be reading between numbers."
datadog,"Now that we have AEM and Datadog running, to access the analytics and reports, we have to do the following:
Open a browser and go to this url http://127.0.0.1:5002 and under Status, scroll down the page until you see adobe.experience.manager under Logs Agent

Log in to Datadog portal
There are so many reports you can view here."
datadog,Below are some of them.
datadog,"Logs > Live Tail

Sample report of Logs > Live Tail
Logs > Analytics > Log Explorer

Sample report of Logs > Analytics > Log Explorer
Logs > Patterns (this is a great feature)

Sample report of Logs > Patterns
Dashboard (of my local mac)

There are several other reports and metrics in the Datadog console, like Dashboards, Monitors, Metrics, and several others."
datadog,All of the above are happy paths without any exceptions or errors or warnings because we are tracking AEM from my local machine.
datadog,"If we are tracking from real servers these will make a lot of sense to system administrators, architects, developers, and others."
datadog,They are invaluable and save a lot of time when managing and debugging AEM running on production servers.
datadog,This bring us to the end of the core content.
datadog,What‚Äôs next?
datadog,There is so much that can be done on AEM with the rich reporting from Datadog.
datadog,"Both platforms are continuously innovating and coming up with new features and options, as well as simplifying things."
datadog,"This innovation and enablement helps businesses with value creation and keeps us builders, developers, architects, and system administrators busy learning the new tricks."
datadog,"Keep learning, ALWAYS!"
datadog,I recently posted an article on how to get set up with Datadog‚Äôs AWS Integration and successfully received metrics.
datadog,Today I‚Äôll be working on forwarding over my CloudWatch logs to Datadog.
datadog,"Step By Step with Pictures: Installing the Datadog AWS Integration and Setting up a Dashboard
You too can use Datadog to monitor your applications!"
datadog,"medium.com

All of the documentation for this set up is located in the following places:
https://app.datadoghq.com/logs/onboarding/cloud
https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/?tab=kinesisfirehosedeliverystream
https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs//SubscriptionFilters.html#DestinationKinesisExample
To start, I‚Äôll check to see if any logs exist already."
datadog,I start on the Datadog Quick Start page.
datadog,"The Datadog Quick Start page
I hover over Logs and click Search."
datadog,I am presented with the Logs page.
datadog,"Yikes, no logs!"
datadog,"Luckily, I see a Getting Started guide under the Logs menu."
datadog,I specify Cloud and select AWS.
datadog,I‚Äôm presented with a few ways of forwarding logs via Kinesis Firehose or CloudFormation.
datadog,Today I select Kinesis Firehose.
datadog,I click the ‚ÄúCreate delivery stream‚Äù link and am presented with the AWS Console.
datadog,I ensure I‚Äôm in the correct region.
datadog,"Per the docs, I give it a name and select the ‚ÄúDirect PUT or other sources‚Äù

I set SSE with AWS-owned CMK, but this is up to you."
datadog,I then hit ‚ÄúNext‚Äù.
datadog,"Per the docs, I disable data transformation and record transformation."
datadog,"I select Third party services provider, and select Datadog from the list."
datadog,"I configure with my API key, specify the data I want to backup to S3, and click ‚ÄúNext‚Äù."
datadog,"I leave the Configure settings the same, with the exception of enabling S3 encryption and click ‚ÄúNext‚Äù."
datadog,"Step 4 is to configure the stream settings
Finally, I review the data and click the blue ‚ÄúCreate delivery stream‚Äù button."
datadog,"Step 5 is to review the Kinesis Stream before creation
After I click create, I land on the Kinesis Service page where I can see my new stream."
datadog,"The Kinesis Firehose Delivery Stream is created
I need to create a role that allows CW to put to Kinesis."
datadog,"I‚Äôm using this trust policy, since my resources are in us-east-2."
datadog,I use the AWS CLI to create a new role with the trust policy from the previous step.
datadog,I create a Permissions document.
datadog,I‚Äôm using us-east-2.
datadog,I use the AWS CLI to attach the policy to the role.
datadog,I then create the Subscription Filter using the Kinesis Stream and IAM role created above.
datadog,Note!
datadog,"I first received an error like this:
An error occurred (InvalidParameterException) when calling the PutSubscriptionFilter operation: Could not deliver test message to specified Firehose stream."
datadog,Check if the given Firehose stream is in ACTIVE state.
datadog,"To fix, I updated the policy for the exact deliverystream resource and allowed firehose PutRecord and PutRecordBatch actions."
datadog,I went back to my log group and verified that the Subscription was created correctly.
datadog,"Note the new Subscription filter in the Subscription Filters window
I now have my AWS Lambda logs in Datadog!"
datadog,Reach out with a comment if you have any questions.
datadog,"If you appreciated the content, I am thankful for a clap!"
datadog,So you‚Äôve got a shiny new Kubernetes cluster up and it‚Äôs a dream.
datadog,"Deploying code is easy, scaling is a breeze, and you‚Äôve never felt so efficient."
datadog,"However, despite claims that Kubernetes is self-healing, there‚Äôs still a nagging feeling in the back of your mind that wants to make sure your cluster is running smoothly."
datadog,"Just like any other tool, you need a monitoring solution to give you insight into Kubernetes."
datadog,"To that end, there are dozens of Kubernetes monitoring tools, but in this post we‚Äôll just review two very prominent tools: Prometheus and Datadog."
datadog,"We‚Äôll discuss these two monitoring solutions in the following categories:
Afterwards, you should have the knowledge you need to decide on a monitoring solution for you and your cluster."
datadog,Let‚Äôs get started.
datadog,"Installation Process
It‚Äôs pretty easy to install both Prometheus and Datadog."
datadog,You just create some resources in Kubernetes and are running in no time at all.
datadog,"Installing Prometheus
Because Prometheus is one of the monitoring solutions that the Kubernetes documentation specifically recommends, it‚Äôs unsurprising that the installation process is pretty easy."
datadog,"All you need to do it create a cluster role, a config map, and a deployment for Prometheus, most of which can be copy pasted from any number of tutorials online (here‚Äôs one to get you started)."
datadog,It takes only a couple minutes to get set up.
datadog,"However, Prometheus comes with a whole ecosystem of tools that support it."
datadog,"If you want more sophisticated dashboards and graphs, you‚Äôll have to spin up Grafana and integrate with it."
datadog,"If you want a decent alerting system, you‚Äôll need to install AlertManager."
datadog,"As you‚Äôll see, this ends up making Prometheus a little more complicated to set up than Datadog."
datadog,"It‚Äôs still not difficult, but it‚Äôs not trivial either."
datadog,"Installing Datadog
If you already have a Datadog account, getting metrics into Datadog is extremely simple."
datadog,You‚Äôll just configure RBAC permissions and install the Datadog agent as a DaemonSet.
datadog,"If you want to send custom metrics to Datadog, you‚Äôll need to do a little more configuration."
datadog,"Datadog ships with visualizations and an alerting layer, so there‚Äôs no need to do any additional setup."
datadog,"Verdict
All in all, Datadog is a little easier to install that Prometheus, as you might expect when comparing a managed service to an open source solution."
datadog,"However, neither is too difficult."
datadog,"Visualizations
Of course, we installed a monitoring solution because we want to get some value out of our metrics."
datadog,For many people this equates to one thing: graphs.
datadog,"Metric Visualization in Prometheus
While Prometheus itself ships with a graphing tool, its functionality is fairly rudimentary."
datadog,"It‚Äôs more likely the case that any Prometheus installation actually relies on Grafana for visualization, and for the purpose of this comparison, we‚Äôll consider Grafana‚Äôs visualization capabilities."
datadog,A graph in Prometheus.
datadog,It‚Äôs not great.
datadog,Grafana makes it easy to create dashboards and graphs of your metrics.
datadog,There are loads of different widgets and options that allow you to tailor your visualization to your needs.
datadog,"And it comes with an easy-on-the-eyes dark theme, if that‚Äôs a consideration for you."
datadog,Visualizing cluster data in Grafana.
datadog,"Metric Visualization in Datadog
Datadog provides very full-featured graphs and dashboards with great performance."
datadog,"Like Grafana, there are many widgets to create any dashboard you could think of."
datadog,The tagging system is great and the query language is very robust.
datadog,Datadog also comes with preset Kubernetes dashboards.
datadog,Part of Datadog‚Äôs built-in Kubernetes dashboard.
datadog,"Verdict
Grafana and Datadog are very similar in their visualization capabilities."
datadog,Both have every feature you need to get started and allow you to put together dashboards that will help you monitor your Kubernetes cluster.
datadog,This one‚Äôs a tie.
datadog,"Finding Kubernetes Events
Metrics aren‚Äôt the only thing to monitor in Kubernetes."
datadog,"Kubernetes also generates API objects called Events that describe things happening in your cluster, such as containers running out of memory, failing to mount a volume, nodes becoming unschedulable, etc."
datadog,Knowing about events in Kubernetes is important as it can be the first step to detecting a bad situation.
datadog,"Kubernetes Events in Prometheus
Prometheus doesn‚Äôt automatically expose Kubernetes events, so you‚Äôll need a different solution to help you with this problem."
datadog,There is a project on Github that will export Kubernetes events as Prometheus metrics.
datadog,You can then import these event metrics into Grafana.
datadog,"Kubernetes Events in Datadog
Datadog‚Äôs agent will gather events from your Kubernetes cluster and then dump them into the ‚ÄúEvents‚Äù section of the app."
datadog,"It‚Äôs not entirely obvious, but you will have to enable it, and you will also have to understand and set up alerts for events to get value from them."
datadog,"As far as visualizing Kubernetes events, each event typically only lists the ‚ÄúReason‚Äù part of an event, so you end up with an event containing a ReplicaSet and a string like ‚ÄúOOM‚Äù or ‚ÄúKILL.‚Äù The UI that shows pod labels is also pretty cramped and hard to read."
datadog,An Event In Datadog.
datadog,That‚Äôs a lot of tiny text in a small space!
datadog,"Verdict
You can rig your Prometheus setup to expose Kubernetes events, but the solution is not optimal."
datadog,Datadog takes this one since it has an officially supported method for doing this.
datadog,"However, Datadog‚Äôs UI for viewing events leaves something to be desired, and doesn‚Äôt help with much more than a high level understanding that something happened."
datadog,"Alerting and Notifications
A monitoring solution that can‚Äôt tell you when something goes wrong is not very useful."
datadog,"In this section, we‚Äôll talk about the alerting and notification engines in Prometheus and Datadog that can help you stay on top of your cluster health."
datadog,"Alerting in Prometheus
Just like Grafana is required to do any meaningful visualization, you‚Äôll need to install AlertManager to get useful notifications from Prometheus."
datadog,"That said, once you‚Äôve installed AlertManager, it‚Äôs got some pretty cool capabilities."
datadog,"You can group alerts together into one notification, or even silence specific alerts for a period of time."
datadog,"There‚Äôs also a neat feature called inhibition that allows you to silence certain classes of alerts when another type of event is active (consider the case that if CPU is high on a container, you might not care to know that the load is also high)."
datadog,"The drawback to AlertManager, however, is that all notification rules are set up through a complicated YAML file that you feed to AlertManager on startup (and which AlertManager will check for updates)."
datadog,"This file can get unwieldy as the complexity of your alerting setup increases, and, as we‚Äôve all experienced, making typos and slight errors in config files can have disastrous effects on a system."
datadog,"Alert thresholds and metrics are also set up in Prometheus‚Äôs YAML configuration, so splitting alerting between these two places can also be a little confusing."
datadog,This is the config for a single alert (minus notifications).
datadog,Imagine doing it hundreds of times!
datadog,"Alerting in Datadog
While Datadog lacks some of AlertManager‚Äôs cool notification rules like inhibition or granular silencing, it has an incredibly robust system of detecting error states."
datadog,"Datadog calls these alerts Monitors, and they can do anything from threshold and anomaly detection on a metric to checking an event for a specific string."
datadog,Datadog provides a nice UI for configuring alerting.
datadog,"By default, Datadog will notify your team through email, but many services have Datadog integrations that let you get notifications through your preferred incident management system."
datadog,"Verdict
Which service you select depends on your use case."
datadog,"If you want tight control over what alerts get sent to your team, Prometheus and AlertManager are probably your best bet."
datadog,"If you‚Äôre looking for complicated alert conditions or you really hate config files, you‚Äôll probably want to go with Datadog."
datadog,"Conclusion
Both Prometheus and Datadog are fully featured, robust monitoring solutions."
datadog,"However, they require extensive configuration to get maximum benefit from monitoring, and they assume that as the DevOps professional, you will know all the things that could possibly go wrong and how to check for them."
datadog,"However, Kubernetes is a relatively new tool, and even with experience, there is always more to learn."
datadog,"And even if you do know all the things to monitor, who‚Äôs got time to endlessly configure a system and watch graphs for hundreds or thousands of resources?"
datadog,"Blue Matador will monitor your Kubernetes cluster and all its important metrics and events, and let you know when you need to take action."
datadog,It can ease the nagging anxiety that there are unknowns in your system waiting to cause you and your team headaches.
datadog,"Best of all, Blue Matador does it all without configuration."
datadog,"Blue Matador detects Kubernetes events like inability to schedule pods, or a deployment not having enough pods."
datadog,All without any configuration!
datadog,All you have to do is install our agent through a DaemonSet and then sit back and rest assured that your Kubernetes cluster is in good hands.
datadog,Give it a try today!
datadog,"At Coinbase, we use Datadog to collect system and application metrics, implement SLIs and SLOs, create dashboards, and more."
datadog,"As the number of dashboards and monitors grew, we began to see the need to codify them."
datadog,We were worried that we didn‚Äôt have tools to detect accidental or malicious modification.
datadog,Imagine a production incident that was not noticed by engineers because of an accidentally muted monitor.
datadog,Codification solves this because modifications are explicit (through code) and are stored in version control (benefitting from notification and code review systems).
datadog,One way of solving this problem would be to store the Datadog components (e.g.
datadog,"Datadog timeboards, screenboards, and monitors) in a version control system and apply changes done through code."
datadog,The downside of this approach is that managing screenboards or timeboards though the code is not convenient or friendly.
datadog,Another way of solving this problem would be to use a Datadog UI-driven approach.
datadog,This would be much more convenient and friendlier to use.
datadog,"This would require detecting changes, creating a request to submit it back to a version control system and the ability to revert/rollback changes that were not approved."
datadog,"To achieve the best of both potential solutions (code and UI-driven approaches) we first started by reviewing existing projects we could find:
https://github.com/trueaccord/DogPush
https://github.com/codenize-tools/barkdog
https://github.com/rapid7/dogwatch
https://github.com/grosser/kennel
Each project had their pros and cons but this came down to two issues: not being able to codify dashboards in addition to monitors (even if we forked and contributed back) or being too complex for our customers."
datadog,"Introducing Coinbase Watchdog
Coinbase Watchdog is a GitHub app and a Golang service that uses the Datadog API to watch for changes in Datadog, achieving the best of both a code and UI-driven approach."
datadog,"When it sees a change, it automatically creates a Pull Request (PR) with the changes in a dedicated Datadog GitHub repository."
datadog,We have control and consensus mechanisms (you can read more about Heimdall here) that provide us the guarantees that a sufficient number of people have reviewed the change before it can land on master.
datadog,"If a PR was not approved and closed by a customer, Watchdog will call Datadog APIs to restore the components from the master branch in source control."
datadog,This approach gives us a UI-driven codification bot.
datadog,All changes made in the Datadog UI will be automatically picked up by the bot and corresponding Pull Requests will be created.
datadog,Watchdog can also detect if a user modified the code (Datadog component JSON) and apply the change to Datadog.
datadog,"The two workflows are pictured here:

Coinbase Watchdog workflows
Configuring Watchdog
The Watchdog service has two types of configuration:
System configuration: this configuration includes all required parameters such as Datadog API/APP keys, GitHub application private key, GitHub project URL, GitHub app installation ID, etc."
datadog,This configuration is passed to the service with environment variables.
datadog,User configuration: this is used by customers.
datadog,"Simple YAML files with a list of Datadog component IDs and metadata such as team, project name, etc."
datadog,You may have many YAML files in the configuration directory and a configuration folder can have any arbitrary number of subfolders.
datadog,"This is an example of a User configuration YAML file:

The components that you see above are:
meta: team: An arbitrary team name identifier."
datadog,meta: slack: A Slack room name to notify of changes.
datadog,dashboards: A list of dashboard IDs to watch.
datadog,monitors: A list of monitor IDs to watch.
datadog,screenboards: A list of screenboard IDs to watch.
datadog,How does Coinbase Watchdog detect changes?
datadog,The Watchdog service is completely stateless.
datadog,There are two ways in which Watchdog detects changes: Full sync and Incremental.
datadog,"Full sync
When the Watchdog service starts for the first time, it will query all components by ID and check each against the components stored in GitHub."
datadog,"If some component files are different, new PRs will be created per user configuration file."
datadog,"Depending on users‚Äô configuration files, this step could potentially make many Datadog API calls."
datadog,"However, this will only happen once on service startup to verify that the current state in Datadog is consistent with the source in GitHub."
datadog,"Watching for incremental changes
This is a fairly straight-forward task, and consists of several steps:
The Datadog APIs conveniently expose a field ‚Äúmodified‚Äù which contains a component modification date."
datadog,"Watchdog polls the APIs https://api.datadoghq.com/api/v1/monitor, https://api.datadoghq.com/api/v1/screen, https://api.datadoghq.com/api/v1/dash ."
datadog,every N minutes (in our case every 10 minutes) and checks if the current time minus modified field value is less then 10 minutes.
datadog,Watchdog uses a git implementation written in Golang under the hood.
datadog,"If step 1 was successful, Watchdog will pull the latest changes from the master branch, create a new local branch, make an HTTP GET request to retrieve the Datadog component from the Datadog API, save the component to a file, and run the equivalent of the git status command to see if the file in the master branch is different from the API response."
datadog,Watchdog will then query GitHub APIs to find if duplicate PRs have been opened and if so it will ignore the current one.
datadog,"An example API response from the Datadog API showing the ‚Äúmodified‚Äù key:

Notifications
When Watchdog creates a new PR it is important to notify the relevant team so that they can review the PR."
datadog,We use a GitHub‚Äôs CODEOWNERS feature for that.
datadog,"In the GitHub repository root we have a CODEOWNERS file with the following lines:
config/reliability/ @engineering/reliability
data/infra/reliability/ @engineering/reliability
If a PR affects files in config/reliability/* or data/infra/reliability/* the Reliability Engineering team will be notified by email."
datadog,"Furthermore, a team can opt-in to Slack notifications by setting a ‚Äúslack‚Äù field under ‚Äúmeta‚Äù in user config file with a slack channel (see above picture)."
datadog,"Future features
In the future, we would like to add more features and are already working on a way to automatically revert changes based on PR expiration."
datadog,We‚Äôre also looking forward to see if others who use Datadog find this service useful and are able and willing to contribute.
datadog,Datadog introduced new dashboard APIs which is currently not supported by Watchdog.
datadog,"We are planning to add this feature soon and meanwhile PRs are highly appreciated ;)
If you‚Äôre interested in contributing to this project, check it out on GitHub here!"
datadog,"If you‚Äôre interested in helping us build a modern, scalable platform for the future of crypto markets, we‚Äôre hiring in San Francisco!"
datadog,This website may contain links to third-party websites or other content for information purposes only (‚ÄúThird-Party Sites‚Äù).
datadog,"The Third-Party Sites are not under the control of Coinbase, Inc., and its affiliates (‚ÄúCoinbase‚Äù), and Coinbase is not responsible for the content of any Third-Party Site, including without limitation any link contained in a Third-Party Site, or any changes or updates to a Third-Party Site."
datadog,Coinbase is not responsible for webcasting or any other form of transmission received from any Third-Party Site.
datadog,"Coinbase is providing these links to you only as a convenience, and the inclusion of any link does not imply endorsement, approval or recommendation by Coinbase of the site or any association with its operators."
datadog,"Unless otherwise noted, all images provided herein are by Coinbase."
datadog,"Adobe Experience Manager aka AEM is a popular Content Management System (CMS) that allows builders, developers to create websites, user interfaces and experiences for a variety of devices."
datadog,AEM platform has and is rated as the beat & a leader in Content Management systems by major analyst firms.
datadog,AEM adoption numbers show it‚Äôs popularity.
datadog,"While the focus of this article is not about AEM‚Äôs greatness, but to make it performant, identify (if any) leaks, slowness, breaches, downtimes and such."
datadog,"Unless we know what the problem(s) is(are), teams will not be able to fix them."
datadog,As a popular quote goes ‚ÄúYou cannot shoot what you don‚Äôt know you‚Äôre aiming for‚Äù.
datadog,And we will use Datadog to do the analysis & reporting job for us.
datadog,"TL;DR
This article is about analyzing Adobe Experience Manger (AEM) with visualization of the data like dashboard, reports, charts using a tool called Datadog which collects information from AEM‚Äôs logs, action calls and other details."
datadog,"Before we begin
Assumptions
This article is for readers with some working knowledge on AEM."
datadog,Please check here for more details on what is AEM.
datadog,"Focus of this article
This article is about integrating AEM with Datadog and how to access the various reports from within Datadog."
datadog,We will not discuss about the functionalities AEM and Datadog in detail.
datadog,"Organization of this article
The content of this article in three parts."
datadog,"(1)What are AEM and Datadog and Why do we need them; (2) How to install, configure Datadog and integrate it with AEM; (3) Finally How to access and view the reports."
datadog,"Now that the stage is set, let‚Äôs dive in to the abyss."
datadog,"Part 1 ‚Äî The What
Caution: A lot of theory
What is AEM?"
datadog,"To put is simple, Adobe Experience Manager is a platform (more than a tool) that lets enterprises build websites and manage digital assets."
datadog,More.
datadog,What is Datadog?
datadog,"Datadog is a SaaS tool that monitors servers and software applications generating metrics, analysis and various reports."
datadog,More.
datadog,Why do we need analytics on AEM?
datadog,"While AEM is a popular, comprehensive and a robust platform offering a lot of features, it does not include tools that track, analyze and report on the platform itself."
datadog,It does have a few reports but not extensive.
datadog,The focus of Adobe on AEM has been more on enabling teams to develop varied customer experiences.
datadog,"Having said that, AEM et better with more features and capabilities with it‚Äôs annual releases/updates."
datadog,Why Datadog?
datadog,"Monitoring a platform like AEM is very crucial , teams have several options to monitor AEM."
datadog,Datadog comes in the same category but is beyond any of the tools comparable.
datadog,"The options, in-depth analysis, reporting makes it unique in the market space."
datadog,Datadog does a real good job at this.
datadog,"In the next section we will see how to install, configure Datadog and integrate it with AEM."
datadog,"Part 2 ‚Äî How
Caution: This gets very technical
Step 1: Installing Datadog
Login to your Datadog account to see instructions on how to install."
datadog,"Screenshot of Datadog Installation Instructions
Step 2: Configuration
You will see something like this if Datadog is running successful yon your machine

Screenshot of Datadog Agent Manager Running Successfully
Step 3: Running AEM
AEM can be setup to be run as a service (servers) or we can run it from a command (developers machines) like below:
$ java -jar cq-quickstart-version-p4502.jar

Adobe Experience Manager Home Page
Step 4: Integrating AEM with Datadog
Following the instructions from Datadog‚Äôs documentation site
Enable logs in datadog.yml file under /opt/datadog-agent/etc/datadog.yaml file."
datadog,"vi /opt/datadog-agent/etc/datadog.yaml
Find and change from ""# logs_enbaled: false"" to ""logs_enabled: true""
Create
$ cd /opt/datadog-agent/etc/conf.d
$ mkdir adobe.experience.manager.d
$ cd adobe.experience.manager.d
$ vi conf.yaml
<add the below lines>
logs:
  - type: file
    path: /Users/Software/aem65/author/crx-quickstart/logs/*.log
    service: aem
    source: adobe.experience.manager
Restart datadog-agent
Get the status of the Agent 
$ launchctl list com.datadoghq.agent
Stop the agent
$ datadog-agent stop
Start the agent
$ datadog-agent start
That‚Äôs it."
datadog,We are done setting up Datadog and AEM.
datadog,In the next section we will see how to access the analytics and read them.
datadog,"Part 3 ‚Äî Reading the Analysis/Reports
Caution: Get your eye/reading glasses, we will be reading between numbers
Now that we have AEM and Datadog running, to access the analytics and reports, we have to do the following:
Open a browser and go to this url http://127.0.0.1:5002 and under Status, scroll down the page until you see adobe.experience.manager under Logs Agent

Login to Datadog portal
There‚Äôs so many reports you can view here."
datadog,"Below are some of them
Logs > Live Tail

Sample report of Logs > Live Tail
Logs > Analytics > Log Explorer

Sample report of Logs > Analytics > Log Explorer
Logs > Patterns (this is a great feature)

Sample report of Logs > Patterns
Dashboard (of my local mac)

There are several other reports and metrics Datadog console has like Dashboards, Monitors, Metrics, and several others."
datadog,Also all the above are happy paths without any exceptions or errors or warnings because we are tracking AEM from my local machine.
datadog,"If we are tracking from real servers these make a lot of sense to system administrators, architects, developers and a lot of stakeholders (if they can read between the lines)."
datadog,These are invaluable and save a lot of time when managing and debugging AEM running on production servers.
datadog,This bring us to the end of the core content.
datadog,What‚Äôs next?
datadog,"There is so much that can be done on AEM, the numerous report on Datadog."
datadog,"Both platforms will not stop continuously innovating coming up with new features, options, simplifying things."
datadog,"This innovation and enablement helps businesses a lot with value creation and keeps us builders, developers, architects, system administrators busy learning the new tricks."
datadog,"Keep learning, ALWAYS!"
datadog,!
datadog,The paid for version of Hashicorp Vault is licensed on a per-request basis.
datadog,"As a FOSS user salivating over their enterprise feature sets, it‚Äôs good to know what I‚Äôm getting into heading into negotiations."
datadog,Thankfully Datadog recently released a Hashicorp Vault intergration!‚Ä¶but it doesn‚Äôt support the request counter endpoint (feature request has been submitted).
datadog,:( This is understandable as the endpoint was only released with the 1.x releases and hasn‚Äôt been formally documented yet.
datadog,"Unlike the status/health endpoints the counters endpoint is authenticated/authorized, so you‚Äôll need to apply the following policy and provision a token."
datadog,"> vault policy read datadog-agent
path ""sys/internal/counters/requests"" {
  capabilities = [""read"", ""list""]
}
Once you‚Äôve provisioned a token drop the following file off in /etc/datadog-agent/checks.d/custom_vault.py:
https://github.com/HireVue/hv-datadog-plugins/blob/master/vault/hv_vault.py
Create a config file in /etc/datadog-agent/conf.d/custom_vault.d/custom_vault.yaml containing the following:

At this point you are ready to start graphing your vault requests:

Note: It is worth noting that querying the health/status/requests with the datadog increments your request count, which gets charged against your monthly total requests."
datadog,Nothing is free.
datadog,Last year I shared an example on how to realize application tracing in Kuberntes with Istio and Jaeger.
datadog,"After that, the industry has made some substantial headway on this front and we are seeing more vendor support as a result."
datadog,"At Buffer, since we primarily use Datadog for Kubernetes and application monitoring, it‚Äôs only fitting to complete the circle with Datadog APM and Logging."
datadog,I had a chance to create a small example for the team and would very much love to share with the community.
datadog,"Okay, without further ado, let‚Äôs dive in!"
datadog,"Installing Datadog agent
First thing first, in order to collect metrics and logs from Kubernetes a Datadog agent has to be installed in the cluster."
datadog,The Datadog team made this quite easy for us.
datadog,There is not much more than following this guide.
datadog,I‚Äôd recommend deploying as a DaemonSet because that‚Äôs all we need.
datadog,The host level deployment is for something else outside of the scope of this post.
datadog,"If you really want to know, it monitors more metrics on the cluster level using kube_state_metrcis."
datadog,"Since we will need both APM and Logging to be enabled, there are 2 environment variables need setting on the DaemonSet."
datadog,"For APM (tracing)
Under the container environment variables section, add this one
- name: DD_APM_ENABLED
  value: 'true'
For logging
Similar to APM, we will need to turn on the flag to tell the Datadog agent to capture logs
- name: DD_LOGS_ENABLED 
  value: 'true'
Super easy so far yeah?"
datadog,Let‚Äôs try to keep it that way!
datadog,Now we can safely assume the Datadog agent will do its job.
datadog,Let‚Äôs move to the application instrumentation.
datadog,"Instrumenting for APM and logging
I have a dream that one day this major step could be completely skipped."
datadog,Imagine if there is a way for a monitoring agent to tap into another runtime without needing to worry about security.
datadog,"Unfortunately, that‚Äôs not quite possible for now despite things have already improved A LOT."
datadog,"In this example, I thrive to provide the simplest way to get things started."
datadog,That‚Äôs my promise to you.
datadog,"Now, let‚Äôs take a look at the code (in node.js)

For APM
That‚Äôs all we need!"
datadog,Line 1‚Äì7 tells the package to send traces to the Datadog agent currently installed on the host ( process.env.DD_AGENT_HOST) on port 8126.
datadog,I will show you how to set up the environment variable shortly in a later section.
datadog,Kudos to you who spotted this!
datadog,Line 5 is quite magical in my opinion.
datadog,The flag will combine a trace with associated logs generated during its execution.
datadog,They will be represented nicely on the Datadog interface.
datadog,"With this, we will be able to diagnose a lot more effectively."
datadog,"Line 6 will put traces to analytics so they can be tagged, searched for convenience."
datadog,That‚Äôs it for the APM part.
datadog,I hope it‚Äôs simple enough.
datadog,Now let‚Äôs move on to the logging.
datadog,"For Logging
Guess what?"
datadog,No instrumentation is needed at all.
datadog,Just use a logger of your choice (I used Winston) and the Datadog agent happily picks things up automatically.
datadog,In my example I didn‚Äôt even log things on the file level.
datadog,All I had to do was from Line 10‚Äì13 to create a format that adds a tag to each log.
datadog,This will help us to filter logs in interest much more easily.
datadog,So far so good?
datadog,Now let‚Äôs talk about the actual deployment to Kubernetes.
datadog,"Deploying the app
I love simplicity."
datadog,I hope we are still on the same page.
datadog,The Kubernetes deployment file is also very straightforward.
datadog,If you still remember the environment variable that tells where dd-trace should send metrics to.
datadog,Here is where the magic happens.
datadog,Line 17 - 21 sets the host IP as an environment variable that could be used by the application.
datadog,"Trying things out
Something I learned is Datadog APM does not always generate a trace for each request."
datadog,"Instead, requests are sampled."
datadog,"Precisely because of this, we cannot expect hitting an endpoint for a few times to see traces generated."
datadog,"This, however, can be worked around if we use a simple benchmark tool."
datadog,"In here let‚Äôs use Apache Benchmark
This will throw 100 requests to the application to ensure some traces will be generated."
datadog,"In my experience, around 6‚Äì10 traces will be generated as a result."
datadog,That‚Äôs quite enough for a PoC.
datadog,"Profit
Now, with everything set up correctly."
datadog,Let‚Äôs see what we will see on the Datadog UI.
datadog,Cool!
datadog,The logs are pouring in.
datadog,Let‚Äôs take a look at the traces!
datadog,Awesome!
datadog,They are here too.
datadog,And the best part is they are already associated with the logs generated during the runtime.
datadog,That‚Äôs it!
datadog,Nice and easy!
datadog,"Closing words
We all love Kubernetes for its ability for application and resource management."
datadog,"However, without good application observability, it may hurt developer velocity, reducing it to a buzzword at best."
datadog,It might even add unnecessary stress on both DevOps and Product engineering teams.
datadog,"Fortunately, as the ecosystem matures we are seeing more vendor support, thus gave birth to this post."
datadog,I‚Äôm super pumped for the ongoing trajectory.
datadog,You may find the complete source code for this post in https://github.com/bufferapp/dd-tracing-logging-examples.
datadog,Cheers!
datadog,"Datadog: Three pillars of observability
I am analyzing Datadog monitors nowadays."
datadog,I would like to share insight which will help you to understand the basics of it.
datadog,"* Table of Contents:-
What is datalog?"
datadog,What types of monitoring can be done?
datadog,"Dashboard introduction
How to integrate with REST OR gRPC service."
datadog,"* Datadog:-
Datadog is a monitoring service for cloud-scale applications, providing monitoring of servers, databases, tools, and services, through a SaaS-based data analytics platform
* What types of monitoring can be done?"
datadog,"Datadog is great for businesses that need‚Ä¶
Cloud monitoring
Server performance monitoring service
Server monitoring tools
Server usage analytics
80+ turn-key integrations for data aggregation
Alert notifications via e-mail and PagerDuty
Full API access
Overlay metrics and events across disparate sources
An easy way to compute rates, ratios, averages, or integrals
Sampling intervals of 10 seconds
Tools for team collaboration
* Datadog introduction:-
In this part, we will see the whole data dog dashboard introduction."
datadog,I will explain all the major key sections.
datadog,A.
datadog,"Events:-
The Event Stream is based on the same conventions as a blog:
Every event in the stream can be commented on."
datadog,Great for distributed teams and maintaining the focus of an investigation.
datadog,"You can filter by: user, source, tag, host, status, priority, incident
On the left-hand side, you can see a list of all data sources integrated."
datadog,"B. Dashboards:- There are 2 types of the dashboard you can create using Datadog
New Timeboard ‚Äî For troubleshooting and correlation
Time-synchronized metrics and event graph Automatic layout."
datadog,Timeboards allows you to troubleshoot issues by pinpointing to the metrics and services at the same time.
datadog,"Datadog time board
2."
datadog,New Screenboard ‚Äî For status board and sharing data.
datadog,Mix widget and timeframes Custom drag-and-drop layout.
datadog,Screenboards are ideal for checking the overall health and status of the services and entire architecture.
datadog,"Datadog screen board
C. Infrastructure:-
The Infrastructure list page shows all hosts monitored by your Datadog application."
datadog,"you can see the tags applied to each machine; as they‚Äôre assigned to perform certain roles, tagging allows you to indicate machines have a certain purpose."
datadog,"D. Monitors:-
Applies to any metric you want, revenue: data center temperature."
datadog,"Multi alerts (by device, host, etc.)"
datadog,"Set alert notification message
E. APM(Tracing):-
Datadog APM provides you with deep insight into your application‚Äôs performance-from automatically generated dashboards monitoring key metrics

Datadog tracing
* How to integrate:-
More than 200 built-in integrations."
datadog,you can integrate it into your project here is an interactive video to get started.
datadog,"* Implement it with REST service

build.gradle
Once you add a dependency, you need to implement statsD client in your rest service like this."
datadog,If you have found this useful Click the üíö below to show your support and share it with other fellow Medium users.
datadog,stay tuned.
datadog,"Since last year(2018), The Data team of our company decided to swich to Datadog to collect the application related metrics."
datadog,"We use Kafka as our queuing service, and we use Kafka connect/Kafka stream applications(JVM based)to make the Data enrichment/transformation/unload."
datadog,Our applications are deployed on AWS managed Kubernetes clusters.
datadog,"One of the challenge is, how to collect application metrics(JMX metrics)constantly and continually with application pods restarts or with the application redeployment."
datadog,"Datadog boasted about their Kubernetes integration which allows native JMX metrics collection and service auto-discovery(link1 , link2, link3), Of course it was not as easy as it has been advertised."
datadog,"There were many bugs on their jmxfetcher, after quite some back and forth with Datadog Devs, we managed to fix many bugs and finally have a relatively satifactory integration."
datadog,"For a kafka connector app(lets name it ‚Äúkafka-connect‚Äù) we have following jmx configuration :

see datadog documentation of jmx integration for more details (link)
Datadog autodiscovery relies on the datadog daemon-set to fetch upon jmx configuration from the kubernetes deployment annotations, so you need to transform upon yaml file to json format."
datadog,"The first code snippet is the transformed yaml file to json annotations, the second code snippet is from our kafka connect application helm chat which convert the jmx configuration yaml file into json annotation format on-fly."
datadog,"Note very important points:
The name after `ad.datadoghq.com/$name` has to be the same as your container name
The ‚Äúcheck_names‚Äù better to contain a UUID, the datadog daemon-set stores the checkname and host ip pair, during a service redeployment, the host ip will change, if the checkname stays the same, the datadog daemon-set will keep check on an outdated host ip and you will lost metrics
never try to convert yaml to json manually, always automate it
In my team, we use Kubenetes Helm chart to deploy kafka connect applications, you can check how we do it with our sample kafka connect helm chart with the built-in datadog jmx autodiscovery support."
datadog,"see : link
If you think it‚Äôs all you need to know about the datadog jmx K8s autodiscovery, then you are so na√Øve, but don‚Äôt worry, I was also naive once!"
datadog,"Everything rolled-out pretty good with upon setup, but after few weeks, we suddenly experienced missing application metrics, after investigations, we found out that the jmxfetcher process in the datadog daemon-set has been constantly killed by our host OOM killer."
datadog,"The Datadog daemon-set spawns up the jmxfetcher process as a sub process:

datadog daemon-set running process
But they start it with `-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap` jvm options, as the datadog main agent process took more memory over the time, at some point Java process won‚Äôt be able to allocate a heapsize with the cgroup size, thus get killed by the host OOM killer."
datadog,"Datadog has implemented an auto-restart mecanic for the jmxfetcher, by the time the other processes took up to 80% of memories, it will try to restart the jmxfetcher again and again, thus, at one point we lost the application metrics."
datadog,"I have written to datadog, request to fail the liveness probe of the datadog pod when the jmxfetcher process get killed."
datadog,unfortunately they never replied.
datadog,"I have instead implemented our own solution based on upon finding:

We have added a further memory check in addition to the liveness probe, when the total memory took by all processes is over 90% of the allocated resource, we will fail the pod and let it to restart."
datadog,"more for datadog daemon-set setup, you can have a look at my data-team-bootstrap project, it contains the datadog daemon-set deployment setup."
datadog,Datadog APM Trace Search from Zero to One is the first part of advanced techniques we use at Zendesk to plan capacity and keep performance characteristics of the multi-tenant system at expected levels.
datadog,"Response times vary between different API endpoints and customers, as the data set grows rapidly, and new products are being launched."
datadog,"If we can scale today, what is the long-term sustainability?"
datadog,"In terms of SLIs:
how much traffic can our system handle before falling/failing over?"
datadog,"when the rate of incoming requests increases by an order of magnitude, how would it affect SLOs?"
datadog,"This article covers practical examples of benchmarking a test system in isolated, controlled environments: changing only a limited number of parameters."
datadog,I also tried to eliminate most of the influencing response time factors such downstream dependencies and network saturation.
datadog,I demonstrate what happens to overall response time when incoming requests throughput exceeds available resources and requests start to queue.
datadog,Visualisations and animated GIFs assist understanding low-level interactions.
datadog,A Practical Look at Performance Theory by Kavya Joshi covers the theoretical aspect of the Performance Modelling problem very well.
datadog,I highly recommend watching this video or reading the slide deck before reading further.
datadog,"Little‚Äôs Law (wikipedia)
The average number of customers in a system (over some interval) is equal to their average arrival rate, multiplied by their average time in the system‚Ä¶ The average time in the system is equal to the average time in queue plus the average time it takes to receive service."
datadog,"The average time it takes to receive service is what we call Service Time, and the average time in the queue is represented by Queueing Delay."
datadog,"From the user‚Äôs perspective, it doesn‚Äôt matter if the bottleneck is either Service Time or Queueing Delay: the impact is the same."
datadog,"For us, it is very important to understand why a response time SLO is not being met."
datadog,Let‚Äôs begin with this animated GIF to demonstrate the visualisation tools we use for analysis.
datadog,"Datadog Agent is required to collect logs from the Nginx container:

The test setup is a set of Docker containers running in a VM: two backend, one proxy, and one Datadog agent:
A single-threaded Ruby application server (Unicorn) runs in two separate containers, one process per container."
datadog,Nginx load balancing method is round robin.
datadog,Two sets of benchmark runs (100ms and 300ms).
datadog,"Each set contains 3 runs with concurrency 1, 4. and 8 respectively."
datadog,Benchmark is run via the tool siege -b -c 1 -t 15min.
datadog,I use the Datadog APM and Logs tools.
datadog,It‚Äôs configured in a way to connect the two together via the HTTP header proxy_set_header X-Request-ID $request_id.
datadog,"With a request_id, you can drill into the APM tooling, as well as inspect the proxy server logs for this specific request."
datadog,"In the case of having downstream dependencies, you can propagate the request_id across entire stack and be able to filter for a specific request."
datadog,"Key finding: Service Time increase is predictable and expected (100ms -> 300ms) even under higher arrival rate, while Queueing Delay increase is outstanding:

Latency Distribution is the most important part of the benchmark results:

High Utilisation (Concurrency: 8)."
datadog,"Response time (Service Time + Queueing Delay): 100ms

High Utilisation (Concurrency: 8)."
datadog,"Response time (Service Time + Queueing Delay): 300ms
Test configuration
Let‚Äôs inspect the test setup to make sure there‚Äôs no influencing response time factors other than arrival rate exceeding the available resources."
datadog,"The Ruby application is a barebones Rails application rake stats => Code LOC: 53 running Rails 5.2.1, Ruby 2.5.1, Unicorn 5.4.1."
datadog,The application is running in development mode with config.cache_classes = true and logging disabled to reduce the I/O impact on the benchmark results.
datadog,"Service Time is controlled by Kernel.sleep(), with no downstream source of saturation like a database or network."
datadog,"Nginx is set at proxy_read_timeout 60, Unicorn at timeout 60."
datadog,Backlog queue for a socket in LISTEN state (Accept Queue) for Unicorn backlog: 64.
datadog,"Nginx runs single worker worker 1 (epoll), worker_connections 4096."
datadog,"The Unicorn server doesn‚Äôt support TCP keepalive, which would help eliminate one of the accept queues, but is unlikely to affect the benchmark results."
datadog,"Nginx keeps track of the time when a request is passed to Unicorn (the time when Queueing Delay timer kicks off) with a header proxy_set_header X-Request-Start ""t=${msec}"" ."
datadog,It is important to note that Nginx accepts an incoming request and hands it over to Unicorn immediately unless the backlog is full (which didn‚Äôt happen according to Raindrops).
datadog,"Nginx upstream_connect_time is unchanged over the low and high arrival rate:

Analysis with Datadog Logging
Attributes Naming Convention
But as Datadog integrations are not covering your custom formats and sources, we decided to make this Attribute Naming Convention (or Taxonomy) public to help you decide how to name your attributes in your own parsers."
datadog,"We need to extend the log format with several key elements, including Service Time and Queueing Delay."
datadog,"We receive these variables from the backend via HTTP headers
Nginx upstream module variables
$upstream_http_name ‚Äî keep server response header fields."
datadog,"For example, the ‚ÄúServer‚Äù response header field is available through the $upstream_http_server variable."
datadog,"We will configure the Nginx log_format to output JSON
The Advantage of Collecting JSON-formatted logs
Datadog automatically parses JSON-formatted logs."
datadog,"For this reason, if you have control over the log format you send to Datadog, it is recommended to format these logs as JSON to avoid the need for custom parsing rules."
datadog,"How the log_format looks like:
The JSON format helps the Datadog agent digest logs without an extra Pipeline."
datadog,"Searching collected logs and APM data is quite powerful:
@http.method:GET
-@http.status_code:200
_exists_:@http.request_id
_missing_:@network.nginx.request_time
@network.unicorn.queueing_delay:>300ms
@network.unicorn.service_time:[100ms TO 250ms]
@network.docker.container_ip:(""172.18.0.4"" OR ""172.18.0.5"")
Drilling down
Now that we know how Queueing Delay influences the overall Response Time in every scenario under low and high arrival rate."
datadog,"The next step is to review these requests under a microscope, read: tcpdump."
datadog,"Every incoming HTTP request passes through two queues: SYN and Accept on both Proxy and Backend sides, totalling four queues before Unicorn can accept() it:
SYN packet handling in the wild
The Accept Queue contains fully established connections: ready to be picked up by the application."
datadog,"When a process calls accept(), the sockets are de-queued and passed to the application‚Ä¶ The maximum allowed length of both the Accept and SYN Queues is taken from the backlog parameter passed to the listen(2) syscall by the application."
datadog,"This time, I have one single-threaded process running."
datadog,I‚Äôm going to make 2 requests sequentially with a Service Time of 45 seconds each.
datadog,"One scheduled 5 seconds after the other, which makes the Queuing Delay 40 seconds."
datadog,The application server worker‚Äôs timeout remains the same at 60 seconds (that matches the proxy_read_timeout set on the proxy).
datadog,"According to the documentation, Nginx‚Äôs backlog on Linux is capped at 511, but in our Docker environment it is net.core.somaxconn=128."
datadog,"Unicorn has its backlog set to a lower value of 64, however, this is more than we need because Raindrops reports no more than 1 queued and 1 active request during the test."
datadog,The first HTTP request succeeded while the second one timed out.
datadog,"The backend would try to send data back through (not shown here), but further transitions (red coloured areas) would be PSH,ACK (Backend -> Proxy) and RST (Proxy -> Backend) in the response because this TCP connection was closed by the client‚Äôs FIN,ACK prior."
datadog,"Let‚Äôs now suppress the low level details and demo the HTTP request/response cycle:
It may be obvious for the second HTTP request to time out, but this is exactly how high Queueing Delay affects overall capacity in most of the systems according to Fail at Scale (Ben Maurer):
Most services process queues in FIFO (first-in first-out) order."
datadog,"During periods of high queuing, however, the first-in request has often been sitting around for so long that the user may have aborted the action that generated the request."
datadog,Processing the first-in request first expends resources on a request that is less likely to benefit a user than a request that has just arrived.
datadog,"For the last example of how Queuing Delay may affect Response Time for a series of HTTP requests, I will initiate 6 requests with Service Time of 45s, 16s, 8s, 4s, 2s and 1s respectively."
datadog,"Keep in mind, now we have one slow request in front of a queue followed by five quicker ones."
datadog,A delay of 1s is being made between each of these requests.
datadog,"Let‚Äôs see how many time out now:

You may notice that only the first request succeeded."
datadog,It demonstrates the disadvantage of processing requests in a FIFO order together with lack of adaptive timeout.
datadog,It‚Äôs rare to see a production system handled by a single-process application but it‚Äôs also rare to see such a low arrival rate approaching that system.
datadog,"Conclusion
In this blogpost, I demonstrated how Queueing Delay influences Response Time under a high arrival rate on a single-threaded application server."
datadog,Tracking both Service Time and Queueing Delay is necessary for capacity planning and performance modelling.
datadog,"The benchmark took 1.5 hours, achieving consistent results."
datadog,"When the Service Time (purple) of an individual request increases from 100ms to 300ms, the overall Queuing Delay (red) increases from 740ms to 1960ms:

High arrival rate of 8 concurrent requests while capacity is limited by 2 workers
At a result, the total Response Time increases from 800ms to 2200ms."
datadog,"When the arrival rate is higher than the number of workers available to process them, then the Queueing Delay has a non-linear impact on Response Time."
datadog,"You can‚Äôt always know whether a request is going to be slow, but just one slow request in front of a queue influences the Queueing Delay for every other request that follows."
datadog,"FIFO disadvantages described here:
When the system is not overloaded, the queue will be empty (or almost empty)."
datadog,Thus there‚Äôs no real difference between popping requests from the front of the queue or the back of the queue.
datadog,Where LIFO processing reduces overhead is when the system is overloaded.
datadog,"Next time
I will cover adaptive timeout, as well as the difference observed when switching the order from Queue to Stack (FIFO -> LIFO)."
datadog,"Again, practical examples with animated GIFs using Datadog solutions will be featured."
datadog,Stay tuned!
datadog,Interested in doing this type of work?
datadog,Join the Zendesk SRE team!
datadog,"* Special thanks to colleagues from Zendesk SRE team (Blake Scrivner, Dan Rieder, Jimmy Dhami), Zendesk Operations teams (Lennard Seah, Edward Savage, Jakob Dalsgaard) and Alexey Ivanov from Dropbox for review and comments!"
datadog,"DataDog is one of the best monitoring tools that provide a variety of different services that you can use to obtain metrics, graphs, alerts, logs and so much more."
datadog,"If you are interested in monitoring your instances, web servers or containers DataDog is the tool you should consider."
datadog,"As the heading suggests in this tutorial, I will be monitoring my AWS EC2 instance with Apache so let‚Äôs dive into it."
datadog,"Alerts Dashboard for Datadog
Prerequisites
It is important to remember that based on your choice of the distro (Rpm or Debian ) specific paths for files will change."
datadog,"RPM based EC2 Instance: Amazon Linux AMI is RPM based distro, I have merely chosen it because I am using an rpm distro daily you could go for a Debian based distro like Ubuntu."
datadog,DataDog Account-DataDog allows 14 days of trial for a newly signed up account.
datadog,"For testing purpose, I will be using a trial account."
datadog,"Vim Experience
Cup of Coffee
Installing the DataDog Agent:

That is how I imagine an agent."
datadog,An agent is a person who acts on behalf of another person or organization.
datadog,"What is a DataDog Agent
To put it in layman terms DataDog agent is a program that runs on your desired instance, it collects the necessary information required for monitoring and various other services and sends this information to the DataDog."
datadog,"Installing the DataDogAgent

Visualization of Steps 2,3 and 4
SSH into your Instance(You can follow this guide and learn to SSH into your Instance)."
datadog,Login into your DataDog Account.
datadog,Click on the Agent Tab and select your distro (Amazon AMI in this case).
datadog,"Copy the one-step install code and paste it in the terminal to install
Once the Agent is installed depending on the distro, you can run the commands and check if your agent is running."
datadog,"DataDog Dog Documentation Page
Basic Commands for DataDog Agent-DataDog provides very well structured documentation for commands and usage, depending on your distro of choice the commands will vary so you can use this link and choose the commands for your distro."
datadog,"Commands for Amazon AMI
Post Agent Installation
Once the agent is installed, it is important to check the status of the agent."
datadog,"If the agent is running, we can check metrics of this instance by using DataDog client app."
datadog,"If the instance is displayed in the dashboard, then the DataDog agent has successfully formed a connection between the instance and the DataDog client app."
datadog,"sudo service datadog-agent status

DataDog Agent Status
Since the DataDog agent is active and running, I can now check if my instance is registered with the DataDog client app."
datadog,"Click on the Infrastructure
Select the Infrastructure list
You will see an instance id (00788fecf7da7b4da)
Double click on it and you will see the real-time metrics

Visualization of Steps
Apache Installation
Since our instance is already being monitored, we can now install Apache and monitor it as well."
datadog,These commands below install and start apache web server.
datadog,"sudo yum install -y httpd
sudo systemctl status httpd
sudo systemctl enable httpd
sudo systemctl start httpd
Configuring Apache for DataDog
For DataDog to work, we must first ensure that the mod_status is loaded in apache."
datadog,This module is responsible for the Apache web server load metrics and page statics.
datadog,"By using the command below
httpd -M |grep status module #RPM based distro
apache2ctl -M                #Debain based distro

Shows that the Status_Mod is loaded
Since the Status _Module is loaded, the next step would be to enable the server status page so that the metrics can be captured."
datadog,#It is a good idea to back up  the conf file incase we need to #rollback changes.
datadog,"cp /etc/httpd/conf/httpd.conf     /etc/httpd/conf/httpd_bk.conf #RPM based
sudo vim /etc/httpd/conf/httpd.conf             #RPM based
sudo vim /etc/apache2/mods-enabled/status.conf  #debain based
Paste the following text in the httpd.conf file
<Location /server-status>
    SetHandler server-status
    Order Deny,Allow
    Deny from all
    Allow from 127.0.0.1
</Location>
ExtendedStatus On
Restart the apache server for changes to take place
sudo systemctl restart httpd
Check the following URL and ensure that you get the HTTP status 200
curl -kI  http://localhost/server-status

HTTP/1.1 200 OK
Configuring Data Agent For Apache
Lastly, we need to configure DataDog agent so that it can collect the metrics and logs from the web server and push them to the DataDog client app."
datadog,Edit the DataDog conf.yaml.example for apache.d and save it as conf.yaml.
datadog,"cd /etc/datadog-agent/conf.d/apache.d
vim conf.yaml.example
#Uncomment the following lines in conf.yaml.example 
instances:
  - apache_status_url: http://localhost/server-status?auto
#Save it as conf.yaml

DataDog Configuration File
If all the amendments are done properly you should now be able to see Apache metrics in your DataDog app."
datadog,"Apache Metrics
Logs
When I first started working with DataDog configuring logs seemed to be the most difficult part."
datadog,"I had to spend an entire day to configure these logs but in the end, I prevailed with the help of my colleague (@Dodson )."
datadog,Here are the steps that I used to obtain the logs in DataDog.
datadog,Edit the DataDog YAML file and enable the logs.It is important to remember that the YAML files are sensitive when it comes to alignment make sure you use a YAML validator to be on the safe side.
datadog,"#Path for datadog yaml file
cd /etc/datadog-agent
sudo vim datadog.yaml
#uncomment and enable the logs and then save the file
logs_enabled: True

logs must be enabled
Edit the conf.yaml file in apache.d to set the path and service of the apache logs."
datadog,It is important to know where your logs are kept as DataDog will be exporting these logs.
datadog,The default configuration that is commented in the datadog.yaml has a different path for logs folder.
datadog,"Before I proceed ahead, I will search the path for my logs folder as I will be adding it in the configuration soon."
datadog,"I will also match the logs name, the default names for logs in the datadog.yaml are error.log and access.log.Upon my investigation, I noticed that my log names were error_log and access_log."
datadog,"#Path where my logs are actually stored
/var/log/httpd
#Path
cd /etc/datadog-agent/conf.d/apache.d
sudo vim conf.yaml
#uncomment the lines from 60 to 70 while mainting the alignment

Verified Path for the Logs
Permissions for logs
For the logs to be fetched by DataDog, we need to give certain permissions to the folder that contains logs."
datadog,"Since my logs are in /var/log/httpd ,the httpd will be granted certain permissions."
datadog,"cd /var/log
chmod 655 -R httpd
Test!"
datadog,It is time to test your workings.
datadog,"Restart DataDog
sudo service datadog-agent restart
Check the DataDog Status
sudo datadog-agent status

Logs are working!"
datadog,Check your DataDog Dashboard for the logs.
datadog,"logs are displayed at the DataDog Dashboard
Final Note
In this tutorial, we have managed to monitor an EC2 instance with Apache and its logs."
datadog,So you‚Äôve got a shiny new Kubernetes cluster up and it‚Äôs a dream.
datadog,"Deploying code is easy, scaling is a breeze, and you‚Äôve never felt so efficient."
datadog,"However, despite claims that Kubernetes is self-healing, there‚Äôs still a nagging feeling in the back of your mind that wants to make sure your cluster is running smoothly."
datadog,"Just like any other tool, you need a monitoring solution to give you insight into Kubernetes."
datadog,"To that end, there are dozens of Kubernetes monitoring tools, but in this post we‚Äôll just review two very prominent tools: Prometheus and Datadog."
datadog,"We‚Äôll discuss these two monitoring solutions in the following categories:
Installation Process
Visualizations
Finding Kubernetes Events
Notifications
Afterwards, you should have the knowledge you need to decide on a monitoring solution for you and your cluster."
datadog,Let‚Äôs get started.
datadog,"Installation Process
It‚Äôs pretty easy to install both Prometheus and Datadog."
datadog,You just create some resources in Kubernetes and are running in no time at all.
datadog,"Installing Prometheus
Because Prometheus is one of the monitoring solutions that the Kubernetes documentation specifically recommends, it‚Äôs unsurprising that the installation process is pretty easy."
datadog,"All you need to do it create a cluster role, a config map, and a deployment for Prometheus, most of which can be copy pasted from any number of tutorials online (here‚Äôs one to get you started)."
datadog,It takes only a couple minutes to get set up.
datadog,"However, Prometheus comes with a whole ecosystem of tools that support it."
datadog,"If you want more sophisticated dashboards and graphs, you‚Äôll have to spin up Grafana and integrate with it."
datadog,"If you want a decent alerting system, you‚Äôll need to install AlertManager."
datadog,"As you‚Äôll see, this ends up making Prometheus a little more complicated to set up than Datadog."
datadog,"It‚Äôs still not difficult, but it‚Äôs not trivial either."
datadog,"Installing Datadog
If you already have a Datadog account, getting metrics into Datadog is extremely simple."
datadog,You‚Äôll just configure RBAC permissions and install the Datadog agent as a DaemonSet.
datadog,"If you want to send custom metrics to Datadog, you‚Äôll need to do a little more configuration."
datadog,"Datadog ships with visualizations and an alerting layer, so there‚Äôs no need to do any additional setup."
datadog,"Verdict
All in all, Datadog is a little easier to install that Prometheus, as you might expect when comparing a managed service to an open source solution."
datadog,"However, neither is too difficult."
datadog,"Visualizations
Of course, we installed a monitoring solution because we want to get some value out of our metrics."
datadog,For many people this equates to one thing: graphs.
datadog,"Metric Visualization in Prometheus
While Prometheus itself ships with a graphing tool, its functionality is fairly rudimentary."
datadog,"It‚Äôs more likely the case that any Prometheus installation actually relies on Grafana for visualization, and for the purpose of this comparison, we‚Äôll consider Grafana‚Äôs visualization capabilities."
datadog,A graph in Prometheus.
datadog,It‚Äôs not great.
datadog,Grafana makes it easy to create dashboards and graphs of your metrics.
datadog,There are loads of different widgets and options that allow you to tailor your visualization to your needs.
datadog,"And it comes with an easy-on-the-eyes dark theme, if that‚Äôs a consideration for you."
datadog,Visualizing cluster data in Grafana.
datadog,"Metric Visualization in Datadog
Datadog provides very full-featured graphs and dashboards with great performance."
datadog,"Like Grafana, there are many widgets to create any dashboard you could think of."
datadog,The tagging system is great and the query language is very robust.
datadog,Datadog also comes with preset Kubernetes dashboards.
datadog,Part of Datadog‚Äôs built-in Kubernetes dashboard.
datadog,"Verdict
Grafana and Datadog are very similar in their visualization capabilities."
datadog,Both have every feature you need to get started and allow you to put together dashboards that will help you monitor your Kubernetes cluster.
datadog,This one‚Äôs a tie.
datadog,"Finding Kubernetes Events
Metrics aren‚Äôt the only thing to monitor in Kubernetes."
datadog,"Kubernetes also generates API objects called Events that describe things happening in your cluster, such as containers running out of memory, failing to mount a volume, nodes becoming unschedulable, etc."
datadog,Knowing about events in Kubernetes is important as it can be the first step to detecting a bad situation.
datadog,"Kubernetes Events in Prometheus
Prometheus doesn‚Äôt automatically expose Kubernetes events, so you‚Äôll need a different solution to help you with this problem."
datadog,There is a project on Github that will export Kubernetes events as Prometheus metrics.
datadog,You can then import these event metrics into Grafana.
datadog,"Kubernetes Events in Datadog
Datadog‚Äôs agent will gather events from your Kubernetes cluster and then dump them into the ‚ÄúEvents‚Äù section of the app."
datadog,"It‚Äôs not entirely obvious, but you will have to enable it, and you will also have to understand and set up alerts for events to get value from them."
datadog,"As far as visualizing Kubernetes events, each event typically only lists the ‚ÄúReason‚Äù part of an event, so you end up with an event containing a ReplicaSet and a string like ‚ÄúOOM‚Äù or ‚ÄúKILL.‚Äù The UI that shows pod labels is also pretty cramped and hard to read."
datadog,An Event In Datadog.
datadog,That‚Äôs a lot of tiny text in a small space!
datadog,"Verdict
You can rig your Prometheus setup to expose Kubernetes events, but the solution is not optimal."
datadog,Datadog takes this one since it has an officially supported method for doing this.
datadog,"However, Datadog‚Äôs UI for viewing events leaves something to be desired, and doesn‚Äôt help with much more than a high level understanding that something happened."
datadog,"Alerting and Notifications
A monitoring solution that can‚Äôt tell you when something goes wrong is not very useful."
datadog,"In this section, we‚Äôll talk about the alerting and notification engines in Prometheus and Datadog that can help you stay on top of your cluster health."
datadog,"Alerting in Prometheus
Just like Grafana is required to do any meaningful visualization, you‚Äôll need to install AlertManager to get useful notifications from Prometheus."
datadog,"That said, once you‚Äôve installed AlertManager, it‚Äôs got some pretty cool capabilities."
datadog,"You can group alerts together into one notification, or even silence specific alerts for a period of time."
datadog,"There‚Äôs also a neat feature called inhibition that allows you to silence certain classes of alerts when another type of event is active (consider the case that if CPU is high on a container, you might not care to know that the load is also high)."
datadog,"The drawback to AlertManager, however, is that all notification rules are set up through a complicated YAML file that you feed to AlertManager on startup (and which AlertManager will check for updates)."
datadog,"This file can get unwieldy as the complexity of your alerting setup increases, and, as we‚Äôve all experienced, making typos and slight errors in config files can have disastrous effects on a system."
datadog,"Alert thresholds and metrics are also set up in Prometheus‚Äôs YAML configuration, so splitting alerting between these two places can also be a little confusing."
datadog,This is the config for a single alert (minus notifications).
datadog,Imagine doing it hundreds of times!
datadog,"Alerting in Datadog
While Datadog lacks some of AlertManager‚Äôs cool notification rules like inhibition or granular silencing, it has an incredibly robust system of detecting error states."
datadog,"Datadog calls these alerts Monitors, and they can do anything from threshold and anomaly detection on a metric to checking an event for a specific string."
datadog,Datadog provides a nice UI for configuring alerting.
datadog,"By default, Datadog will notify your team through email, but many services have Datadog integrations that let you get notifications through your preferred incident management system."
datadog,"Verdict
Which service you select depends on your use case."
datadog,"If you want tight control over what alerts get sent to your team, Prometheus and AlertManager are probably your best bet."
datadog,"If you‚Äôre looking for complicated alert conditions or you really hate config files, you‚Äôll probably want to go with Datadog."
datadog,"Conclusion
Both Prometheus and Datadog are fully featured, robust monitoring solutions."
datadog,"However, they require extensive configuration to get maximum benefit from monitoring, and they assume that as the DevOps professional, you will know all the things that could possibly go wrong and how to check for them."
datadog,"However, Kubernetes is a relatively new tool, and even with experience, there is always more to learn."
datadog,"And even if you do know all the things to monitor, who‚Äôs got time to endlessly configure a system and watch graphs for hundreds or thousands of resources?"
datadog,"Blue Matador will monitor your Kubernetes cluster and all its important metrics and events, and let you know when you need to take action."
datadog,It can ease the nagging anxiety that there are unknowns in your system waiting to cause you and your team headaches.
datadog,"Best of all, Blue Matador does it all without configuration."
datadog,"Blue Matador detects Kubernetes events like inability to schedule pods, or a deployment not having enough pods."
datadog,All without any configuration!
datadog,All you have to do is install our agent through a DaemonSet and the sit back and rest assured that your Kubernetes cluster is in good hands.
datadog,Give it a try today!
elasticapm,"Photo by Luke Chesser on Unsplash
What is Elastic APM?"
elasticapm,Elastic APM is an application performance monitoring system built on the Elastic Stack.
elasticapm,"It allows you to monitor software services and applications in real-time, by collecting detailed performance information on response time for incoming requests, database queries, calls to caches, external HTTP requests, and more."
elasticapm,This makes it easy to pinpoint and fix performance problems quickly.
elasticapm,Elastic APM also automatically collects unhandled errors and exceptions.
elasticapm,"Errors are grouped based primarily on the stacktrace, so you can identify new errors as they appear and keep an eye on how many times specific errors happen."
elasticapm,"-Elastic
This article consists of three parts:
Monitoring Flask / Flask-RESTPlus Applications
Monitoring FastAPI Applications
Monitoring Python Applications
Monitoring Flask / Flask-RESTPlus Applications
Installation
Elastic APM has built-in support for Flask."
elasticapm,"Since Flask RESTPlus and Flask-RESTful are extensions for Flask, the same steps apply for Flask-RESTPlus as well as Flask-RESTful."
elasticapm,"Install Elastic APM agent using pip:
pip install elastic-apm[flask]
Implementation
Let‚Äôs first import the required packages:
from flask import Flask
from elasticapm.contrib.flask import ElasticAPM
import elasticapm
Now, let's create an instance of Flask, which will be our WSGI application."
elasticapm,"app = Flask(__name__)
We can initialize the APM agent by using either environment variables or in our application code itself."
elasticapm,"In this article, we will initialize the APM agent in our code itself."
elasticapm,"To create an instance of Elastic APM agent, we need the following parameters:
server_url ‚Üí The URL of the Elastic APM
service_name ‚Üí Name of the application
environment ‚Üí The environment in which the application is running e.g."
elasticapm,"dev, qa or prod
server_url = 'http://localhost:8200'
service_name = 'DemoFlask'
environment = 'dev'
Next, we will initialize the APM Agent."
elasticapm,"We need to pass the Flask instance app as the first argument for initializing the APM agent, along with the parameters that we defined above."
elasticapm,"apm = ElasticAPM(app, server_url=server_url, service_name=service_name, environment=environment)
Our APM agent is now ready."
elasticapm,"Now, let‚Äôs open Kibana (e.g."
elasticapm,http://localhost:5601/) to see the logged data.
elasticapm,Open the Kibana dashboard and go to the APM tab.
elasticapm,You can see our service DemoFlask listed there.
elasticapm,"Click on the service name and go to Metrics, where you can track the CPU and Memory Usage."
elasticapm,"In the transactions tab, you can see the visualization related to each request your application receives, such as Transaction duration and Requests per minute."
elasticapm,You can also view the list of all the endpoints along with their average duration.
elasticapm,Click on a transaction to see more details for the transaction.
elasticapm,You can also add additional information about the transaction by using labels.
elasticapm,"elasticapm.label(platform='DemoPlatform')
To add default labels to all transactions, we can use Flask‚Äôs app.before_request decorator."
elasticapm,"@app.before_request
def apm_log():
    elasticapm.label(platform = 'DemoPlatform',                     
                     application = 'DemoApplication')
The information of the labels will be visible in the metadata tab in the trace sample of the transaction."
elasticapm,"Note that, by default, the transaction and error data will be recorded only when the application is not in debug mode."
elasticapm,Sample code can be found from the link mentioned in the Resources section.
elasticapm,"Monitoring FastAPI Applications
To monitor FastAPI/Starlette Applications properly using Elastic APM, you need to use Python 3.7+
Installation
Install the Elastic APM agent using pip:
pip install elastic-apm
Implementation
First, let‚Äôs import the required packages:
import uvicorn
from fastapi import FastAPI
from elasticapm.contrib.starlette import make_apm_client, ElasticAPM
Next, we will create an APM client using the SERVICE_NAME , SERVER_URL and ENVIRONMENT."
elasticapm,"Also, we will specify the global labels at the same time using GLOBAL_LABELS."
elasticapm,"apm_config = {
 'SERVICE_NAME': 'DemoFastAPI',
 'SERVER_URL': 'http://localhost:8200',
 'ENVIRONMENT': 'dev',
 'GLOBAL_LABELS': 'platform=DemoPlatform, application=DemoApplication'
}
apm = make_apm_client(apm_config)
Now, let‚Äôs initialize the Elastic APM agent."
elasticapm,"app = FastAPI()
app.add_middleware(ElasticAPM, client=apm)
The FastAPI application is now ready to send the logs to Elastic Server."
elasticapm,Sample code can be found from the link mentioned in the Resources section.
elasticapm,"Monitoring Python Applications
We can create an Elastic APM Client to monitor Python applications that do not use a framework (e.g."
elasticapm,"Flask, Django or FastAPI)."
elasticapm,An example of these applications could be schedulable code.
elasticapm,"Installation
Install Elastic APM agent using pip:
pip install elastic-apm
Implementation
First, we will create an Elastic APM Client
from elasticapm import Client
import elasticapm
client = Client(
    {'SERVICE_NAME': 'DemoPython',
     'SERVER_URL': 'http://localhost:8200',
     'ENVIRONMENT': 'dev'}
)
For frameworks like Flask and FastAPI, Elastic APM automatically instruments the application and also begins and ends the transactions."
elasticapm,"However, for Python applications that do not use such frameworks, we need to manually instrument the application and also begin and end the transactions."
elasticapm,"To automatically instrument your application to capture HTTP requests, database queries, etc., add the following line
elasticapm.instrumentation.control.instrument()
To begin a transaction, use begin_transaction method with the appropriate transaction type as the parameter."
elasticapm,"For example,
client.begin_transaction('schedule')
To complete a transaction, use the end_transaction method which takes two arguments viz."
elasticapm,transaction name and result.
elasticapm,"For example,
client.end_transaction('demo-transaction', 'success')
Sample code for monitoring Python application can be found from the link mentioned in the Resources section."
elasticapm,"Nowadays, in this competitive world every single software company analyses the following parameters in one form or the other :-
Their products reach to the users(No of hits per minute) and their user‚Äôs experience."
elasticapm,"How are their applications performing in terms of response time of APIs, database transaction time etc.?"
elasticapm,What are the areas of concern in a particular service that‚Äôs causing the errors or delaying the response rate corresponding to the request by the users?
elasticapm,There are several other concerns similar to the above mentioned ones on which the health of a distributed software ecosystem of a software Organisation depends.Doing the Application Performance Monitoring(APM) of all the application/services involved in a product provides us with solutions for the above mentioned concerns.
elasticapm,"In software world we refer these concerns as metrics and to track these metrics corresponding to the services involved in our software product we do APM.There are several tools in the market to analyse these metrics some of them are Elastic, New Relic."
elasticapm,"Elastic APM
Elastic APM is an application performance monitoring system which is built on top of the Elastic Stack (Elasticsearch, Logstash, Kibana, Beats)."
elasticapm,"Similar to other APM solutions, Elastic APM allows us to track key performance-related information such as requests, responses, database transactions, errors, etc."
elasticapm,regarding our software service.
elasticapm,"High Level Overview of the working of Elastic APM :-

High Level Diagram(HLD) of the working of Elastic APM
Edge machines contains our services and there is an APM Agent(Which we will see how to integrate with our service)attached to our service, it sends the data to APM Server(Which is an open source application written in GO) and the server transform the recieved data into Elasticsearch documents and send them to Elasticsearch and from here its gets reflected in our Kibana APM UI in terms of charts and other metrics."
elasticapm,"In this post, I will describe how to integrate Elastic APM to your java service so that we can track the above mentioned key metrics of our service.Most commonly used methods are :-
Using Dependency injection (Genrally used when there is a single entry point in our service)."
elasticapm,Using the Elastic APM JavaAgent(can be used in all types of services).
elasticapm,"Using Dependency Injection
Step 1."
elasticapm,"In your pom.xml file add the following dependency of Elastic APM :-
<dependency>
    <groupId>co.elastic.apm</groupId>
    <artifactId>apm-agent-attach</artifactId>
    <version>1.15.0</version>
</dependency>
Step 2."
elasticapm,"Adding these following environment variables in the run configuration of your service :-
ELASTIC_APM_APPLICATION_PACKAGES=com.docon.yourServiceName
ELASTIC_APM_CAPTURE_BODY=true
ELASTIC_APM_ENVIRONMENT=yourEnvironment(local/qa/staging/prod)
ELASTIC_APM_SERVER_URLS=http://localhost:8080
ELASTIC_APM_SERVICE_NAME=yourServiceName
OR you can also add these as system properties in the argument section of the configurations :-
-Delastic.apm.application_packages=""co.yourServicePackage""
-Delastic.apm.capture_body=""true""
-Delastic.apm.environment=""yourEnvironment(local/qa/staging/prod)""
-Delastic.apm.server_urls=""http://localhost:8080""
-Delastic.apm.service_name=""yourServiceName""
Step 3."
elasticapm,"The Final step is to update the file in your service where your main function(Single Entry Point source) is present and add the following piece of code :-
public static void main(String[] args){
   ElasticApmAttacher.attach();
   SpringApplication.run(MyApplication.class, args);
}
Using Elastic APM Java Agent
Setting up the APM Agent depends on the type of Application server we are using , detailed Steps regarding Setup of Elastic APM Java Agent can be found in its authentic documentation."
elasticapm,"You‚Äôre done with the integration.Start using your service and see the various performance related information(requests, response, database transaction.. etc) and monitor your service in the Elastic‚Äôs Kibana APM UI after running the service locally or deploying it to the respective environment (stage/qa/prod)."
elasticapm,Watch your application‚Äôs performance.
elasticapm,"I have been working with elastic stack for last couple of years and have used most of the beats filebeat, monitoringbeat, and packetbeat for various system and platform modules like kafka, redis, mongodb,filesystem,and host resources CPU/Memory monitoring."
elasticapm,I found setting up ELK is comparatively easier than other monitoring tools for a quick and clear visualisation of business and technical KPIs.
elasticapm,Recently looked into APM (Application Performance Monitoring) from the elastic stack and tried to integrate it with NodeJS based application.It indeed gives really nice stats about application performance quickly.I found it quite handy to quickly monitor my APIs performance and find application bottleneck if any.
elasticapm,What can be monitored with APM ?
elasticapm,"CPU usage
Memory usage
Throughput (TPS/RPS) and average response time."
elasticapm,Transaction span breakup (e.g.
elasticapm,"time spend on DB operation , external http calls , app internal processing etc..)
Can create custom span if doesn‚Äôt exist in default list."
elasticapm,Micro services based interaction and flow.
elasticapm,"Setup APM server
Setting up APM server is fairly easy."
elasticapm,"Install below components :
Elastic search
Kibana
APM server
I have used docker compose to setup the whole stack."
elasticapm,"https://github.com/kamalkalyani/cart-manager/blob/master/docker-compose/apm-compose.yml
APM Integration
APM comes with predefined set of modules that are monitored just by integrating APM sdk with in your app."
elasticapm,"NodeJS based integration
# install apm node module
    npm install elastic-apm-node
# Add below code to your startup script 
     // Add this to the VERY top of the first file loaded in your    
     appconst apm = require('elastic-apm-node').start({    
        // Override service name from package.json    
        // Allowed characters: a-z, A-Z, 0-9, -, _, and space       
      serviceName: 'cart-manager', })
That‚Äôs it your application is ready to be monitored."
elasticapm,"Launching APM dashboard from Kibana
Launch APM dashboard
Samples dashboard visualisations






Sample app to see the full integration working :"
elasticapm,"Image from: https://www.elastic.co/guide/en/apm/get-started/current/images/apm-architecture-cloud.png
APM stands for Application Performance Monitoring."
elasticapm,That means you want to measure the performance of your application and your servers.
elasticapm,"How they are served, how much memories are consumed."
elasticapm,Where is a bottleneck?
elasticapm,And so many things.
elasticapm,"It may trigger some notifications if it finds high memory usage, or a remote call is taking too much time."
elasticapm,Those triggers can be based on so many things.
elasticapm,Let‚Äôs skip that part for now.
elasticapm,"Behind the story
Back in Pathao days, we used to use New Relic."
elasticapm,New Relic comes handy.
elasticapm,"For PHP, you just need to install their agent."
elasticapm,And install a package.
elasticapm,That‚Äôs all.
elasticapm,You‚Äôll be getting output in the New Relic‚Äôs dashboard as soon as the server starts to serve the requests.
elasticapm,"But, my current company (Digital Healthcare Solutions, previously known as Telenor Health)‚Äôs OPs proposed Elastic APM."
elasticapm,"So, I had to go through how it works."
elasticapm,"Till now, I started to learn Elastic Search for at least 4 times, never succeeded."
elasticapm,"Anyway, so I was looking for available packages."
elasticapm,I came to visit the following package.
elasticapm,"The package is good, but under the hood, it sends HTTP requests to the APM server."
elasticapm,Which is actually costly.
elasticapm,"And, it doesn‚Äôt support APM Server 7.x."
elasticapm,"philkra/elastic-apm-laravel
IMPORTANT Looking for a maintainer/owner."
elasticapm,"If you want to take over the project, please open an issue here."
elasticapm,"Laravel‚Ä¶
github.com

That‚Äôs why I had to build one from scratch."
elasticapm,"In this article, I am going to explain how to use my package with any PHP code."
elasticapm,The package already makes it easy to use with Laravel or Lumen.
elasticapm,But you‚Äôre not bound to use that.
elasticapm,You can use it in your own way.
elasticapm,What is Elastic APM?
elasticapm,"Okay, did you skip the feature photo?"
elasticapm,Have a look then.
elasticapm,The photo states the underlying structure of how it works.
elasticapm,"You need to install an APM agent for your favorite language (till now, APM agents don‚Äôt support a lot of languages."
elasticapm,So check that out).
elasticapm,"Then, that agent will collect data on your code execution."
elasticapm,It‚Äôll then send to the APM server.
elasticapm,APM servers will then send those data to Elasticsearch Server and you‚Äôll be able to view those data in Kibana.
elasticapm,That‚Äôs how it actually works under the hood.
elasticapm,"Keep in mind, so far I found that the APM Dashboard UI comes with XPack, which means you‚Äôll have to invest some money on it."
elasticapm,"Installation
Elastic provides a PHP APM agent."
elasticapm,This agent will collect data from our server and will insert those data into the APM server.
elasticapm,I used a docker container to serve my PHP application.
elasticapm,The docker file looks like below.
elasticapm,Dockerfile for PHP container.
elasticapm,Ignore the CMD section.
elasticapm,"In the above snippet, check line 16 and those commands."
elasticapm,"We cloned the APM's git repository, then configured and installed that in our container."
elasticapm,Line 22 copies an .ini file.
elasticapm,The .ini file is below.
elasticapm,"elastic_apm.ini file
In elastic_apm.ini file, line 2 points out the path of our git cloned repository‚Äôs src/bootstrap_php_part.php file."
elasticapm,Line 4 points out the URL of the APM server.
elasticapm,"If you‚Äôre not using docker, then you can just git clone the repository, then install it."
elasticapm,And then integrate the extension with php.
elasticapm,That‚Äôs all for the APM agent install.
elasticapm,"Before we dive into the package, you can get basic ideas of the terms from the agent‚Äôs documentation."
elasticapm,"Basically,
The transaction is, when your application is running then it‚Äôs creating a transaction."
elasticapm,Each request is counted as a transaction.
elasticapm,Each transaction has a name and a type.
elasticapm,"The Span is when you execute a set of codes, the information you‚Äôre dealing with, can be sent to the server as a span."
elasticapm,A span is a piece of information when the code is executed.
elasticapm,A DB query can be a span.
elasticapm,Or HTTP request information can be a span.
elasticapm,"The Package & Usage
ssi-anik/elastic-apm-php
The package depends on elastic's apm-agent-php extension."
elasticapm,"If want to use with Laravel, Laravel version >= 6.x ‚Ä¶
github.com

So, at first, let‚Äôs have a look at how to integrate the package with PHP."
elasticapm,Then we‚Äôll look at how to integrate with Laravel/Lumen.
elasticapm,The agent itself requires PHP ‚â• 7.2 that‚Äôs why this package requires a minimum of PHP 7.2.
elasticapm,"Installation
composer require anik/elastic-apm-php
Integration with PHP
A class Anik\ElasticApm\Agent is the public entry point of all the interactions."
elasticapm,And the Agent class cannot be instantiated.
elasticapm,It uses a singleton object.
elasticapm,"So, whenever you need to interact, you‚Äôll call Agent::instance()."
elasticapm,It‚Äôll give you a single object from wherever you call throughout the request lifecycle.
elasticapm,"To set a name and type for a transaction, you‚Äôll need to instantiate an object of Anik\ElasticApm\Transaction with name and type."
elasticapm,"After successfully instantiating the object, you will need to pass it to the Agent class using its setTransaction method."
elasticapm,"Agent::instance()->setTransaction(new Transaction('name', 'type'));
If you want to send data for this transaction, you‚Äôll have to use a span."
elasticapm,"To create a new span, Anik\ElasticApm\Contracts\SpanContract interface has to be implemented."
elasticapm,"getSpanData(), getName(), getType(),getSubType() methods must have to be implemented."
elasticapm,"But if you use available trait Anik\ElasticApm\Spans\SpanEmptyFieldsTrait then you can skip getAction(), getLabels() method."
elasticapm,"If you want to send data to your APM server, then you can implement these methods as well."
elasticapm,Read the agent documentation given above to have a better idea for the method return values.
elasticapm,"When you finish implementing a Span class, then you can add the span as
Agent::instance()->addSpan($implementedSpanObject);
So, when you‚Äôre done adding spans, then before returning the result, you need to push those transactions and spans to the APM agent."
elasticapm,"To do so, use
Agent::instance()->capture();
The above method will process all the transactions and spans, then pushes them to the agent."
elasticapm,And agent then takes care of the transaction and spans and sends them to the server.
elasticapm,"Note: If you want to do everything of your own then you can use the Agent::getElasticApmTransaction() to get the current transaction of the agent or Agent::newApmTransaction($name, $type) to create a new transaction."
elasticapm,Make sure to call end() method if you created a new Transaction.
elasticapm,"Or if you want to put the spans you add to a new transaction, then you can use Agent::captureOnNew() to send with a new transaction."
elasticapm,You don‚Äôt need to call end when using captureOnNew.
elasticapm,"If you ever want in your code to get a fresh instance of Agent, then you can call Agent::reset() first and then Agent::instance() or Agent::reinstance() will do the same."
elasticapm,"Finally, keep in mind that if you‚Äôre calling any of the capture*() method, Transaction must be provided."
elasticapm,Without passing Transaction will raise Anik\ElasticApm\Exceptions\RequirementMissingException exception.
elasticapm,This is all for the PHP integration.
elasticapm,"Integration with Laravel/Lumen
For Laravel,
The package already uses the package discovery feature."
elasticapm,"But still, add Anik\ElasticApm\Providers\ElasticApmServiceProvider::class in your config/app.php‚Äòs providers array."
elasticapm,Add Anik\ElasticApm\Facades\Agent::class in your config/app.php's facade array.
elasticapm,php artisan vendor:publish to publish the configuration file.
elasticapm,"For Lumen,
You don‚Äôt need to enable Facade to use this package."
elasticapm,Copy elastic-apm.php from package‚Äôs src/config directory to your lumen project‚Äôs config directory.
elasticapm,// in your bootstrap/app.php file.
elasticapm,"use Anik\ElasticApm\Providers\ElasticApmServiceProvider;
$app->register(ElasticApmServiceProvider::class);
$app->configure('elastic-apm');
Change your configuration file as per your requirement."
elasticapm,"Tracking Application Errors
If you want to send your error data to you APM server, then
For Laravel, in bootstrap/app.php
// COMMENT THIS SECTION
/**
 *  $app->singleton(
 *      Illuminate\Contracts\Debug\ExceptionHandler::class,
 *      App\Exceptions\Handler::class
 *  );
 */
// USE THIS SECTION
use Illuminate\Contracts\Debug\ExceptionHandler;
use Anik\ElasticApm\Exceptions\Handler;
use App\Exceptions\Handler as AppExceptionHandler;
use Symfony\Component\HttpKernel\Exception\NotFoundHttpException;
use GuzzleHttp\Exception\ConnectException;
$app->singleton(ExceptionHandler::class, function ($app) {
    return new Handler(new AppExceptionHandler($app), [
        // NotFoundHttpException::class, //(1)
        // ConnectException::class, //(2)
    ]);
});
For Lumen, in bootstrap/app.php
// COMMENT THIS SECTION
/**
 * $app->singleton(
 *   Illuminate\Contracts\Debug\ExceptionHandler::class,
 *   App\Exceptions\Handler::class
 * );
 */ 

// USE THIS SECTION
use Illuminate\Contracts\Debug\ExceptionHandler;
use Anik\ElasticApm\Exceptions\Handler;
use App\Exceptions\Handler as AppExceptionHandler;
use Symfony\Component\HttpKernel\Exception\NotFoundHttpException;
use GuzzleHttp\Exception\ConnectException;
$app->singleton(ExceptionHandler::class, function ($app) {
    return new Handler(new AppExceptionHandler(), [
        // NotFoundHttpException::class, //(1)
        // ConnectException::class, //(2)
    ]);
});
Anik\ElasticApm\Exceptions\Handler accepts an array of exception classes as the second parameter that won‚Äôt be sent to the APM server."
elasticapm,"By default, the NotFoundHttpException error is not pushed to the APM server."
elasticapm,That‚Äôs why (1) & (2) were commented to show the usage.
elasticapm,"If your application encounters an error and the error is successfully caught by the Exception Handler, and the transactions are set, then it‚Äôs guaranteed that the APM server will receive a stack trace of the error."
elasticapm,"As the PHP agent provides no API to send stack trace, thus your trace has a chance to be trimmed by the ES, longer than certain characters."
elasticapm,"The response was returned with 500 (marked) & the exception with stack trace
Track Application‚Äôs Request & Response
Track your application‚Äôs number of requests it serves with status code and duration it took to serve, you can use the provided middleware."
elasticapm,"For Laravel, in your app/Http/Kernel.php class,
<?php
use Anik\ElasticApm\Middleware\RecordForegroundTransaction;
class Kernel extends HttpKernel {
    protected $middleware = [
        // ...        
        RecordForegroundTransaction::class,
        // ..
    ];
}
For Lumen, in your bootstrap/app.php file,
use Anik\ElasticApm\Middleware\RecordForegroundTransaction;
$app->middleware([
    // ...
    RecordForegroundTransaction::class,
    // ...
]);
When a request is served, the transaction name will be in the following order
If the route handler uses uses parameter i.e; HomeController@index (controller action)."
elasticapm,If the route handler uses as parameter i.e; ['as' => 'home.index'] (named route).
elasticapm,"If above fails, then HTTP_VERB ROUTE_PATH i.e; GET /user/api."
elasticapm,"If nothing matches, 404, then uses index.php or user-provided name from the configuration."
elasticapm,"Transaction of the request (Step 1)

Name route as transaction (Step 2)

Route with verb (Step 3)

Not found routes (Step 4)

Span as the request was served
Track HTTP Remote Calls
If you‚Äôre using Guzzle, then you can use the provided Middleware for Guzzle."
elasticapm,"use GuzzleHttp\HandlerStack;
use GuzzleHttp\Client;
use Anik\ElasticApm\Middleware\RecordHttpTransaction;

$stack = HandlerStack::create();
$stack->push(new RecordHttpTransaction(), 'whatever-you-wish');
$client = new Client([
    'base_uri' => 'https://httpbin.org',
    'timeout'  => 10.0,
    'handler'  => $stack,
]);
$client->request('GET', '/');

Remote HTTP call track
Track Queue Worker
To track the Jobs, you need to use the provided Job middleware whenever you‚Äôre dispatching a new job."
elasticapm,"You can use either from the below,
From the class with the middleware method."
elasticapm,"use Anik\ElasticApm\Middleware\RecordBackgroundTransaction;
use Illuminate\Contracts\Queue\ShouldQueue;
class TestSimpleJob implements ShouldQueue 
{
    public function middleware () {
        return [ new RecordBackgroundTransaction()];
    }
    
    public function handle () {
        app('log')->info('job is handled');
    }
}
Otherwise, when dispatching a job
use Anik\ElasticApm\Middleware\RecordBackgroundTransaction as JM;
use App\Jobs\ExampleJob;
dispatch((new ExampleJob())->through([new JM()]);

Tracking Job Processing
Note: If you use php artisan queue:work then it‚Äôs a long-running job."
elasticapm,That‚Äôs why it‚Äôll only send one Transaction.
elasticapm,"As no process is created, thus you‚Äôll not get any transaction or span."
elasticapm,"On the other hand, if you use queue:listen, i.e; php artisan queue:listen it uses a new process for each job it picks, thus you‚Äôll get a new transaction and spans for that transaction for each job."
elasticapm,"Tracking Query Execution
Query execution is handled automatically and pushed to the APM Server."
elasticapm,"Query execution
That‚Äôs all."
elasticapm,Hope you‚Äôll like it.
elasticapm,Don‚Äôt forget to put a star on this project.
elasticapm,"Tracking Redis Query Execution
Redis query execution is not handled automatically."
elasticapm,"If you‚Äôre using Redis as your Cache Driver, then you‚Äôll have to explicitly mention that you want to enable Redis Query Logging by putting ELASTIC_APM_SEND_REDIS=true in your .env file."
elasticapm,"Redis Query Execution
And, also for the development purpose, the docker-compose.yml file for the ES, Kibana & APM (Don‚Äôt use in production)

docker-compose.yml
Happy coding."
elasticapm,‚ù§
inspectit,"Today we are going to see a fabulous open-source tool to perform different types of tasks, from tracing, monitoring, or instrumentation: InspectIT."
inspectit,"This tool is a Java Agent, which we already know a little better from the last post we did, and you can see it here."
inspectit,This software tries to minimize two things.
inspectit,"On the one hand, the configuration time needed to use other Application Performance Management, APM, tools."
inspectit,"Such as Jaeger, Prometheus, Zipkin or Micrometer."
inspectit,"And on the other hand, reduce the modifications to be made in our applications, if we want to perform instrumentation tasks."
inspectit,"InspectIT is based on OpenCensus, which is a set of open software libraries made in different languages that allow us to obtain distributed metrics and traces."
inspectit,This software already has a wide range of exporters that allow sending the information to other monitoring tools.
inspectit,And InspectIT supports most of these exporters.
inspectit,"For all these reasons, InspectIT is a great tool."
inspectit,As it is a Java Agent we will not need to modify our applications to obtain performance information.
inspectit,"And with the preconfigured exporters, we can obtain metrics and traces automatically and send them to different destinations."
inspectit,"Through the examples, we will be able to see how to obtain this information from our application."
inspectit,The operation will be similar in the different examples.
inspectit,"In order to make it work we will have to follow the next two steps:
Associate the java agent stored in the library through the JVM argument ‚Äò-javaagent:/full/path/to/library‚Äô."
inspectit,Associate through a JVM argument the exporter property to be used.
inspectit,"We can associate one or more properties, each one with its corresponding argument."
inspectit,"For the first example, we will use a Jaeger exporter, with which we will be able to obtain the application traces."
inspectit,"The base of it will be one of our examples that we have done in previous posts, based on Apache Camel, and that you can see here."
inspectit,"Just to remember, Jaeger is a tool or Tracer that will allow us to collect the information of the traces of our application and to visualize them in an own graphical interface."
inspectit,"The steps are as follows:
On the one hand, we have to download the library that contains the java agent, we can do it from here."
inspectit,And we place it in a path that we will indicate later when we start the application.
inspectit,"Start Jaeger, for example with a docker-compose like the following one."
inspectit,"version: '2.4'
networks:
  sandbox-apache-net:
    ipam:
      driver: default
      config:
        - subnet: 172.24.0.0/16
services:
  mysql:
    image: mysql:5.7.26
    mem_limit: 2G
    container_name: sandbox-apache-mysql
    hostname: sandbox-apache-mysql
    networks:
      sandbox-apache-net:
        ipv4_address: 172.24.1.1
    environment:
      MYSQL_HOST: sandbox-apache-mysql
      MYSQL_ROOT_PASSWORD: root
    ports:
      - 3306:3306
    volumes:
      - ./configs/mysql/conf.d/custom.cnf:/etc/mysql/conf.d/custom.cnf
      - ./configs/mysql/scripts:/docker-entrypoint-initdb.d
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - 16686:16686
      - 14268:14268
Finally, start the JVM passing the arguments that allow us to configure the desired exporter."
inspectit,"For the case of Jaeger we will use the following ones:
-javaagent:/home/deesebc/Downloads/inspectit-ocelot-agent-1.8.1.jar -Dinspectit.exporters.tracing.jaeger.url=http://127.0.0.1:14268/api/traces 
-Dinspectit.exporters.tracing.jaeger.service-name=inspectitJaegerExample
In the URL property, we indicate the address where Jaeger is located, and with service-name we can indicate the name with which we will register the Jaeger traces."
inspectit,"As a previous step to see how Jaeger works, we are going to make several queries to our application."
inspectit,So that they can be registered by InspectIT.
inspectit,"If you use the code of my application, it will be an invocation similar to this: http://localhost:9090/book/1."
inspectit,If we access the URL http://localhost:16686/search we will be able to access the trace browser and search for our application‚Äôs traces.
inspectit,"In the next example, to see more of the potential of InspectIT and to see how it works to obtain metrics, we will make use of the exporters for Prometheus."
inspectit,The example on which we will be based will be this one.
inspectit,We start again preparing a docker-compose that allows us to deploy Prometheus.
inspectit,"We can base it on the one from the previous example and it would be something similar to this:
version: '2.4'
networks:
  sandbox-apache-net:
    ipam:
      driver: default
      config:
        - subnet: 172.24.0.0/16
services:
  mysql:
    image: mysql:5.7.26
    mem_limit: 2G
    container_name: sandbox-apache-mysql
    hostname: sandbox-apache-mysql
    networks:
      sandbox-apache-net:
        ipv4_address: 172.24.1.1
    environment:
      MYSQL_HOST: sandbox-apache-mysql
      MYSQL_ROOT_PASSWORD: root
    ports:
      - 3306:3306
    volumes:
      - ./configs/mysql/conf.d/custom.cnf:/etc/mysql/conf.d/custom.cnf
      - ./configs/mysql/scripts:/docker-entrypoint-initdb.d
      
  prometheus:
    image: prom/prometheus:v2.6.1
    ports:
      - 9091:9090
    volumes:
      - ./configs/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      sandbox-apache-net:
        ipv4_address: 172.24.1.2
    extra_hosts:
      docker.host: 172.28.0.1
172.28.0.1 is the IP of the docker bridge interface."
inspectit,The next point will be to start our application with the arguments that allow us to export the information to Prometheus.
inspectit,"-javaagent:/home/deesebc/Downloads/inspectit-ocelot-agent-1.8.1.jar -Dinspectit.exporters.metrics.prometheus.host=172.28.0.1 
-Dinspectit.exporters.metrics.prometheus.port=8888
Let‚Äôs remember that for Prometheus to work it has to read, from a specific URL, information about the application."
inspectit,So on the one hand we must configure Prometheus to read from a specific point.
inspectit,"And we will do this through the Prometheus configuration file (part of the docker-compose):
scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 1m
    static_configs:
      - targets: ['localhost:9090']
  - job_name: 'apache_example'
    scrape_interval: 1m
    metrics_path: '/metrics'
    static_configs:
      - targets: ['172.28.0.1:8888']
And through the JVM arguments, we will indicate to InspectIT that we want to expose the information of our application in the IP and port indicated."
inspectit,Something that in the example on which we based was done by Spring Actuator.
inspectit,"Once everything is started, we will make a couple of invocations as mentioned above."
inspectit,And now we can access Prometheus and see the monitoring that has been done.
inspectit,If we access the route http://localhost:8888/metrics we will be able to see the different metrics that we are generating from the application.
inspectit,And if we access the Prometheus URL http://localhost:9091/targets we can see if our endpoint is being read correctly by Prometheus.
inspectit,The next step will be to access http://localhost:9091/graph and make a graph based on the metrics obtained.
inspectit,"For example, one that counts the invocations that we make to endpoints of our application, through the parameter http_in_count."
inspectit,"As you can see, it‚Äôs really easy."
inspectit,There are no more excuses to perform application performance management tasks with InspectIT.
inspectit,"And these are just a couple of examples, but you can do more through the different exporters."
instana,"According to Gartner (Gartner and Moore), IT teams are dealing with increasing amounts of data and a wider variety of tools to monitor that data."
instana,"This is resulting in greatly increased complexity in keeping the system in a good operational state, and can cause ‚Äúsignificant delays in identifying and solving issues‚Äù."
instana,"‚ÄúIT operations are challenged by the rapid growth in data volumes generated by IT infrastructure and applications that must be captured, analysed and acted on‚Äù, says Padraig Byrne, Senior Director Analyst at Gartner (Gartner and Moore)."
instana,"All IT departments these days have a vast array of often not- or poorly-integrated IT monitoring systems, and a lack of properly-integrated tools results in a significant impact on your business (TechTarget)."
instana,"Indeed, not doing anything about integrating that system log from your virtualisation server into the corresponding logs from the database environment could be the very undoing of your business:
‚ÄúFailing to do anything about the poor data quality in your systems, on the other hand, can set you back as much as 100 times the cost of preventing it at the point of entry.‚Äù (TechTarget)
So how do you do something about this situation?"
instana,"Recent events have shown that we are all more reliant than ever on our online systems, whether they have become the main source of revenue for sales, or the backbone of our communications system, integrating and managing, and going beyond simply reacting to problems must be the way to maintain control and manage costs."
instana,"To bring this level of control, IBM believes there are some key steps involved which all organisations should consider to some degree:
‚ÄúPlanned or unplanned, because downtime = money (that‚Äôs lost money/revenue as well as customer dissatisfaction, market share and possibly brand damage etc) these are some of the knock-on effects of downtime."
instana,"‚Äú (IBM and Metcalfe)
According to the (Aberdeen and Arsenault) report, the average cost per hour of downtime is $260,000."
instana,That‚Äôs up 60% since 2014.
instana,"That‚Äôs obviously an average, but as (IBM and Metcalfe) point out, the reputational damage to your business could be much worse."
instana,"However, for many organisations it is not simply a case that you can implement some solution and suddenly you are able to predict outages and thus reduce downtime."
instana,"The lack of integration between systems you have means that you have the following hurdles to overcome first:
Reducing the noise from systems to cut down on duplicate events, unnecessary alerts, etc."
instana,Standardising (or normalising) the information coming from the different sources so that they can be combined to build a bigger picture.
instana,"Understanding and gaining insight to the actual topology of the systems you are running, and the interactions between the different components."
instana,E.g.
instana,"if that database server goes down, which microservices or functions are affected?"
instana,"If I write poor code in one of my functions, which other components call that function that might be then affected (often referred to as the blast radius)."
instana,Are changes made to the environment to fix issues actually put under change control and documented?
instana,Is there an audit trail around the last time that fix was implemented?
instana,How much control of knowledge capture do you have so that you can learn from previous downtime to allow your teams to reach the solution quicker the next time?
instana,This diagram illustrates the journey all organisations need to take to reach an optimum position.
instana,"Consider where your company is and where it can reasonably get to:

AI for IT Operations is a journey on which your organisation should embark in order to provide a ‚Äúshift left‚Äù in its ability to handle outages and downtime."
instana,By ‚Äúshift left‚Äù I mean that issues relating to customer experience (in the case of retailers) or communications can be handled by more front-line IT support people rather than domain experts whose primary job is not to provide support.
instana,AI for IT Operations is not a big-bang.
instana,You should start considering how you can collect the information you are generating into one place.
instana,"All those logs, all those systems spewing out logging information should be brought together so that they can be arranged and analysed to drive better insights."
instana,Once they‚Äôre all in one place you need to organise them.
instana,This involves normalising the information and bringing the information into similar data structures.
instana,A basic example is converting time and date entries in the logs to be the same format.
instana,With the information arriving in a format which is consistent you can start the analysis phase.
instana,This is where a product like IBM CloudPak for Watson AIOps brings its IT knowledge rules to help you.
instana,"Instead of you needing to set up a rulebase in your analysis tool, IBM Cloud Pak for Watson AIOps already has all the information it needs to:
Detect patterns and recognise issues."
instana,Tag and classify the elements of the information into related and unrelated events.
instana,"Correlate everything together to give a picture of an incident, the affected components and underlying causes."
instana,"For example, the slow-running of a website might be down to a long ping time to a database server which is caused by a misconfiguration of a firewall rule."
instana,‚ÄúArtificial ignorance‚Äù (Digital Guardian and Zhang) to detect anomalies and ignore the routine stuff which otherwise gets in the way.
instana,Being able to correlate and isolate issues is a massive step forward for any IT Operations team.
instana,It cuts down the hunting for information and utilises the expert knowledge inherent in the components talking to each other which might not otherwise be available in your organisation.
instana,Remember that it‚Äôs only when all of the people in your IT Operations team sit in a room and discuss a fault that all of the knowledge about all of the components is there.
instana,"No one person has a complete view or understanding of the whole system, from networking to firewalls to servers to databases to microservices."
instana,Having a ‚Äúdigital twin‚Äù in the form of IBM Cloud Pak for Watson AIOps means that it can draw all this information together.
instana,"By now we‚Äôve reached the Reactive stage in our implementation maturity, where we are able to make smarter and quicker decisions because we‚Äôre armed with all the relevant information."
instana,But how do we take it to the next level?
instana,Being able to predict problems and therefore be proactive where AI is infused in your IT Operations landscape is where organisations need to get to in order to be able to maintain control over the increasingly-complex and increasingly-mission-critical environments they preside over.
instana,There are two dimensions to this ‚Äî anomaly detection and protection.
instana,Anomaly detection is primarily where you want things which are beginning to go wrong to be detected and for you to be alerted with recommended next best actions.
instana,It‚Äôs not enough to sample logs coming into the management system on a frequent basis.
instana,What if something happens between times when the samples are taken?
instana,You need to read every line of the logs and decide whether what you see is ‚Äúnormal‚Äù or not.
instana,You also need to be able to review what you did the last time this kind of anomaly occurred.
instana,Was there an Ansible runbook you ran to fix something?
instana,Did you deploy more containers or pods to raise the compute power available?
instana,The constant vigilance is something which IT Operations teams are struggling with most.
instana,"To be always on top of what‚Äôs going on, weeding out the noise from the real issues, and knowing what to do about it ‚Äî if anything ‚Äî is what an AI for IT Operations tool does."
instana,"However, spotting anomalies and acting before they become issues is one thing if the system is relatively static."
instana,Where you have developers adding new functionality or updating existing functionality you have an additional vector of code change which can have unintended consequences on your IT Operations.
instana,"While your crack team of software developers may be amongst the best in the business, you need to consider the dependability (Laprie and Kanoun #) of changes to the code."
instana,They are under the same spiralling complexity situation as the Operations team.
instana,They don‚Äôt have a complete understanding of every line of code running and are assuming that if they do their job right (according to the documentation) when it comes to publishing an API or calling an endpoint then all will be well.
instana,But how do you know?
instana,"The second dimension of constant vigilance, therefore is spotting potential flaws in code being injected into the environment before it goes in."
instana,This is where Application Performance Management (APM) tools such as Instana help you.
instana,"Being able to discover, map, find root cause and optimise code before it is let loose in your environment is something that you build into a CI/CD pipeline to further protect your system."
instana,"In addition to proactively trapping issues before they become problems, you also need the kind of fine-level instrumentation of the code that runs as you do of the IT environment it runs on."
instana,"You know how many compute cores are being used, network bandwidth consumed and memory allocated to servers, but do you know which components in your kubernetes pods are capturing all the resources?"
instana,Which module is killing the response time to a database?
instana,Without a tool such as APM the chances are you don‚Äôt.
instana,"So in addition to bringing the logging information together for your physical and virtual IT environment, you need the instrumentation and logging of the performance of the code."
instana,It‚Äôs at this point you move to Proactive actioning of issues where AI is infused not only into the operating environment but also every line of code.
instana,"IT organisations are dealing with an ever-increasing level of complexity, from IT operations itself to the developers."
instana,"Using a tool like IBM Cloud Pak for Watson AIOps with Instana allows you to become proactive and to be better and quicker at resolving issues, often before they become issues at all."
instana,The impact of this on your business is cost mitigation or avoidance together with your ability to further scale the sophistication of your customer experience to meet expectations.
instana,"Getting to this point is a journey and one which every organisation starts at a different place, but one to which every organisation will benefit."
instana,"It‚Äôs been a few months since IBM announced a definitive agreement to acquire Instana, an application performance monitoring and observability company."
instana,"‚ÄúThe combination of the Instana platform and IBM Watson AIOps capabilities extends and enriches IBM‚Äôs AI-powered automation portfolio to deliver more advanced capabilities to help our clients move from reactive to proactive management of IT operations.‚Äù ‚Äî Pratik Gupta, CTO, IBM Hybrid Cloud Management & AI Powered Automation
I wanted to take a moment and share some perspective on what this key partnership means for our IBM Power Systems customers."
instana,Instana has been built from the ground up to take advantage of new technologies like Kubernetes and cloud-native services to fill critical gaps.
instana,"Instana brings a wealth of innovative capabilities such as comprehensive collection of application tracing, automatic construction of log relationships, metrics, simplified instrumentation and so much more."
instana,"At a very high level, Instana‚Äôs architecture consists of a management dashboard (can run on-prem in your data center or as a cloud-based SaaS solution) and agents that collect data from your underlying infrastructure."
instana,"As of this writing, Instana supports host agents for AIX and Linux on Power, as shown below."
instana,Download Instana agents for IBM Power Systems.
instana,"Download agents for IBM Power Systems
Installing the agents just takes a few minutes."
instana,"Once they‚Äôre running, you can see all sorts of interesting metrics in your Instana dashboard:
A dashboard showing infrastructure metrics collected by Instana."
instana,"Dashboard of host metrics and application inventory collected by Instana on IBM Power Systems
Instana not only collects information about compute nodes, but also has an extensive set of application discovery and monitoring capabilities."
instana,"As you can see in the example above, Instana automatically discovered that I had an instance of MariaDB installed and running inside of a container ‚Äî that‚Äôs deep introspection at its finest!"
instana,"Best of all, it‚Äôs easy to give Instana a test drive today ‚Äî just hop over to the website and sign up for the free trial."
instana,"It‚Äôs entirely SaaS-based, so it just takes a few minutes and you‚Äôll be on your way to installing agents and looking at all kinds of interesting metrics!"
instana,"From an IBM Power Systems perspective, we‚Äôre very excited about this partnership and the future of hybrid cloud monitoring and AI-driven insights for the platform!"
instana,"For more details about this partnership, check out this blog post by Pratik Gupta, CTO, IBM Hybrid Cloud Management & AI Powered Automation."
instana,"When IBM announced that it was buying Instana last week, it struck me as the first shot across the bow of market maturation."
instana,One of the first indications of Market maturation is consolidation.
instana,"To validate this theory, let‚Äôs go back a few years."
instana,"For several years, DORA (DevOps Research & Assessment) has run surveys and assessed the state of DevOps."
instana,"The surveys have shown steady progress:
In 2014, three of the five recommendations were about culture:
‚Äî Peer-reviewed change approval process
‚Äî Version control for all production artifacts
‚Äî Proactive monitoring
‚Äî High-trust organizational culture
‚Äî Win-win relationship between dev and ops
By 2015, automation and technology-based practice improvements were already more important than they were the year before:
It was gratifying, though unsurprising, to find that deployment pain was predicted by whether the key continuous delivery practices had been implemented: comprehensive test and deployment automation, the use of continuous integration including trunk-based development, and version control of everything required to reproduce production environments."
instana,A generative organizational culture was also highly correlated with low deployment pain.
instana,A 2016 survey supported these findings.
instana,I helped lead the survey and produced the report for xMatters and Atlassian.
instana,"We surveyed more than 1,000 technology organizations on the maturity of their DevOps culture, operations, continuous delivery, architecture, and testing."
instana,"Organizations ranked most mature in their culture, which makes sense since DevOps launched as a cultural movement and organizations have been working on the culture aspects of DevOps the longest."
instana,"Here are the complete rankings:
‚Äî Culture and organization alignment
‚Äî Continuous delivery
‚Äî Operations and support
‚Äî Design and architecture
‚Äî Test and verification
I saw the movement firsthand at xMatters."
instana,The company was trying to manage literally tens of thousands of virtual machines before it turned to containers and then to Kubernetes to orchestrate the containers.
instana,"Finally, with their hands tied up from maintaining data centers around the world, they moved to GCP so they could get out of the maintenance business and back in the innovation game."
instana,"A New Age of Automation
The culture of collaboration and transparency is still an important element of high performing organizations, but automation is more dependent on technology than it used to be."
instana,"In fact, a new breed of companies is automating certain aspects of business to free workers from repetitive tasks and toil so they can focus on innovation and new projects."
instana,"New (and some old) companies include:
‚Äî Harness for CI/CD and more
‚Äî Instana for monitoring
‚Äî Gusto and Clearview for HR
‚Äî To a lesser extent: Jenkins, Ansible, CircleCI, GitLab, and Hardbees
So let‚Äôs get back to IBM and Instana."
instana,One of the primary signs that an industry is maturing is consolidation.
instana,IBM‚Äôs purchase of Instana looks to be the first shot toward consolidation in this new automation paradigm.
instana,If IBM recognizes the importance of process automation enough to act.
instana,you can bet some other big players will do the same.
instana,"Think Oracle, SAP, and Microsoft."
instana,"What will the impact be on cloud platforms like AWS, Azure, and GCP?"
instana,"I expect many people will become redundant in their current roles, including engineers."
instana,But new roles will emerge for new purposes.
instana,"We‚Äôll retrain, adapt, and create a new economy."
instana,This is what happens in every industrial revolution.
instana,This should be fun!
instana,How About Your Perspective?
instana,What stories or lessons do you have on this topic?
instana,Please leave a comment!
instana,"Application Performance Monitoring (APM ) empowers companies to monitor the performance and availability metrics of their business-critical applications, receive alerts immediately in case of performance issues /erroneous rising, and generate reports for periodic performance analysis."
instana,"According to the Gartner report on APMs, every APM should have five main dimensions to meet the common expectations from customers :
End-user experience monitoring
Application runtime architecture discovery and modelling
User-defined transaction profiling
Application component monitoring
Reporting & Application of data analytics
These are the baseline expectations from any successful APM usage."
instana,"However, nowadays, the containerized world is forcing people to see the whole picture regarding the control and visibility of the infrastructure."
instana,"This is a new requirement, and it implies new capabilities from APMs, such as monitoring the following:
Kubernetes Integration & Cluster status
Deployment and Manifest Details
Analytics and Tracing
Pipeline Feedbacks from APM
Kubernetes Perspective of Instana

Kubernetes Cluster Overview
With Instana, you can see all the details of your kubernetes clusters ."
instana,"This ability is critical for identifying root causes, fitting the best practices, seeing what‚Äôs left on VMs / Bare Metal in terms of CPU and Memory reservation."
instana,The following items are the most useful things you can glean from Instana regarding kubernetes.
instana,"Total Memory/CPU Limits & Requests
Total Pod Number and Allocation and their distribution to namespaces and nodes
Kubernetes Components Status (Etcd, controller manager, scheduler, etc.)"
instana,"Cluster Events
Nodes Healths

Bottom-Up Pod Trace in Kubernetes Cluster
As you can see on the screenshot above, you can easily trace from a pod to the node with a bottom-up approach with showing pod dependencies like:
The node and the namespace that the pod belongs to
Services that are created with tracked pod

Detailed Deployment Manifests on Instana
Instana provides a complete deployment manifest on the Kubernetes cluster, and this enables you to check the current status of the deployment and its configuration."
instana,You don‚Äôt need to connect your kubernetes cluster and run some kubectl command!
instana,"MicroService Communication / Dependency on each other

Service Dependency on Specific Application Perspective
Before getting into the details on service dependency, I should mention the application perspective that enables people to focus only on what they want to see on any APM dashboard."
instana,"With the Application perspective, you can group your services to specific subsets according to the namespaces, HTTP status call response, container labels, JVM versions, runtime and many more items!"
instana,"Let‚Äôs say you have created a view within a logical group for your services, and you want to see the dependencies between them on your coherent subset (Application Perspective)."
instana,"With Instana‚Äôs dependency graph, you can hover/underline and double size your services according to some predefined capabilities which are :
Max Latency
Max Erroneous Call Rate
Incoming Calls
For better understanding and, you can play with the view according to the Upstream/ Downstream calls to/from your services."
instana,"Analytics and Tracing
First of all, we need to identify two terms calls and traces :
A call models conversation between two services."
instana,"It is constructed of descriptive caller and callee information containing endpoints, type-specific payloads, parameters, exceptions, and specifics."
instana,"&
A trace is the snapshot of one request and its journey through a service structure."
instana,"This might be the direct consequence of a request initiated by the client of a consumer, which might also be triggered by a planned job or some other internal execution."
instana,A specific trace may consist of several calls.
instana,"Trace Analytics on Instana
For the traces on Instana, you can filter your calls by :
Application and Service Name
Specific Endpoint
Service Type (HTTP, database, messaging, etc.)"
instana,"Technology (Java,NodeJS,.net etc.)"
instana,"Latency Spectrum
Erroneous or not

Call Analytics and related stack traces on Instana
In the call analytics screen on Instana, you will see the details about stack trace and any exceptions of the calls being traced."
instana,"Moreover, time spent on services or databases related to the request, callee details regarding service/pod/application and its position on your infrastructure, etc."
instana,These items provided by Instana analytics make developer‚Äô s/SRE‚Äôs life easier on Root Cause Analysis.
instana,"Instana AutoProfiling in Java
Profiles are essential for discovering execution problem areas and bottlenecks at the code level."
instana,It‚Äôs the first step in gaining better performance with less compute resource usage.
instana,"AutoProfile‚Ñ¢, a feature of Instana, continuously checks available profiles to report to Instana, unlike other APMs where a client should physically start profiling."
instana,AutoProfile‚Ñ¢ consequently plans and persistently performs profiling of your crucial environments for providing better RCA (Root Cause Analysis).
instana,"And now AutoProfile‚Ñ¢ is currently on beta for Java and here is the way that you can enable this feature :
During the technical beta phase, the profiling feature is disabled by default."
instana,"To enable profiling, edit the agent configuration file
<agent_install_dir>/etc/instana/configuration.yaml
com.instana.plugin.profiling.java:
enabled: true
As you can see below, you can see all the methods with their wait time within an auto-generated profile."
instana,"Furthermore, if you click any of the methods, you will see the actual code with its line numbers on a new window."
instana,"Thanks to that, identifying places that causes latency in the code will be as easy as pie!"
instana,"Java Wait Time Tree View for Specific Profile
Besides the wait times on Instana, you will see a Flame Graph regarding the CPU usage and hot spots separated at the method level!"
instana,"Java CPU Flame Graph for Specific Profile
Instana Pipeline Feedback with Jenkins
Visibility of an application‚Äôs dependency on the infrastructure it‚Äôs running on is a crucial aspect that should be considered."
instana,Instana integrates with CI/CD pipelines and let‚Äôs talk about what the prerequisites are and how to do it in Jenkins or any CI / CD tool that you have.
instana,"First thing first, you need to install the Instana plugin before starting the work."
instana,"Once you downloaded it, you need to create a token from settings on Instana UI within proper privileges (Configuration of Releases)."
instana,"Required Permission for Instana Token
Once you created a token, you need to go Jenkins->Configure Jenkins and do your proper configurations for Instana

Instana Configuration on Jenkins
As a final step, you just need to make a call to Instana after your successful deployments."
instana,Here is an example of a partial Jenkinsfile that is calling the releaseMarker plugin.
instana,Release marker creates a deployment marker on all the dashboards on Instana that we are going to monitor our performance improvements and the increase in error rates.
instana,"In other words, it shows the effects of the deployment on our application performance and infrastructure stability."
instana,"Partial Jenkinsfile as an Example
The thing is, you don‚Äôt have to use Jenkins in your CI/CD pipeline at all!"
instana,What you need is a POST request to Instana API.
instana,"Basic Curl command for Using Release Marker
Final Thoughts and Closing Notes
Based on my consulting experience on cloud and DevOps, I realized that application containerization/modernization is the new direction for technology departments, and every team has to keep up with that for every aspect."
instana,"For example, if you are evolving from a monolith to a microservice architecture or from VMs to containers, you have to be ready for new changes ahead."
instana,"Every component in your infrastructure should be designed for the new era, and I believe Instana is one of the products in the IT sector that is ready for the now and the future!"
instana,"Kloia partners with Instana for APM
After Kloians discovered Instana in their early stage during 2017, they played with it, piloted it, challenged it and after decided to be a partner with."
instana,This was purely a kloian-driven process.
instana,"Although we usually used to work with various APM alternatives, Instana has advantages especially if you have workload on Kubernetes and/or Microservices or if you have transition plans towards those‚Ä¶ This is reflected in the tool by its features like:
Automated Discovery
Distributed Tracing
Automated Monitoring powered by Machine Learning
Kubernetes-native Monitoring
Besides,
It also works on-premises!"
instana,No application restart required!
instana,"(For some certain type of software stack)

Instana is enriched with its sensors which can automatically detect and begin to collect metrics, including:
Docker, Kubernetes, Rancher, OpenShift
Websphere, Weblogic, Varnish, Zookeeper
Spark, Solar, Hana, Redis, Neo4j, MongoDB, Cassandra, Kafta, ElasticSearch
PostgreSQL, Microsoft SQL, Oracle, MariaDB
AWS, GCP
Go, .NET, Java, Python, Haskell, Node.js, PHP
and many more‚Ä¶
We are constantly looking for new practices, approaches and tools for our Application Modernization and Microservices Transition projects."
instana,Instana fits well in that perspective with its Kubernetes-native support and Microservices-friendly features.
instana,Here is a short introduction for Instana to get a fast initial feeling: https://www.kloia.com/instana
instana,"Below I‚Äôve listed the slides I presented on the first day of a distributed tracing workshop organized by Naver Corp. and held in Seoul, South Korea."
instana,"At the very beginning of the talk, I made a point to state that the scaling of distributed tracing needed to be both up (more/high) and down (less/low), and importantly reflecting the capacities of the consumers ‚Äî man or machine."
instana,"After introducing my experience and research as well as Instana, the application performance monitoring vendor I‚Äôm employed by, I listed some areas of interest driving my current engineering design and development."
instana,The first part of the talk focuses on the high-level architectural issues.
instana,I started the talk with an opinion that there were two directions for the future of observability.
instana,One focused on creating far more effective monitoring and management models tailored to human capabilities and capacities.
instana,The other on detailed capture and reconstruction of execution.
instana,"I then introduced my version of the three pillars of observability as opposed to metrics, tracing, and logging ‚Äî as promoted by conf speakers these days."
instana,"Measurement encompasses the instrumentation, observation, and capturing of some software phenomenon ‚Äî it is mainly independent of the model."
instana,"Model includes metrics, tracing, and logging."
instana,"Each model has pros and cons, depending on the context and causation ‚Äî operational vs. diagnostics."
instana,"Looking forward, we need to develop newer models that are far more effective at monitoring and managing microservices and reflect many other changes in platforms, runtimes, and libraries as well communication and coordination."
instana,"Memory is concerned with the recording, retrieval, recollection, and reconstruction of changes that occurred to and are represented by the model."
instana,Scaling up one of the pillars causes a rise in cost and reduction in capability.
instana,More measurement leads to higher overhead costs and reduced accuracy.
instana,Bigger models result in greater transport costs and impaired attention.
instana,Larger memory capacities increase storage and decrease significance signaling.
instana,There are many aspects in scaling observability technology ‚Äî it is not just more (or less).
instana,Is the technology able to record both short and long-running phenomenon?
instana,At what level of depth or coverage is the technology targeting?
instana,How big or small is the model?
instana,How much of the processing by the technology is performed locally as opposed to remotely?
instana,Is the data tailored more for a machine than man?
instana,Is it focused on signals over data?
instana,Today scaling observability is far more challenging than it needs to be.
instana,There is far too much emphasis placed on collecting more and more (big) data than hooking up observations to (re)actions via embedded adaptive controllers.
instana,Effective management of any system involves directing attention and action.
instana,To scale up to larger systems requires scaling down.
instana,There is a lot of confusion surrounding monitoring and observability.
instana,The way I see it monitoring is as a strategic process that directs observability.
instana,This is far more apparent when observability is dynamic and adaptive ‚Äî essential in the scaling of a process to changes in workload and context.
instana,"Controllability, which is focused on steering software behaviors, helps define the policies employed by the Monitoring process and is governed by the Management process."
instana,All communication lines transfer both data and directives between each other.
instana,Each process is self-regulated to a degree in fulfilling promises.
instana,Most of what we observe is insignificant.
instana,Monitoring is the process that adds significance to just a tiny slice of the data that is collected by observability.
instana,To scale an observability technology requires a reduction in transmission and post-processing costs where there is no novelty.
instana,Monitoring is fundamentally about the discovery and observation of objects of concern.
instana,"From a series of signals, an observer infers the present state and predicts possible future states were there is a model and a memory of such."
instana,Much of today‚Äôs observability tooling is designed with simple (big) data collection in mind.
instana,Processing of the model and storage is done in the cloud.
instana,"Such monitoring offerings operate as a semi-structured backend storage system ‚Äî effectively a big data dustbin that can be indexed, searched, and presented in charts."
instana,The main objective of both application monitoring and management is all but lost in data and chart junk.
instana,And it does not scale.
instana,"In scaling observability, there needs to be a shift in the locality of computation and storage‚Äî from cloud to edge."
instana,"Measurement, model, and memory need to be regulated by self-adaptive agents (in the general sense) and at different degrees of scoping and time scales."
instana,"Scaling comes from the smart collective

It is paramount to intelligently and adaptively reduce the size of data, the cost of collection, as well as the time scales and localities involved if we are to scale an observability pipeline."
instana,All that is instrumented need not be measured.
instana,All that is measured need not be collected.
instana,All that is collected need not be transmitted.
instana,All transmissions need not be stored.
instana,Less is more.
instana,"Let‚Äôs now be more specific about the scaling concerns with tracing with an example of a service graph where a calls b and c, and c calls d and e.

Alongside the connections and flows between instrumented services we have connections and flows to a trace agent or server where data is stored."
instana,"The previous topology presents some glaring problems in scaling, but these can be mitigated somewhat by having each service have a separate datastore."
instana,Datastores can then connect when there is linked trace data.
instana,This linking does require the transfer of information about the locations of such datastores.
instana,The federated approach does still have some issues in that it is not possible post-completion of a trace to discard all data if it is deemed insignificant.
instana,Why not instead let each called service decide whether to propagate its collected trace data back up through the caller chain and have datastores at roots only?
instana,A benefit of this approach is that services in other domains can be traced.
instana,Zooming down to the ground level ‚Äî the measurement of distributed traces.
instana,There are two points in the current and most common distributed trace lifecycle implementation where it is possible to decide whether to measure and then whether to collect and transmit the data to a tracing service ‚Äî at the point of creation of the root in a trace or following completion of a trace.
instana,"Sampling is the more common technique in limiting the amount of trace data collected, transmitted, and stored."
instana,Most tracing client libraries offer random.
instana,Random in that 1 in every N is selected for tracing.
instana,The scope can be global to the process or specific to a particular name or some other labeling.
instana,Windowing is more useful than random when there is a need to compare one measurement with another within a particular time frame.
instana,Conditional is windowing that is dynamically activated and deactivated based on some varying aspect within the environment of execution.
instana,It is also possible to combine all sampling techniques in order to collect a minimal amount of trace data in all periods and then vary the degree of collection based on fixed windows and environmental conditions.
instana,Rate limiting can be used to ensure that a fixed amount of requests are traced.
instana,"Sampling or other forms of trace reduction create problems to monitoring such as how to make observers, both human and machine, aware of the incompleteness of the data and inform them to what degree within a window."
instana,The other intervention point in the lifecycle is after completion of a request.
instana,"A client side library can choose which data should be transmitted and stored based on some property of the request or trace, such as wall clock timing."
instana,Many libraries and locally deployed agents buffer up the collected trace data before it is transmitted further on down the pipeline to the storage backend.
instana,Before sending the library or agent can employ other forms of data reduction.
instana,Buffers can support the dropping of new trace data when the process that drains the buffer and pushes the data onwards is not able to keep up with an arrival rate.
instana,Dropping can be more selective when there is a threshold set.
instana,"Before forwarding the buffered data, some of the trace data can be discarded."
instana,"If it is paramount that all trace data be transmitted, then producers, typically the application threads, can be delayed."
instana,This impact would need to be noted.
instana,Another option available both at the tracing source and storage backend is the degradation of the trace memory.
instana,This is already employed in storing metrics.
instana,"Dropping down to ground zero‚Ä¶

Some costs aspects of a trace are fixed such, as the requirement to collect the time twice."
instana,"Others such as adding tags, transmitting items along with a trace context, adding logging (a map object), and capturing stacks are optional."
instana,Note: The chart below was used just to order the items.
instana,Stacks go off the charts!
instana,"As the leader in monitoring cloud-native, Kubernetes (K8s) based applications, Instana has long made sense out of the complexities that K8s based applications entail."
instana,"Instana‚Äôs Automatic Kubernetes Monitoring continuously monitors K8s based applications at scale by automatically discovering all clusters, pods, containers, and services deployed by K8s and deploying the appropriate, technology specific sensors required to monitor the entire environment."
instana,"With Instana, K8s services are automatically correlated to application services so you always know the impact of the K8s platform on the performance of your applications."
instana,"Since launching the first version of K8s monitoring, Instana has continuously broadened its ‚Äòout-of-the-box‚Äô support for K8s clusters across multiple vendors and distributions."
instana,Instana‚Äôs Automatic Application Performance Monitoring (APM) platform monitors the health of K8s as well as the performance of the cloud-native applications that run on them.
instana,"Instana currently supports bare metal Kubernetes, Amazon EKS, Red Hat OpenShift, Google GKE, Azure AKS, Oracle OKE, and more."
instana,"Regardless of which K8s version you are running, Instana makes it incredibly easy to deploy the Instana Agent into your environment."
instana,"The Instana agent can be installed in numerous ways including; via a YAML file, through Helm Chart, directly from public cloud providers like Google GKE, and recently announced, via the Instana‚Äôs Red Hat OpenShift Kubernetes Operator."
instana,"No matter which installation method you choose, only a single, lightweight agent is required per host."
instana,"Instana extends K8s coverage with Giant Swarm integration
With all of the previously mentioned versions of K8s, the user administers and controls the clusters themselves."
instana,"As more business critical enterprise production applications move to K8s, organizations realize that the daily operational challenges of managing applications, the underlying infrastructure, and performance of cloud-native environments can be overwhelmingly complex."
instana,"This is where Giant Swarm, a K8s Managed Service Provider (MSP), comes into play."
instana,Giant Swarm is focused on helping organizations manage their K8s performance at scale.
instana,Users leave the day-to-day administration and maintenance of their clusters in the capable hands of Giant Swarm.
instana,Instana has expanded its K8s monitoring reach with a first of its kind integration with Giant Swarm‚Äôs K8s managed service.
instana,"Together, Giant Swarm and Instana remove the ‚Äòchaos‚Äô of managing K8s based applications and environments, enabling users to focus on what they do best, building great software."
instana,"Giant Swarm proactively manages the K8s infrastructure, alleviating many of the operational challenges for their user base, while Instana provides the application level insights that developers need to prioritize application optimization opportunities."
instana,"Additionally with Instana, developers are able to hone in on the applications and services that they are responsible for with Application Perspectives."
instana,"With Giant Swarm handling the operational duties, the development team can leverage Instana‚Äôs Application Perspectives to fully understand the state and performance of the applications and services they are responsible for."
instana,"Users of Giant Swarm and Instana can install the integration directly from Giant Swarm‚Äôs application catalogue and, with just a few clicks, get the application level insights required to tame cloud-native K8s based applications."
instana,"To learn more about the Giant Swarm, Instana integration register for the joint webinar on June 12th where K8s experts from Giant Swarm and Instana will discuss:
Practical strategies for managing and monitoring Kubernetes environments
Reducing the cost, complexity, and lack of visibility into Cloud-Native architectures
Empowering teams to focus on what they do best."
instana,Delivering high-quality software!
instana,The digital enterprise collects nearly nine million euros from investors.
instana,The head office is now moving to the main market and the product development remains in Cologne.
instana,"The travel fund is lavishly filled
With a recently completed financing round, the Cologne based software startup ArangoDB wants to venture a larger step into the USA."
instana,"The company, founded in 2014, received venture capital of just under nine million euros."
instana,New to this is the US tech investor Bow Capital.
instana,Target Partners once again invests in ArangoDB.
instana,And the company joined the software specialists in 2017.
instana,The startup sells database software designed to make it easier for software developers to work.
instana,With more and more companies turning more and more to digital services or apps.
instana,Their IT departments are increasingly looking for help in the development process.
instana,"ArangoDB names corporations such as Airbus, Thomson Reuters and Barclays as reference customers."
instana,German startups like Instana from Solingen are also benefiting from similar developments.
instana,"According to the company, ArangoDB already makes more than 50 percent of its sales in the USA."
instana,"The business is also growing fastest there, according to a press release."
instana,The official headquarters is therefore relocated to San Francisco.
instana,"On the west coast larger teams in the areas of marketing, customer service and personnel are to be set up."
instana,"Networks form in Silicon Valley
The startup hopes to gain several advantages from the increased presence in Silicon Valley."
instana,"The existing customers, including numerous large US companies today it should feel better looked after."
instana,"In addition, it is easier to get to tech savvy employees."
instana,"In addition, one hopes for a network effect as part of the Silicon Valley ecosystem."
instana,The team of six employees in the US is expected to double by the end of the year.
instana,They are also being strengthened by the relocation of German startup staff in order to build expertise in new teams and to facilitate the transfer of the corporate culture.
instana,"Nevertheless, the old hometown of Cologne continues to play a major role."
instana,"With more than 40 employees, the central product and software development should take place from here."
instana,A similar step was taken some time ago by drone defense startup Dedrone.
instana,"Its headquarters have also been relocated to the USA, the engineers work from the old location Kassel."
instana,"Booking @ Amsterdam
At the end of April 2018, I visited Amsterdam for a good reason."
instana,"Visiting the good places that I couldn‚Äôt
visited 3 years ago, and after filling that power, I just made a talk about Microservice Best Practices
on Kubernetes."
instana,"The event is handled by Booking, and I was very happy with their hospitality."
instana,Thank you again !
instana,Let me provide brief summary of each topic I have mentioned on the event.
instana,"You can see my slides here, if you are not so much patient :)
1."
instana,"Glory of REST
Microservices are like humans, and they need to communicate with each other by using well structured interfaces."
instana,"Richardson‚Äôs Maturity Model is a good reference to this
2."
instana,"Power of HATEOAS
Hypermedia As The Engine Of Application State provides navigate-able resources that you will find all the informations within the response."
instana,Forget about trying to generate some links on different kind of client applications to navigate next resources by using previous one.
instana,3.
instana,"Distributed Configuration
When you switched to the Microservice Architecture, you will need to configure multiple services at the same time, that configs must be applied to applications in real-time, etc‚Ä¶ Distributed configuration can be handled with Consul as key/value pair, git2consul for synchronizing configurations to Consul, and you may need to keep those configurations on a simple git project."
instana,4.
instana,"Client Code Generation
In order to communicate microservices, you may have 2 options at least to make inter service communications."
instana,"If you are already using service discovery, you can think about Feign Client."
instana,"Or else, you can use swagger-codegen to generate client library whenever you deploy your app to any kind of environment."
instana,"Do not think about writing client libraries manually for your hundreds of microservices, just trigger a Jenkins job and take a REST!"
instana,5.
instana,"Kubernetes Warm-up
You can create a k8s folder to keep your k8s resource definitions to use on deployment pipeline."
instana,"A typical micro service may have deployment, service definition at least for deployment and exposing your application to the outside or at least to the load balancer
6."
instana,"CI/CD
If you have kubernetes specifications within your project, you are ready to deploy your app by using Jenkins with a simple kubectl configuration
within jenkins servers."
instana,"In order to reduce complexity, you can use multi stage builds to build docker image to use in your k8s deployment."
instana,7.
instana,"Monitoring
Even you are in a stable environment like k8s, you need to track your infrastructure and application insights."
instana,"To collect metrics, you can use
Prometheus, and to serve them in a good dashboard, you can use Grafana."
instana,"CoreOS team developed a good project that is called prometheus operator
comes with a built-in kubernetes configurations."
instana,One click monitoring !
instana,8.
instana,"Logging
There are several types of logging architecture on kubernetes and I mainly focused on cluster level logging with daemon set agents."
instana,"You can send your logs to logging backend like Elasticsearch to show on Kibana dashboard, or if you don‚Äôt want to maintain ELK stack, you can use
logz.io which is a hosted Kibana as a service."
instana,"Just create a daemonset to ship your logs to logz.io
9.APM & Service Mesh
Monitoring and Logging may not help you all the time, you may need to see deeper insights about your application."
instana,"When it comes to
Microservice and Container world, Instana is a good choice to handle Tracings, Monitoring with a simple sensor integration."
instana,"You can create your
infrastructure map, see traces and spans for a request lifecycle, even you can see real time service requests on simple dashboard."
instana,10.
instana,"API Gateway
If you are planning to expose your services to the public, you definitely manage your APIs with an API Gateway to perform Authentication,
Authorization, Rate Limiting, API Versioning, etc‚Ä¶ I have used Tyk API Gateway to set this up in Kubernetes to route traffic to microservices
after successfully validated by API Gateway."
instana,11.
instana,"Event Sourcing & CQRS
In a synchronous world, you can only change 1 object in 1 transaction at a time."
instana,"When you switch to distributed systems, you need to
use 2-phase commits in an extended architecture."
instana,"Again, with this strategy, whenever you made an update to current state of an object, all
the previous states will be gone."
instana,"You can use Event Sourcing with asynchronous events stored in an event store like Apache Kafka, Hazelcast, etc‚Ä¶
Also, you can separate read (query) and write (command) in order to handle events asynchronously and populate desired views on database to serve it
via query later."
instana,Hope above sections would be a good reference for your next Microservice Architecture design.
jaeger,"Last time, we used Prometheus Alert Manager to configure rules that would send notifications via Slack when triggered."
jaeger,"Even though having alerts and notifications it‚Äôs great, can metrics help you troubleshoot or explain a problem by themselves?."
jaeger,"This is where the problem arises; metrics are good to tell you that something happened with a single instance, according to the boundaries you defined for their values, but as soon as you start working with a distributed system, metrics won‚Äôt tell you the story of a request that goes through multiple components."
jaeger,"With the microservices boom, systems are becoming more complex, and to understand pathological behavior we need to understand the requests end to end."
jaeger,This is where distributed tracing helps you; it captures the activities performed in a request giving you the context missing in metrics and logs.
jaeger,"In this post, we will extend our application observability capabilities by generating spans and export them into an open-source distributed system named Jaeger."
jaeger,"But first, let‚Äôs start by defining what a trace is."
jaeger,"You will find all the resources in this repository: https://github.com/jonathanbc92/observability-quickstart/tree/master/part3
Tracing
A trace is a collection of spans, where each span is a record of an operation performed by a single service; they have a name, start time, duration, context, and additional metadata to bring additional information."
jaeger,Traces allows you to observe the journey of a request as it goes through all the services of a distributed system.
jaeger,"With the analysis of trace data, you can see the behavior of a request, identify issues, bottlenecks, and potential areas for improvement and optimizations."
jaeger,"To generate spans, you rely on instrumentation, using an API or SDK provided by a tracer client library."
jaeger,"Instrumentation
You can manually instrument your application by coding the start and finish of spans in pieces of code that provide meaningful information to you."
jaeger,"As an alternative, some frameworks offer automatic instrumentation, which saves time and reduces effort by avoiding the need to modify your codebase."
jaeger,"Manual and automatic instrumentation are not exclusive; in fact, you might end up combining both; automatic instrumentation to leverage the advantage of using less or no code and manual instrumentation where you need more control within a service."
jaeger,"There are many tracing solutions out there that include their own client libraries to perform instrumentation in many different languages, some of them are:
Jaeger: Developed by Uber and now a CNCF graduated project."
jaeger,Zipkin: Initially developed by Twitter based on Google Daper paper.
jaeger,AWS X-Ray: AWS Distributed Tracing System.
jaeger,Google Cloud Trace: Distributed Tracing System for Google Cloud (Formerly Stackdriver Trace).
jaeger,Azure Application Insights: Feature of Azure Monitor.
jaeger,"If you want to go for a more agnostic option, you have OpenTelemetry, which provides manual and auto instrumentation SDK."
jaeger,"It has exporters for Jaeger and Zipkin, and many vendors are working to support it on their platforms."
jaeger,"Jaeger
Jaeger is an open-source distributed tracing system initially developed by Uber."
jaeger,It is used for monitoring and troubleshooting microservices-based distributed systems.
jaeger,"Jaeger architecture has the following components:
Jaeger Client: Implementation of OpenTracing API used to instrument applications."
jaeger,Jaeger Agent: Network daemon that listens for spans sent over UDP.
jaeger,Jaeger Collector: Receives the traces from the agents and runs them through a processing pipeline.
jaeger,Storage: Component on which the traces are stored.
jaeger,Jaeger Query: Service that retrieves traces from the storage and presents them on the UI.
jaeger,"Deploying Jaeger
There are many strategies to deploy Jaeger in Kubernetes:
All in One: All Jaeger components are deployed in a single pod that uses in-memory storage."
jaeger,Production: The components are deployed separately.
jaeger,"The collector and query are configured to work with Cassandra or Elasticsearch, being Elasticsearch recommended over Cassandra."
jaeger,"Streaming: Replicates the production strategy, but it also includes the streaming capabilities of Kafka; it sits between the collector and storage to reduce the pressure on the storage under high load situations."
jaeger,"For the sake of simplicity, we will use the all-in-one deployment strategy, using Helm with the Operator, although take into consideration that this is for testing purposes only."
jaeger,"If you are in a production deployment, it is highly recommended to deploy with any of the remaining strategies."
jaeger,"To deploy, we add the helm repository and install Jaeger custom resources with the operator."
jaeger,"helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm repo update
helm install jaeger jaegertracing/jaeger-operator -n observability
Then, create the Jaeger custom resource with kubectl apply -f

On previous posts we used kubectl port forward command to expose the UIs."
jaeger,"From now on, as a persistent alternative, we will create a NodePort service."
jaeger,"If you are using minikube, to get your node IP run minikube ip

Jaeger UI on port 30007
We are ready to start instrumenting our NodeJS services, but we need to do some OpenTelemetry preparation first."
jaeger,"Configuring OpenTelemetry
Fortunately, configuring OpenTelemetry is a straightforward task."
jaeger,"First, you need to choose which instrumentation you are going to use and instantiate it."
jaeger,For manual instrumentation: use Tracing SDK.
jaeger,For automatic instrumentation: use Node SDK.
jaeger,"Automatic instrumentation includes OpenTelemetry API, so we also have the ability to generate custom spans anytime."
jaeger,"Then, we need to define where we are going to send our spans."
jaeger,"We will export the spans to Jaeger, but there are many additional exporters available that you can use."
jaeger,"Each exporter has its own configuration; Jaeger Exporter, by default, sends the spans to localhost:6832 which is the jaeger agent URL."
jaeger,"In a production deployment, this is expected because you deploy the Jaeger agent alongside your services, but in this case, we will use the agent that is already included within the jaeger pod."
jaeger,"When we are done configuring the exporter, we need to add it to a span processor and initialize the provider with register()."
jaeger,"To automate the instrumentation, you need to register the right modules; for example, if you want to instrument HTTP calls, there‚Äôs an http module; if you want to instrument the MySQL calls, there‚Äôs a mysql module, and many more."
jaeger,"This time we will be instrumenting HTTP requests, Express Framework, and MySQL library automatically."
jaeger,"Lastly, your export the tracer to be used in your service."
jaeger,"If you noticed, we have configured HttpInstrumention to ignore any requests to the /metrics endpoint."
jaeger,"Don't forget that Prometheus pulls the metrics from it; by ignoring it, we avoid having unwanted traces from Prometheus."
jaeger,"Now, go ahead and test the services:
kubectl port-forward service/hello-service-svc -n applications 8080
curl http://localhost:8080/sayHello/iroh #On a different terminal
Hey!"
jaeger,"this is iroh, here is my message to you:  It is important to draw wisdom from many different places
Back in Jaeger UI, you should see that the services are available in the Service dropdown."
jaeger,Select hello-service and click on Find Traces.
jaeger,"Jaeger Seach Form
If you can‚Äôt see the services, double check OpenTelemetry configuration, it should point to Jaeger agent service using UDP port."
jaeger,"We should see three span colors, one per service."
jaeger,"There will be at least two kinds of spans on each of the services, GET spans representing the requests instrumented by the HTTP instrumentation, and Middleware and Route spans instrumented by Express instrumentation."
jaeger,Some of the middleware spans are from the middleware functions we created to gather values for the metrics on part1 of this series.
jaeger,"If we click on any of the spans, we should see some attributes that give us more context about that Span."
jaeger,"Jaeger‚Äôs HTTP span
Don't forget that we also instrumented MySQL."
jaeger,Notice that it includes very useful attributes like the database statement and user.
jaeger,"Jaeger‚Äôs MySQL span
So far, we have a lot of information available."
jaeger,But what if we want more fine-grained control of what happens in our service?
jaeger,How do we combine automatic and manual tracing?
jaeger,"Context Propagation
Before creating our custom spans, we need to answer first: How do you correlate the spans?."
jaeger,"For the spans to be correlated, they should share some information; that information is shared through the context."
jaeger,The context contains information that can be passed between functions within the same process (in-process propagation) and between different processes (inter-process propagation).
jaeger,"Then, propagation is the mechanism by which a context is moved across different services or processes."
jaeger,"By now, you already saw both."
jaeger,Did you wonder how the spans from the three services belong to the same trace?
jaeger,Or how the spans from different functions in the same service can be related as parent and child?.
jaeger,The answer: context propagation.
jaeger,"There are many protocols for context propagation; the most common are:
W3C Trace-Context HTTP Propagator
B3 Zipkin Propagator
OpenTelemetry can use both, but in some cases, you may be forced to use one specifically."
jaeger,"For example, to propagate context in Istio, you are required to use the B3 Headers."
jaeger,"Manual Instrumentation
To create your first span, you need to import the tracer from the file where we configured OpenTelemetry and call startSpanmethod."
jaeger,"The span needs a name, and optionally you can include custom attributes and the context."
jaeger,"In this case, we are retrieving the current context with context.active() ; if there is an active context, the span will be created within that context."
jaeger,"After you start a span, you do some stuff with your code, and then you must end the span."
jaeger,"To propagate the context between different functions, either to add attributes to the span or create a child span, you need to wrap up the calls in context.with but also set the desired span in the current context with setSpan."
jaeger,"In the code below, we create a Router GET span, and then we set it as the current span before calling the getPerson function."
jaeger,"As a result, the getPerson span will be created as a child of Router GET span."
jaeger,"If we do some tests, the result will be:

This time, we have HTTP, MySQL, and Express Framework spans automatically generated, and custom spans manually generated from the functions in our code using OpenTelemetry."
jaeger,"Conclusion
Distributed tracing may sound scary initially, but everything will make sense as soon as you get started."
jaeger,"Also, the OpenTelemetry community it‚Äôs making things even easier for us, and it's improving very fast."
jaeger,You just saw how easy it is to combine automatic and manual instrumentation to get the best of your services tracing data.
jaeger,Happy Tracing üîé!
jaeger,when embarking on a journey to build cloud native applications and/or decomposing a monolithic application into microservices one of the issues you will encounter at one point in time is the issue of getting a good insight in what the system is actually doing.
jaeger,"The benefit of monolithic applications is that logging and monitoring can be done in one place, or at least a limited number of places."
jaeger,"Building a distributed solution, holding multiple services in a multitude of containers who are distributed over multiple cloud regions provide the issue that a single user interaction will trigger actions on multiple environments."
jaeger,"When invoking an action on a monolithic application all logging will be on that specific server, doing the same the logging showcasing the entire chain of events will be distributed over all kinds of different systems (containers / serverless functions / virtual machines)."
jaeger,To help you tackle this issue Jaeger provides a part of this solution.
jaeger,"Jaeger, an open source, end-to-end distributed tracing solution to Monitor and troubleshoot transactions in complex distributed systems."
jaeger,"As on-the-ground microservice practitioners are quickly realizing, the majority of operational problems that arise when moving to a distributed architecture are ultimately grounded in two areas: networking and observability."
jaeger,It is simply an orders of magnitude larger problem to network and debug a set of intertwined distributed services versus a single monolithic application.
jaeger,"High Available Jaeger collectors in Oracle Cloud
In a recent blogpost I outlined how to build an (extreme) high available deployment of Jaeger collectors in Oracle Cloud to optimally benefit from the way Oracle Cloud is high available by nature."
jaeger,"High Available Jaeger Deployment in Oracle Cloud
The post outlines that for extreme high available deployment a number of nine nodes could provide the right number of Jaeger collector nodes to make sure you optimally benefit from the advantages of Oracle High Availability Cloud infrastructure."
jaeger,For details on the reasoning please refer to the previous blogpost on this subject.
jaeger,"Configure the Jaeger Agent
To ensure that each individual Jaeger Agent (deployed on an application node) is able to work with the available Jaeger collector nodes you will have to make sure your agent configuration supports this."
jaeger,"Jaeger Agent gRPC connections
The Jaeger agents connect via gRPC to the collector node."
jaeger,Part of the instructions given to the Jaeger agent is the address of the Jaeger collector or Jaeger collectors.
jaeger,"The basic CLI command to connect instruct the Jaeger Agent to connect to the Jaeger collector over gRPC is shown below;
./jaeger-agent ‚Äî reporter.grpc.host-port 10.10.1.217:14250
As we do require a high available deployment we will have to provide the Jaeger agent with multiple Jaeger collector addresses which can be done with a CLI command as shown below."
jaeger,In the below example we will provide two different Collector endpoints to be used for gRPC communication.
jaeger,"./jaeger-agent ‚Äî reporter.grpc.host-port 10.10.1.217:14250, 10.10.1.207:14250
Even though the above works without fail in a real production environment you will most likely want to start the agent as a daemon using Linux systemd."
jaeger,"It is an option to pass all the address:port combinations directly as part of the systemd config, however, this is not a best practice."
jaeger,A better way is to ensure you store the Jaeger collector endpoints and all other Jaeger configuration in a configuration file and refer to this file when starting the Jaeger Agent.
jaeger,"Starting the Jaeger agent with a configuration file can be done using the command shown below;
./jaeger-agent ‚Äî config-file=agent.yaml
The most basic YAML configuration could look like the one shown below."
jaeger,For a high available you will have to define multiple Jaeger collectors obviously.
jaeger,"reporter:
type: grpc
grpc:
host-port: 10.10.1.217:14250
(do note that medium is not really good in showing the correct level of indentation for YAML files)
Enterprise Architecture standard of distributed tracing
When developing a serious enterprise architecture with the goal to support DevOps teams with the right level of guidance to develop distributed solutions in a meaningful and unified way the topic of observability needs to be addressed."
jaeger,Leaving the topic to the different application responsible teams will ensure that the end result is a multitude of different solutions and will prevent you from building an enterprise wide observability capability.
jaeger,Not having this enterprise wide observability capability will prevent you from getting the overall view into your landscape.
jaeger,To prevent this issue it will be needed that an enterprise wide standard is created and is being provided to the different teams to adopt into their services.
jaeger,The enterprise wide standard should consist out of guidance and examples as well as a number of predefined building blocks and central services.
jaeger,When done right components like the ‚ÄúJaeger collector‚Äù are pre-build components that can be deployed by an application team and who are centrally developed and maintained.
jaeger,Components like the Kafka bus and the ‚ÄúJaeger Ingester‚Äù should be services that are available and running within the enterprise landscape.
jaeger,"By having the standards, the guidance, the examples and building blocks and available services available to all the DevOps teams will make the inclusion of an enterprise wide standard for distributed tracing more efficient."
jaeger,This story is just an additional snippet on using Jaeger for Distributed tracing.
jaeger,"GCP in particular already have stackdriver which is awesome in my opinion and I may have a single pane of glass for all of my services through monitoring, metric dashboard and alerting, uptimecheck and one of the things to be discussed is tracing."
jaeger,"Operations: Cloud Monitoring & Logging | Google Cloud
Monitor, troubleshoot, and improve application performance on your Google Cloud environment."
jaeger,"Key features Real-time log‚Ä¶
cloud.google.com

As I talk with several people, there are some preference that they want to explore the open source (eg."
jaeger,prometheus-grafana-kiali-jaeger) so this short story is about using jaeger to see tracing from istio metrics.
jaeger,Notes: this story is about the concept not a guide for any production env.
jaeger,"Please follow the official documentation from each of the products for real environment
For a quick installation we can go to the documentation from Istio-Jaeger (at this point of time the latest istio is on 1.8 so I am using that documentation)."
jaeger,"Jaeger
After completing this task, you understand how to have your application participate in tracing with Jaeger, regardless‚Ä¶
istio.io

What need to do: (super simple)
Install jaeger
Open dashboard to see the tracing
Now for this particular test I add one more part on the environment so that the traffic will have a north-south from istio-ingress-gateway and also an east-west to another services calling from the existing pod."
jaeger,"[Client] ‚Üê ‚Üí [Istio Ingress Gw] ‚Üê ‚Üí [Hello-go3] ‚Üê ‚Üí [hello-go]

I add another http get (sorry just a quick add not a proper one so there is this static url) from hello-go3 to hello-go instance in hello-1 namespace which will be my new image for the hello-go3."
jaeger,"Adding the VirtualService for the hello-go in hello-1 namespace

Then the rest is just to open the jaeger
#install jaeger - quickinstallation
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.8/samples/addons/jaeger.yaml
#port-forward using istioctl
istioctl dashboard jaeger
and open the http://localhost:16686

We can search for specific services we want to see, and list all operation within a period of time

The tracing see the path from [ ingressgateway ] ‚Üê ‚Üí [ hello-go3 ] in hello-3 NS ‚Üê ‚Üí [ hello-go ] in hello-1 NS

üëã Join FAUN today and receive similar stories each week in your inbox!"
jaeger,"Ô∏è Get your weekly dose of the must-read tech stories, news, and tutorials."
jaeger,"Follow us on Twitter üê¶ and Facebook üë• and Instagram üì∑ and join our Facebook and Linkedin Groups üí¨

If this post was helpful, please click the clap üëè button below a few times to show your support for the author!"
jaeger,‚¨á
jaeger,"Many of us use NGINX as our reverse proxy gateway for microservices,
That NGINX config can get complex and integrating Jaeger inside is not a trivial task."
jaeger,This article takes into consideration that you already implemented Jaeger tracing in your microservices using the header uber-trace-id as the trace id to add spans to.
jaeger,"So lets get started, first we need to see what‚Äôs needed to accomplish this:
NGINX image with opentracing and jaeger libraries, check this out for alpine
NGINX config that loads and configures the tracing ‚Äî up next
Jaeger NGINX configuration JSON file to set your outgoing traces endpoint and more ‚Äî up next
So lets start with some documentation that I based this on, for the NGINX conf I used this example and this for the opentracing syntax."
jaeger,We have this great article that helps get started and also provides an example for integrating the jaeger in your code.
jaeger,"Lastly if you want to use something else in addition or instead of Jaeger, this is a good place to start."
jaeger,"NGINX configuration
Now we need to configure our NGINX, I like to split it into 2 parts
The ‚Äúmain‚Äù configuration that loads the module and tracer
The actual reverse proxy section
This is the main configuration ‚Äî notice lines 2 and 24

Next we want to integrate the opentracing and jaeger to the microservices reverse proxy:

named nginx.conf for syntax highlighting only
This is very important, this line has to be there, I‚Äôve commented on that on the gist as well, but doing it again here since its not documented, you need to add log_subrequest on; otherwise the propagation for auth_request and further won‚Äôt work!"
jaeger,"If you read the Opentracing NGINX reference you can say that you don‚Äôt have to specify opentracing_propagate_context; for each location, you can put in on the server directive, and although it won‚Äôt fail and will allow you to run NGINX with this conf, for me it did not propagate the context when using it on the server directive."
jaeger,"Last, we have the Jaeger configuration for nginx."
jaeger,"Although this is a JSON file, it utilizes the C++ Jaeger client so if you are missing some documentation there (I know I needed some) the best place to look is at their Github page at the moment."
jaeger,"{
  ""service_name"": ""nginx-reverse-proxy"",
  ""sampler"": {
    ""type"": ""const"",
    ""param"": 1
  },
  ""reporter"": {
    ""localAgentHostPort"": ""jaeger-logzio-agent:6831""
  },
  ""headers"": {
    ""jaegerDebugHeader"": ""jaeger_debug_id"",
    ""jaegerBaggageHeader"": ""jaeger_baggage"",
    ""traceBaggageHeaderPrefix"": ""uberctx_""
  },
  ""baggage_restrictions"": {
    ""denyBaggageOnInitializationFailure"": false,
    ""hostPort"": """"
  }
}
For reporter if you want to use the Jaeger collector directly you can do:
""reporter"": {        
    ""endpoint"": """"http://jaeger-logzio-collector.default.svc.cluster.local:14268/api/traces""
}
In the end it will look something like this:"
jaeger,Past week I got questioned again about Jaeger ‚Äî an end to end distributed tracing.
jaeger,That question come from my workmates that they‚Äôre in doubt whether the Jaeger can be single point of failure.
jaeger,"Though this post will not answer that case explicitly, but it will give a new perspective about how Jaeger should be properly deployed in production (both for me and for you ‚Äî the readers)."
jaeger,"First time when I get my hand dirty with the so called things as ‚Äúdistributed tracing‚Äù, I always use Jaeger all-in-one docker image which just works."
jaeger,At that time I don‚Äôt think that it would be hard for DevOps or SRE to give the resilient environment of Jaeger for the developer so that developer can focus on their code and help them to trace the request‚Äôs flow.
jaeger,"So, for the end of this preamble, I just want to clarify that I write this post just to documented about what I learn instead giving some advice about dos and don‚Äôts."
jaeger,"Development and Playground Mode
In Development, Localhost or even Playground mode, the all-in-one Jaeger installation is the right choice for the developer to play with Jaeger."
jaeger,"Using below docker compose YAML file, we can easily run all Jaeger‚Äôs component and play with it."
jaeger,This is what I have done when I learn about Jaeger back in last year of 2018.
jaeger,"Understand Your System Behavior By Implement Distributed Tracing Using Jaeger
I‚Äôve been more than 3 years in programming and building many applications from simple website to an API that needs to‚Ä¶
medium.com

version: '3'

services:
  jaeger:
    image: jaegertracing/all-in-one:1.7
    container_name: jaeger
    restart: on-failure
    ports:
      - 5775:5775/udp
      - 6831:6831/udp
      - 6832:6832/udp
      - 5778:5778
      - 16686:16686
      - 14268:14268
      - 9411:9411
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
At first, I imagine that the installation of Jaeger may look like this even in the production mode."
jaeger,"Wrong Jaeger Deployment Installation
This because I didn‚Äôt read the documentation thoroughly, not before the question about ‚Äúhow to deploy Jaeger in production‚Äù came."
jaeger,"So, after that, I revisit Jaeger website and learn about the Architecture and Deployment strategy."
jaeger,"Jaeger Architecture
Architecture
Architecture See also: Jaeger's clients adhere to the data model described in the OpenTracing standard."
jaeger,"Reading the‚Ä¶
www.jaegertracing.io

Although this looks like useless point and all the documentation about this already written in official website, I think it is not that worthless to mention it again."
jaeger,"As I stated above, we can deploy Jaeger using all-in-one strategy."
jaeger,This means that any Jaeger components can be installed in one high spec machine.
jaeger,"But, this is come into problem when we talk about ‚Äúsingle point of failure‚Äù, and isn‚Äôt it kind of weird when we want to trace the large distributed service but send the metrics into only one ‚Äúmonolith‚Äù service?"
jaeger,Isn‚Äôt it kind of weird when we want to trace the large distributed service but send the metrics into only one ‚Äúmonolith‚Äù service?
jaeger,"So, I take a look into official documentation, Jaeger can provide two way to deploy as a scalable distributed system:
Directly write metrics into persistent storage
Buffer the trace metrics into Kafka before writing into persistent storage
Directly write metrics into persistent storage

Illustration of direct-to-storage architecture."
jaeger,"Image from https://www.jaegertracing.io/docs/1.21/architecture/
In this deployment strategy, the Jaeger collector directly writes the trace metrics into Database."
jaeger,Then Jaeger UI access DB to visualize the system behavior.
jaeger,"This scenario works well with small to medium traffic, because Jaeger supports two types of persistent storage that renowned works well under high workloads."
jaeger,"Also, both type of storage can be deployed in cluster mode so this will eliminate our concerns about single point of failure in storage."
jaeger,"For your additional information, in the official documentation, ‚ÄúFor large scale production deployment the Jaeger team recommends Elasticsearch backend over Cassandra.‚Äù
Buffer the trace metrics into Kafka before writing into persistent storage

Illustration of architecture with Kafka as intermediate buffer."
jaeger,"Image from https://www.jaegertracing.io/docs/1.21/architecture/
This is the deployment scenario that I may choose for production because of several reasons."
jaeger,"First, as far as I know, Kafka can scale and work very well even under big data produced into it."
jaeger,You can learn more about Kafka in my another blog post about Kafka or take a quick look about this benchmark.
jaeger,"Second, we can decoupled the persistent storage or DB (that will takes time to persist data into disk) from the collector (which may receive hundreds metric per second to be saved)."
jaeger,"Third, as the complement for the first and second reason, we can deploy many Jaeger collector and Jaeger ingester, so that metrics can be seen via Jaeger UI instantly."
jaeger,"Ok, this third reason may leads to the new question: How we can vertically scale Jaeger collector and ingester?"
jaeger,Would it means metrics data spreadly send into multi collector?
jaeger,"Deployment
The main Jaeger backend components are released as Docker images on Docker Hub: There are orchestration templates for‚Ä¶
www.jaegertracing.io

To answer that question, again we must refer to the official Jaeger documentation."
jaeger,Thanks to it‚Äôs enough clarity.
jaeger,"And yes, metrics data can send into multi collector."
jaeger,"Below is the resume how each component should be installed:
Jaeger Agent
Jaeger client libraries expect jaeger-agent process to run locally on each host."
jaeger,This is clear statement that Agent should be installed in host machine or if you prefer you can directly send your trace metrics directly into Jaeger collector.
jaeger,"This also suggested by the creator of Jaeger, Yuri Shkuro in this responses:
Jaeger agent should always run on the same host as the application, as a sidecar or a host agent."
jaeger,"Alternatively, Jaeger clients can be configured to send spans directly to the collector, which then can run anywhere."
jaeger,"- Yuri Shkuro
Jaeger agent should always run on the same host as the application, as a sidecar or a host agent."
jaeger,Cf.
jaeger,"https://medium.com/jaegertracing/deployment-strategies-for-the-jaeger-agent-1d6f91796d09
medium.com

If you use Kubernetes to deploy your services, you can also refer into this great article:
Deployment strategies for the Jaeger Agent
If you‚Äôve been following the evolution of the Kubernetes templates for Jaeger, you might have noticed an important‚Ä¶
medium.com

Jaeger agent acts as intermediate buffer between your application to the Jaeger collector."
jaeger,Having this close to your application will benefit to your performance since your application will send data using UDP protocol (commonly port 6831) and then buffer it to Jaeger collector using gRPC (commonly port 14250 in Jaeger collector).
jaeger,"Because UDP is stateless protocol, it makes sense that installing in same host will reducing the risk of lost of data when sending metrics."
jaeger,"Jaeger Collector
The collectors are stateless and thus many instances of jaeger-collector can be run in parallel."
jaeger,"Actually we can run only once Collector for many Agent, but for scalability we can also deploy it as many as we want
Jaeger Ingester
jaeger-ingester is a service which reads span data from Kafka topic and writes it to another storage backend (Elasticsearch or Cassandra)."
jaeger,Ingester works as a worker to consume Kafka message.
jaeger,We can also deploy many Jaeger ingester to make it more as responsive as possible to write tracing data into our data storage (Elasticsearch) when traces message published into Kafka.
jaeger,The only limitation about how many you should deploy Jaeger ingester is how many you setup your Kafka topic partition.
jaeger,"This is because when there is more consumer (ingester) than the topic partition, some of the ingester will idle because it will not receives the message."
jaeger,"To learn about this, you should learn about the Kafka consumer group id which I explained in Kafka tutorial post."
jaeger,"Jaeger Query UI
jaeger-query serves the API endpoints and a React/Javascript UI."
jaeger,"The service is stateless and is typically run behind a load balancer, such as NGINX."
jaeger,Jaeger Query UI is a dashboard to visualize about the tracing.
jaeger,It connects directly into Elasticsearch (or Cassandra) to query our tracing data.
jaeger,In all-in-one Docker image we may not see any persistent storage and that‚Äôs true!
jaeger,"In all-in-one binary, we can use In Memory or Badger storage which is not recommended for heavy tracing metrics."
jaeger,"Example Using Docker Compose
In the end of the learning, as usual, I always included the working example because common software engineer tend to try the code instead only reading and to give the reader a chance to get their hand dirty too."
jaeger,":)
This example just give you the idea and proof that multi installation Jaeger Agent, Collector and Ingester is just works fine and answering the first question that the Jaeger components can be scaled."
jaeger,"In this example I want to create two services, which having architecture design like this (including Jaeger components):

Example services architecture
We will create two services one named Dora The Explorer (you may familiar with this from my previous blog) and another one is Umbrella service."
jaeger,For service Dora we send tracing data into Jaeger Agent port 1111 and for Umbrella‚Äôs to 1112.
jaeger,"Actually, you must install Jaeger Agent in the same host, so using localhost:6831 for each application will never be conflicted."
jaeger,"However, since this example we use Docker Compose, we mimicking that application in host 1 is using Jaeger Agent port 1111 and application in host 2 using port 1112."
jaeger,Each application send data into their respective Jaeger Agent in the same host through UDP.
jaeger,Each Jaeger Agent then (both in port 1111 and 1112) then send with static load balancing to 2 Jaeger Collector using gRPC protocol in port 14250.
jaeger,Collector then publish message into same Kafka topic.
jaeger,This is the part that you must give an attention: you must create more than one partition regarding how many you would deploy Jaeger ingester.
jaeger,"For example, if you want to deploy 4 Jaeger Ingester, you need at least 4 partition of Kafka topic to make it work in maximum efforts."
jaeger,Let‚Äôs try it!
jaeger,"First, let‚Äôs run below docker compose file using this command:
MY_IP=$(ifconfig | sed -En 's/127.0.0.1//;s/."
jaeger,*inet (addr:)?(([0-9]*\.){3}[0-9]*).
jaeger,"*/\2/p') docker-compose -f docker-compose-copy.yml up

Clone this repo and checkout into branch with-external-service :
$ git clone https://github.com/yusufsyaifudin/go-opentracing-example.git
$ cd go-opentracing-example
$ git checkout with-external-service
Run main.go and external_service/main.go in separate terminal."
jaeger,"Then do cURL into it:
curl -X GET 'localhost:1323/dora-the-explorer?is_rainy_day=true'
You will get something like this:

Running two API service and cURL into it."
jaeger,"Open browser then go to http://localhost:16686/search, search for newcoming tracing, you will get view something like this:

Jaeger UI shows one trace data already come in 4 minutes ago."
jaeger,The detail of the request life-span.
jaeger,"Now, try to run load testing using k6 to proof that even under load test the Jaeger can still receives the tracing data without no error:
$ k6 run --vus 10 --duration 30s load-testing.js
Load testing for engineering teams | k6
Code-driven, JavaScript load tests that fit into our existing tool chain, clean APIs, command line so easy to automate‚Ä¶
k6.io


k6 Load Testing to prove that Jaeger Agent won‚Äôt blocking out the request and make the single point of failures."
jaeger,"After that, you can back into Jaeger UI (http://localhost:16686/) and then check if many tracing span show in Jaeger UI."
jaeger,Please note that it may take a while for Jaeger UI to show the list of tracing.
jaeger,"But, in my experience the Jaeger consistently show all span using this deployment strategy (deploying each Jaeger component with different docker image)."
jaeger,"Back then when I use all-in-one Docker Image, I sometimes find that some spans is missing and I don‚Äôt find it again using this new scenario of deployment as far as I observe."
jaeger,What Next?
jaeger,Again as I stated in the preamble that this post only documented my experience during learning deploying Jaeger components as individual service.
jaeger,We then can conclude that Jaeger can works under high workloads with its ability to deploy in vertical scale.
jaeger,"Ticketmaster Traces 100 Million Transactions per Day with Jaeger
Ticketmaster engineers conquer the complexity of their microservices architecture with Jaeger‚Äôs distributed tracing‚Ä¶
medium.com

Some of us may already using Kubernetes in your architecture."
jaeger,"For this case, you can learn from Jaeger Medium blog posts:
Deployment strategies for the Jaeger Agent
If you‚Äôve been following the evolution of the Kubernetes templates for Jaeger, you might have noticed an important‚Ä¶
medium.com

A Guide to Deploying Jaeger on Kubernetes in Production
Deploying Jaeger Tracing on containers with K8s in production involves multiple components with different options and‚Ä¶
medium.com

Written by Yusuf on Wed 18 ‚Äî Thu 19, November 2020 during the Covid-19 Pandemic."
jaeger,"The Startup
Get smarter at building your thing."
jaeger,Join The Startup‚Äôs +795K followers.
jaeger,"Follow
140



Sign up for Top 10 Stories"
jaeger,"Continuing from the previous gateway service tutorial, we can now know howto implement open tracing to our application."
jaeger,Why open tracing?
jaeger,"Jaeger terminology and components
Just to recap to another article."
jaeger,Jaeger presents execution requests as traces.
jaeger,A trace shows the data/execution path through a system.
jaeger,A trace is made up of one or more spans.
jaeger,A span is a logical unit of work in Jaeger.
jaeger,"Each span includes the operation name, start time, and duration."
jaeger,Spans may be nested and ordered.
jaeger,"Jaeger includes several components that work together to collect, store and visualize spans and traces."
jaeger,Jaeger Client includes language-specific implementations of the OpenTracing API for distributed tracing.
jaeger,These can be used manually or with a variety of open source frameworks.
jaeger,Jaeger Agent is a network daemon that listens for spans sent over User Datagram Protocol.
jaeger,The agent is meant to be placed on the same host as the instrumented application.
jaeger,Jaeger Collector receives spans and places them in a queue for processing.
jaeger,Query is a service that retrieves traces from storage.
jaeger,Jaeger Console is a user interface that lets you visualize your distributed tracing data.
jaeger,"Prerequisites:
Creating a gateway service with node js, typescript and fastify."
jaeger,"In this article we are going to create a gateway service that will serve all future micro-services that we will learn‚Ä¶
jsisaacdev.medium.com

Create a folder called tracer and in it create a logger.ts."
jaeger,"create a logger function that will receive a span, an event and data obtained from our response."
jaeger,"export function logger(span, event, data) {
    span.log({ event: event, value: data })
    span.finish();
}
export function head(request, name) {
    let ctx = request.ctx;
    return  ctx.tracer.startSpan(name, { childOf: ctx.span });
}
create a tooling.ts
import fastify from 'fastify';
import {Span, Tracer} from 'opentracing';
export default async function(req: fastify.FastifyRequest, res, next){

const ip = req.ips;
let source = req.headers['user-agent'] || ''

if (req.headers['x-ucbrowser-ua']) {  //special case of UC Browser
    source = req.headers['x-ucbrowser-ua'];
}
const tracer = req['jaeger']().tracer as Tracer;
const span = req['jaeger']().span as Span;
req['useragent'] = {
    ip: ip,
    userAgent: source
}
req['ctx'] = { span, tracer }
return
}
How to use it in your service
Let us get started by importing our library to our service in the server.ts file: The custom plugin file can be found and downloaded in github in the folowing link https://github.com/jayisaac0/tracer-jaeger-custom-plugin/releases/tag/0.1
Download the zip file and extract it in the src folder of the gateway service
import jaegerCustomPlugin from './libraries/tracer/jaegerCustomPlugin';
Before you register swagger to our fastify app add the following lines of code:
const host = process.env.HOST || (require('../config/url.json')[process.env.NODE_ENV]).host;
const scheme = process.env.SCHEME || (require('../config/url.json')[process.env.NODE_ENV]).scheme;
const expose = process.env.NODE_ENV === 'production' ?"
jaeger,"false : true;
const configs = (require('../config/url.json')[process.env.NODE_ENV]);
app.register(jaegerCustomPlugin, {
    serviceName: process.env.PROJECT_NAME,
        reporter: {
        agentHost: configs.jaeger.host,
        agentPort: configs.jaeger.port
    }
});
The code is responsible for fetching jaeger configs from the url.json."
jaeger,Add the a jaeger object in it containing a client host and port.
jaeger,"""jaeger"": {
    ""host"": ""localhost"",
    ""port"": 6832
},
In our auth.ts file let us import our logger and tooling modules from our tracer library:
import {logger, head} from '../../../libraries/tracer/logger';
Using it:
const createUserSchema: RouteSchema = {
    tags: [`${action}`], summary: `Login to app`,
    body: Requests.requestBody(userInterface, ['email', 'password']),
}
app.post('/auth', { schema: createUserSchema}, async(request, response) => {
let span = head(request, 'GATEWAY USER AUTHENTICATION: Login user');
let user;
try {
    user = await requestmaker({
        service: 'auth',
        action: 'user/auth',
        method: 'POST',
        data: request.body,
        ctx: request['ctx']
    })
} catch (ex) {
    return response.code(400).send(ex)
}
    logger(span, ""login"", user);
    response.send(user);
});
done();
};"
jaeger,Today we are going to expand our example of Apache Camel and include Jaeger.
jaeger,But before we will explain a little about OpenTraicing and Jaeger.
jaeger,"OpenTracing is, as they define themselves, vendor-neutral APIs and instrumentation for distributed tracing."
jaeger,"And although Uber created it, now it is open-source and has important companies behind it."
jaeger,OpenTracing wants to form a common language around what a trace is and how to handle it in our applications.
jaeger,"And to understand how it works we must first understand several concepts:
Distributed Tracing: It is a method used to profile and monitor applications."
jaeger,It helps us pinpoint where failures occur and what causes the malfunction.
jaeger,"Span: It is the main component of a distributed trace, which represents an individual unit of work performed in a distributed system."
jaeger,They encapsulate information about the application.
jaeger,Trace: It is an acyclic Span graph.
jaeger,Tracer: Is the implementation of the API that will collect the Span and publish them.
jaeger,"A trace could be represented like this:

And if we take into account the time, with this other graph:

Knowing this, it will be clearer when we say that Jaeger will be a Tracer that will allow us to collect the information of the traces of our application and display them in a graphical interface itself."
jaeger,"With which we can incorporate Jaeger to our docker-compose with the following instruction:
jaeger:
image: jaegertracing/all-in-one:latest
ports:
‚Äî 6831:6831
‚Äî 16686:16686
Once we start, we will be able to access its graphic interface through the URL http://localhost:16686
Once we have it ready, we will configure our application."
jaeger,"This can be done in four simple steps:
Add the camel-opentracing-starter library."
jaeger,Which will auto-configure our Spring Boot application for the use of Open Tracing.
jaeger,Add the @CamelOpenTracing notation in the main class.
jaeger,This will enable the use of Open Tracing.
jaeger,"Add an OpenTracing implementation, in this case, Jaeger."
jaeger,Through the io.jaegertracing:jaeger-client library.
jaeger,Create an environment variable JAEGER_SERVICE_NAME to indicate which application is collecting data.
jaeger,"To see the example better, we are going to test two methods, one with JPA and another from a previous version that uses the SQL component."
jaeger,We will make several calls and then access Jaeger.
jaeger,Through the UI we will select our application in the Service field and press the Search button.
jaeger,At that time Jaeger will show us which are the calls we have made.
jaeger,"If we select some of the invocations, we will see with more details the parts of it."
jaeger,"In this case, as they are very basic methods, the trace is very simple."
jaeger,"You can even select several traces and compare them with a simple click:

As we can see in a simple way we can collect important information about the application."
jaeger,This information can help us for example to debug a microservice and see which parts of it are a possible bottleneck.
jaeger,"Ifyou are dealing with microservices, serverless architecture, on any other type of distributed architecture, you have probably heard the term ‚ÄúDistributed Tracing‚Äù."
jaeger,"You may have been wondering what it‚Äôs all about, and where should you start, in this post, I‚Äôll tell you about the journey we passed at Duda, from the day we heard about distributed tracing and started to explore whether it will be useful to use it in our company, to the exploration on what is distributed tracing all about, what are the different solutions out there, and what‚Äôs their architectures, and finally, I will present our final solution, how we instrumented our(hundred of machines)services and what we are directed to."
jaeger,"In order to do so, I will answer the following questions:
Why would you want to even read about distributed tracing?"
jaeger,"What is distributed tracing, where it all began, what are the core components of it?"
jaeger,"I will also tell about our considerations at Duda, why we decided to work with specific tools and specifications, and in what way we implemented our monolith and services."
jaeger,"The WHY
Let‚Äôs start with the most important question ‚Äî why would you even want to invest time in integrating distributed tracing into your technology stack."
jaeger,"While there are many reasons, I‚Äôll mention those who are the most important from my perspective."
jaeger,"Reveals service dependencies
The strategic decision was taken, your company started to move to a distributed architecture, the number of components starts to increase, and the ability to understand your company architecture decreases, using distributed tracing you can Trace the path of a request as it travels across a complex system."
jaeger,"Some tools even compute and draw a full dependency graph, it can help to have an overview of your architecture and deep dive to understand dependencies better."
jaeger,"Discover the latency of the components along a given path
You can discover the latency by monitoring a request from the edge services using monitoring systems."
jaeger,"OK, you got the alert, now you need to find out what component causes the specific request to exceed the SLO."
jaeger,"That‚Äôs exactly why distributed tracing is here for, Locating components in the path that are bottlenecks or that cause failure."
jaeger,"Root cause analysis
Imagine the following scenario ‚Äî you wake up by an alert, it‚Äôs 2 AM, a request that involves 5 different microservices fails repeatedly."
jaeger,"You‚Äôre jumping to the logs, still trying to open your eyes against your ultra brightened screen, are looking for errors around the time of the alert, but the stream of data is too big to figure out what happened, it takes too long."
jaeger,"Using distributed tracing, you can find the first service that failed, get logs from the failure, and some other stuff(tracing implementation depended)."
jaeger,"Collect events during the request
In order to help in the debug process, you may add baggage to the trace, for example, at Duda, the company I work for, we are adding all the evaluated feature flags to the trace, by that, in a case of failure, we can know exactly the flags that were evaluated inside each one of the services on the request path."
jaeger,"The WHAT
Now when we have discussed why would you even want to read the rest of this post, if you‚Äôre still with me(I hope, as distributed tracing is awesome!"
jaeger,"), let‚Äôs continue to what is distributed tracing, and what are the different solutions you can find out there."
jaeger,"First, let‚Äôs start with the basics, where all the distributed tracing solutions originated from."
jaeger,"While there were some distributed tracing solutions before, Google Dapper(2010) design paper is a, or the cornerstone of distributed tracing."
jaeger,"This paper explains how google developed a production-grade tracing tool, with 3 key goals behind it."
jaeger,Low overhead ‚Äî the tracing system should have a negligible performance impact on running services.
jaeger,"In
some highly optimized services, even small monitoring overheads are easily noticeable."
jaeger,"For example, a single Google search query traverses thousands of machines and services, Google can‚Äôt afford a non-negligible increment to each of these requests."
jaeger,"Application-level transparency ‚Äî Tracing should not require active collaboration for programmers, as it may be fragile and consume programmers‚Äô expensive time to learn it."
jaeger,Scalability ‚Äî It needs to handle google‚Äôs scale for at least a few years.
jaeger,They also add a requirement that the trace data will be available minutes after the request.
jaeger,"Service instrumentation and terminology
Dapper introduced some terminology, it may differ between different solutions, but this is the ideas are used in most of its successor solutions."
jaeger,Trace: The description of a transaction as it moves through a distributed system.
jaeger,"Span: A named, timed operation representing a piece of the workflow."
jaeger,"Spans accept key: value tags as well as fine-grained, timestamped, structured logs attached to the particular span instance."
jaeger,"(Span) Context: Trace identifying information that accompanies the distributed transaction, including when it passes the service to service over the network or through a message bus."
jaeger,"The span context contains the trace identifier, span identifier, and any other data that the tracing system needs to propagate to the downstream service."
jaeger,Instrumentation: Instrumentation is the process through which your application‚Äôs code is extended to capture and report trace spans for the operations of interest.
jaeger,"Annotations: annotations(sometimes called baggage), allows the developer to enrich the trace with user-defined data, it can be used to save counters, relevant logs, and whatever data can help to investigate an incident."
jaeger,"The trace context is being serialized and passed during the call between instrumented services, will it be RPC, event message, SMTP, or any other communication channel you have in mind after the client send the server the trace data(for example by HTTP header in REST calls), the server will deserialize the span and start a new one which is pointing to its parent span, the span was received by the client."
jaeger,"These following images help to demonstrate the relationship between the different components:

A trace lifecycle(The OpenTracing overview)

Dapper trace tree (Dapper a Large-Scale Distributed Systems Tracing Infrastructure, Google Technical Report dapper 2010)
Trace collection and storage
After the trace is being collected in each instrumented server, it has to be aggregated by that the entire trace and spans can be shown in a single UI to enable the observer to receive insights about the request and it‚Äôs internal communication."
jaeger,The way Dapper introduced is a three-stage process.
jaeger,"Span data is written to a local log file
Dapper collectors reading from daemon on production machines the traces
Collectors writing the trace to a single Bigtable repository

Dapper trace collecting (Dapper a Large-Scale Distributed Systems Tracing Infrastructure, Google Technical Report dapper 2010)
This methodology gave google a median of 15-second latency for the collection, which is very impressive for a high scale with log overhead on the existing applications."
jaeger,"In order to improve the performance, sampling is being used, which means that only a fraction of all traces is being logged and collected."
jaeger,"There is an assumption here is that for most use cases, it will be enough to get all or at least most of the insights, and that performance degradation should be neglectable."
jaeger,"The evolution of Dapper
After we talked about the ancestor, let‚Äôs get to the solutions available these days ‚Äî many of them share the same concept or even solution as Dapper."
jaeger,"The solutions can be grouped into 2 groups:
Open Source Solutions
Zipkin(Twitter)
Jaeger(Uber)
AppDash
Enterprise Solutions
Amazon X-Ray
Google Cloud Trace
Datadog
Lightstep
New Relic
Those are some, but not all of the solutions out there."
jaeger,"This post won‚Äôt compare them, I‚Äôll just say that each one of the solutions has pros and cons, and the benefits depend on your architecture, language, and mostly the stack."
jaeger,"Once you chose one, to avoid coupling to a specific solution during the instrumentation, multiple specs and standards raised:
W3 specification ‚Äî defines standard HTTP headers and a value format to propagate context information."
jaeger,"OpenTracing ‚Äî OpenTracing is comprised of an API specification, frameworks, and libraries that have implemented the specification, and documentation for the project."
jaeger,"OpenCensus ‚Äî OpenCensus is a set of libraries for various languages that allow you to collect application metrics and distributed traces, then transfer the data to a backend of your choice in real-time."
jaeger,"OpenTelemetry ‚Äî A collaboration between the creators of OpenTracing and OpenCensus, which is created to replace them with a unified specification with instrumentation libraries written in a variety of languages."
jaeger,OpenTracing is now an incubating project of CNCF (Cloud Native Computing Foundation).
jaeger,"Implementation at Duda
Now when we have the fundamental knowledge about distributed tracing, I‚Äôd like to share with you my experience with instrumenting more than 150 machines using Jaeger and Opentracing."
jaeger,"We have decided to instrument our services using Opentracing, as back then it was the only production-ready solution(Open Census is in beta stages), as we have thousands of requests per second, we need a robust solution that won‚Äôt increase the latency."
jaeger,"There were multiple reasons why we chose Jaeger, first, it‚Äôs a mature open source solution CNCF graduated project, and because at Duda we are using logz.io as our ELK stack solution, and they started to offer a distributed tracking solution with ElasticSearch store and Jaeger UI, this integration not only diminished the operational burden of implementing the solution by ourselves but also exposed it and encouraged our developers to use the new tool, by having all the observability in a single place and by correlating the log to the relevant trace."
jaeger,Our architecture at Duda composed of a Spring framework monolith and about 10 Spring Boot microservices.
jaeger,"For the microservices, Spring boot starters make their magics, so all I had to do was to instrument both our internal rest-client and events shared library."
jaeger,"In order to enable developers to know what was the exact in-service flow, I also instrumented our feature flags library so it will add the flag key and the specific value evaluated in the flow to the trace baggage."
jaeger,"In addition to the applicative instrumentation, we ran a Jaeger agent on each machine and connected them to a collector that ship the logs to logz.io ElasticSearch."
jaeger,"Now, when you have a solid background about tracing, let‚Äôs look on an example of a jaeger trace composed of 4 spans, where service1 communicating with service2 using a REST call (where service1 is the client and service2 is the server), service2 evaluates a feature flag doSomthing.featureFlag.enabled with the value of true, and as a result, it produces an event that is being consumed by service1."
jaeger,"As you may note the starting time of each subsequent span is greater than its previous, using this information jaeger can calculate the time of each span, and help you detect bottlenecks in your flow."
jaeger,"Jaeger trace example
Finally, we had sessions with developers, that explains about distributed tracing as part of our observability solution, when it should be used and how, we passed over some code examples so they will know how to instrument all the important and bottleneck-suspicious flows so we have the maximum information and minimum distractions in our trace."
jaeger,"That‚Äôs all for now, hope you have a brighter sight on WHAT is distributed tracing, and WHY you should use distributed tracing in your organization, if you have any question regarding the implementation or on the decision we took, or any idea or advice, just respond to the post!"
jaeger,"Blog illustration
The title sounds cool, right?"
jaeger,"I know, but what is this distributed tracing?"
jaeger,I had the same question when I was asked to set one up for a client.
jaeger,"Let‚Äôs get some background
Distributed tracing is a method used to debug, monitor, and troubleshoot applications built using modern distributed software architectures."
jaeger,The applications should be instrumented with the OpenTracing APIs* to identify an incoming request to pinpoint where failures occur and what causes poor performance.
jaeger,"Jaeger is an OpenSource distributed tracing technology graduate by Cloud Native Computing Foundation (CNCF) used to monitor and troubleshoot microservice-based distributed systems for performance optimization, root cause analysis, service dependency analysis, and many more use cases."
jaeger,"It comprises five components:
Client: A language-specific OpenTracing API that is implemented by instrumenting the applications
Agent: a network daemon that listens for spans** and sends it over to collectors
Collector: Validates, indexes and stores the traces received from the agents
Ingester: An integrated service between the Kafka topic and storage backend
Query: a service to retrieve the traces*** from a storage backend and hosts a UI to display them
* The OpenTracing API provides a standard, vendor-neutral framework for instrumentation."
jaeger,A developer can introduce a different distributed tracing system by simply changing the configuration of the Tracer in the code.
jaeger,"** Span represents a single unit of work that includes the operation name, start time, and duration
*** A trace is made up of one or more spans
What‚Äôs in the Cloud today?"
jaeger,Now that we learned some Jaeger jargon let‚Äôs talk about this specific use case at play.
jaeger,"The client I worked with had set up the entire Jaeger stack on Amazon Web Services (AWS) as follows:

What‚Äôs in Cloud today?"
jaeger,"(Figure 1)
Applications are instrumented with the Jaeger Clients (AWS Lambda Functions) to interact directly with the Jaeger collector to forward the spans
The Jaeger collector is deployed on an EC2 instance and configured with an AWS Managed Streaming for Apache Kafka (MSK) to validate, index and store the spans
The Jaeger Ingester was set up on an EC2 instance to read the spans from AWS Kafka and write it to the Elastic Search to view them on the Jaeger UI
The Requirement
It seems like everything is in place, right?"
jaeger,No!
jaeger,"Here comes the tricky part; the client has planned to implement distributed tracing (Jaeger) for the mission-critical applications running on an On-Prem OpenShift cluster for analytics, visualization, and reporting."
jaeger,"Given the requirements, the initial plan was to send the traces directly from agents (on OpenShift cluster) to the collector (on AWS)."
jaeger,"Sounded pretty straight forward at first glance, but a wrench was thrown in as I realized the data transfer between On-Prem applications and AWS has to be secure."
jaeger,I also found that there wasn‚Äôt enough bandwidth to send real-time span data from the Jaeger agent (on OpenShift cluster) to the Jaeger collector (on AWS).
jaeger,"If the spans are backed up, the agents will drop the spans and the whole purpose will be defeated."
jaeger,"Even though Jaeger supports gRPC TLS communication between the agent and the collector, bandwidth was a primary concern."
jaeger,"Whiteboard Session
With the bandwidth and security in transit issues, I had to go back to the drawing board and come up with a solution to address these two significant areas:
On-Prem Data retention in case of connectivity issues or data queuing due to bandwidth limitations
Network bandwidth limitation between On-Prem Openshift Cluster and AWS
After hours of brainstorming, I came up with the following: well, to start off with,

Whiteboard Sketch (Figure 2)
Ensure the version compatibility between Jaeger, Kafka, and MirrorMaker
Install Jaeger components (only collector & agent) using it‚Äôs OpenShift Operator
Leverage the self-provision option in the Jaeger OpenShift Operator to auto-install the Kafka cluster(ZooKeeper, Kafka and MirrorMaker) by using a Strimzi Kafka Kubernetes Operator
Use MirrorMaker Kubernetes object provided by Strimizi Kafka Kubernetes Operator to replicate the OpenShift Kafka cluster events to the AWS MSK cluster
Note: It‚Äôs worth noting that the Jaeger collector or agent is not designed to handle the load when backed up by the spans, but a Kafka cluster can be used as a streaming service between the Jaeger collector and backend storage (DB) to offload the span data."
jaeger,"Note: To leverage the self-provisioning Kafka cluster option in Jaeger, a Strimiz Operator must be deployed in the OpenShift cluster before the Jaeger Openshift Operator deployment."
jaeger,"R & D
To prove the findings in the whiteboard session (Figure 2), I started with our in-house OpenShift cluster and an AWS MSK cluster to test the use case and understand the nuances in the process,
Trial & Error
When the Jaeger Openshift Operator is deployed with a self-provision Kafka cluster, it deployed the following:
Four components of Jaeger (agent, collector, ingester, and query)
A Kafka Cluster using Strimizi Operator
Backend storage (ElasticSearch)

Trial & Error (Figure 3)
As per the design (Figure 2), I only needed the Jaeger agent, collector and a Kafka cluster, but I realized that there is no option in Jaeger Openshift Operator to enable or disable the backend storage such as Cassandra or ElasticSearch, ingester, or the query components (Figure 3)."
jaeger,"Alteration
To overcome the above challenge, instead of using the Jaeger OpenShift Operator, I created the required Jaeger components (collector and agent) as raw Kubernetes YAML files:

Altered Sketch (Figure 4)
Collector has the Kubernetes Deployment, ConfigMap, and a Service YAML files
The agent has the Kubernetes Daemonset as it needs to run on every node in the OpenShift cluster and a Service YAML files
For the Kafka cluster, I used the Strimizi Kafka Kubernetes Operator to deploy a simple Kafka cluster and a Kafka topic."
jaeger,"Before deploying the Jaeger‚Äôs agent and collector to the OpenShift cluster using the raw Kubernetes YAML files, I set the backend storage type to Kafka with the Kafka Brokers and Kafka topic information in the Jaeger collector‚Äôs Kubernetes Deployment YAML file."
jaeger,"Hello World Spans
Now that the architecture is altered (Figure 4), I wanted to make sure that Jaeger collector can forward the spans to the Kafka cluster."
jaeger,I created and deployed a sample Python application instrumented with the Jaeger client libraries to the OpenShift cluster.
jaeger,Hello World!!
jaeger,"(Figure 5)
On the Jaeger side of the house, the agent was able to listen and batch the spans, the collector was receiving the spans from the agent."
jaeger,"On the Kafka side of the house, the spans were actively streamed into the Kafka topic."
jaeger,"At this point, I confirmed that Jaeger successfully communicated and forward the spans to the Kafka."
jaeger,"Replication
Now to replicate the spans from the OpenShift Kafka topic to AWS MSK‚Äôs topic, I used the Strimizi Kafka Kubernetes Operator‚Äôs MirrorMaker."
jaeger,MirrorMaker is one of Kafka‚Äôs features used to replicate the events between multiple Kafka instances.
jaeger,I configured the MirrorMaker Kubernetes YAML file with the consumer (OpenShift Kafka) and producer (AWS MSK) clusters information and deployed it to the OpenShift cluster (Figure 5).
jaeger,"VOILA, It worked!"
jaeger,I was able to read the sample Python application‚Äôs spans in the AWS‚Äôs MSK topics events.
jaeger,"The Ultimate Sketch
Following the alterations through the trial and error phase, here is the final design

Conclusive Sketch (Figure 6)
The End
To rephrase my journey, I started with the Jaeger OpenShift and Strimzi Kafka Kubernetes Operators."
jaeger,"Still, after the R&D and alterations to the initial sketch, I wind up with raw Kubernetes YAML files for Jaeger components and Strimzi Kafka Kubernetes Operators for Kafka cluster."
jaeger,"With the ultimate sketch, I wrap up the distributed tracing in a hybrid cloud using Apache Kafka blog without compromising the On-Prem Data retention and Network bandwidth limitation concerns."
jaeger,I‚Äôm always up for a discussion; leave a comment below!!
jaeger,"Well, that‚Äôs it for now."
jaeger,See you again!
jaeger,Happy Tracing üöÄüöÄ
jaeger,"Jaeger Integration with spring boot application
Let‚Äôs first understand what is Jaeger
Jaeger is open source software for tracing transactions between distributed services."
jaeger,It‚Äôs used for monitoring and troubleshooting complex microservices environments.
jaeger,Ridesharing company Uber developed Jaeger as an open source project in 2015.
jaeger,It was accepted as a Cloud Native Computing Foundation (CNCF) Incubation project in 2017 and promoted to graduated status in 2019.
jaeger,What is distributed tracing?
jaeger,Distributed tracing is a way to see and understand the whole chain of events in a complex interaction between microservices.
jaeger,"Modern, cloud-native software development relies on microservices: independent services that each provide a different core function."
jaeger,"When a user makes a request in an app, many individual services respond to produce a result."
jaeger,A single call in an app can invoke dozens of different services that interact with each other.
jaeger,How can developers and engineers isolate a problem when something goes wrong or a request is running slow?
jaeger,We need a way to keep track of all the connections.
jaeger,That‚Äôs where distributed tracing comes in.
jaeger,"It‚Äôs often run as part of a service mesh, which is a way to manage and observe microservices."
jaeger,Jaeger uses distributed tracing to follow the path of a request through different microservices.
jaeger,"Rather than guessing, we can see a visual representation of the call flows."
jaeger,Organized information about transactions is useful for debugging and optimization.
jaeger,"Jaeger includes tools to monitor distributed transactions, optimize performance and latency, and perform root cause analysis (RCA), a method of problem-solving."
jaeger,"Jaeger terminology and components
Jaeger presents execution requests as traces."
jaeger,A trace shows the data/execution path through a system.
jaeger,A trace is made up of one or more spans.
jaeger,A span is a logical unit of work in Jaeger.
jaeger,"Each span includes the operation name, start time, and duration."
jaeger,Spans may be nested and ordered.
jaeger,"Jaeger includes several components that work together to collect, store, and visualize spans and traces."
jaeger,Jaeger Client includes language-specific implementations of the OpenTracing API for distributed tracing.
jaeger,These can be used manually or with a variety of open-source frameworks.
jaeger,Jaeger Agent is a network daemon that listens for spans sent over User Datagram Protocol.
jaeger,The agent is meant to be placed on the same host as the instrumented application.
jaeger,This is usually implemented through a sidecar in container environments like Kubernetes.
jaeger,Jaeger Collector receives spans and places them in a queue for processing.
jaeger,"Collectors require a persistent storage backend, so Jaeger also has a pluggable mechanism for span storage."
jaeger,Query is a service that retrieves traces from storage.
jaeger,Jaeger Console is a user interface that lets you visualize your distributed tracing data.
jaeger,Why Jaeger?
jaeger,"As on-the-ground microservice practitioners are quickly realizing, the majority of operational problems that arise when moving to a distributed architecture are ultimately grounded in two areas: networking and observability."
jaeger,It is simply an orders of magnitude larger problem to network and debug a set of intertwined distributed services versus a single monolithic application.
jaeger,"Jaeger in Action
We will be integrating jaeger on a spring boot applications."
jaeger,"First, Let‚Äôs quickly set up our spring boot applications."
jaeger,The idea here is generating names by concatenating famous scientist names with animal names.
jaeger,"So, We will build 3 microservices using spring boot i.e animal-name-service, name-generator-service, and scientist-name-service."
jaeger,Client Request for a scientist and animal concatenated name from name-generator-service which internally calls animal-name-service and scientist-name-service.
jaeger,The same is demonstrated in the below diagram.
jaeger,"Microservice Example
Let‚Äôs quickly build our three Microservices using spring initializer."
jaeger,We will add spring-boot-starter-web dependency while generating spring boot applications.
jaeger,Now we have 3 spring boot applications ready.
jaeger,Let‚Äôs add these 3 microservices to a folder named opentracing-microservices-example.
jaeger,And import this folder in your favorite editor.
jaeger,I use IntelliJ.
jaeger,As we have to call animal-name-service and scientist-name-service from name-generator-service.
jaeger,we are choosing to feign client for this.
jaeger,So let‚Äôs add spring-cloud-starter-openfeign:2.2.3.RELEASE dependency in name-generator-service.
jaeger,Here is the code for all 3 microservices.
jaeger,"AnimalNameService:
package com.example.ans;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.core.io.ClassPathResource;
import org.springframework.http.HttpHeaders;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestHeader;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.List;
import java.util.Random;
import java.util.stream.Collectors;
@SpringBootApplication
public class AnimalNameService {
public static void main(String[] args) {
SpringApplication.run(AnimalNameService.class, args);
}
}
@RestController
@RequestMapping(""/api/v1/animals"")
class AnimalNameResource {
private final List<String> animalNames;
private Random random;
public AnimalNameResource() throws IOException {
InputStream inputStream = new ClassPathResource(""/animals.txt"").getInputStream();
try (BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream))) {
animalNames = reader.lines().collect(Collectors.toList());
}
random = new Random();
}
@GetMapping(path = ""/random"")
public String name(@RequestHeader HttpHeaders headers) {
String name = animalNames.get(random.nextInt(animalNames.size()));
return name;
}
}
application.properties :
server.port=9000
NameGeneratorService:
Here, I am using com.shekhargulati:strman:0.4.0 library for converting animal and scientist name to kebab case."
jaeger,"package com.example.ngs;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.openfeign.EnableFeignClients;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import static strman.Strman.toKebabCase;
@SpringBootApplication
@EnableFeignClients
public class NameGeneratorService {
public static void main(String[] args) {
SpringApplication.run(NameGeneratorService.class, args);
}
}
@FeignClient(name = ""scientist-service-client"", url = ""${scientist.service.prefix.url}"")
interface ScientistServiceClient {
@GetMapping(""/api/v1/scientists/random"")
String randomScientistName();
}
@FeignClient(name = ""animal-service-client"", url = ""${animal.service.prefix.url}"")
interface AnimalServiceClient {
@GetMapping(""/api/v1/animals/random"")
String randomAnimalName();
}
@RestController
@RequestMapping(""/api/v1/names"")
class NameResource {
@Autowired
private AnimalServiceClient animalServiceClient;
@Autowired
private ScientistServiceClient scientistServiceClient;
@GetMapping(path = ""/random"")
public String name() throws Exception {
String animal = animalServiceClient.randomAnimalName();
String scientist = scientistServiceClient.randomScientistName();
String name = toKebabCase(scientist) + ""-"" + toKebabCase(animal);
return name;
}
}
application.properties :
server.port=8080
scientist.service.prefix.url=http://localhost:8090
animal.service.prefix.url=http://localhost:9000
ScientistNameService:
package com.example.sns;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.core.io.ClassPathResource;
import org.springframework.http.HttpHeaders;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestHeader;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.List;
import java.util.Random;
import java.util.stream.Collectors;
@SpringBootApplication
public class ScientistNameService {
public static void main(String[] args) {
SpringApplication.run(ScientistNameService.class, args);
}
}
@RestController
@RequestMapping(""/api/v1/scientists"")
class ScientistNameResource {
private final List<String> scientistsNames;
private Random random;
public ScientistNameResource() throws IOException {
InputStream inputStream = new ClassPathResource(""/scientists.txt"").getInputStream();
try (BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream))) {
scientistsNames = reader.lines().collect(Collectors.toList());
}
random = new Random();
}
@GetMapping(path = ""/random"")
public String name(@RequestHeader HttpHeaders headers) {
String name = scientistsNames.get(random.nextInt(scientistsNames.size()));
return name;
}
}
application.properties :
server.port=8090
Now we will run all 3 applications and go to http://localhost:8080/api/v1/names/random in a browser."
jaeger,"We will get some random name example: john-cockcroft-snapping-turtle
So Now our application setup is done."
jaeger,Now let‚Äôs integrate jaeger to these applications so that we can trace each request.
jaeger,We just need to add the below dependency to all 3 pom.xml.
jaeger,"<dependency>
<groupId>io.opentracing.contrib</groupId>
<artifactId>opentracing-spring-jaeger-cloud-starter</artifactId><version>3.1.2</version>
</dependency>
And we need to add below properties in the application.properties file for all 3 applications."
jaeger,"spring.application.name=<name-of-the-application> // example : name-generator-service (this will be displayed in jaeger for respective service)
opentracing.jaeger.udp-sender.host=localhost //udp host for sender."
jaeger,"By default Jaeger libraries use a UDP sender to report finished spans to the jaeger-agent daemon
opentracing.jaeger.udp-sender.port=6831 // udp port
opentracing.jaeger.log-spans=true // logs the spans in console
Run Jaeger in docker via the below command :
docker run -p 9090:16686 ‚Äî name jaeger -d jaegertracing/all-in-one:1.17
Now restart the application."
jaeger,And go to localhost:9090 in a browser.
jaeger,We will get a jaeger homepage.
jaeger,"Also, go to http://localhost:8080/api/v1/names/random in a browser."
jaeger,"Similarly, you will get some random name."
jaeger,But now we can trace the request.
jaeger,Check in jaeger dashboard choose service name-generator-service.
jaeger,then click on find traces.
jaeger,we will get traces as shown in the below image for the name-generator-service.
jaeger,"Jaeger Name Generator Service
We can clearly see that there are 5 spans when we drill down on this."
jaeger,"name-generator-service(1 span)
name-generator-service->animal-name-service(2 spans)
name-generator-service->scientist-name-service(2 spans)
This is shown in the below image."
jaeger,"Jaeger Name Generator Service Trace
Here, everything is auto-configured by opentracing-spring-jaeger-cloud-starter library which has a Class named TracingAspect basically doing magic."
jaeger,"@Aspect
class TracingAspect {
    TracingAspect() {
    }

    @Around(""execution (* feign.Client.*(..))"
jaeger,"&& !within(is(FinalType))"")
    public Object feignClientWasCalled(ProceedingJoinPoint pjp) throws Throwable {
        Object bean = pjp.getTarget();
        if (!"
jaeger,"(bean instanceof TracingClient)) {
            Object[] args = pjp.getArgs();
            return (new TracingClientBuilder((Client)bean, FeignTracingAutoConfiguration.this.tracer)).withFeignSpanDecorators(FeignTracingAutoConfiguration.this.spanDecorators).build().execute((Request)args[0], (Options)args[1]);
        } else {
            return pjp.proceed();
        }
    }
}
I have added Dockerfile,docker-compose, and docker-setup.sh for making it easier to run this application."
jaeger,checkout code and run docker-setup.sh directly.
jaeger,You can find the code at my Github repository link.
jaeger,This is inspired by Shekhar Gulati‚Äôs Blog.
jaeger,"I am an Application Architect at IBM, working on building a platform to accelerate continuous delivery with quality, ensuring a modern flexible way to enable DevOps and support an agile culture."
jaeger,"Complexity as scale
For the past year, due to the need of distributed transaction monitoring and root cause analysis in a complex distributed micro-service environment, we introduced Jaeger framework to help us tackle the problem."
jaeger,"Since our platform is being used by multiple tenants, we had to take a decision on how we would implement the multi-tenancy Jaeger with Elasticsearch as backend."
jaeger,This is a practical exercise on how to setup Jaeger with Elasticsearch to support multiple tenants.
jaeger,"But first, you should read the following article Jaeger and multitenancy which talks about various multi-tenancy options with Jaeger."
jaeger,"The context
We are building and running a platform based on Kubernetes, which allows our customers to build and deploy their own applications using our platform, thus the specific requirements when it comes to tracing data:
One Elasticsearch instance supporting all the tenants,
Each tenant‚Äôs trace data has to be persisted separately ‚Äî with various retention timeframes,
Ability for every tenant to view and query its own tracing data,
As minimal development activities as possible, thus reusing the existing Jaeger functionalities."
jaeger,"The solution
After going through enough material from different sources to have a clear picture, I decided on the following solution which consists of:
An Elasticsearch instance installed in an independent namespace of the tenants ones ‚Äî we want to manage our own ES cluster,
Install a Jaeger collector for each tenant, configured to use the ES cluster with the specific tenant name/id,
Install the Jaeger agents as sidecars to the services that are being traced,
For each tenant configure it‚Äôs own Jaeger‚Äôs elastic search index cleaner settings,
Everything set up with 0 development effort."
jaeger,"Implementing the solution
Right, now let‚Äôs jump to the ‚Äúcode‚Äù and see how we can configure the above story."
jaeger,For this exercise I have deployed all the components using Helm so look at the code snippet from this perspective.
jaeger,"Installing the Elasticsearch has nothing special to it, thus you can follow the detailed online documentation using Helm on how to do it using various ES image flavours."
jaeger,"For the sake of this exercise we will assume that we‚Äôve installed ES with the following configuration in the jaeger namespace:
clusterName: ""elasticsearch"" 
nodeGroup: ""master""
masterService: """"
roles:
  master: ""true""
  ingest: ""true""
  data: ""true""
httpPort: 9200
transportPort: 9300
Moving on to the Jaeger‚Äôs part, first we need to tell it to work with the newly installed Elasticsearch cluster."
jaeger,"Since we want to store the data in ES separatelly for each tenant we will have to provide an index prefix, the tenant‚Äôs name, specific for each tenant."
jaeger,"storage:
  type: elasticsearch
  elasticsearch:
    host: elasticsearch-master.jaeger.svc.cluster.local
    indexPrefix: <TENANT_NAME>
    extraEnv:
      # We need this one for the index cleaner (later in our story)
      - name: INDEX_PREFIX
        value: <TENANT_NAME>
We said earlier that we‚Äôll have one collector for each tenant."
jaeger,"So, we will just enable the collector deployment and disable the Jaeger agent component."
jaeger,"agent:
  enabled: false
collector:
  enabled: true
  image: jaegertracing/jaeger-collector
  pullPolicy: IfNotPresent
We also want to expose for each tenant their own Jaeger UI in order to see the tracing data."
jaeger,"query:
  enabled: true
  image: jaegertracing/jaeger-query
  basePath: /ops/jaeger/<TENANT_NAME>
Jaeger has a self-ES-index-cleaning component that can be configured per tenant in our setup."
jaeger,We just need to add the following configuration.
jaeger,Since this is part of the same configuration and installation for our tenant it will clean-up the elasticsearch indexes configured under the env variable INDEX_PREFIX (we did this step earlier when we setup the storage type).
jaeger,"esIndexCleaner:
  enabled: true
  image: jaegertracing/jaeger-es-index-cleaner
  schedule: ""59 23 * * *""
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  numberOfDays: 3
If you are using Helm to deploy the Kubernetes resources you can just provide your tenant‚Äôs name at install time using --set key=value and reference it in your helm chart file."
jaeger,"Let‚Äôs have a final look at the yaml configuration needed to install the Jaeger components for one tenant, using the Helm chart."
jaeger,"storage:
  type: elasticsearch
  elasticsearch:
    host: elasticsearch-master.jaeger.svc.cluster.local
    indexPrefix: <TENANT_NAME>
    extraEnv:
      - name: INDEX_PREFIX
        value: <TENANT_NAME>
agent:
  enabled: false
collector:
  enabled: true
  image: jaegertracing/jaeger-collector
  pullPolicy: IfNotPresent
query:
  enabled: true
  image: jaegertracing/jaeger-query
  basePath: /ops/jaeger/<TENANT_NAME>
esIndexCleaner:
  enabled: true
  image: jaegertracing/jaeger-es-index-cleaner
  schedule: ""59 23 * * *""
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  numberOfDays: 3
The only thing remaining is to deploy the Jaeger‚Äôs agent component as a sidecar to our services and make sure to link it to the proper collector for each tenant."
jaeger,This can be easily done by adding a new container into your deployment as described here.
jaeger,"Assuming that your deployment has an application named my-app running a container from yourimagerepository/hello-my-image on port 8080, you‚Äôll need to add the additional jaeger-agent container where the args needs to point to the correct collector for ."
jaeger,"Depending on your architectural needs, you can benefit from deploying a single agent per pod or a single agent per set of pods or even an agent per cluster‚Äôs node."
jaeger,"apiVersion: apps/v1
kind: Deployment
...
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/name: my-app
    spec:
      containers:
      - image: yourimagerepository/hello-my-image
        name: my-app-cntr
        ports:
        - containerPort: 8080
      - image: jaegertracing/jaeger-agent:1.17.0
        name: jaeger-agent
        resources:
          limits:
            cpu: 20m
            memory: 20Mi
        args: [""--reporter.grpc.host-port=jaeger-<TENANT_NAME>-collector.jaeger.svc.cluster.local:14250""]
And that‚Äôs about all there is to deploy Jaeger with Elasticsearch for multi-tenancy purposes."
jaeger,Repeating the above process for every tenant might be tedious and error prone so consider moving all these changes into a Helm chart and deploy them as add-ons for your tenants.
jaeger,‚ÄúDo.
jaeger,Or do not.
jaeger,"There is no try.‚Äù
Additional aspects to consider when configuring for a production setup."
jaeger,Since Jaeger doesn‚Äôt come with any authentication/authorization mechanism for its UI you will need to protect it.
jaeger,However this is quite easy since the Jaeger‚Äôs helm chart has build-in support for the ingress resource and there are multiple documented ways to protect them.
jaeger,Review the Elasticsearch security to prevent unauthorized access to your Elasticsearch cluster.
jaeger,Verify that the Elasticsearch Index Cleaner job is being executed and it removes the old data.
jaeger,You can check for each tenant‚Äôs ES indexes being removed.
jaeger,"kubectl logs jaeger-tenant1-es-index-cleaner-1596412740-29njp -n jaeger
Removing tenant1-jaeger-service-2020-07-31
Removing tenant1-jaeger-span-2020-07-31
kubectl logs jaeger-tenant2-es-index-cleaner-1596412740-mdl8l -n jaeger
Removing tenant2-jaeger-span-2020-07-31
Removing tenant2-jaeger-service-2020-07-31
Special thanks üç∫ goes to my colleague George Safta for his work on in bringing it to live."
jaeger,"This is the end of the tutorial, and we are going to create the docker-compose.yml with all needed service to run and use the application."
jaeger,"Running and testing application
Go application folder and run the command
docker-compose up -d
After that run the application using local profile
./gradlew bootRun --args='--spring.profiles.active=local'
For Jaeger go to browser and navigate: http://localhost:16686/
For Kafka Control Center UI go to browser and navigate: http://localhost:9021/
For Postgres use PgAdmin4 with URL: http://localhost:5050 and configure Connection using host postgres
To create a person you can use CURL
curl --header ""Content-Type: application/json"" \
  --request POST \
  --data '{ ""first_name"" : ""John"", ""last_name"" : ""Wick"", ""date_of_birthday"": ""1973-03-03"", ""gender"": ""M"" }' \
  http://localhost:8080/health-v1/persons
To register schema on Schema Registry go to Control Center using http://localhost:9021

To store a measurement you can use Conduktor Tool"
jaeger,"Photo by Trevin Rudy on Unsplash
This article will describe creation of two simple micro-services using Sanic with multiple workers, and Jaeger configuration that will help visualizing flows them."
jaeger,"From Sanic official Documentation :
‚Äú Sanic is a Python 3.6+ web server and web framework that‚Äôs written to go fast."
jaeger,"It allows the usage of the async/await syntax added in Python 3.5, which makes your code non-blocking and speedy.‚Äù
In fact, writing an API with Sanic is as simple as :
from sanic import Sanic
from sanic import response
import random
app = Sanic(__name__)
@app.route(""/example-api"")
async def example(request):
    random_value = random.randint(0, 100000)
    return response.json(random_value)

if __name__ == ""__main__"":
    app.run(port=8000, host=""0.0.0.0"")
With multiple micro-services, visualisation has many advantages such as a broad view of all micro services, an easy way to see failed requests, and a way to identify system bottlenecks."
jaeger,Jaeger is an open source solution that will offer instrumentation tools and also a web interface to visualize requests.
jaeger,"Code is available here
Tracing comes with domain specific vocabulary :
Span : A time window of a specific code block execution
Child and Parent Spans : Child spans are spans that are attached to a parent span."
jaeger,"Parents spans could have multiple children spans
Tags : Useful to attach global informations to spans."
jaeger,"It could be anything : for instance the request or response, or a flag to specify that the request has an error
Key/values : We can attach key/values pair to spans, jaeger will also keep track of the exact moment where we save these key/values
Sampler : It is where we define the general strategy of traces ingestion."
jaeger,"We could configure Jaeger to ingest all spans within batches, or trace a percentage of all request
It is also important to keep in mind that the Jaeger Client sends spans via UDP."
jaeger,"UDP unlike TCP, does not guarantees delivery of data and that packets will be delivered in the order they were sent."
jaeger,Jaeger also offers a web interface to visualize traces - available at http://localhost:16686.
jaeger,"(Almost) Real world scenario
Generating random integers is a simple example, but not very representative of a real world scenario."
jaeger,"Consider the following example requirements :
We need to handle a shop backend for that will expose catalog and inventory services, where we will be able to configure items, update stocks and see what items are in stocks
These requirements can be implemented with 3 APIs :
Add new items to the catalog
Put items in stocks
List catalog items that are in stock
A database to store items and stocks will be needed, and MySQL is a good candidate for that."
jaeger,"Catalog micro-service will be in charge of storing items that exists in the system, and Inventory micro-service will be responsible to store items‚Äô stocks."
jaeger,"Coding
Let‚Äôs start with a Dockerfile template that will be used by our two micro services
FROM python:3.7-slim
WORKDIR /app
COPY requirements.txt /app
RUN pip install -r requirements.txt
COPY ."
jaeger,"/app
CMD [""bash"", ""start.sh""]
‚åõ Time saver trick ‚åõ: copying only requirements.txt file just before running pip install will decrease dramatically docker build time if your code change -but not your requirements- because docker layer built at line 3 won‚Äôt change, and will be taken from the cache, docker will only build new layers starting line 5 because that layer changed."
jaeger,"Now, docker-compose file to link apps with Mysql and Jaeger
inventory:
  build: inventory
  ports:
    - ""8001:8001""
  depends_on:
    - db-inventory
  links:
    - jaeger
  environment:
    - JAEGER_AGENT_HOST=jaeger

db-inventory:
  image: mysql:5.7
  restart: always
  environment:
    MYSQL_ROOT_PASSWORD: somepwd
    MYSQL_DATABASE: INVENTORY_DB
    MYSQL_USER: inventory-user
    MYSQL_PASSWORD: inventorypwd
catalog:
  build: catalog
  ports:
    - ""8000:8000""
  environment:
    - JAEGER_AGENT_HOST=jaeger
  depends_on:
    - db-catalog

db-catalog:
  image: mysql:5.7
  restart: always
  environment:
    MYSQL_ROOT_PASSWORD: somepwd
    MYSQL_DATABASE: CATALOG_DB
    MYSQL_USER: catalog-user
    MYSQL_PASSWORD: catalogpwd
jaeger:
  image: ""jaegertracing/all-in-one:latest""
  expose:
    - ""16686""
    - ""6831/udp""
  ports:
    - ""5775:5775/udp""
    - ""6831:6831/udp""
    - ""6832:6832/udp""
    - ""5778:5778""
    - ""16686:16686""
    - ""14268:14268""
    - ""9411:9411""
Configure Sanic workers with Jaeger
You may use multiple workers to get the most performance of Sanic, and if you do so, you will need to init tracer for each workers, and we can use after_server_start listener to do that."
jaeger,"We will also need to use a scope manager called ContextVarsScopeManager which will automatically apply parent span propagation to children coroutines, tasks or scheduled callbacks."
jaeger,We will also configure sampler to sample all traces.
jaeger,"@app.listener('after_server_start')
async def notify_server_started(app, loop):
    init_tracer(""inventory"")
def init_tracer(service):
    config = Config(
      config={
        'sampler': {
            'type': 'const',
            'param': 1,
        },
        'logging': True,
      },
      service_name=service,
      validate=True,
      scope_manager=ContextVarsScopeManager()
    )
    config.initialize_tracer()
1."
jaeger,"Inventory Micro Service
This micro-service will handle stocks."
jaeger,Database schema will be simple : it will keep number of stock available for each items.
jaeger,"Whenever stock equal zero, then it will mean that this particular item won‚Äôt be available anymore."
jaeger,"""""""CREATE TABLE IF NOT EXISTS STOCK (ITEM_ID int, STOCK int, PRIMARY KEY (ITEM_ID))""""""
Put item in stock API will look like :
@app.route(""/fill"", methods={""POST""})
async def put_in_stock(request):
    with opentracing.tracer.start_span('/fill') as span:
        product_id = int(request.json['product_id'])
        stock = int(request.json['stock'])
        try:
            await _put_in_stocks(db, product_id, stock)
            span.set_tag('response', ""OK"")
            return response.json(status=200, body=""OK"")
        except Exception as e:
            span.set_tag('response', e)
            span.set_tag(tags.ERROR, True)
            db.rollback()
            return response.json(status=500, body=""KO"")
This piece of code will start a new span called ‚Äúfill‚Äù and save, in case of error, exception message into that span."
jaeger,In that case these tags will show if request was successful or not.
jaeger,"Example of an error trace
Get stocks API will look like :
@app.route(""/stocks"", methods={""GET""})
async def get_stocks(request):
    tracer = opentracing.global_tracer()
    span_ctx = tracer.extract(format=Format.HTTP_HEADERS, carrier=request.headers)
    with tracer.start_span(""get_stocks"", child_of=span_ctx) as span:
        try:
            items = await _get_all_stocks(db)
            return response.json(status=200, body=items)
        except Exception as e:
            span.set_tag('response', e)
            span.set_tag(tags.ERROR, True)
            return response.json(status=500, body=""KO"")
Notice here the tracer.extract, that line will extract from the request headers context about the parent Span."
jaeger,"In fact this API will be called by Catalog micro-service, and will ‚Äúattach‚Äù that span as a children span."
jaeger,2.
jaeger,"Catalog Micro Service
This micro-service will handle Items."
jaeger,"Another simple schema containing : ID, name & price."
jaeger,"""""""CREATE TABLE IF NOT EXISTS ITEM (ID int NOT NULL AUTO_INCREMENT, NAME CHAR(20) NOT NULL, PRICE FLOAT, PRIMARY KEY (ID))""""""
Add item API :
@app.route(""/item"", methods={""POST""})
async def add_item(request):
    tracer = opentracing.global_tracer()
    with tracer.start_active_span('add_item') as scope:
        name = request.json['name']
        price = float(request.json['price'])
        try:
            _create_new_item(db, name, price)
            return response.json(status=200, body=""OK"")
        except Exception as e:
            print(e)
            return response.json(status=500, body=e)
start_active_span will start a parent span, and all following spans started with start_span will be automatically attached like a children span."
jaeger,Finally get available items API.
jaeger,"That API will fetch all configured items in database, and return only those who are in stock by calling Inventory micro-service :
@app.route(""/available"")
async def get_available_items(request):
    tracer = opentracing.global_tracer()
    with tracer.start_active_span('get_available_items') as scope:
        try:
            items = _fetch_all_items(db)
            inventory = await _fetch_all_inventory()
            available_items = _retain_only_items_in_stock(items, inventory)
            return response.json(status=200, body=available_items)
        except Exception as e:
            print(e)
            return response.json(status=500, body=e)
async def _fetch_all_inventory():
    headers = {}
    tracer = opentracing.global_tracer()
    with tracer.start_span(""_fetch_all_inventory"", child_of=tracer.active_span) as span:
        span.set_tag(tags.HTTP_METHOD, ""GET"")
        tracer.inject(span, Format.HTTP_HEADERS, carrier=headers)
        response = requests.get(""http://inventory:8001/stocks"", headers=headers)
        return response.json()
Notice here the tracer.inject, this will send in request headers information about the current span."
jaeger,"catalog micro-service trace that queries it‚Äôs own database and inventory micro-service API
Conclusion
That‚Äôs it."
jaeger,"After seeing important concepts about Jaeger, we configured async Sanic apps to work with Jaeger, supporting multiple workers."
jaeger,"We know how to trace our calls between micro-services by configuring parent spans using start_active_span or children spans with start_span, and propagate spans context between requests using tracer.inject & tracer.extract."
jaeger,We also know how to attach value to spans to visualize partial or final results of some code blocks.
jaeger,"Photo by Josh Riemer on Unsplash
Before getting started with spring application let‚Äôs look at what is Jaeger and no little bit about it."
jaeger,"Jaeger
Jaeger, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies."
jaeger,"It is used for monitoring and troubleshooting microservices-based distributed systems, including:
Distributed context propagation
Distributed transaction monitoring
Root cause analysis
Service dependency analysis
Performance / latency optimization
Why Jaeger?"
jaeger,"As on-the-ground microservice practitioners are quickly realizing, the majority of operational problems that arise when moving to a distributed architecture are ultimately grounded in two areas: networking and observability."
jaeger,It is simply an orders of magnitude larger problem to network and debug a set of intertwined distributed services versus a single monolithic application.
jaeger,more details.
jaeger,"Spring boot application using Jaeger
Now that you know little bit about Jaeger, let‚Äôs understand what is application that we will be using for this tutorial."
jaeger,"As Jaeger was built from day 1 to be able to process huge data and distributed applications, for this tutorial we need a distributed application."
jaeger,So I have created two microservices relay-service and sprint-service.
jaeger,"The architecture of the two microservices is as shown in the picture below

Microservices used in this tutorial
relay-service: This microservice is internet facing service so it can be called by using CURL, POSTMAN or any other rest/web client."
jaeger,"Once called, it then starts a new relay process and calls sprint-service to execute sprints with relayId."
jaeger,sprint-service: This microservice then creates 4 tasks for given relayId and executes them sequentially as it would happen in any relay race.
jaeger,"To use Jaeger with spring-boot below dependencies are used,
compile ""io.opentracing.contrib:opentracing-spring-cloud-starter:0.1.13""
compile ""io.jaegertracing:jaeger-client:0.31.0""
In relay-service, we are letting spring-boot take care of instrumentation so that the Tracing spans are automatically published."
jaeger,"So the only configuration we have done in relay-service is,
@Bean
public io.opentracing.Tracer initTracer() {
        Configuration.SamplerConfiguration samplerConfig = new
               Configuration.SamplerConfiguration()
                .withType(""const"").withParam(1);
        return Configuration.fromEnv(""relay-service"")
                .withSampler(samplerConfig).getTracer();
}

@Bean
public RestTemplate restTemplate(
          RestTemplateBuilder restTemplateBuilder) {
        return restTemplateBuilder.build();
}
Here a Jaeger tracer is declared as bean and as you are in spring boot world (which is great at autowiring as you know üòé), all necessary configuration is automatically done and Jaeger client will publish spans for all the HTTP methods that are executed."
jaeger,"In sprint-service however, we will not only configure Tracer bean as we did in relay-service but also we will publish spans using Jaeger client API."
jaeger,A span can be created using tracer object.
jaeger,The span recording will start with start method and will stop using finish method as shown below.
jaeger,"Span sprintSpan = tracer.buildSpan(""sprint-"" + count)
                .withTag(""player"", player).start();

doSomeRunning(player);

sprintSpan.finish();
Enough about coding, let‚Äôs run both the microservices and see the goodness of Jaeger with spring boot."
jaeger,Here relay-service is configured to run on default port 8080 and sprint-service is configured to run on 8081.
jaeger,Once both the microservices are started the only thing left is starting Jaeger UI which runs on port 16686.
jaeger,"There are multiple ways in which Jaeger and related tools are started, the easiest way is to start jaeger-all-in-one command."
jaeger,Here is the link to installations on different operating systems.
jaeger,"Jaeger in action:
Following are some of screenshots of Jaeger UI showing various stages."
jaeger,"Jaeger UI home before events

2."
jaeger,Let‚Äôs hit http://localhost:8080/start-relay endpoint of relay-service see traces in Jaeger UI.
jaeger,3.
jaeger,"Detailed traces in Jaeger UI

4."
jaeger,"Custom tags in spans

Additional Links
These additional references should also help you:
source code
jaeger-installation
opentracing-spring-jaeger-starter"
jaeger,"The OpenTracing Pulsar Client is an integration of the Pulsar Client and OpenTracing APIs which are based on Pulsar Client Interceptors, a monitoring tool in the StreamNative Hub."
jaeger,OpenTracing is an open distributed tracing standard for applications and OSS packages.
jaeger,"Many tracing backend services support OpenTracing APIs, such as Jaeger, Zipkin and SkyWalking."
jaeger,This blog guides you through every step of how to trace Pulsar messages by Jaeger through OpenTracing API.
jaeger,"Prerequisite
Before getting started, make sure you have installed JDK 8, Maven 3, and Pulsar (cluster or standalone)."
jaeger,"If you do not have an available Pulsar, follow the instructions to install one."
jaeger,"Step 1: start a Jaeger backend
1."
jaeger,Start a Jaeger backend in Docker.
jaeger,"docker run -d -p 6831:6831/udp -p 16686:16686 jaegertracing/all-in-one:latest
If you have successfully started Jaeger, you can open the Jaeger UI website successfully."
jaeger,"Tip
If you do not have a Jaeger Docker environment, you can download the binaries or build from source."
jaeger,2.
jaeger,Visit http://localhost:16686 to open the Jaeger UI website without a username or password.
jaeger,"Step 2: add maven dependencies
This step uses OpenTracing Pulsar Client, which is integrated with the Pulsar Client and OpenTracing APIs based on Pulsar Client Interceptors, to trace Pulsar messages."
jaeger,"Developed by StreamNative, the OpenTracing Pulsar Client acts as a monitoring tool in the StreamNatvie Hub."
jaeger,Add Jaeger client dependency to connect to Jaeger backend.
jaeger,"<dependency>
 <groupId>org.apache.pulsar</groupId>
 <artifactId>pulsar-client</artifactId>
 <version>2.5.1</version>
</dependency>
<dependency>
 <groupId>io.streamnative</groupId>
 <artifactId>opentracing-pulsar-client</artifactId>
 <version>0.1.0</version>
</dependency>
<dependency>
  <groupId>io.jaegertracing</groupId>
  <artifactId>jaeger-client</artifactId>
  <version>1.2.0</version>
</dependency>
Step 3: use OpenTracing Pulsar Client
For easier understanding, this blog takes a usage scenario as an example."
jaeger,Suppose that you have three jobs and two topics.
jaeger,Job-1 publishes messages to the topic-A and Job-2 consumes messages from the topic-A.
jaeger,"When Job-2 receives a message from topic-A, Job-2 sends a message to the topic-B, and then Job-3 consumes messages from topic-B."
jaeger,"So there are two topics, two producers and two consumers in this scenario."
jaeger,"According to the scenario described previously, you need to start three applications to finish this job."
jaeger,"Job-1: publish messages to topic-A
Job-2: consume messages from topic-A and publish messages to topic-B
Job-3: consume messages from topic-B
Job-1
This example shows how to publish messages to topic-A in Java."
jaeger,"Configuration.SamplerConfiguration samplerConfig = Configuration.SamplerConfiguration.fromEnv().withType(""const"").withParam(1);
Configuration.ReporterConfiguration reporterConfig = Configuration.ReporterConfiguration.fromEnv().withLogSpans(true);
Configuration configuration = new Configuration(""Job-1"").withSampler(samplerConfig).withReporter(reporterConfig);
Tracer tracer = configuration.getTracer();
GlobalTracer.registerIfAbsent(tracer);
PulsarClient client = PulsarClient.builder()
        .serviceUrl(""pulsar://localhost:6650"")
        .build();
Producer<String> producerA = client.newProducer(Schema.STRING)
        .topic(""topic-A"")
        .intercept(new TracingProducerInterceptor())
        .create();
for (int i = 0; i < 10; i++) {
    producerA.newMessage().value(String.format(""[%d] Hello"", i)).send();
}
Job-2
This example shows how to consume messages from topic-A and publish messages to topic-B in Java."
jaeger,"Configuration.SamplerConfiguration samplerConfig = Configuration.SamplerConfiguration.fromEnv().withType(""const"").withParam(1);
Configuration.ReporterConfiguration reporterConfig = Configuration.ReporterConfiguration.fromEnv().withLogSpans(true);
Configuration configuration = new Configuration(""Job-2"").withSampler(samplerConfig).withReporter(reporterConfig);
Tracer tracer = configuration.getTracer();
GlobalTracer.registerIfAbsent(tracer);
PulsarClient client = PulsarClient.builder()
        .serviceUrl(""pulsar://localhost:6650"")
        .build();
Consumer<String> consumer = client.newConsumer(Schema.STRING)
        .topic(""topic-A"")
        .subscriptionName(""open-tracing"")
        .subscriptionType(SubscriptionType.Shared)
        .intercept(new TracingConsumerInterceptor<>())
        .subscribe();
Producer<String> producerB = client.newProducer(Schema.STRING)
        .topic(""topic-B"")
        .intercept(new TracingProducerInterceptor())
        .create();
while (true) {
    Message<String> received = consumer.receive();
    SpanContext context = TracingPulsarUtils.extractSpanContext(received, tracer);
    TypedMessageBuilder<String> messageBuilder = producerB.newMessage();
    messageBuilder.value(received.getValue() + "" Pulsar and OpenTracing!"
jaeger,""");
    // Inject parent span context
    tracer.inject(context, Format.Builtin.TEXT_MAP, new TypeMessageBuilderInjectAdapter(messageBuilder));
    messageBuilder.send();
    consumer.acknowledge(received);
}
Job-3
This example shows how to consume messages from topic-B in Java."
jaeger,"Configuration.SamplerConfiguration samplerConfig = Configuration.SamplerConfiguration.fromEnv().withType(""const"").withParam(1);
Configuration.ReporterConfiguration reporterConfig = Configuration.ReporterConfiguration.fromEnv().withLogSpans(true);
Configuration configuration = new Configuration(""Job-3"").withSampler(samplerConfig).withReporter(reporterConfig);
Tracer tracer = configuration.getTracer();
GlobalTracer.registerIfAbsent(tracer);
PulsarClient client = PulsarClient.builder()
        .serviceUrl(""pulsar://localhost:6650"")
        .build();
Consumer<String> consumer = client.newConsumer(Schema.STRING)
        .topic(""topic-B"")
        .subscriptionName(""open-tracing"")
        .subscriptionType(SubscriptionType.Shared)
        .intercept(new TracingConsumerInterceptor<>())
        .subscribe();
while (true) {
    Message<String> received = consumer.receive();
    System.out.println(received.getValue());
    consumer.acknowledge(received);
}
Now, you can run Job-3, Job-2 and Job-1 one by one."
jaeger,"You can see the Job-3 receives logs in the console as below:
[0] Hello Pulsar and OpenTracing!"
jaeger,[1] Hello Pulsar and OpenTracing!
jaeger,"...
[9] Hello Pulsar and OpenTracing!"
jaeger,"Congratulations, your jobs work well."
jaeger,Now you can open the Jaeger UI again and there are ten traces in the Jaeger.
jaeger,You can click a job name to view the details of a trace.
jaeger,"The span name is formatted as To__<topic-name> and From__<topic-name>__<subscription_name>, which makes it easy to tell whether it is a producer or a consumer."
jaeger,"Summary
As you can see, OpenTracing Pulsar Client integrates Pulsar client and OpenTracing to trace Pulsar messages easily."
jaeger,"If you are using Pulsar and OpenTracing in your application, do not hesitate to try it out!"
jaeger,"Additionally, I also wrote a tech blog for How to Use Apache SkyWalking to Trace Apache Pulsar Messages."
jaeger,"For the complete content, see here."
jaeger,"About the author
Penghui Li is a PMC member of Apache Pulsar and a tech lead in Zhaopin.com, where he serves as the leading promoter to adopt Pulsar."
jaeger,"His career has always involved messaging service from the messaging system, through the microservice, and into the current world with Pulsar."
jaeger,You can follow him on twitter.
jaeger,"OPENTRACING (Distributed Tracing)
Before starting about Jaeger, Let‚Äôs go around OpenTracing technique and how to use it in micro-services environment with tools like Jaeger."
jaeger,"In micro-services architecture, many applications communicating with each other than ever before."
jaeger,"While application performance monitoring is great for debugging inside a single app, as a system expands into multiple services, how can you understand , how much time each service is taking, where the exception happens, and the overall health of your system?"
jaeger,"In particular, how do you measure network latency between services ‚Äî such as how long a request takes between one app to another?"
jaeger,"To deal with all these problems and scenarios, Distributed Tracing comes into the picture,
‚ÄúDistributed tracing is the art and science of making distributed traces valuable.‚Äù
Distributed tracing is a method used to tracking and monitoring the applications mostly built using micro-services architecture."
jaeger,It helps in finding where failures occur and what causes poor performance.
jaeger,"The Major Components that plays a crucial role in distributing Tracing are:-
Trace: A recording of a transaction as it moves through a distributed system."
jaeger,"Span: A named, timed operation representing a piece of the workflow."
jaeger,"Spans have a timestamp, duration, and are annotated with tags and logs."
jaeger,"To Show Distributed Tracing in Action, we will be using Jaeger as our Tracer Implementation."
jaeger,"JAEGER: A Distributed Tracing System
Jaeger is one of the major tool which is used for Distributed Tracing System, it will monitor, troubleshoot and analyse micro-services base applications using tracing system."
jaeger,"Following is the architectural flow for Jaeger, with all components of jaeger and how these components work together in pipeline to show end result in UI."
jaeger,"Jaeger Deployment steps in Kubernetes for Micro-services Applications :-
Before Starting deployment of Jaeger in Kubernetes, It is important to configure Jaeger-Client libraries in Application with other libraries of Application, so that it will be easier for other components of Jaeger to fetch the application data for tracing."
jaeger,"Jaeger Tracing can be compatible with languages like Go,Python,Java,Node and C++."
jaeger,"Lets Start with Deployment stages with each components:-
Jaeger-Agent
Jaegar-Agent is a Daemon that fetches workflow from Jaegar-Client present in Application via UDP network and sent it to Jaeger Collector."
jaeger,It can be deployed using two ways i.e Daemonset and Sidecar.
jaeger,In our case we used Sidecar format for Jaeger Agent which will run as a sidecar container in same application pod and fetches application details using UDP network.
jaeger,This is example application running with sidecar as jaegar-agent.
jaeger,2.
jaeger,"Jaeger-Collector
Jaeger Collector Collects the traces coming from Jaeger agent in form of batches and pass it over to storage."
jaeger,It is collector only which validates the traces and pass it to storage using pipeline.
jaeger,3.
jaeger,"Jaeger Query
Jaeger query is responsible for fetching traces from storage and helps in showing traces on UI."
jaeger,Jaeger us having its own UI for monitoring tracing but we can integrate other tool as well like ELK etc.
jaeger,Here in our case we had used Default UI of Jaeger.
jaeger,4.
jaeger,"Jaeger-Storage
Jaegar-Storage stores the validated traces coming in pipeline from collector section.As of now Jaeger using two Storage types:-
(i)."
jaeger,"Elastic Storage
(ii) Cassandra Storage
In our case we are using Cassandra as storage , which will be mount to jaegar-collector for fetching traces and jaegar-query for pushing traces to show on UI."
jaeger,"Here Below given is service file ,Stateful-set file

Common configuration required for storage with some components are as below:-
apiVersion: v1
kind: ConfigMap
metadata:
  name: jaeger-configuration
  labels:
    app: jaeger
    app.kubernetes.io/name: jaeger
data:
  span-storage-type: cassandra
  collector: |
    collector:
      zipkin:
        http-port: 9411
    cassandra:
      servers: cassandra
      keyspace: jaeger_v1_dc1
  query: |
    cassandra:
      servers: cassandra
      keyspace: jaeger_v1_dc1
  agent: |
    collector:
      host-port: ""jaeger-collector:14267""
Validation Of Jaegar Deployment with Application
These are running deployment for all components of jaegar with cassandra Storage."
jaeger,"In our case, Below given service endpoint is with type as ‚ÄúLoadBalancer‚Äù for application such ordermgr and jaegar-query."
jaeger,we can deploy it using ingress as well with DNS hosted zone.
jaeger,The UI Part Of Jaegar with some tracing output for GET request is as follows :-
jaeger,"Zipkin & Jaeger
To monitor the stability of the application , we need logging , metrics and tracing."
jaeger,"In microservices environment, Logging will help you to get the error details of a service, metrics will get you the abnormal trend of a service, but only tracing will help you pin-point where the service call has actually failed."
jaeger,"Let‚Äôs see how we can setup opensource distributed tracing software like Jaeger and Zipkin in GKE,
To enable distributed tracing , all the incoming requests to / from microservices should be enabled with trace ids and tags and they should report the traces to a collector."
jaeger,All the services should also forward the headers downstream and the tracer backend like Jaeger or zipkin should be able to query and search these traces.
jaeger,"To ease the instrumentation of the microservices, there are opentracing and opencensus library packages available for major languages like C++, Go , java, javascript, Python , Ruby etc."
jaeger,Opencensus is backed by google and opentracing is backed by CNCF and they have now jointly formed opentelemetry.
jaeger,"For the purpose of this demo i have used the bookinfo sample application , which is available as part of the Istio installation."
jaeger,"First let‚Äôs create a GKE cluster in us-central1 region, with min nodes as 3.
gcloud container clusters create demo --enable-autoupgrade --enable-autoscaling --min-nodes=2 --max-nodes=10 --num-nodes=3 --zone=$zone
Next we will go ahead and get the credentials for the cluster and create a cluster role binding."
jaeger,"gcloud container clusters get-credentials demo --zone $zone --project $project
kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value core/account)

GKE cluster
We will now download the latest stable version of istio for installation."
jaeger,"curl -L https://istio.io/downloadIstio | sh -
Verify the installation,
cd istio-1.5.4/bin
./istioctl verify-install
Now we will go ahead and deploy the istio ecosystem, as part of the installation it will also install grafana, prometheus, kiali and Jaeger
./istioctl manifest apply --set profile=demo --set values.tracing.enabled=true
If you want to use zipkin as the tracer, use the below command instead of above."
jaeger,"./istioctl manifest apply --set profile=demo --set values.tracing.enabled=true --set values.tracing.provider=zipkin
Next we label the namespace ‚Äòdefault‚Äô as istio-injection enabled, so all the services deployed will have a istio side-car proxy."
jaeger,"kubectl label namespace default istio-injection=enabled
Now we will deploy the application."
jaeger,"cd istio-1.5.4/
kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
Check whether the pods and services are running as intended,

GKE services
kubectl get services
kubectl get pods
kubectl exec -it $(kubectl get pod -l app=ratings -o jsonpath='{.items[0].metadata.name}') -c ratings -- curl productpage:9080/productpage | grep -o ""<title>."
jaeger,"*</title>""
Now we will create the gateway for the application,
kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
Now open up the firewall rules
export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?"
jaeger,"(@.name==""http2"")].port}')
export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?"
jaeger,"(@.name==""https"")].port}')
gcloud compute firewall-rules create allow-gateway-http --allow tcp:$INGRESS_PORT
gcloud compute firewall-rules create allow-gateway-https --allow tcp:$SECURE_INGRESS_PORT
To introduce an error and visualize it in Jaeger / Zipkin, we will induce delay fault between the products and reviews service for the user jason, more details are available in the below link
kubectl apply -f samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml
Fault Injection
This task shows you how to inject faults to test the resiliency of your application."
jaeger,"Set up Istio by following the‚Ä¶
istio.io


Book Info application
Now lets open the Jaeger ui , by doing a portforward on the jaeger-query service."
jaeger,"kubectl port-forward --namespace istio-system $(kubectl get pod \
--namespace istio-system --selector=""app=jaeger"" \
--output jsonpath='{.items[0].metadata.name}') \
8080:16686

Google cloud shell ‚Äî Port forwarding the Jaeger Query Service
Click on web-preview on the cloud shell, Navigate to the error time span to the view the details."
jaeger,"Jaeger UI

Error identification in Jaeger UI
the DAG in Jaeger is given below,

Jaeger DAG
Lets see how we can view this error detail in zipkin, get the credentials of the cluster where you have deployed zipkin as the tracer, then execute the below command to do the port forward of the zipkin service and do a web-preview from the cloud shell."
jaeger,"kubectl port-forward --namespace istio-system $(kubectl get pod \
--namespace istio-system --selector=""app=zipkin"" \
--output jsonpath='{.items[0].metadata.name}') 8080:9411

Zipkin UI Lens
the DAG graph is displayed as below in zipkin

Zipkin DAG
The different error response flags are given below for your reference, you can use them to troubleshoot the issue."
jaeger,"DC - Downstream connection termination
UH - No healthy upstream hosts."
jaeger,UF - Upstream connection failure.
jaeger,UO - Upstream overflow.
jaeger,NR - No route configured.
jaeger,URX - Rejected because of upstream retry limit or maximum connection attempts reached.
jaeger,LH - Local service failed health check request.
jaeger,UT - Upstream request timeout.
jaeger,LR - Connection local reset.
jaeger,UR - Upstream remote reset.
jaeger,UC - Upstream connection termination.
jaeger,DI - The request processing was delayed for a period specified via fault injection.
jaeger,FI - The request was aborted with a response code specified via fault injection.
jaeger,RL - The request was rate limited locally by the rate limiting filter.
jaeger,UAEX - The request was denied by the external authorization service.
jaeger,RLSE - The request was rejected because there was an error in rate limit service.
jaeger,IH - The request was rejected because it set an invalid value for a strictly-checked header in addition to 400 response code.
jaeger,SI - Stream idle timeout in addition to 408 response code.
jaeger,"Thanks for reading through this post, hope it helped you ."
jaeger,"Cable mess
Photo by Milestoned on flicker.com."
jaeger,"Introduction
During an application-monitoring workshop, I was introduced to the distributed tracing."
jaeger,I was immediately interested in that and I understood the potentiality that this method can offer to monitor a distributed system in production.
jaeger,"So, I started to learn about Jaeger¬π, OpenTracing¬≤, traces, spans, tags, ‚Ä¶
Then I instrumented my first APIs using HTTP headers for the transport layer and everything was fine."
jaeger,I was able to see the tracing in action!
jaeger,But then I wondered: how can I instrument services that don‚Äôt expose APIs and that don‚Äôt speak each other through HTTP?
jaeger,"I‚Äôm speaking about services that are part of the same pipeline, that work on the same data in an event-driven architecture or that use direct requests to communicate, but in which I can‚Äôt use an HTTP header to propagate down the context information."
jaeger,"Distributed tracing: a very brief description
Distributed tracing, is a method used to profile and monitor applications, especially those built using a microservices architecture."
jaeger,"Distributed tracing helps pinpoint where failures occur and what causes poor performance.¬≥
That means you can easily understand and monitor your services in production in a visual way."
jaeger,Tracing adds observability.
jaeger,"Thanks to that, the troubleshooting teams can analyze issues and debug a system in all its parts."
jaeger,It simplifies and reduces the time for the root cause discovery.
jaeger,"In addition, it can be useful to the developers to better understand how to develop a new feature or introduce an improvement in the system."
jaeger,"Example of trace and spans
Since the scope of this article is not an introduction about distributed tracing I don‚Äôt deepen into this."
jaeger,"To understand better what tracing is, I posted below some useful articles."
jaeger,"Redis as a message queue
Referring to my previous evaluation, in case you can‚Äôt propagate the information context through HTTP Headers, you can use a message queue."
jaeger,"So, I created the example application Distributed Tracing with Redis‚Å¥ in which I simulated a pipeline composed of 3 different apps: one main service and two different workers that work on the same data."
jaeger,"In this example, the main service starts the two workers by executing a shell command."
jaeger,The main service passes a parameter ‚Äî that contains the job id ‚Äî to the apps.
jaeger,"The application‚Äôs transaction cycle
In the application, the main service starts a new tracing span and then propagates the span context saving it in Redis, our message queue."
jaeger,The context is saved using the job id as the key.
jaeger,"Then it starts the execution of the two workers, just providing the job id."
jaeger,"When the two workers start, it is their responsibility to retrieve the context from Redis, create a new span, and establish a relationship with the main span."
jaeger,"The two workers are executed in a sequential way, so only when the first worker is completed, the second will start."
jaeger,"All the apps simulate the execution of internal tasks, sending some tracing spans, tags, logs to the Jeager Agent."
jaeger,The following image can be useful to describe better what these apps do.
jaeger,"The application‚Äôs transaction cycle
The architecture
The application‚Äôs architecture is mainly composed of:
Apps module
Redis, to propagate the span context
the Jaeger stack: Agent, Collector, Query/UI
Elasticsearch, to save the traces
The image below shows the tracing architecture."
jaeger,"Tracing architecture
Let‚Äôs jump into the code!"
jaeger,I instrumented the components using OpenTracing.
jaeger,"So, I added in each of them the code to send the spans to the Jaeger Agent."
jaeger,"In order to do that, I used the Jaeger clients and the OpenTracing libraries for NodeJS and Python."
jaeger,"In the following sections, I briefly described how I instrumented the code to propagate the context."
jaeger,"The main service
In the following snippet of code, the main service creates the new main span, saves the context information, and then starts up the two workers providing the job id."
jaeger,"As shown in the code, the context span is saved in Redis using a key-value pair, providing the job id as the key."
jaeger,The value is instead filled with the context span in the TEXT_MAP format provided by OpenTracing.
jaeger,"The worker apps
Here below you can find the snippets of code developed for the two apps to read the span context from Redis."
jaeger,"When the worker apps start, the job id is provided as an input parameter."
jaeger,The worker creates a continuation span that will be attached to the main span before being extracted from Redis using the job id key.
jaeger,Then some tasks are executed internally by the worker.
jaeger,"During the execution of the internal tasks, new child spans are created."
jaeger,All of them are created establishing a follows from reference to the propagated parent span context.
jaeger,"All the child spans will be displayed in the same trace, as children of the main process span."
jaeger,A very similar Python version of the code is displayed below for the second worker.
jaeger,"Visualizing traces
If you deploy and start all the components and you open a browser on http://localhost:16686/, you will be able to see all the traces sent by the three apps through the Jaeger UI."
jaeger,"Jaeger UI
If you select a trace, you can see the details and the time spent from each component, also when they execute their internal tasks."
jaeger,"In the example below, we can see:
the main span created by the main service (in blue)
the spans created around the tasks executed by the first worker (in yellow)
the spans created and attached by the second worker (in brown)
All the spans are part of the same trace."
jaeger,"Application‚Äôs trace and spans
Conclusion
In the article, I presented a possible solution to instrument apps for distributed tracing when you have a system in which the services are triggered using direct requests, but not through Rest APIs."
jaeger,"So, HTTP headers are not available to propagate the context and you don‚Äôt want to introduce them in your system."
jaeger,"The aim can be reached by instrumenting the apps using Jeager, OpenTracing, and adding a message queue in the architecture for the transportation layer."
jaeger,"The presented solution can be also modified and used in an event-driven architecture, in which the services are using a message queue to share the process information."
jaeger,You can simply add the context spans information to the messages in the queue.
jaeger,This blog was originally published at https://signoz.io/blog/distributed-tracing-jaeger-cassandra/.
jaeger,"For best experience with screenshots of implementation, visit the original link

What is distributed tracing?"
jaeger,"Distributed tracing, also called distributed request tracing, is a method used to profile and monitor applications, especially those built using a micro-services architecture."
jaeger,Distributed tracing helps pinpoint where failures occur and what causes poor performance.
jaeger,How does tracing differ from logs?
jaeger,Lack of structure in logs makes indexing and hence storage costly and no proper format to search while debugging.
jaeger,"It‚Äôs all in the mental model of the developer
Logs are printed concurrently for application serving multiple requests making it difficult to debug and find the order of execution of a log line."
jaeger,"Logs do not propagate context across services
A simple workaround for maintaining context across logs is passing a global requestId in the header when one service calls another service."
jaeger,"A trace is more about an individual request and adding info to it as it moves across process boundaries, adding tags with valuable information about deployment versions, priority, IP, device info, etc."
jaeger,"Tools and cost to run it in-house
Zipkin and Jaeger are two popular choices for request tracing."
jaeger,Zipkin was originally inspired by Dapper and developed by Twitter.
jaeger,It‚Äôs now maintained by a dedicated community.
jaeger,Jaeger was originally built and open-sourced by Uber.
jaeger,Jaeger is a Cloud Native Computing Foundation project.
jaeger,"Jaeger Architecture [Official Doc]:
Instrument application using jaeger client libraries available in multiple languages
JaegerClient sends spans to jaeger-agent which is usually deployed as a daemonSet in each host to receive UDP or HTTP spans."
jaeger,"If we skip jaeger-agent and send spans directly to jaeger-collector then UDP spans may be missed
Jaeger-Agent can be set to batch the span and sample data before sending to the collector which then stores to DB for persistence
Jaeger supports Elastic, Cassandra and Kafka as backend databases but there is a github issue tracking integration of other storage plugins like BadgerKV and InfluxDB
Jaeger Query service enables querying the DB for traces via UI
Factors on which cost depends:
Level of instrumentation ‚Äî detailed instrumentation means more spans
RPS being served by applications ‚Äî more requests being served means more traces
Number of days of data retention needed ‚Äî more days of data need more storage
Infrastructure cost to run OSS tools
Employee resource to set up and maintain OSS tools
We will share a more detailed analysis of the cost to run Jaeger in-house soon."
jaeger,"Set up Jaeger for Kubernetes
We shall install Jaeger from Helm chart."
jaeger,The other recommended way to install Jaeger is using Jaeger Operator but I find the native Jaeger helm chart easier.
jaeger,"Install Prometheus Operator for enabling ServiceMonitor and visualising metrics about Jaeger by running: helm install stable/prometheus-operator
Add JaegerTracing repo to your helm
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
The below chart will deploy jaeger-agent as a DaemonSet and deploy the jaeger-collector and jaeger-query components as Deployments."
jaeger,Check the helm repo of Jaeger this Link.
jaeger,"We need to modify the values.yaml file:
provisionDataStore.cassandra=true - This the default value."
jaeger,This will create a new Cassandra cluster.
jaeger,"If we wish to use an existing Cassandra cluster check this
Enable persistence in Cassandra cassandra.persistence.enabled=true
Enable serviceMonitor for exposing Jaeger related metrics to Prometheus
serviceMonitor: enabled: true additionalLabels: {release: prometheus}
4."
jaeger,Enable sample application already instrumented to send metrics to jaeger-agent.
jaeger,Read the full blog post on this medium blog.
jaeger,"For now, we just need to set hotrod.enabled=true
With the new values.yaml file, install Jaeger with the below command:
helm install jaeger jaegertracing/jaeger -f values.yaml
Watch status of pods by running kubectl get pods -w
Now wait for Cassandra cluster to get ready."
jaeger,The collector and query service will restart several times before the DB is ready.
jaeger,"More about Cassandra setup in Jaeger
Looking at schema creation script at Jaeger Repo, the default retention period of traces in Cassandra is set to 2 days
TRACE_TTL ‚Äî time to live for trace data, in seconds (default: 172800, 2 days)`
The Replication Factor is 2 and LZ4Compressor is used to compress trace data."
jaeger,"Now run, kubectl exec -it jaeger-cassandra-0 /bin/bash to get into the Cassandra container and then run nodetool status, the below is the result:
Load Column shows the space consumed in each disk attached to Cassandra node."
jaeger,Owns column is around 67% which is correct since the replication factor is 2 and the number of nodes is 3.
jaeger,Hence 2/3 of data is in each node.
jaeger,"Table Names: dependencies_v2, duration_index, operation_names_v2, service_name_index, service_names, service_operation_index, tag_index, traces
Sample application to see tracing in work
We enabled HotROD application while installing Jaeger from helm chart, remember?"
jaeger,"To access the UI of the HotROD application run
kubectl port-forward svc/jaeger-hotrod 4000:80."
jaeger,The below screen will be visible.
jaeger,"Click on a few buttons and check whether you get a response about a driver arriving in some time, something like below."
jaeger,Now to access the Jaeger UI run kubectl port-forward svc/jaeger-query 8080:80.
jaeger,"You will see a dashboard like below:
The left-hand side panel will show you some filters to apply to your traces."
jaeger,From Services choose customer and click on Find Traces button.
jaeger,The right pane will display the list of traces.
jaeger,The below figure shows one trace from the trace list.
jaeger,"Each title in trace list displays the service which started the trace, the operation name set and the time taken by the trace on the RHS
The body shows the total number of spans in the trace and number of errors highlighted in red color
The body shows the services through which the trace has passed through
The RHS of the body also shows the time of the trace
From the right panel of dashboard, you can choose to order traces based on the longest trace or most number of spans or most recent traces."
jaeger,"Now, click on a trace to view the details of a single trace."
jaeger,An individual trace consists of many spans where each span represents a unit of operation performed by the application like calling mysql or redis or other services.
jaeger,The spans have parent-child relationships and correctly represent the order of execution (sequential or parallel) along with the time taken by each span.
jaeger,Clicking on span from mysql service shows the exact query executed and the time it takes.
jaeger,"Ideally, you should mask queries that have personal data."
jaeger,You need to check how this is handled with Jaeger instrumentation or from the collector side.
jaeger,The below image shows the left panel of Jaeger-UI in detail.
jaeger,You can filter to see traces of mysql service which took more than 1s by choosing Service and Min Duration filter.
jaeger,"You can also filter based on Operation of that service and if you wish to see all the traces where mysql service responded with an error, just set the Tags filter with value error=true."
jaeger,We can also filter based on various other tags that you have instrumented.
jaeger,Since we now know that instrumentation plays a big role in being able to filter and analyse traces based on tags.
jaeger,Most of the OpenCensus libraries provide auto-instrumentation libraries for different languages.
jaeger,"OpenTracing and OpenCensus are merged to OpenTelemetry to provide a vendor neutral instrumentation
Monitor Jaeger using Prometheus and Grafana
Run kubectl port-forward svc/prometheus-grafana 3000:80 to proxy to grafana dashboard installed in your Kubernetes cluster."
jaeger,"At the login page fill the below credentials which is the default setting when installing prometheus-operator:
username: admin password prom-operator
Go to Dashboards -> import and add id 10001 and choose data source as Prometheus."
jaeger,The publicly available dashboard can be found at this link.
jaeger,You need to generate a sufficient amount of traffic to your sample application to get such graphs.
jaeger,These graphs do not correspond to the default installation of HotROD application.
jaeger,"The above dashboard is of Jaeger Collector which displays:
Spans received per second
sum(rate(jaeger_collector_spans_received_total[5m]))
Average in-queue latency
Batch size of spans
Queue length
Spans dropped per second
Latency to save span to DB
Similar important metrics for Jaeger Agent around reporter spans submitted and batch size is displayed in the image above."
jaeger,Among other metrics are HTTP and UDP requests and drop rate of spans.
jaeger,Configure an alert on these metrics at a threshold you are comfortable with.
jaeger,Latency and Request rate to query service is also there in the dashboard to keep track of UI access.
jaeger,"Above image shows how to monitor Cassandra usage by Jaeger:
Write Error Rate sum(rate(jaeger_cassandra_errors_total[5m]))*100/sum(rate(jaeger_cassandra_attempts_total[5m]))
Read Error Rate sum(rate(jaeger_cassandra_read_errors_total[5m]))*100/sum(rate(jaeger_cassandra_read_attempts_total[5m]))
Write Duration by table
increase(jaeger_cassandra_latency_ok_sum[5m])/increase(jaeger_cassandra_latency_ok_count[5m])
Writes per second by table
sum(rate(jaeger_cassandra_inserts_total[5m])) by (table)
How to find issues from the Flame graph
Chapter 9 from this book from Yuri Shkuro, the author of Jaeger gives details on how to find patterns in your tracing data which are likely indicative of a performance issue."
jaeger,The spans with tag error=true are marked in red and can provide useful information about the error in the logs section or other tags.
jaeger,Optimising time taken by the longest span in the trace would help the most in reducing the trace time.
jaeger,Probably the server was waiting on a database query and our database driver is not instrumented for tracing.
jaeger,"Whenever a considerable portion of the trace is unaccounted for, ask for instrumentation."
jaeger,The staircase pattern means sequential execution.
jaeger,"This may require a deeper look into whether it is intended or it is happening unintentionally, if such, there lies a scope of improvement."
jaeger,"For example, I have seen many times where using an object-relational mapping (ORM) library has produced the ‚Äústaircase‚Äù pattern without the developer even realizing that it is happening."
jaeger,What could cause a series of spans to finish at the same time?
jaeger,One possible explanation is when the system supports timeouts with cancellations.
jaeger,"In the above figure, the top-level span may have been waiting for the four tasks to finish, but since they did not complete in the allotted timeframe, it canceled them and aborted the whole request."
jaeger,"In this scenario, we may want to tune the timeout parameter or to investigate why the individual work units were taking longer than anticipated."
jaeger,"Another example where we can observe this pattern is when there is a resource contention and all the requests are waiting on some lock, such as a long-running database transaction from another request that locked the table."
jaeger,"Once the lock is released, our units of work can complete quickly."
jaeger,"We may want to investigate what it is that is blocking all these spans, by adding additional instrumentation."
jaeger,"Conclusion
I have been working with Jaeger and see a lot of potential in improving the UI of traces."
jaeger,"More importantly, I would say there is a need to merge monitoring and tracing for the following reasons:
Prometheus gives us aggregated metrics, which is great for getting alerts on an erroneous service or a spike in latency."
jaeger,"To debug it, we need to drill down to traces in during that time and figure out exactly which spans and tags of traces during that time need inspection."
jaeger,Tracing alone does not provide the overall performance of a service.
jaeger,We may need to maintain SLAs of individual services and hence looking into anomalies in traces of that service needs attention on priority.
jaeger,I am also analyzing the cost of running Jaeger in-house and the price APM vendors ask.
jaeger,I think there is a huge gap in between.
jaeger,If it remains the case companies will always be confused whether to use commercial vendors or run everything in-house.
jaeger,"For any Jaeger/Tracing related queries, I am reachable at:
On a mission to make observability essential and affordable to every business"
jaeger,"Photo by Marten Bjork on Unsplash
One of the challenges of running microservice architecture software is to be able to trace requests between the hosted services including the reverse proxy or the load balancer."
jaeger,This feature is very helpful for improving the effectiveness of the operation shifts and provides the SRE engineers with all the needed information for investigating incidents on the production environments.
jaeger,"While using the ‚ÄúX-Request-ID‚Äù header and pass it to the called service can help in correlating the logs from the involved services in responding to a single request, It does not provide the needed information about the flow of the request."
jaeger,"In other words, The ‚ÄúX-Request-ID‚Äù can not tell which service called which service."
jaeger,Comparing the timestamps of the logs can helps in getting this information.
jaeger,"However, It will be a lot of effort and it will not be accurate always."
jaeger,"Another way to trace web requests flows is my implementing and using OpenTracing frameworks, libraries, and tools for tracing web requests between microservices."
jaeger,"OpenTracing is comprised of an API specification, frameworks and libraries that have implemented the specification, and documentation for the project."
jaeger,OpenTracing allows developers to add instrumentation to their application code using APIs that do not lock them into any one particular product or vendor.
jaeger,"https://opentracing.io/docs/overview/what-is-tracing/
OpenTracing supports several programming languages such as Go, Ruby, and Python (The full list can be found here)."
jaeger,"In addition, several tools and third party services are already implying and supporting OpenTracing."
jaeger,One of the tools that support OpenTracing is Traefik which is a reverse proxy and load balancer.
jaeger,"In this post, I will review and demonstrate Traefik operating support."
jaeger,"Traefik OpenTracing Support
The main idea behind OpenTracing is built around two fundamental types:
Span: is the basic object of a distributed trace."
jaeger,The span represents an action or event occurred during serving the request.
jaeger,"It also encapsulates all the needed information regarding the action such as the start time, end time and attached tags."
jaeger,A distributed trace of a given request consists of one or more spans.
jaeger,Tracers: These are applications that are responsible for creating and updating spans.
jaeger,These applications can be used also to visualize the collected spans or traces.
jaeger,Each of the tracers compatible with OpenTracing API must provide clients to be integrated with services and collect the span data.
jaeger,"Example of such applications Jaeger and Zipkin,
Traefik supports several OpenTracing backends or tracers such as Jaeger, Zipkin, Instana, and Datadog."
jaeger,That means Traefik is utilizing several tracer clients and can be configured to publish events to different OpenTracing backends based on the needs of the project.
jaeger,"Implementation
In this section, I will present how to use the open tracing feature from Traefik with two different backend Jaeger and Zipkin,
Common Configuration
The below configurations are common and applies to all the supported backends."
jaeger,"The first items set the service name on the backend application, spans and traces can be searched based on this value."
jaeger,The second item allows the truncation of the span names in case they exceed the defined length.
jaeger,The 0 value can be used to disable this feature.
jaeger,"Zipkin
Below is all the Traefik configuration that can be used to integrate Zipkin with Traefik."
jaeger,"The Configuration items include:
zipkin: Enable Zipkin as a tracing backend."
jaeger,httpEndpoint: setting the Zipkin endpoint used for collecting the events.
jaeger,sameSpan: Use Zipkin SameSpan RPC style traces or not.
jaeger,id128bit: Use Zipkin 128 bit trace IDs.
jaeger,sampleRate: a value between 0 and 1 that represents the rate of the traced requests.
jaeger,This is helpful in case we need to trace only a percentage of the requests and not 100% or the requests.
jaeger,"After deploying Traefik with the above configurations, we will start seeing that Traefik added a set of HTTP headers to be able to trace the request and pass it also the backend service so they can contribute to the trace information in case they are also supporting OpenTracing."
jaeger,"The below Image show the added headers

The below image shows the Zipkin web interface, form this UI it possible to perform the following actions
Search for a specific request trace
View The trace tags and other details."
jaeger,View the trace flow and the component or services involved in serving the request.
jaeger,"For instance, as shown in the below image we can see the involved middleware and the entry points in serving the requests."
jaeger,"Jaeger
Jaeger is the default tracing backend for Traefik."
jaeger,Below is all the Traefik configuration that can be used to integrate Jaeger with Traefik.
jaeger,"The Configuration items include:
jaeger: Enable Jaeger as a tracing backend."
jaeger,samplingServerURL: The Jaeger sampling server URL.
jaeger,"samplingParam: The enabled sampling strategy, supported values are constz: 0 or 1 value that specifies either sampling or not."
jaeger,probabilistic: sampling based on a percentage value ranges between 0 and 1. rateLimiting: sampling a specific number of requests per second.
jaeger,localAgentHostPort: Jaeger agent address (IP + port) that will be used to send data to it.
jaeger,gen128Bit: Boolean value to enable generating 128-bit trace IDs.
jaeger,This is optional.
jaeger,propagation: Propagation header type either b3 or jaeger.
jaeger,traceContextHeaderName: The HTTP header name used for the trace id.
jaeger,endpoint: The jaeger collector URL (Optional).
jaeger,user: Jaeger user (Optional).
jaeger,password: Jaeger Password (Optional).
jaeger,"After deploying Traefik with the above configurations, we will start seeing that Traefik added the defined jaeger HTTP header to be able to trace the request and pass it the backend service so they can contribute to the trace information in case they are also supporting OpenTracing."
jaeger,The below Image show the added header.
jaeger,One difference between Zipkin and Jaeger is that Jaeger uses one HTTP header for defining the trace span while Zipkin is using several HTTP headers for defining the trace span.
jaeger,Another difference is the Backend UI.
jaeger,Jaeger UI is more friendly and supports more features such as trace filtering and comparing different traces.
jaeger,The below image shows the Jaeger interface and how the spans are viewed on the UI.
jaeger,Below is the docker swarm stack that I used to deploy Traefik with Both Zipkin and Jaeger.
jaeger,"Conclusion
Distributed Tracing is very helpful for debugging and monitoring modern distributed software architectures, such as microservices."
jaeger,Trafik supports several OpenTracing backends and it provides straightforward and simple configurations for integrating Traefik with these backends.
jaeger,"While building applications that comprises of multiple microservices, it is essential to have a mechanism in place to collect and analyze the details of API calls, timing data needed to troubleshoot latency problems and logging error generated from API calls."
jaeger,"Jaeger is one such solution and used for monitoring and troubleshooting application built following microservice based architecture with following capabilities:
Distributed context propagation
Distributed transaction monitoring
Root cause analysis
Service dependency analysis
Performance / latency optimization
Jaeger is hosted by the Cloud Native Computing Foundation (CNCF) as the 7th top-level project (graduated in October 2019)."
jaeger,"Eclipse MicroProfile, OpenTracing and Jaeger
As there are multiple tracing solutions out there similar to Jaeger(such as Zipkin), it is really good to avoid vendor lock-in by having some standardization around APIs that work with different providers.The OpenTracing addresses this part of the problem, it a vendor-agnostic API to help developers easily instrument tracing into their code base without worrying about underlying tracing implementation."
jaeger,Good news is that Eclipse MicroProfile has standardized the use of OpenTracing API in the stack.
jaeger,You can find more details here: https://github.com/eclipse/microprofile-opentracing .
jaeger,"In nutshell, you can switch between various tracing implementations without making any major code change in your application."
jaeger,"The changes are limited to making some config entries in the application depending upon the tracing provider(and your customization requirements) and then of course, using the right dependency based on the vendor."
jaeger,"Helidon MP and Jaeger
In this post I am sharing simple Helidon MicroProfile based application that uses Jaeger to trace the API calls."
jaeger,"Heres is the link to the official doc :https://helidon.io/docs/latest/#/tracing/03_jaeger
The complete source used for building this example is available here: https://github.com/jobinesh/cloud-native-applications/tree/master/helidon-example-mp-jaeger ."
jaeger,"As you have noticed, this is a regular simple Helidon MP application."
jaeger,"That said, however, a couple of things thing that you my find interesting in this example application:
Dependency to helidon-tracing-jaeger in the pom."
jaeger,"Here is the pom used for this example: https://github.com/jobinesh/cloud-native-applications/blob/master/helidon-example-mp-jaeger/pom.xml
Jaeger Tracing Config in the application.yaml: https://github.com/jobinesh/cloud-native-applications/blob/master/helidon-example-mp-jaeger/src/main/resources/application.yaml
The org.eclipse.microprofile.opentracing.Traced annotation: This allows fine-tuned control over which classes and methods create OpenTracing spans."
jaeger,More details here:http://download.eclipse.org/microprofile/microprofile-2.0-javadocs-test/apidocs/org/eclipse/microprofile/opentracing/Traced.html.
jaeger,"The following GreetResource class from this example uses this annotation (specified at class level): https://github.com/jobinesh/cloud-native-applications/blob/master/helidon-example-mp-jaeger/src/main/java/io/helidon/examples/mp/jaeger/GreetResource.java
How to run this example?"
jaeger,"The detailed steps are available here: https://github.com/jobinesh/cloud-native-applications/blob/master/helidon-example-mp-jaeger/README.md
This post originally appeared on Jobinesh‚Äôs personal blog page: https://www.jobinesh.com/2020/04/tracing-api-calls-in-your-helidon.html
The views expressed on this post are my own and do not necessarily reflect the views of my employer."
jaeger,"Why you must start becoming familiar with Jaeger, Zipkin and all OpenTracing based libraries."
jaeger,"In our daily work, as developers working on a fast-changing startup environment, it's almost impossible to accomplish all product features without adding some more complexity to already existing processes (and currently we have a lot)."
jaeger,"A basic development pipeline would be:
Write code
Test locally
Test on distributed dev environment
QA test
Production release
No one squad is encouraged about one system itself, no one works as a maintainer for a specific one, instead, we are problem owners."
jaeger,One problem could involve 1 to N systems.
jaeger,"So, depending on what problem you're solving, you could need to write code in more than one service."
jaeger,"Unit and integration tests are a great option to validate if your feature works as expected, but just as API level."
jaeger,"When you need to start integrating with other services, maybe you want to know which payload you are sending and receiving, validate timeouts for requests, or just validate the order of the executions."
jaeger,"Most of the time, this problem is solved by adding logs."
jaeger,"log.info(‚ÄúSaving owner info: Property id {}‚Äù, propertyId);
Ok, it works."
jaeger,"We have some tools to organize application logs, such as Kibana."
jaeger,The problem starts when you need to track a request that involves more than two services.
jaeger,"I faced that problem and solved it by adding the relevant identifiers to that log:
log.info(‚Äú[MY-FEATURE] Saving owner info: Property id {}‚Äù, propertyId);
Well, now our code starts looking a little tangled."
jaeger,I have a log identifier (MY-SERVICE) and could filter by propertyId.
jaeger,What if the second service doesn‚Äôt receive a propertyId as a parameter?
jaeger,"You must remember that each service is a business domain abstraction, so most of the cases, you won‚Äôt have the same parameters to track your logs."
jaeger,The problem starts growing.
jaeger,"Now, imagine a weird bug in production."
jaeger,"No one knows where it is, but some features are not working properly because of it."
jaeger,"Let‚Äôs make this example harder: That feature is on the payment process, so basically, the company is losing money."
jaeger,"The first option is to watch the logs, they always have the truth."
jaeger,What if they don‚Äôt have a log identifier?
jaeger,We start filtering information based on what we know about the bug.
jaeger,Which system should we start looking at?
jaeger,Where did the service execution start?
jaeger,"We can solve that problem using just logs and our experience (we did it in the past), but wasting engineering efforts while losing money ‚Äî at the same time ‚Äî is never always a good choice, we must find a better way to solve this!"
jaeger,"At this point, logs are not enough."
jaeger,We need to start tracing.
jaeger,"Distributed tracing, also called distributed request tracing, is a method used to profile and monitor applications, especially those built using a microservices architecture."
jaeger,Distributed tracing helps pinpoint where failures occur and what causes poor performance.
jaeger,‚Äî OpenTracing foundation.
jaeger,Let‚Äôs think about tracing as a higher log level.
jaeger,"Logs are simple units, isolated and without any relationship between them."
jaeger,"Tools like Kibana can organize it in a more readable way, but the information they give is limited."
jaeger,Implementing tracing is not only adding a new library.
jaeger,"We need some external tools to make the insights make sense, such as a traces collector."
jaeger,"The OpenTracing foundation has created a set of conventions and practices adopted by almost all tracing libraries to make them compatible, even when the services are not written in the same language."
jaeger,"After all, if we are talking about a cross tracing service for our entire micro-service ecosystem, language should not be a problem."
jaeger,How complex is our platform?
jaeger,I consider this is the first question before choosing a solution.
jaeger,Some service discovery tools allow us to trace requests between services.
jaeger,"If our platform is at an early stage, we could mix those traces to see where the request stopped, with the container logs of the last service called on the request."
jaeger,"Of course, it means we still depending on how much logs we have implemented and our service discovery provider."
jaeger,"In our case, Istio ‚Äî our Service Mesh ‚Äî is tracking every internal call between services, so it‚Äôs easy to see the complete request trace at a high level."
jaeger,"Traces at the request level
Most of the companies started with a single app."
jaeger,"A main project whose with the pass o time, gain more and more features, with a mix of practices, with some difficulties to maintain and for some unknown reason, each time becomes harder to deploy locally."
jaeger,Commonly known as The Monolith.
jaeger,"Now, 7 years later, due to the big amount of features and internal services inside, this monolith needs to be traced too."
jaeger,Having traces at the service mesh level is not enough and logs are not solving that problem.
jaeger,"Also, as the monolith growth, new microservices were created, in fact, currently, we have more than ~100 microservices in production ‚Äî and there is a big chance I‚Äôm outdated about the quantity ‚Äî so, we really need to know what is happening inside each one."
jaeger,"Uber, Jaeger, and OpenTracing
Same as other startups such as Netflix and Airbnb, Uber gave a big contribution to the open-source software community: Jaeger."
jaeger,"They developed a set of services to generate traces, process and collect them, showing the result in an interactive dashboard."
jaeger,"Later, Uber left the project and the Cloud Native Computing Foundation improved it, under the OpenTracing principles."
jaeger,Implementing Jaeger is very easy if your application libraries are updated (at least you have the last 2 years version).
jaeger,"Some frameworks like Spring include plug and play starters, so just add the dependencies, configure some properties and you‚Äôre ready."
jaeger,"Some of the properties you need to be familiar with are:
Sender URL, it‚Äôs the collectors URL."
jaeger,"You have two options to send traces, HTTP or UDP protocol."
jaeger,Sampling is the param to inform to collector how many requests we want to trace.
jaeger,"For example, you could specify to trace just 2 requests per second."
jaeger,Service name refers to the name you will see in the dashboard for this service.
jaeger,"Since the following examples will be based on a Java application, core concepts are based on opentracing conventions, so you will find exactly the same names in the docs for other programming languages."
jaeger,"If you want to know how to integrate the Jaeger Spring starter with your application, just take a look at the official repo and follow the readme file."
jaeger,"As we want to add tracing to our monolith, the starter doesn‚Äôt work for us, so we will do it manually."
jaeger,"First, we will add the dependencies:

Then, we will configure our Tracer."
jaeger,"There are some concepts you need to be familiar with to understand how it works:
Trace, the big unit."
jaeger,"This refers to the complete process, the entire travel."
jaeger,Span is the basic information unit.
jaeger,It‚Äôs related to one trace id.
jaeger,A trace can have multiple spans.
jaeger,Tag is very specific information.
jaeger,"You could configure tags for a span, such as parameters, logs, or some other relevant info."
jaeger,"So, let‚Äôs start configuring our Tracer."
jaeger,"Same as any other bean able to be created once and used through the entire application, we will use the spring context to mark it as a managed bean:

Explaining each line:
From lines 5 to 10 we are just getting preconfigured values from a properties file."
jaeger,Line 14 we create a Tracer object from the opentracing package.
jaeger,Line 15 we create a B3 map encoder.
jaeger,"We will talk about that in a few seconds‚Ä¶
Line 17 and 18 is creating an AsyncReporter, it will be encouraged to encode the trace payloads in the right format to be consumed by the collector."
jaeger,Line 21 creates the JaegerTracer object using the objects created lines above.
jaeger,"Now, pay attention to lines 22, 23."
jaeger,".registerInjector(Format.Builtin.HTTP_HEADERS, b3Codec) 
.registerExtractor(Format.Builtin.HTTP_HEADERS, b3Codec)
We explained before Trace is the biggest unit."
jaeger,"So, if we are tracing across multiple distributed services‚Ä¶."
jaeger,"all of them should have the same trace ID, right?"
jaeger,How those services will know the base trace id?
jaeger,That‚Äôs where the opentracing foundation standards take action.
jaeger,We can ‚Äúinject‚Äù information to one trace.
jaeger,"So, when the trace leaves the current service (ex."
jaeger,"some request) he goes with some information, such trace id."
jaeger,"Same way, we can ‚Äúextract‚Äù information from an incoming request, here the scenario changes, but don‚Äôt worry, we will see it later."
jaeger,The important thing by.
jaeger,now is you understand we can send and consume trace information between services.
jaeger,Where is that information stored?
jaeger,Headers.
jaeger,"Opentracing foundation defined a group of headers called B3-headers, where you will find relevant trace information."
jaeger,"Those headers are not stored in some database, they travel through your entire process injected on each request, being consumed and repeating the cycle through the end."
jaeger,"x-b3-traceid
x-b3-spanId
x-b3-parentspanid
x-b3-sampledx-b3-flags
So, coming back to lines 22 and 23, we are just saying to the tracer ‚ÄúHey, make sure you will check if there is an existing trace, use the same."
jaeger,"Also, send the trace information on each outgoing request‚Äù
At this point we have a JaegerTracer configured."
jaeger,Now we should start tracing all incoming requests.
jaeger,"Again, in Spring projects ‚Äî or another modern framework ‚Äî , we have this feature enabled for free."
jaeger,"In our case, we will create a filter class and create the trace at this level:

Explaining what are we doing here, just getting request information and creating a new trace in a try with resources structure."
jaeger,"Look at the lines 12 and 13:
try (Scope incomingRequest = initSpan(extractHeaders(req), resource)) {."
jaeger,"incomingRequest.span().setTag(Tags.HTTP_METHOD.getKey(),    req.getMethod()); chain.doFilter(request, response); 
}
Scope is our local trace."
jaeger,The Scope is creating a Span object.
jaeger,"Inside the Span, we are creating Tags."
jaeger,"Let‚Äôs explain:

Let‚Äôs look at those 2 weird and unknown methods: initSpan and extractHeaders:

We are creating a span for this method."
jaeger,"The jaegerTracer is an instance of our configured tracer, and basically we are asking if the incoming request has the b3 headers."
jaeger,"If true, we will create a child span based on the tracer information provided by those headers, if not, you will start a new trace context."
jaeger,"When we are working with nested methods, and we are tracing each one, the spans objects of the lower-level methods are automatically created as a child of the higher ones."
jaeger,"Finally, the helper method to extract headers:

Now, we have all incoming requests to our application traced."
jaeger,"Let‚Äôs test it locally using an all-in-one docker image:
docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 14250:14250 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.17
Then, configure the properties to target the container URL and run your application, do some request and look at the Jaeger UI:

You can find the entire filter code here."
jaeger,What about the inner methods?
jaeger,"Yes, that‚Äôs the main reason we decided to start using tracing."
jaeger,"The same way we created a scope and span objects on filter ‚Äî the highest level in our application ‚Äî we can now copy the same logic on inner application methods;

As explained before, each span created under a higher-level method ‚Äî traced, of course ‚Äî , will be created as a child span."
jaeger,Should I write the same code for each method I need to trace?
jaeger,"Since we are already using Spring in our application, we could improve the code using some aspects."
jaeger,"In our case, we decided for creating a class-level annotation, so we could add tracing for an entire resource, service or repository object level with just one line of code."
jaeger,"And the aspect configuration:

Now, you just need to add @Traceable annotation on each class you want to trace."
jaeger,"Just to keep in mind, Spring AOP cannot proxy private methods, so in case do you need to trace them, you could use manual implementation."
jaeger,"Don‚Äôt worry, all of them are created under the same Scope."
jaeger,"First results in prod
We implemented tracing in all our core services as a first step to release."
jaeger,"Once deploy was ready, the first results were very satisfactory."
jaeger,We decided to use Honeycomb as the main collector for our platform traces instead of the native Jaeger UI.
jaeger,Why?
jaeger,"Honeycomb offers a so much better query system, allowing us to save time and effort to catch the trace we need and also centralize our performance metrics in just one place."
jaeger,Find more info about this awesome tool here.
jaeger,"It allows us to identify and solve critical problems such:
Queries taking so much time at the database level
Circular dependencies between services
Process optimization for scale
Each line you see is a span."
jaeger,"Each span has relevant information allowing us to detect critical errors in prod very fast, saving time, engineering effort and money."
jaeger,Metrics are the key factor for success.
jaeger,Monitoring our systems allows us to anticipate unexpected scenarios and improve our resilience and reliability strategies.
jaeger,Liked this content?
jaeger,Want to work on a highly distributed environment in an evolving microservice architecture while fundamentally impacting the lives of hundreds of thousands of people in one of the fastest-growing markets?
jaeger,Come reinvent people's way of living with us!
jaeger,"Today we are going to see a fabulous open-source tool to perform different types of tasks, from tracing, monitoring, or instrumentation: InspectIT."
jaeger,"This tool is a Java Agent, which we already know a little better from the last post we did, and you can see it here."
jaeger,This software tries to minimize two things.
jaeger,"On the one hand, the configuration time needed to use other Application Performance Management, APM, tools."
jaeger,"Such as Jaeger, Prometheus, Zipkin or Micrometer."
jaeger,"And on the other hand, reduce the modifications to be made in our applications, if we want to perform instrumentation tasks."
jaeger,"InspectIT is based on OpenCensus, which is a set of open software libraries made in different languages that allow us to obtain distributed metrics and traces."
jaeger,This software already has a wide range of exporters that allow sending the information to other monitoring tools.
jaeger,And InspectIT supports most of these exporters.
jaeger,"For all these reasons, InspectIT is a great tool."
jaeger,As it is a Java Agent we will not need to modify our applications to obtain performance information.
jaeger,"And with the preconfigured exporters, we can obtain metrics and traces automatically and send them to different destinations."
jaeger,"Through the examples, we will be able to see how to obtain this information from our application."
jaeger,The operation will be similar in the different examples.
jaeger,"In order to make it work we will have to follow the next two steps:
Associate the java agent stored in the library through the JVM argument ‚Äò-javaagent:/full/path/to/library‚Äô."
jaeger,Associate through a JVM argument the exporter property to be used.
jaeger,"We can associate one or more properties, each one with its corresponding argument."
jaeger,"For the first example, we will use a Jaeger exporter, with which we will be able to obtain the application traces."
jaeger,"The base of it will be one of our examples that we have done in previous posts, based on Apache Camel, and that you can see here."
jaeger,"Just to remember, Jaeger is a tool or Tracer that will allow us to collect the information of the traces of our application and to visualize them in an own graphical interface."
jaeger,"The steps are as follows:
On the one hand, we have to download the library that contains the java agent, we can do it from here."
jaeger,And we place it in a path that we will indicate later when we start the application.
jaeger,"Start Jaeger, for example with a docker-compose like the following one."
jaeger,"version: '2.4'
networks:
  sandbox-apache-net:
    ipam:
      driver: default
      config:
        - subnet: 172.24.0.0/16
services:
  mysql:
    image: mysql:5.7.26
    mem_limit: 2G
    container_name: sandbox-apache-mysql
    hostname: sandbox-apache-mysql
    networks:
      sandbox-apache-net:
        ipv4_address: 172.24.1.1
    environment:
      MYSQL_HOST: sandbox-apache-mysql
      MYSQL_ROOT_PASSWORD: root
    ports:
      - 3306:3306
    volumes:
      - ./configs/mysql/conf.d/custom.cnf:/etc/mysql/conf.d/custom.cnf
      - ./configs/mysql/scripts:/docker-entrypoint-initdb.d
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - 16686:16686
      - 14268:14268
Finally, start the JVM passing the arguments that allow us to configure the desired exporter."
jaeger,"For the case of Jaeger we will use the following ones:
-javaagent:/home/deesebc/Downloads/inspectit-ocelot-agent-1.8.1.jar -Dinspectit.exporters.tracing.jaeger.url=http://127.0.0.1:14268/api/traces 
-Dinspectit.exporters.tracing.jaeger.service-name=inspectitJaegerExample
In the URL property, we indicate the address where Jaeger is located, and with service-name we can indicate the name with which we will register the Jaeger traces."
jaeger,"As a previous step to see how Jaeger works, we are going to make several queries to our application."
jaeger,So that they can be registered by InspectIT.
jaeger,"If you use the code of my application, it will be an invocation similar to this: http://localhost:9090/book/1."
jaeger,If we access the URL http://localhost:16686/search we will be able to access the trace browser and search for our application‚Äôs traces.
jaeger,"In the next example, to see more of the potential of InspectIT and to see how it works to obtain metrics, we will make use of the exporters for Prometheus."
jaeger,The example on which we will be based will be this one.
jaeger,We start again preparing a docker-compose that allows us to deploy Prometheus.
jaeger,"We can base it on the one from the previous example and it would be something similar to this:
version: '2.4'
networks:
  sandbox-apache-net:
    ipam:
      driver: default
      config:
        - subnet: 172.24.0.0/16
services:
  mysql:
    image: mysql:5.7.26
    mem_limit: 2G
    container_name: sandbox-apache-mysql
    hostname: sandbox-apache-mysql
    networks:
      sandbox-apache-net:
        ipv4_address: 172.24.1.1
    environment:
      MYSQL_HOST: sandbox-apache-mysql
      MYSQL_ROOT_PASSWORD: root
    ports:
      - 3306:3306
    volumes:
      - ./configs/mysql/conf.d/custom.cnf:/etc/mysql/conf.d/custom.cnf
      - ./configs/mysql/scripts:/docker-entrypoint-initdb.d
      
  prometheus:
    image: prom/prometheus:v2.6.1
    ports:
      - 9091:9090
    volumes:
      - ./configs/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      sandbox-apache-net:
        ipv4_address: 172.24.1.2
    extra_hosts:
      docker.host: 172.28.0.1
172.28.0.1 is the IP of the docker bridge interface."
jaeger,The next point will be to start our application with the arguments that allow us to export the information to Prometheus.
jaeger,"-javaagent:/home/deesebc/Downloads/inspectit-ocelot-agent-1.8.1.jar -Dinspectit.exporters.metrics.prometheus.host=172.28.0.1 
-Dinspectit.exporters.metrics.prometheus.port=8888
Let‚Äôs remember that for Prometheus to work it has to read, from a specific URL, information about the application."
jaeger,So on the one hand we must configure Prometheus to read from a specific point.
jaeger,"And we will do this through the Prometheus configuration file (part of the docker-compose):
scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 1m
    static_configs:
      - targets: ['localhost:9090']
  - job_name: 'apache_example'
    scrape_interval: 1m
    metrics_path: '/metrics'
    static_configs:
      - targets: ['172.28.0.1:8888']
And through the JVM arguments, we will indicate to InspectIT that we want to expose the information of our application in the IP and port indicated."
jaeger,Something that in the example on which we based was done by Spring Actuator.
jaeger,"Once everything is started, we will make a couple of invocations as mentioned above."
jaeger,And now we can access Prometheus and see the monitoring that has been done.
jaeger,If we access the route http://localhost:8888/metrics we will be able to see the different metrics that we are generating from the application.
jaeger,And if we access the Prometheus URL http://localhost:9091/targets we can see if our endpoint is being read correctly by Prometheus.
jaeger,The next step will be to access http://localhost:9091/graph and make a graph based on the metrics obtained.
jaeger,"For example, one that counts the invocations that we make to endpoints of our application, through the parameter http_in_count."
jaeger,"As you can see, it‚Äôs really easy."
jaeger,There are no more excuses to perform application performance management tasks with InspectIT.
jaeger,"And these are just a couple of examples, but you can do more through the different exporters."
jaeger,"Table of contents
Distributed monitoring pain point
Limitations of standard Kubernetes dashboard and in-house tool
cAdvisor
Kube-state-metrics
Prometheus
Grafana
Kubewatch
Jaeger
MetricFire
Conclusion
Distributed monitoring pain point
The growing adoption of microservices architecture is also driving the adoption of containers to package, distribute and run the microservices."
jaeger,"This requires orchestrators to handle availability, performance, and deployments of those containers on the server."
jaeger,"However, the entire setup around microservices, containerization, and orchestrators complicates logging and monitoring since various distributed and diversified applications are interacting with each other."
jaeger,"A single point of failure can sometimes discontinue the uninterrupted process, making us aware of the issue, but detecting other issues is another story."
jaeger,"Although a container orchestration tool such as Kubernetes orchestrates containers in various distributed systems and subdues the intricacies introduced by distributed processing, Kubernetes is itself complicated and has too many components to monitor."
jaeger,"Unlike a monolithic application where there are just two components to monitor ‚Äî applications and the hosts, Kubernetes has four: Nodes(hosts), the Kubernetes platform itself, Docker containers, and the containerized microservices."
jaeger,"Evidently, traditional monitoring tools that log parameters like CPU use, memory use, input-output (I/O) per second, latency, and network bandwidth are rendered inadequate in a cloud-native era of Microservices, Docker containers, and Kubernetes."
jaeger,The monitoring strategies in the cloud-native era need granular detail at the container or services level.
jaeger,"Moreover, traditional monitoring methods were devised along with a long-running host model."
jaeger,"A traditional data center is formed of a number of servers hosting monolithic applications, with static IPs and hostnames."
jaeger,"The monitoring was associated with these constant parameters, rarely changing in opposition to microservices architecture."
jaeger,Microservices-based applications are characteristically deployed on containers that are dynamic and transient.
jaeger,Kubernetes requires a number of application models to be running.
jaeger,Kubernetes has this tendency to place the pods on whichever nodes it deems fit unless otherwise indicated.
jaeger,"Actually, Kubernetes‚Äô ability to schedule pods is the epitome of its self-adjusting system."
jaeger,"Therefore, monitoring tools in containerized environments need to offer instant service-discovery and auto-detection of lifecycle events of containers."
jaeger,They should also require adjusting metrics as containers are created or restarted every second.
jaeger,"In a nutshell, identifying problems in a microservices environment is a little more challenging than in a monolithic environment, as requests navigate between various stack layers under the multitudes of services."
jaeger,Modern monitoring tools are required to monitor these interconnected layers while also resourcefully classifying application and infrastructure behavior to simplify troubleshooting.
jaeger,"Limitations of standard Kubernetes dashboard and in-house tools
The standard Kubernetes dashboard offers a basic UI that displays resource utilization information."
jaeger,"In addition, it can organize applications running in the cluster and the cluster itself."
jaeger,"However, the Kubernetes dashboard lacks the sophistication of more advanced Kubernetes monitoring tools such as Prometheus and Grafana."
jaeger,"On top of that, the Kubernetes dashboard relies on Heapster, a deprecated performance monitoring and metrics collection system for Kubernetes."
jaeger,Organizations invested in Kubernetes should look across the plethora of monitoring tools instead of developing their own tools internally.
jaeger,"The following tools are not only efficient at monitoring Kubernetes, they are also undergoing constant improvement owing to an open-source community."
jaeger,"Introduction
When it comes to developing applications within the microservice architecture, the number of microservices can grow quickly."
jaeger,Managing microservices becomes harder with each new or updated microservice.
jaeger,"When an application experiences a slowdown and its ‚Äúdata flow‚Äù goes through several different microservices, pinpointing the exact location of a slowdown may be difficult for a developer."
jaeger,"Before starting with the actual code and tutorial portion, let us start with a brief explanation of what tracing is."
jaeger,Tracing is a way to track a request from its starting point through the entire network of microservices.
jaeger,"In a typical Java microservice application, the ‚Äúchain‚Äù starts either with the front-end or API making a REST request to some entry microservice."
jaeger,"That microservice then handles the request (usually with JAX-RS) and queries other microservices, databases, or external applications."
jaeger,"As we can see, the number of requests inside the network increases and spreads out throughout multiple different destinations (especially in large applications)."
jaeger,"This is all well and good, but when a problem occurs a developer must go through a lot of logs (produced by the selected logging framework, such as Fluentd or Logstash ‚Äî in KumuluzEE you can use the KumuluzEE Logs extension to simplify logging) to find the problem."
jaeger,"If a problem is severe (such as a complete crash), a solution is usually discovered quickly or even handled automatically by some container orchestration tool (such as Kubernetes)."
jaeger,Tougher problems are the slowdowns in which the application still works but in a limited capacity.
jaeger,This is where the tracing comes in.
jaeger,"When implemented across the entire application, entire request flows are saved and presented to the user in an easy to use graphical interface."
jaeger,The base unit is called a span.
jaeger,A span can be an incoming or outgoing request; execution of a Java method; access to the database; etc.
jaeger,Each span contains basic information such as name and timestamps (additional data can be added within the code).
jaeger,"Spans are related to each other (children, nested spans) and together form a ‚Äútrace.‚Äù More detailed analysis can be made by joining microservices and their relations to a graph."
jaeger,"In conclusion, a trace is a sequence of events, called spans, which describe a path through the application."
jaeger,"KumuluzEE OpenTracing
KumuluzEE OpenTracing was released as an extension for the KumuluzEE framework."
jaeger,It is a part of MicroProfile specification.
jaeger,It supports both Jaeger and Zipkin.
jaeger,We will demonstrate how to add tracing to an existing KumuluzEE application using the KumuluzEE OpenTracing extension.
jaeger,The whole process will be demonstrated step-by-step with screenshots of each step.
jaeger,"Prerequisites
Before starting, make sure, that you have the following things ready:
Installed Java (8 and up)."
jaeger,"Installed Docker (for running Jaeger or Zipkin; this is optional if you are going to run Jaeger/Zipkin as a standalone service),
Cloned starting project from GitHub (https://github.com/kumuluz/kumuluzee-samples/tree/master/kumuluzee-opentracing-tutorial)."
jaeger,"Jaeger
Running Jaeger can be as simple as entering this line in the console:
$ docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.9
The Jaeger GUI is now accessible on http://localhost:16686."
jaeger,It consists of three main screens.
jaeger,"The first one is the ‚ÄúSearch‚Äù tab, which enables us to search through our traces with different criteria."
jaeger,"Search tab in Jaeger GUI
The second one is the ‚ÄúCompare‚Äù tab, which allows for a comparison of two spans."
jaeger,"Compare tab in Jaeger GUI
The last one is the ‚ÄúDependencies‚Äù tab, which displays a graph of our microservices and their respective connections (not shown due to being an empty page)."
jaeger,"Right now, we have no data."
jaeger,Sample data can be added by exploring the GUI because Jaeger adds its own traces.
jaeger,"Trace list in Jaeger GUI
We can now open one trace."
jaeger,"Trace details in Jaeger GUI
Zipkin
If you have chosen to use Zipkin instead of Jaeger, Zipkin can also be run inside Docker:
docker run -d -p 9411:9411 openzipkin/zipkin
The Zipkin GUI is accessible on http://localhost:9411."
jaeger,The interface is very similar to Jaeger.
jaeger,"The entry screen looks like this:

Search tab in Zipkin GUI
We can not test Zipkin yet due to not having any data (Zipkin does not store its own traces)."
jaeger,"Starting Project Structure
Before diving deeper, let us explain our starting project."
jaeger,"The project consists of 5 microservices:
master ‚Äî This is the entry point of the application."
jaeger,It is served on http://localhost:8080 (actual endpoint on v1/master).
jaeger,"When queried, it makes two requests: to the alpha endpoint v1/alpha and to the beta endpoint v1/beta."
jaeger,alpha ‚Äî This is the first of 4 ‚Äúslave‚Äù microservices.
jaeger,"It is served on http://localhost:8081 and has two endpoints: /v1/alpha (just returns a value) and /v1/alpha/beta, which queries the gamma endpoint v1/gamma."
jaeger,beta ‚Äî This is the second of 4 ‚Äúslave‚Äù microservices.
jaeger,"It is served on http://localhost:8082 and has one endpoint: /v1/beta, which queries alpha endpoint /v1/alpha/beta."
jaeger,Simulated lag is added to this request (random delay).
jaeger,gamma ‚Äî This is the third of 4 ‚Äúslave‚Äù microservices.
jaeger,"It is served on http://localhost:8083 and has one endpoint: /v1/gamma, which queries delta endpoint /v1/delta."
jaeger,This microservice is different because it uses a simulated database with CDI.
jaeger,delta ‚Äî This is the last of 4 ‚Äúslave‚Äù microservices.
jaeger,"It is served on http://localhost:8084 and has one endpoint: /v1/delta, which just return a value."
jaeger,"Microservices and their connections
Adding KumuluzEE OpenTracing Dependency
To start with tracing the first thing we need to do is add the KumuluzEE OpenTracing dependency to our application."
jaeger,"Locate the pom.xml file in the root folder and add the following dependency for Jaeger:
<dependency>
    <groupId>com.kumuluz.ee.opentracing</groupId>
    <artifactId>kumuluzee-opentracing-jaeger</artifactId>
    <version>${kumuluzee-opentracing.version}</version>
</dependency>
For Zipkin:
<dependency>
    <groupId>com.kumuluz.ee.opentracing</groupId>
    <artifactId>kumuluzee-opentracing-zipkin</artifactId>
    <version>${kumuluzee-opentracing.version}</version>
</dependency>
This needs to be done for all microservices."
jaeger,"At the time of writing this post, the latest version of KumuluzEE OpenTracing was 1.3.1."
jaeger,You do not need to add the version manually because the version is defined in the root pom as a variable and will be used automatically.
jaeger,"Just by adding this dependency, tracing is automatically enabled on all incoming JAX-RS requests."
jaeger,"To see how this looks inside your chosen tracing GUI, simply visit the master endpoint in your browser:
http://localhost:8080/v1/master."
jaeger,"After the page loads, we will see if any traces were added."
jaeger,"Traces in Jaeger without any names and connections between them

Traces in Zipkin without any names and connections between them
Commit for this step (for Jaeger)
We can see that there is a trace for each microservice with confusing names."
jaeger,"That is not what we want, but it is a good first step."
jaeger,"The next step is to add the service name configuration field in order to make our traces more readable since the default service name is the Kumuluz instance id, which is just a bunch of numbers and letters (as seen in the image)."
jaeger,We can do this in the config.yml file (located in src/main/resources).
jaeger,"Add the service name field:
kumuluzee:
  opentracing:
    jaeger:
      service-name: master 
    zipkin:
      service-name: master
We can also add the property kumuluzee.name, which will be used as a service name if the service name is not provided (the service name is checked first, then kumuluzee.name and lastly the instance id)."
jaeger,"Remember, this needs to be done for all five microservices."
jaeger,Let us rerun our microservices and try again.
jaeger,"Traces are now more human-friendly and readable:

Traces in Jaeger with added names

Traces in Zipkin with names
There are several other settings available, but we do not need them for this sample."
jaeger,"For more information about other settings, check the KumuluzEE OpenTracing GitHub page."
jaeger,Note: Settings for Jaeger and Zipkin are different.
jaeger,Make sure that you are setting the correct fields.
jaeger,"Commit for this step (for Jaeger)
Adding JAX-RS Outgoing Requests Tracing
As already mentioned before, incoming JAX-RS requests are traced automatically."
jaeger,The same does not apply to outgoing requests.
jaeger,"At the moment, we have traces for each individual microservice, but we want to see the whole trace grouped together."
jaeger,We need to add some code to achieve that.
jaeger,"First, locate the Resource.java file (src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/master) and change the initialization logic for the Client class."
jaeger,"private Client client = ClientBuilder.newClient();
with
private Client client = ClientTracingRegistrar.configure(ClientBuilder.newBuilder()).build();
For a microservice to resume the trace of some other microservice, the details of the trace need to be sent along with the REST request (achieved with HTTP headers)."
jaeger,This is what a ClientTracingRegistrar.configure method does: it makes sure that the required headers are added to each outgoing request.
jaeger,"After changing this line in all microservices (except the delta microservice, which does not have a client), the result should be the following trace:

Traces in Jaeger with added connections

Traces in Zipkin with added connections
If we open this trace, we can see the whole request with all the microservices in one."
jaeger,"Full trace view in Jaeger

Full trace view in Zipkin
This is exactly what we wanted; the overview of the whole request will all the timestamps."
jaeger,"We can also look at the ‚ÄúDependencies‚Äù tree now, which is updated with our microservices:

Dependencies view in Jaeger

Dependencies view in Zipkin
Commit for this step
Additional Features
We will demonstrate three additional features of tracing:
Handling exceptions in spans."
jaeger,Adding custom data to spans.
jaeger,Adding custom spans (such as database access).
jaeger,"Handling Exceptions
Exceptions are handled automatically by KumuluzEE OpenTracing."
jaeger,"To demonstrate this, we will throw an exception in the delta microservice."
jaeger,"Locate the Resource.java file (src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/delta) and add the following line:
@GET
public Response get() {
    throw new RuntimeException(""Something went wrong here."
jaeger,""");
    // return Response.ok(""delta"").build();
}
We now have to restart the delta microservice and refresh the page."
jaeger,"The created trace now looks like this:

Excepion preview in Jaeger

Exception preview in Zipkin
We can see from the trace that exception was added to the trace as a log."
jaeger,We will cover adding logs in the next section.
jaeger,"Adding Custom Data to Spans
If we look back to our project structure, we added some simulated lag to our application in the beta microservice."
jaeger,"Basically, we added a random delay from 1 to 1000 milliseconds to the request."
jaeger,We will add this parameter to the trace to see how long we have to wait for the request.
jaeger,We start by moving the wait time to a new variable.
jaeger,Then we inject the Tracer instance (we also added @RequestScoped for CDI injection).
jaeger,"After that, we can access the current span with tracer.activeSpan and add our delay to it."
jaeger,"We can do it in three ways: with adding a tag, adding a log entry or adding a baggage item."
jaeger,"We will demonstrate all three:
setTag();
log();
setBaggageItem();
Full code (src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/beta/Resource.java):
@Path(""beta"")
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
@RequestScoped
public class Resource {
    private Client client = ClientTracingRegistrar.configure(ClientBuilder.newBuilder()).build();
    @Inject
    private Tracer tracer;
    @GET
    public Response get() {
        try {
            int waitDelay = ThreadLocalRandom.current().nextInt(1, 1000 + 1);
            tracer.activeSpan().setTag(""waitDelay"", waitDelay);
            tracer.activeSpan().log(""Waited "" + waitDelay + "" milliseconds."
jaeger,""");
            tracer.activeSpan().setBaggageItem(""waitDelay"", String.valueOf(waitDelay));
            Thread.sleep(waitDelay);
            Response r1 = client
                    .target(""http://localhost:8081/v1"")
                    .path(""alpha"")
                    .path(""beta"")
                    .request()
                    .get();
            String response = r1.readEntity(String.class);
            return Response.ok(""beta->"" + response).build();
        } catch (Exception e) {
            return Response.serverError().build();
        }
    }
}
Choosing a method of storing custom data is up to the developer."
jaeger,"Tags are often used for storing metadata information (such as IP addresses, span types, versions, etc."
jaeger,"), logs are used for storing messages (such as exceptions) and baggage is used for storing data, which can be retrieved later with the getBaggageItem() method."
jaeger,This is not the only thing we can do with an injected tracer.
jaeger,"By injecting the tracer, you get access to its methods."
jaeger,The main thing you can do with it is start spans manually.
jaeger,You can read more in the OpenTracing documentation.
jaeger,"Also, read the documentation for more details on when to use each method of adding custom data to spans (baggage, log, or tag)."
jaeger,"Let us restart the beta microservice and see what our trace looks like now:

Additional data in Jaeger

Additional data in Zipkin
Commit for this step
Adding Custom Spans
The final thing we will do in this guide add tracing to functions outside of JAX-RS."
jaeger,This way we can include methods and functions that are outside of a REST service to the distributed trace.
jaeger,"Typical examples are calls to the database, calls to external applications using protocols other than REST services, and similar scenarios."
jaeger,"To demonstrate this, we will show how to add calls to the database."
jaeger,We have implemented a simulated database in our gamma microservice.
jaeger,The easiest way to add custom spans is to use the @Traced annotation and put it on the class.
jaeger,"This way, all the methods will be traced."
jaeger,This annotation can also be used on a single method if we only want to trace a specific method inside the class.
jaeger,It is also possible to annotate the class and then disable tracing on methods by annotating them and setting the property value to false.
jaeger,Annotating and setting the value to false can also be used to disable automatic tracing of JAX-RS incoming requests.
jaeger,We will put the @Traced annotation to our Database class and all methods inside the class will be traced.
jaeger,It is also possible to change the span name by changing the operationName parameter.
jaeger,"Let us see how this looks like inside the code (Database.java file, located in src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/gamma):
@ApplicationScoped
@Traced(value = true, operationName = ""testingChangedOperationName"")
public class Database {
    private HashMap<Integer, String> data;
    @PostConstruct
    private void init() {
        data = new HashMap<Integer, String>();
        data.put(1, ""gamma"");
    }
    public String get(Integer id) {
        return data.get(id);
    }
}
As a result, we get the following span added to our trace:

Custom span inside trace in Jaeger

Custom span inside trace in Zipkin
We could achieve the same thing by injecting a tracer and manually creating the span."
jaeger,This is used when a developer wants a more fine-grained control over created spans.
jaeger,"That way, more that one span can be created inside one method."
jaeger,"Commit for this step
Summary
In this article, we have demonstrated the basic principles of distributed tracing for microservices."
jaeger,We implemented the tracing of an existing application using the KumuluzEE OpenTracing extension.
jaeger,We did not need to write a lot of code.
jaeger,We only changed a few lines and added some annotations.
jaeger,This shows how simple it is to add distributed tracing to your existing microservices and get all the benefits of distributed tracing such as tracing requests through an entire network of microservices and easier pinpointing of slowdowns.
jaeger,"Even though we covered the basics of tracing, we left a few things out."
jaeger,"For example, we did not include integration with a MicroProfile Config extension and KumuluzEE config frameworks, which would allow additional tracing configuration such as ignoring tracing on JAX-RS endpoints and changing the way that spans are named."
jaeger,We have explained more advanced features only briefly but would suggest the reader dig deeper into OpenTracing if they plan to use it in real-world applications.
jaeger,We also used the basic Jaeger/Zipkin configuration and ran the all-in-one Docker images.
jaeger,"Before running either one in production, consult the documentation for proper use cases and guidelines."
jaeger,Disclaimer: this article is an updated version of the original with the only difference being the added Zipkin part.
jaeger,"Introduction
With the emergence of cloud native technologies such as containers, micro-services and serverless architectures, new challenges for software development arises."
jaeger,"One of them is detecting problems in a distributed system, which is way complicated than a monolith system due to its weak coupling nature and the de-synchronization."
jaeger,This struggle gets amplified when scaling out these systems.
jaeger,"To help developers troubleshoot issues, OpenTelemetry comes into place."
jaeger,It is a standardization project supported by the CNCF foundation and historically was composed of two projects; OpenTracing and OpenCensus.
jaeger,"OpenTracing helps developers trace a request in a complicated distributed systems to figure out bottlenecks and and slow components in the request path which need optimizations, fixes or deeper debugging."
jaeger,"As mentioned before, OpenTracing project is a standard that describes how to trace, record and analyze transactions."
jaeger,Fortunately community provided multiple implementations of this standard.
jaeger,We are going to use Python implementation to trace a Django application with the help of Jaeger agent.
jaeger,"The Django application
You can find the application on my github account."
jaeger,It is a simple web application composed of user management and a graph rendering app that uses dot files to create png graphs.
jaeger,"It basically runs
dot -Tpng <dot-file> -o <output.png> on a user input graph and show the list of the PNG graphs back in the browser."
jaeger,"I included a function that randomly waits a couple of seconds to simulate latency of a call between components

Empty function that wait for a random number of seconds
Requirements.txt
Other than Django requirements we will need to install OpenTracing python library and python-django wrapper of the previous lib."
jaeger,All libs are provided in the requirements.txt of the github project.
jaeger,"Setting up test playground
All you need to setup your playground is to clone the Django app project, install the requirements and run both the web server and Jaeger, (in this example it is a docker container, you can explore other solution if you use different platforms say kubernetes etc ‚Ä¶)

deploy the Django app
You need also to run Jaeger to be able to visualize traces

Running Jaeger in a docker container
The Django app is already configured to send traces to Jaeger agent, you can check and modify these configuration in settings.py

settings.py for configuring opentracing and jaeger
The django_opentracing lib makes use of Django middlewares to trace each request."
jaeger,it exposes also a decorator if you only want to trace certain view.
jaeger,The only caveat is that the actual implementation of the wrapper (which is still under development) only traces Django views.
jaeger,which means you only get depth 1 of each request.
jaeger,No information of the calls inside the view itself.
jaeger,"Trace of index call with one depth view
So I forked the project and played around the code to enable tracing function calls inside the view by adding an option to the decorator to differentiate between a view and a other function calls

you can fork or clone and install my version from my github account https://github.com/piratos/python-django
After installing the forked version of django_opentracing, lunch the app and try to create a graph

Graph creation page
Now go to Jaeger web dashboard and look for the latest trace

Jaeger traces with depth two
You can see the child spans of the main view and their latency, in this example of course the slowest call was the random wait which lasted 2 seconds then the create graph which is the dot command call and finally the fastest call was listing the existing graphs due to Django caching the database query."
jaeger,"Conclusion
Tracing is one of the pillars of monitoring cloud native calls."
jaeger,"It gives a deep view of the apps interaction to help find latency, bad integration and non-optimized components."
jaeger,Tracing should be used in conjunction with other monitoring techniques such as logging and metrics collection.
jaeger,"When it comes to analyzing processes across multiple services in a microservice-architecture based application, one approach is to use a tracing tool."
jaeger,The principle of a tracer is simple.
jaeger,Services are instrumented with a client implementing the OpenTracing API specification in order to report calls of defined endpoints to a central collector unit.
jaeger,"One widely used tracer is called ‚ÄòJaeger‚Äô, its architecture shown below."
jaeger,"jaeger architecture
https://www.jaegertracing.io/img/architecture-v1.png
Jaeger clients report so called ‚ÄòSpans‚Äô, which are logical units of work and contain the useful information about requests, to a network daemon ‚Äòjaeger-agent‚Äô that listens for this information on UDP."
jaeger,"It then batches the information and sends it to the jaeger-collector, which acts as the central data collector for all distributed agents."
jaeger,In a docker swarm landscape this component is designed to be deployed on all swarm nodes as an infrastructure component.
jaeger,Across a microservice architecture the propagation of requests during a process through the various services is called ‚Äòtrace‚Äô in jaeger-terminology.
jaeger,It can be thought of the path of execution and represents a directed acyclic graph of spans.
jaeger,"principle of a trace and a span
https://www.jaegertracing.io/img/spans-traces.png
Jaeger provides an easy to use all-in-one docker image, with all components integrated."
jaeger,"Note, that this is only reasonable when getting started with using jaeger."
jaeger,"Be aware, that it is using a in-memory database ‚Äî tracing information will not be persisted."
jaeger,"For production environments you should configure one of the storage backends Cassandra, Elasticsearch or Kafka."
jaeger,"Docker Hub ‚Äî all-in-one jaeger-tracing image
hub.docker.com

Supposing, the jaeger-all-in-one.ymlconfiguration file

docker swarm configuration file
by executing docker stack deploy -c jaeger-all-in-one.yml jaeger-stack the whole ‚Äòjaeger‚Äô-stack, consisting of agent, collector, query and UI, is deployed into the stack jaeger-stack."
jaeger,By default an overlay-network is created where the services reside in.
jaeger,It is very easy to instrument a Spring-Boot 2 App with the Jaeger-OpenTracing API implementation.
jaeger,Let‚Äôs demonstrate distributed tracing by a very simple example of two apps AppA (runs on port 8080) and AppB (9080) that have the same REST-endpoint called greeting .
jaeger,"Compared to AppA ‚Äî greeting which just returns a simple JSON-object, AppB ‚Äî greeting calls AppA ‚Äî endpoint and also returns a simple object."
jaeger,Add the the current opentracing-spring-jaeger-web-starter to the maven POM in order to ensure that Spring Boot will auto configure a Jaeger implementation of OpenTracing‚Äôs Tracer when the application starts.
jaeger,"The first one ensures that, the @RestController ‚Äî API gets spans ‚Äòserverside‚Äô."
jaeger,"In order to propagate the trace-information across micro-services we manually instrument the Feign ‚Äî client with a tracer like:

which is enabled by the second dependency."
jaeger,Configure the tracing-settings in the application configuration file (.yml) by setting the opentracing.jaeger properties.
jaeger,"By default, Jaeger clients are reporting spans over UDP to localhost ."
jaeger,"When you run your app in a container within a swarm, your localhost is isolated by the networking namespace from the actual host where Jaeger agent is running."
jaeger,Therefore it is required to set the host of the jaeger-agent accordingly.
jaeger,"After calling the ‚Äògreeting‚Äô-endpoint of AppB we see the corresponding trace on our jaeger-UI http://localhost:16686
Jaeger UI trace example overview
summary of the ‚Äògreeting‚Äô-trace of AppB
A closer look reveals exact timings of our request-trace:
jaeger UI tracing example details
Checkout the whole demo-project on github!"
jaeger,"In this article, we are going to look at deploying Jaeger on Kubernetes and OpenShift with Elasticsearch storage using operators."
jaeger,We will go through the configuration (custom resources) and also see what benefits OpenShift offers over vanilla Kubernetes.
jaeger,To get started with Jaeger operator refer to our operator blog post or documentation.
jaeger,What is the operator?
jaeger,Kubernetes operator is a software component that simplifies deployment and operations of an application running in a Kubernetes cluster ‚Äî in our case Jaeger and Elasticsearch.
jaeger,"Think of it as software that knows how to deploy, monitor, upgrade and scale an application."
jaeger,"Behind the scenes, the operator uses Kubernetes custom resource (CR) to expose application configuration."
jaeger,The operator watches the resource and accordingly it makes changes to the application configuration or deployment based on the options provided in the CR.
jaeger,To make life even easier with operators there is one additional component ‚Äî Operator Lifecycle Manager (OLM).
jaeger,"This component helps users install, update, and manage the lifecycle of all operators and their associated services running across their clusters."
jaeger,"To learn more about operators refer to the Kubernetes documentation, OpenShift or coreos documentation."
jaeger,"Elasticsearch operator on Kubernetes
In this section, we are going to use elastic.co Elasticsearch operator as backend storage for Jaeger."
jaeger,Refer to the Elasticsearch documentation on how to deploy the Elasticsearch operator.
jaeger,Jaeger configuration in this section can also be used for any external Elasticsearch cluster.
jaeger,"Create an Elasticsearch CR that will be used by the operator to deploy a single node Elasticsearch instance:
cat <<EOF | kubectl apply -f -
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: quickstart
spec:
  version: 7.5.0
  nodeSets:
  - name: default
    count: 1
    config:
      node.master: true
      node.data: true
      node.ingest: true
      node.store.allow_mmap: false
EOF
Before deploying Jaeger we have to get the password from Elasticsearch secret and create a new secret for Jaeger with username and password."
jaeger,"Alternatively, we could specify these two options directly in storage options in Jaeger CR."
jaeger,"PASSWORD=$(kubectl get secret quickstart-es-elastic-user -o=jsonpath='{.data.elastic}' | base64 --decode)
kubectl create secret generic jaeger-secret --from-literal=ES_PASSWORD=${PASSWORD} --from-literal=ES_USERNAME=elastic
Now the secret jaeger-secretwith username and password for Elasticsearch has been created and we can specify it in spec.storage.secretName within the Jaeger CR."
jaeger,We have to also specify Elasticsearch URL and injected CA certificate as a volume from quickstart-es-http-certs-public secret.
jaeger,"cat <<EOF | kubectl apply -f -
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simple-prod
spec:
  strategy: production
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: https://quickstart-es-http:9200
        tls:
          ca: /es/certificates/ca.crt
        num-shards: 1
        num-replicas: 0
    secretName: jaeger-secret
  volumeMounts:
    - name: certificates
      mountPath: /es/certificates/
      readOnly: true
  volumes:
    - name: certificates
      secret:
        secretName: quickstart-es-http-certs-public
EOF
The above configuration works since Jaeger 1.16.0 (#PR1918)."
jaeger,"Older Jaeger versions should deploy, however the cron job to clean old data will fail on TLS related errors."
jaeger,Note that spark-dependencies also does not support TLS (#ISSUE83).
jaeger,"The successful deployment can be verified by:

kubectl get deployment                                                                                                                                                                                                                                                                               
NAME                    READY     UP-TO-DATE   AVAILABLE   AGE
simple-prod-collector   1/1       1            1           4m12s
simple-prod-query       1/1       1            1           4m12s
Now let‚Äôs have a look at deploying Jaeger on OpenShift using self-provisioning of Elasticsearch cluster."
jaeger,"Openshift 4
Within an OpenShift environment Jaeger can make use of cluster logging and automatically provision an Elasticsearch cluster based on the configuration in Jaeger CR."
jaeger,"OpenShift 4 also comes by default with OLM and user interface, therefore Jaeger provisioning can be done directly in the user interface."
jaeger,We will show how to deploy via OLM‚Äôs user interface.
jaeger,"The same could be accomplished by directly deploying operators without OLM, however we will use benefits of ‚Äúclick on a button‚Äù updates and other management features OLM provides."
jaeger,First we have to deploy Jaeger and Elasticsearch operator via OLM.
jaeger,Open OpenShift UI and navigate to Operators and OperatorHub menu and search for Elasticsearch and Jaeger.
jaeger,Deploy Elasticsaerch cluster logging operator.
jaeger,Deploy Jaeger operator.
jaeger,Then we can go to Installed Operators menu to verify operators were deployed.
jaeger,There we click on Jaeger and create an instance.
jaeger,Installed Operators menu.
jaeger,Jaeger Operator details.
jaeger,Create Jaeger instance with self-provisioned Elasticsearch.
jaeger,"We can also create an instance in the command line:
cat <<EOF | kubectl apply -f -
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simple-prod
spec:
  strategy: production
  storage:
    type: elasticsearch
    elasticsearch:
      nodeCount: 1
      resources:
        requests:
          cpu: 200m
          memory: 1Gi
        limits:
          memory: 1Gi
EOF
This CR is significantly simpler than the one for external Elasticsearch."
jaeger,"First we only have to create a single CR for Jaeger and storage, additionally, we no longer have to inject certificates, user credentials or the number of primary and replica shards."
jaeger,All the configuration is done automatically by the operator.
jaeger,"For instance, the operator autonomously chooses data replication factor based on the nodes in the cluster."
jaeger,"Behind the scenes, Jaeger operator creates Elasticsearch CR (for cluster logging Elasticsearch) which triggers Elasticsearch deployment for the given configuration."
jaeger,Persistent storage can be specified in.elasticsearch.storage by providing storage class name and size.
jaeger,Based on this configuration operator provisions persistent volume claim (PVC) and persistent volume (PV).
jaeger,The persistent volume is bound to the Elasticsearch instance by its name and it should be reused if the instance with the same name is re-created.
jaeger,Created Jaeger instance will show up in Jaeger tab.
jaeger,"Once we click on the instance we will see what Kubernetes objects belong to it, and we can also modify the configuration if needed."
jaeger,List of Jaeger instances.
jaeger,"Let‚Äôs also have a look at created deployments by operators:
kubectl get deployment                                                                   
NAME                                                    READY deployment.apps/elasticsearch-cdm-defaultsimpleprod-1   1/1       
deployment.apps/simple-prod-collector                   1/1     
deployment.apps/simple-prod-query                       1/1    
Deployment on OpenShift also provides simplified and secure access to Jaeger console."
jaeger,Console URL can be obtained from the networking menu in UI or via oc get routes.
jaeger,To login to Jaeger we use our OpenShift credentials.
jaeger,"Conclusion
We have deployed Jaeger with Elasticsearch in two different ways."
jaeger,First we have used vanilla Kubernetes and upstream Elasticsearch operator.
jaeger,This required more configuration work and the creation of multiple Kubernetes objects.
jaeger,In the second scenario we have used OpenShift 4 with Operator Lifecycle Manager (OLM) user interface to provision Jaeger instance with Elasticsearch storage.
jaeger,This didn‚Äôt require any storage and security configuration.
jaeger,Last but not least OLM provides automatic updates for operators and their instances.
jaeger,"As explained on the Eclipse Che website, ‚ÄúChe brings your Kubernetes application into your development environment and provides an in-browser IDE, allowing you to code, build, test and run applications exactly as they run on production from any machine‚Äù."
jaeger,"However when deployed in your production environment, those same applications can be monitored using observability tools to understand their performance to help inform future improvements."
jaeger,"Wouldn‚Äôt it be nice if we could also leverage these observability tools within the Che development environment, to identify these improvement opportunities before rolling out the changes to a test (staging) or production environment?"
jaeger,In this blog post we will show how simple it is to add Jaeger to your development workspace and observe how your application performs.
jaeger,"We will use che.openshift.io as the hosting environment, although you could setup a local Che server."
jaeger,"Create the Workspace
Che 7 introduced the capability to define a development workspace in a yaml format called a devfile."
jaeger,Example devfiles can be found in the Red Hat Developers GitHub organization.
jaeger,"For this post, we are going to use a modified version of the Spring Boot getting started devfile that adds the Jaeger all-in-one backend to the workspace."
jaeger,"The main change is to add the following section just before the commands top level node:
-
    type: dockerimage
    alias: tracing
    image: jaegertracing/all-in-one:latest
    env:
      - name: MEMORY_MAX_TRACES
        value: ""5000""
      - name: COLLECTOR_ZIPKIN_HTTP_PORT
        value: ""9411""
    memoryLimit: 128Mi
    endpoints:
      - name: 'tracing-ui'
        port: 16686
      - name: 'collector-grpc'
        port: 14250
        attributes:
           public: 'false'
      - name: 'collector-http'
        port: 14268
        attributes:
           public: 'false'
      - name: 'collector-zipkin'
        port: 9411
        attributes:
           public: 'false'
      - name: 'agent-config'
        port: 5778
        attributes:
           public: 'false'
      - name: '6831/udp'
        port: 6831
        attributes:
           public: 'false'
      - name: '6832/udp'
        port: 6832
        attributes:
           public: 'false'
    volumes:
      - name: tmp
        containerPath: /tmp
The modified version of the devfile can be found here, with some additional memory limit changes required when using with che.openshift.io."
jaeger,"To start the workspace on che.openshift.io, open a browser (Chrome recommended due to issue on some versions of Firefox), with this url."
jaeger,"Add OpenTracing instrumentation
When the workspace is initially opened, there is no OpenTracing instrumentation of the application."
jaeger,"OpenTracing instrumentation can implicitly be added by including a dependency on opentracing-spring-jaeger-cloud-starter as shown in the updated pom.xml below, along with updating the spring-boot-starter-parent version to 2.2.0.RELEASE (required by the OpenTracing instrumentation)."
jaeger,This dependency automatically instruments the inbound and outbound HTTP requests.
jaeger,It also bootstraps the Jaeger tracer to report the tracing data to the Jaeger backend (included in the workspace).
jaeger,"The default configuration of the tracer will report the data via UDP to the Jaeger agent, although the application can be configured to report the data via HTTP directly to the collector."
jaeger,The final step is to add a property that will define the service name within the tracing data.
jaeger,This is achieved by creating the src/main/resources folder and then create a file application.properties with the contents above.
jaeger,"Tracing the running application
On the righthand side of the workspace is a cube symbol that when selected causes a tree to be expanded."
jaeger,Under the User Runtimes/tools tree node is a task called run webapp.
jaeger,Selecting this option will run the Spring Boot application.
jaeger,"When started, a window will appear with a button Open Link."
jaeger,Press this button to start a browser for the application.
jaeger,"In the same tree, select the User Runtimes/tracing option tracing-ui which will launch the Jaeger UI in a separate browser tab."
jaeger,Press the refresh button at the top of the browser a couple of times to see the text Span reported in the console window.
jaeger,Change to the Jaeger UI tab to see the resulting traces that were reported from the application.
jaeger,"Summary
This post has demonstrated how OpenTracing with Jaeger can easily be introduced into an Eclipse Che workspace, to allow a developer to obtain tracing information from their application during development."
jaeger,"Although this particular example is simple, only capturing tracing from a single service, the benefit offered by Che is to enable complete applications (multiple services) to be used within the same workspace ‚Äî thus producing more interesting traces, and enabling the developer to understand the performance of their developed service in the context of the complete application."
jaeger,"This is a super-alpha-example-only*, intended as a proof of concept for integrating observability tools into a front-end web application."
jaeger,"*OpenTelemetryJS and many related tools are in ALPHA at time of writing, in addition, the below example hacks around some yet-to-be-implemented components for the sole purpose of demonstrating the tools we will likely be using a little further down the track!"
jaeger,(more on this in Notes section at the end).
jaeger,"In short ‚Äî lets focus on the concepts, not the implementation üò¨
Observability?"
jaeger,"O‚ÄôReilly have a nice writeup here ‚Äî but put very simply, it refers to the utility provided when you combine the three pillars (as defined in Distributed Systems Observability by Cindy Sridharan):
Logs:
‚ÄúAn event log is an immutable, timestamped record of discrete events that happened over time‚Äù
Metrics:
‚ÄúMetrics are a numeric representation of data measured over intervals of time.‚Äù
Traces:
‚ÄúA trace is a representation of a series of causally related distributed events that encode the end-to-end request flow through a distributed system.‚Äù
This article relates to the integration of tracing into front-end web applications (e.g."
jaeger,React apps).
jaeger,"The tools
OpenTelemetry JS: is the (alpha) JavaScript version of OpenTelemetry, a framework for collecting traces, metrics and logs from applications."
jaeger,"Jaeger: provides ‚Äúopen source, end-to-end distributed tracing."
jaeger,"Monitor and troubleshoot transactions in complex distributed systems‚Äù
Step #1: run all the Jaeger things:
# yes this example uses docker, cos, easy
docker run -d ‚Äî name jaeger -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:1.14
Open Jaeger UI: http://localhost:16686/
Step #2: run a CORS proxy
docker run -p 8888:3000 psimonov/cors-anywhere
Step #3: clone demo repo
git clone https://github.com/danwild/opentelemetry-js.git
Step #4: build packages and example
# core repo
cd opentelemetry-js
npm install
# crude demo exporter
cd packages/opentelemetry-exporter-zipkin-web
npm install
npm run prepare
# crude demo web app
cd ../../examples/tracer-web-jaeger
npm install
npm start
Point your browser at: http://localhost:8090 to run the demo traces + export."
jaeger,"Step #5: explore Jaeger UI
Refresh http://localhost:16686, and you should be able to see your service:

Finding your service via the Jaeger UI
Once you select your service, hit ‚ÄúFind Traces‚Äù:

List of traces matching search params in Jaeger UI
Then select a trace to explore it‚Äôs spans in more detail:"
jaeger,"Introduction
In this article, I would like to go through with you about how to view traces from both Jaeger and Zipkin as a single view."
jaeger,You might be thinking that it should be just fine to stick to one of the other.
jaeger,"However, with the increasing use of Microservices style architecture, choose of tracers is becoming independent."
jaeger,Jaeger and Zipkin support OpenTracing specification and each tracer works independently based on their own Propagation format implementation ‚Äî Jaeger and Zipkin B3.
jaeger,"System Architecture
Figure 1."
jaeger,"Architecture to illustrate the use case
Using the simple diagram above, you could see that each of the system is behaving independently and hence for this use case, I choose different tracer as well to present the practical problem which we could be facing in the real world."
jaeger,"Solution
Fortunately, we could integrate these two tracers nicely and elegantly."
jaeger,"Jaeger has provided quite a flexible way of working with Zipkin, which you can checkout on the Github Jaeger-Zipkin."
jaeger,"So, we can configure Jaeger to use Zipkin‚Äôs Propagation format ‚Äî B3 Propagation."
jaeger,"fun initTracer() {
    val samplerConfig = SamplerConfiguration().withType(""const"").withParam(1)
    val reporterConfig = ReporterConfiguration()
        .withLogSpans(true)
    val codecConfig = CodecConfiguration().withPropagation(Propagation.B3)
    val tracer = Configuration(""componentSvcA"")
        .withCodec(codecConfig)
        .withSampler(samplerConfig)
        .withReporter(reporterConfig)
        .withTraceId128Bit(true)
        .tracer
    GlobalTracer.registerIfAbsent { tracer }
}
Source code is available on Github Jaeger-Zipkin-Sample."
jaeger,The sample code is using OpenTracing Java Annotation library (article can be found on below).
jaeger,"OpenTracing Annotation
OpenTracing provides annotation driven based such as @Traced."
jaeger,"The annotation is very simple concept which makes very‚Ä¶
medium.com

Result
Once we configured Jaeger to use B3 Propagation format, the traces are in a single view as we expected to be."
jaeger,Figure 2.
jaeger,"Overview of A Trace

Figure 3."
jaeger,"Detail of A Trace
Tony Tony
I'm interested in software development and practical ops to ease devops meaningful to business value

Follow"
jaeger,Recently I've been reading about application observation and got fascinated with Jaeger Tracing and the benefits tracing brings to visualize your data flow.
jaeger,"For deeper understanding, I recommend the book Mastering Distributed Tracing by Yuri Shkuro, an engineer at Uber, creator of Jaeger."
jaeger,He wrote a great tutorial on tracing and optimizing an application so here I‚Äôll mostly focus how to basically instrument your Go application for tracing.
jaeger,"Since I was already playing with Echo, a nice and minimalist web framework for Go I decided to use it together with other tools to create some sample applications."
jaeger,"I also contributed a tracing middleware and submitted a Prometheus Metrics middleware as well, waiting to be merged."
jaeger,The example is composed of 3 ‚Äúmicroservices‚Äù.
jaeger,"The first is a Formatter, taking a name and returning a ‚ÄúHello [Name]‚Äù string."
jaeger,"The second, Publisher, just receives a string, calls the Echo microservice and prints the string to the console."
jaeger,The base of these two came from Yuri‚Äôs own tutorial repo and uses Go standard lib and a tracing library that provides some methods to make one‚Äôs life easier that I will detail later.
jaeger,"The third is a server created with Echo Framework, and the middleware to provide tracing that can be found it on the echo-contrib repo."
jaeger,"It receives the ‚ÄúHello‚Äù string, prints it out and calls a simulated function that takes some random time to execute."
jaeger,The complete code is in my Go-playground repository under microservices and can be used as base for your own applications or tests.
jaeger,"To run this code, you can use Jaeger all-in-one on your own machine, just run it in Docker and open http://localhost:16686 on your browser."
jaeger,"$ docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 9411:9411 \
  jaegertracing/all-in-one:latest
This is a good post that discusses Jaeger infrastructure and it's components."
jaeger,"Take a look if planning to deploy on your cluster:
Distributed Tracing Infrastructure with Jaeger on Kubernetes
One cannot overstate the importance of monitoring infrastructure as an integral component of distributed systems (or‚Ä¶
medium.com

Let's go deeper on code."
jaeger,"Client app
The client app generates the initial call for the data flow with a name as argument."
jaeger,"The main method starts by creating a tracer instance, where you set the type of tracing required like sampling or constant, log the traces and etc."
jaeger,On our example it‚Äôs wrapped by an Init function on the lib and reused for other services as well.
jaeger,"func main() {
...
tracer, closer := tracing.Init(""hello-client"")
defer closer.Close()
opentracing.SetGlobalTracer(tracer)
helloTo := os.Args[1]
span := tracer.StartSpan(""say-hello"")
span.SetTag(""hello-to"", helloTo)
defer span.Finish()
ctx := opentracing.ContextWithSpan(context.Background(), span)
helloStr := formatString(ctx, helloTo)
printHello(ctx, helloStr)
}
In the main function, we create the tracer named ‚Äúhello-client‚Äù and a span which is the definition of a unit of work within a service then we call two internal functions with the created context."
jaeger,This is important so the tracing IDs are persisted during the whole execution of the flow not only in the application but also between different applications or services as we will see.
jaeger,"func formatString(ctx context.Context, helloTo string) string {
  span, _ := opentracing.StartSpanFromContext(ctx, ""formatString"")
  defer span.Finish()
  v := url.Values{}
  v.Set(""helloTo"", helloTo)
  url := ""http://localhost:8081/format?"""
jaeger,"+ v.Encode()
  req, err := tracing.NewTracedRequest(""GET"", url, nil, span)
  if err != nil {
    panic(err.Error())
   }
  resp, err := xhttp.Do(req)
   if err != nil {
     panic(err.Error())
   }
  helloStr := string(resp)
  span.LogFields(
    otlog.String(""event"", ""string-format""),
    otlog.String(""value"", helloStr),
   )
  return helloStr
}
In this function we initially create a span to trace it‚Äôs execution, then do the logic required in the function like encoding the data into the URL."
jaeger,Finally we call the NewTracedRequest function from our lib.
jaeger,This function is similar to the http.NewRequest from std library but it takes the span and embeds the trace headers into the call.
jaeger,"Let‚Äôs take a look into this function:
// NewTracedRequest generates a new traced HTTP request with opentracing headers injected into it
func NewTracedRequest(method string, url string, body io.Reader, span opentracing.Span) (*http.Request, error) {
 req, err := http.NewRequest(method, url, nil)
 if err != nil {
  panic(err.Error())
 }
 ext.SpanKindRPCClient.Set(span)
 ext.HTTPUrl.Set(span, url)
 ext.HTTPMethod.Set(span, method)
 span.Tracer().Inject(span.Context(),
  opentracing.HTTPHeaders,
  opentracing.HTTPHeadersCarrier(req.Header))
return req, err
}
Here we can see that we take the request parameters, create a standard http.NewRequest and inject into this request the span information to be sent to the external service."
jaeger,If the called service uses tracing too it can add ‚Äúchild‚Äù spans that will be linked to this execution.
jaeger,"Going back to our formatString function, we send the HTTP request and then with the call results we add this info to the trace itself as log fields."
jaeger,"This can be seen in the trace details:

Formatter service
This microservice is a simple HTTP server listening for a URL and formatting the output."
jaeger,"func main() {
 tracer, closer := tracing.Init(""formatter"")
 defer closer.Close()
 http.HandleFunc(""/format"", func(w http.ResponseWriter, r *http.Request) {
  spanCtx, _ := tracer.Extract(opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(r.Header))
  span := tracer.StartSpan(""format"", ext.RPCServerOption(spanCtx))
  defer span.Finish()
  helloTo := r.FormValue(""helloTo"")
  helloStr := fmt.Sprintf(""Hello, %s!"
jaeger,""", helloTo)
  span.LogFields(
   otlog.String(""event"", ""string-format""),
   otlog.String(""value"", helloStr),
  )
  w.Write([]byte(helloStr))
 })
log.Fatal(http.ListenAndServe("":8081"", nil))
}
The service creates it‚Äôs own tracer named ‚Äúformatter‚Äù so it‚Äôs correctly identified by Jaeger, then on the handler we extract the tracing information from the request, create a span to report this execution and do the function business logic."
jaeger,"See that we also add logging information to this span so it can be seen on the trace:

Notice that each function (tracer) is identified by a color
We will see that by using the Echo framework and it‚Äôs tracing middleware, all the header extraction, injection is transparent."
jaeger,We have to do it here because this service uses pure Go Std library.
jaeger,"Publisher App
The publisher app is very similar in structure to the Formatter where we create a tracer and in the handler we extract the trace information from HTTP headers, create the function span and call the Echo-app microservice."
jaeger,"See that in case this call fails, we add the info to the trace with an error tag so it get indicated on Jaeger (small exclamation mark on the span):
...
resp, err := xhttp.Do(req)
  if err != nil {
   span.LogEvent(""Could not contact echo: "" + err.Error())
   span.SetTag(""error"", true)
   return
  }

Echo app
The Echo app is a little more complete and provides easy to use functions so you can focus on the business logic."
jaeger,"First we define new Echo app, add the tracing middleware and start it:
package main
import (
...
""github.com/labstack/echo-contrib/jaegertracing""
""github.com/labstack/echo/v4""
""github.com/labstack/echo/v4/middleware""
)
func main() {
 e := echo.New()
 c := jaegertracing.New(e, nil)
 defer c.Close()
 // Application routes
 e.GET(""/test/:name"", testHandler)
 e.Logger.Fatal(e.Start("":8080""))
}
Whenever we create an Echo app and attach the tracing middleware to it, the tracer ‚Äúecho-tracer‚Äù is created and a root span also is created to trace the whole execution of the call inside the Echo application."
jaeger,"We can then add ‚Äúchild‚Äù spans to the handlers:
func testHandler(c echo.Context) error {
 sp := jaegertracing.CreateChildSpan(c, ""test handler"")
 defer sp.Finish()
 var name = """"
 name = c.Param(""name"")
 sp.LogEvent(""Called testHandler function, HTTP name param is: "" + name)
 sp.SetBaggageItem(""name"", name)
 sp.SetTag(""name_tag"", ""name"")
 time.Sleep(10 * time.Millisecond) // Simulate longer execution
// Call slow function 5 times, it will create it's own span
 ch := make(chan string)
 for index := 0; index < 5; index++ {
  // Do in parallel
  go jaegertracing.TraceFunction(c, slowFunc, ""Test String"", ch)
 }
 for index := 0; index < 5; index++ {
  fmt.Println(<-ch)
 }
ret := fmt.Sprintf(""Test path, name: %s"", name)
 return c.String(http.StatusOK, ret)
}
// A function to be wrapped
func slowFunc(s string, c chan string) {
 time.Sleep(time.Duration(rand.Intn(50)) * time.Millisecond)
 c <- ""received "" + s
}
Here in the testHandler function, we create a child span called ‚Äútest handler‚Äù by using a convenience function from the tracing middleware lib by just passing the http context and the name."
jaeger,"Then we add a log event, a tag and baggage to the span as optional items to show tracing capabilities."
jaeger,Baggages can be added to the trace and be persisted thru other services.
jaeger,Then we call slowFunc (which just sleeps a random amount of time) by using another convenience function from our middleware in Echo (the tracing lib in the playground project also has this for Std lib) called TraceFunction.
jaeger,"This is a wrapper that receives the http context, the called function and it‚Äôs arguments."
jaeger,Then it wraps the execution with a span adding some information to it.
jaeger,The advantage of using the middleware or the lib is that the amount of tracing code added to your business logic is minimal taking little time and effort to add this instrumentation.
jaeger,"The idea of this function is to work like a Python Decorator, avoiding changes on the calling or called code."
jaeger,"Of course more info can be added to the traces as tags, logs or baggages as seen in the example."
jaeger,"Complete trace
Here Jaeger shows the complete timeline for our event and the functions that were called on multiple services shown in different colors."
jaeger,"Jaeger also generates the trace graph for all services, times and amount of calls."
jaeger,"Conclusion
As demonstrated, instrumenting an application with tracing brings fantastic visibility of your data flow and does not put a burden on the developers to add boilerplate to the code."
jaeger,The libs created for this example shows that can be simple to add proper tooling to your arsenal making everyone‚Äôs life easier.
jaeger,"If you have suggestions, want to contribute or support me, message me on Twitter or open an issue on the tracker repository."
jaeger,OpenTracing provides annotation driven based such as @Traced.
jaeger,The annotation is very simple concept which makes very easy to use and understand.
jaeger,"However, there are some limitations on it."
jaeger,"Secondly, Spring Sleuth have couple of annotations which have much flexible way of defining the tracing span according to your needs such as@NewSpan, @SpanTag, etc‚Ä¶ but Spring Sleuth does not support OpenTracing yet."
jaeger,"As a result, I am creating custom annotations library for OpenTracing purposed ‚Äî OpenTracing Java Annotation."
jaeger,The library is very small and does not depends on Spring but can be integrated to Spring.
jaeger,"There are couple of usages you can make use of the annotations:
Creating a new span
@NewSpan
public void calculateTax(TaxModel model) {
    ...
}
Override Default Span‚Äôs OperationName
@NewSpan(operationName=‚ÄùcalculateGST‚Äù)
public void calculateTax(TaxModel model) {
    ...
}
Include Tag on Span
@NewSpan
public void calculateTax(TaxModel model, @SpanTag(""tag-name"") String tagValue) { 
    ...
}
Dynamic Tag on Span
@NewSpan(tagMapper = @SpanTagMapper(resolver = TaxModelTagMapper.class))
public void calculateTax(TaxModel model) {
  ...
}
public class TaxModelTagMapper implements TagMapper<TaxModel> {
  public Map<String, Object> tag(TaxModel model) throws Exception {
    ...
  }
} 
Integrating to SpringBoot
Step 1: Register the Aspect class as spring bean:
<?xml version=""1.0"" encoding=""UTF-8""?>
<beans xmlns=""http://www.springframework.org/schema/beans""
       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:context=""http://www.springframework.org/schema/context""
       xsi:schemaLocation=""http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/context
        http://www.springframework.org/schema/context/spring-context.xsd"">
<bean class=""io.opentracing.contrib.annotation.handler.NewSpanHandler"" />
</beans>
Step 2: Include SpringBoot AOP dependencies
compile 'org.springframework.boot:spring-boot-starter-aop'"
jaeger,Why do I need tracing if I have a good logging and monitoring framework?
jaeger,"Application logs are beneficial for displaying important events if something is not working as expected (failure, error, incorrect config, etc.)."
jaeger,"Although it is a very crucial element in application design, one should log thriftily."
jaeger,"This is because log collection, transformation, and storage are costly."
jaeger,"Unlike logging, which is event-triggered and discrete, tracing provides a broader and continuous application view."
jaeger,Tracing helps us understand the path of a process/transaction/entity while traversing the application stack and identifying the bottlenecks at various stages.
jaeger,This helps to optimize the application and increase performance.
jaeger,"In this post, we will see how to introduce tracing in logs and visualize it easily."
jaeger,"In this example, we will use Prometheus, Grafana Loki, Jaeger, and Grafana Tempo as datasources for monitoring metrics, logs, and traces respectively in Grafana."
jaeger,What is Distributed-tracing?
jaeger,"In a microservices architecture, understanding an application behavior can be an intriguing task."
jaeger,"This is because the incoming requests may span over multiple services, and each intermittent service may have one or more operations on that request."
jaeger,It thus increases complexity and takes more time while troubleshooting problems.
jaeger,Distributed tracing helps to get insight into the individual operation and pinpoint the areas of failure caused by poor performance.
jaeger,What is OpenTracing?
jaeger,"OpenTracing comprises an API specification, frameworks, and libraries to enable distributed tracing in any application."
jaeger,OpenTracing APIs are very generic and prevents vendor/product lock-in.
jaeger,"Recently, OpenTracing and OpenCensus merged to form OpenTelemetry (acronym OTel)."
jaeger,"It targets the creation and management of telemetry data such as traces, metrics, and logs through a set of APIs, SDKs, tooling, and integrations."
jaeger,"Note: OpenCensus consists of a set of libs for various languages to collect metrics and traces from Applications, visualize them locally and send them remotely for storage and analysis."
jaeger,What are the fundamental elements of OpenTracing?
jaeger,Span: It is a primary building block of a distributed trace.
jaeger,"It comprises a name, start time, and duration."
jaeger,Trace: It is a visualization of a request/transaction as it traverses through a distributed system.
jaeger,Tags: It is key-value information for identifying a span.
jaeger,"It helps to query, filter and analyze trace data."
jaeger,Logs: Logs are key-value pairs that are useful for capturing span-specific logging messages and other debugging or informational output from the application itself.
jaeger,Span-context: It is a process of association of certain data with the incoming request.
jaeger,This context is accessible in all other layers of the application within the same process.
jaeger,What are available tools compatible with OpenTracing?
jaeger,"Zipkin: It was one of the first distributed-tracing tools developed by Twitter, inspired by Google Dapper paper."
jaeger,Zipkin is coded in Java and supports Cassandra and ElasticSearch for backend scalability.
jaeger,"It comprises clients or reporters to gather trace data, collectors to index and store the data, a query service to extract and retrieve the trace data, and UI to visualize the traces."
jaeger,"Zipkin is compatible with the OpenTracing standard, so these implementations should also work with other distributed tracing systems."
jaeger,Jaeger: Jaeger is another OpenTracing compatible project from Uber Technologies written in Go.
jaeger,Jaeger also supports Cassandra and ElasticSearch as scalable backend solutions.
jaeger,"Although its architecture is like Zipkin, it comprises an additional agent on each host to aggregate data in batches before sending it to the collector."
jaeger,"Appdash: Appdash, created by Sourcegraph, is another distributed tracing system written in Go."
jaeger,It also supports the OpenTracing standard.
jaeger,"Grafana Tempo: Tempo is an open source, highly scalable distributed tracing backend option."
jaeger,"We can easily integrate it with Grafana, Loki, and Prometheus."
jaeger,"It only requires object storage and is compatible with other open tracing protocols like Jaeger, Zipkin, and OpenTelemetry."
jaeger,"Enabling and Visualizing Traces
There are many hands-on tutorials/demos available, but they exist for the docker-compose environment."
jaeger,We will run a tracing example in a Kubernetes environment.
jaeger,"We will take the classic example provided by Jaeger, i.e., HOTROD."
jaeger,"Although Jaeger has its own UI to visualize traces, we will visualize it in Grafana with Jaeger as a data source."
jaeger,"Similarly, we will also see how Grafana Tempo is useful for visualizing the traces."
jaeger,For getting started we will clone the Jaeger GitHub repo.
jaeger,"Enable distributed tracing in Microservice application
You can check how to enable OpenTracing by navigating through the repo as shown below."
jaeger,"Convert docker-compose manifest to Kubernetes manifest
In the hotrod directory, check the existing Docker manifests."
jaeger,You will see the docker-compose.yml file deploying services like Jaeger and HOTROD.
jaeger,We will use kompose to convert docker-compose manifest to Kubernetes manifest.
jaeger,You will see some files being created.
jaeger,"We are specifically interested in hotrod-deployment.yaml, hotrod-service.yaml, jaeger-deployment.yaml, and jaeger-service.yaml."
jaeger,"For simplicity, we will add the following label in the hotrod-deployment manifest."
jaeger,"Enable Jaeger tracing in the deployment manifest
Now we need to add the following environment variables in hotrod-deployment.yaml."
jaeger,JAEGER_AGENT_HOST: It is a hostname to communicate with an agent (defaults to localhost).
jaeger,JAEGER_AGENT_PORT: It is a port to communicate with an agent (defaults to 6831).
jaeger,"JAEGER_SAMPLER_TYPE: Four types are available remote, const, probabilistic, ratelimiting (defaults to remote)."
jaeger,"For example, const type refers to sampling decision for every trace."
jaeger,JAEGER_SAMPLER_PARAM: It is a value between 0 to 1 (1 for sampling every trace and 0 for sampling none of them).
jaeger,"JAEGER_TAGS: It is a comma-separated list of name=value tracer-level tags, which get added to all reported spans."
jaeger,Now we will apply these manifests.
jaeger,Note that this will require a running Kubernetes cluster as a pre-requisite.
jaeger,"Install Prometheus and Loki
Next, we install Prometheus, Loki, and Grafana."
jaeger,The Prometheus Operator Helm chart (kube-prometheus-stack) will install Prometheus and Grafana.
jaeger,Loki Helm chart () will install Loki and Promtail.
jaeger,This post provides more details about log monitoring with Loki.
jaeger,We need to add Jaeger and Loki data-sources in Grafana.
jaeger,You can achieve this by either manually adding it or having it in the code.
jaeger,We will have the latter one by creating a custom values file prom-oper-values.yaml as shown below.
jaeger,uid: It is a unique user-defined id.
jaeger,access: It states whether the access is proxy or direct (server or browser).
jaeger,isDefault: It sets a data source to default.
jaeger,version: It helps in the versioning of the config file.
jaeger,editable: It allows to update data source from UI.
jaeger,We will now upgrade the kube-prometheus-stack Helm chart with the custom values.
jaeger,"If you go to the data sources, you can see jaeger and loki added here."
jaeger,It‚Äôs time to see how traces are being logged in the log message.
jaeger,"For this, we will go to the HOTROD UI and trigger the request from there."
jaeger,"Note: In our configuration, we have given the name loki and jaeger for the Loki and Jaeger data sources respectively."
jaeger,Note: Grafana and HOTROD services are using ClusterIP we will use port-forwarding to access the UI.
jaeger,"Go to explore, select loki as a data source, and select Log labels as {app=""hotrod""} to visualize the logs."
jaeger,You can see the span context containing info like trace and span id in JSON.
jaeger,Copy the trace id.
jaeger,"Duplicate the window and go to explore, and select Jaeger as a data source."
jaeger,Paste the trace id and run the query for visualizing all the traces of the request.
jaeger,"Configure Loki Derived Fields
This technique won‚Äôt be effective while analyzing burst requests."
jaeger,We need something that will be more efficient and easy to operate.
jaeger,"For this, we will use the concept of Loki derived fields."
jaeger,Derived fields allow us to add a parsed field from the log message.
jaeger,We can add a URL comprising the value of the parsed field.
jaeger,"Let‚Äôs see how this does the trick, but first, add the following config in the prom-oper-values.yaml:
Note that datasourceUid has the value of Jaeger's uid."
jaeger,This will help identify the data source while creating the internal link.
jaeger,matcherRegex has the regex pattern for parsing the trace id from the log message.
jaeger,URL comprises a full link if it points to an external source.
jaeger,"If it's an internal link, this value serves as a query for the target data source."
jaeger,$${__value.raw} macro interpolates the field's value into the internal link.
jaeger,"Add new log labels using Promtail pipelines
We will add one more change for ease of operation."
jaeger,"As you have seen earlier, there was no trace id label on the Loki log."
jaeger,"To add a particular label, we will use pipelineStages to form a label out of log messages."
jaeger,Create a loki-stack-values.yaml file and add the following code to it.
jaeger,Here pipelineStages is used to declare a pipeline to add trace id label.
jaeger,You can find more details of the pipeline parameters here.
jaeger,Now we will upgrade both kube-prometheus-stack and loki-stack Helm charts with updated values.
jaeger,"Visualize distributed tracing in Grafana using Jaeger and Tempo
We will again visit HOTROD UI and trigger the request from there."
jaeger,"In the Grafana dashboard, click explore and select loki as a data-source."
jaeger,"Add {app=""hotrod""} in Log labels."
jaeger,Now you will see a derived field with the name TraceID with an automatically generated internal link to Jaeger.
jaeger,You will also see an extra label with the name traceID.
jaeger,"Click the derived field TraceID, and it will directly take you to Jaeger data-source and show all the traces of the particular trace id."
jaeger,This makes switching between logs and traces much easier.
jaeger,"Also, this makes clear how to parse the log message according to the requirement."
jaeger,"Next, we will add Grafana Tempo as a data source and visualize traces with minimal changes with the same setup."
jaeger,"To enable this add the following lines in prom-oper-values.yaml and upgrade the Helm chart:
Change the data-source uid in loki's configuration to tempo's uid (e.g."
jaeger,datasourceUid: my-tempo) in prom-oper-values.yaml.
jaeger,Tempo uses Jaeger client libraries to receive all the trace related information.
jaeger,"So, we will delete the Jaeger deployment and its service."
jaeger,"To install Tempo in a single binary mode, we will use the standard Helm chart provided by Grafana."
jaeger,We also need to change the JAEGER_AGENT_HOST variable in HOTROD ( hotrod-deployment.yaml) to tempo for the correct identification of traces.
jaeger,"Incorrect value or missing value may lead to the following error:

Re-apply the hotrod-deployment manifest to incorporate the changes made."
jaeger,"Once again, visit the HOTROD UI and trigger the request from there."
jaeger,Now check for HOTROD logs in loki.
jaeger,You notice that the link in the derived field changes to Tempo.
jaeger,Click it and you can visualize all the trace information like before.
jaeger,"Conclusion
To summarize the post, we touched upon the following points:
How to enable distributed tracing in a microservice application."
jaeger,How to convert a docker-compose manifest into Kubernetes manifest.
jaeger,How to enable Jaeger tracing in the deployment manifest of an application.
jaeger,How to configure Loki derived fields.
jaeger,How to parse log messages to add new labels using the Promtail pipeline concept.
jaeger,How to visualize distributed tracing in Grafana using Jaeger and Tempo data sources.
jaeger,We hope you found this blog informative and engaging.
jaeger,"If you have questions, feel free to reach out to me on Twitter or LinkedIn and start a conversation :)"
jaeger,"At a glance
Software system:
All cloud-native infrastructure running on Kubernetes
Approximately seventy services corresponding to six-hundred containers
Weave Cloud, an automation and management platform for development and DevOps teams
Approximately twenty engineers
Problems:
Metrics provided only a vague, general overview of system; logging data increased storage costs, slowed programs
Lacked a means to quickly surface individual requests
Needed a more complete picture of system to fix issues like latency and slow queries
Solution:
Jaeger tracing
Results:
Scalable, targeted tracing for quicker resolution of internal and customer-facing issues
Ability to easily search for specific requests helps engineers zoom in on root causes
Selective sampling cuts storage costs and prevents slowing of programs
Tracing combined with metrics and logging provides a multidimensional view of system issues
The company
Founded in 2014, Weaveworks Inc. makes software that helps developers and DevOps teams build, run and manage containerized applications on Kubernetes."
jaeger,"Its products include GitOps-based cluster management, and application delivery, observability and monitoring solutions for services running on Kubernetes."
jaeger,It is a founding member of the Cloud Native Computing Foundation.
jaeger,"The company offers both free open-source and commercial software, as well as paid services, including: Weave Cloud, a platform as a service (PaaS) for deploying, monitoring and managing containers and microservices in cloud-native applications; Weave Scope, a real-time monitoring and visualization tool for distributed applications, available in open-source and hosted versions; Weave Cortex, an open-source Prometheus-based multitenant time-series database and monitoring system for applications and microservices; and the Weaveworks Kubernetes Platform for managing and automating clusters."
jaeger,Weaveworks employs approximately 20 engineers who support around 70 different services deployed in over 600 containers.
jaeger,They must continually tune and troubleshoot its software system to retain monitoring customers spoilt for choice.
jaeger,"‚ÄúSelling monitoring is quite tough; it‚Äôs a crowded market,‚Äù said Engineering Director at Weaveworks, Bryan Boreham."
jaeger,"Monitoring-software users always seem to want more ‚Äî more visibility, more information, more detailed answers."
jaeger,"For example, in addition to a broad overview of their systems, customers may want a closer look at details like individual requests."
jaeger,"If one provider can‚Äôt deliver what they desire, they may find another who can."
jaeger,"To better serve these customers, Weaveworks engineers sought a sharper lens for seeing small details."
jaeger,They needed to quickly surface specific information to help troubleshoot internal and customer-facing issues.
jaeger,"They had a rather large collection of logging and metrics tools, but none that could readily zero in on particulars."
jaeger,The team finally found the versatile zoom tool they wished for in Jaeger for distributed tracing.
jaeger,"Challenges
In the past, Weaveworks engineers often troubleshot system behavior through Prometheus metrics."
jaeger,"However, many of those metrics were not particularly useful because their aggregate nature hides outliers and doesn‚Äôt allow engineers to rapidly zero in on specific problems within systems."
jaeger,"‚ÄúIf you do a thousand really fast things and one really slow thing, then what‚Äôs the average?"
jaeger,"Even a histogram ‚Äî it‚Äôs just not very interesting,‚Äù Boreham said."
jaeger,Logging can also be practically useless in the event of an outage or customer-service issue.
jaeger,A logging system spewing out tons of identical statements does not help engineers quickly find a root cause.
jaeger,"In the past, Weaveworks generated about 50 gigabytes of logs per day, most of which consisted of the same message from ten different components, according to Boreham."
jaeger,This is because log generation tends to be limited and hard to tune.
jaeger,"‚ÄúIt‚Äôs almost infinitely likely that whoever wrote that bit of code did not log the one thing you need to know,‚Äù he said."
jaeger,"As an example of the need for greater visibility, Weave Scope shows diagrams of how components in distributed applications interact."
jaeger,"It‚Äôs always been quite common for users to ask: ‚ÄúCan I see an individual request?‚Äù
Exposing such granular information from inside programs can be quite challenging."
jaeger,"Weave Scope features about 20 metrics, none of which provide visibility into individual requests."
jaeger,"They offer only a broad, aggregated view of how applications are behaving."
jaeger,"The Solution
Weaveworks engineers turned to tracing, hoping it would accomplish what logs and metrics could not."
jaeger,"First, they instrumented their code with the OpenTracing API, and tried Tom Wilkie‚Äôs Loki, an opinionated reimplementation of OpenZipkin that used a pull-based model similar to that of Prometheus (when Wilkie joined GrafanaLabs, he redesigned Loki into a log-management solution)."
jaeger,"However, this method did not scale well, according to Boreham."
jaeger,"This is partly because, like Prometheus, Loki was designed as a single-process architecture."
jaeger,"Then they found Jaeger, an OpenTracing-native distributed-tracing platform."
jaeger,"Jaeger not only scales, it allows them to easily expose specific requests and speed up root-cause discovery."
jaeger,"And its search feature enables them to ask their own questions pertaining to a unique case, not just the ones pre-programmed into a log generator."
jaeger,"What is more, they can creatively combine Jaeger with logs, metrics and time-series data for enhanced views into system issues."
jaeger,"The engineering team easily set up Jaeger for basic instrumentation with just three or four lines of code, Boreham said; one additional line allowed for further inspection of SQL query execution."
jaeger,Weaveworks does not expose Jaeger tool directly to customers.
jaeger,"Instead, engineers use it to troubleshoot internal as well as customer-facing problems."
jaeger,The company also leverages Jaeger to sharpen the monitoring capabilities of its offerings.
jaeger,"For example, thanks to Jaeger, Weave Scope users can now actually view individual requests."
jaeger,"The versatility of Jaeger allows the engineers to not only isolate specific requests, but also examine patterns."
jaeger,These are not the mass aggregates and averages of their metrics tools.
jaeger,They allow them to view a manageably narrow set of spans within a trace to gauge how a service is performing.
jaeger,Boreham mentioned these in a talk about optimizing queries with Jaeger and Prometheus at KubeCon + CloudNativeCon Europe 2018.
jaeger,"He identified several interesting tracing patterns to pay attention to, including:
The longest span, which is the best place to start looking for slow queries
A gap between spans, indicating an additional span is needed to see what is happening within the gap
A long diagonal group of spans, or ‚Äústaircase,‚Äù which indicates serialized requests
Many spans extending to exactly the same length, suggesting an artificial constraint like a timeout
Lots of spans finishing at the same time, which suggests some sort of interlock
Jaeger can search through the past, react in the present and optimize for the future."
jaeger,"After an outage or other incident, the team can perform forensics to discover the culprit; when the team receives an alert in production, they can use Jaeger to quickly drill down to the root cause; and in tasks of intensive optimization, they can proactively comb through data for possible points of improvement."
jaeger,"Benefits
Engineers can tune Jaeger to investigate different types of issues."
jaeger,"The remotely controlled sampling feature lets them choose how much data to collect from individual services; they configure sampling policies in a central location, and the Jaeger platform automatically distributes them to Jaeger tracers running inside the services."
jaeger,Multitenant-software providers like Weaveworks can turn sampling up or down on different customers‚Äô data.
jaeger,"This allows them to hit the sweet spot on different processes, user instances, etc., and render collected data in diagrams that convey useful information."
jaeger,A Weave Scope user once complained that the software‚Äôs UI was slow.
jaeger,He also said that Weave Scope was chewing up resources on his system in the process of monitoring its data.
jaeger,"Logging and metrics tools could not pinpoint the cause, so the engineers turned to Jaeger to trace the data in this customer‚Äôs system."
jaeger,"At first, the traces returned about 30,000 lines on one operation, Boreham said."
jaeger,"Those were too many to handle, so he tweaked the code so that Jaeger would receive less information in the traces."
jaeger,"‚ÄúWhat I discovered, eventually, was that the system in question had 25,000 zombie processes on it,‚Äù Boreham said."
jaeger,"Investigating further, he determined that the customer‚Äôs machine was iterating through a huge chunk of data."
jaeger,Boreham made three or four changes to solve the problem.
jaeger,He called the customer and explained the importance of periodically clearing zombie processes from their machine.
jaeger,The team also changed its hosted code to prevent this problem from recurring.
jaeger,"Basically, information gathering is now capped at 2,000 processes per machine, since any in excess of that are likely zombie processes."
jaeger,"The patterns in tracing spans give engineers the ‚ÄúGoldilocks‚Äù view into systems ‚Äî not too far away, not too close up."
jaeger,"With Jaeger traces, Boreham‚Äôs team discovered the ‚Äústaircase‚Äù pattern in Weave Cortex."
jaeger,"They found that the querier was executing two 12-seconds-long requests, one after the other."
jaeger,Engineers made adjustments to the code calling into DynamoDB ‚Äî the database Cortex uses at its storage layer ‚Äî to parallelize these requests for greater speed.
jaeger,Jaeger can also conserve storage space and spending.
jaeger,"Constantly putting lots of data into logs can get expensive, and may slow down programs."
jaeger,"Jaeger sampling captures an adequate amount of data without overloading storage with useless, repetitive information."
jaeger,Sampling and a 14-day retention policy for trace data have cut Weaveworks‚Äô storage costs.
jaeger,The team can always turn the sampling rate up or down if need be.
jaeger,"And no one on the team has ever complained about Jaeger slowing down a program, Boreham said."
jaeger,"Powerful Jaeger combos
The team often learns much better information through tracing than they do with their older tools; however, they have not thrown them out."
jaeger,They often combine them with tracing for a more complete picture of a system issue.
jaeger,"For example, they still use standard text file logs, but now they put trace ids into logs in Cortex, and sometimes link the two together."
jaeger,The team often examines tracing data and Prometheus time-series data side by side.
jaeger,"For instance, while investigating latency, the team surfaced a Jaeger trace showing a slow call to DynamoDB; then Prometheus time-series data showed an ongoing load on that table."
jaeger,They fixed the problem by tweaking the provisioning of DynamoDB.
jaeger,"Jaeger wishlist
Boreham looks forward to the introduction of more advanced sampling features in Jaeger."
jaeger,"For one, he would like to sample based on whether a trace is ‚Äúinteresting‚Äù or not, which, he admits, sounds a bit like magic."
jaeger,"However, the tail-based sampling feature on Jaeger‚Äôs road map could deliver something quite close."
jaeger,"While head-based sampling makes the sampling decision at the start of a trace, tail-based sampling collects all information ‚Äî in nonpersistent storage for efficiency ‚Äî and then decides if it‚Äôs worth sampling."
jaeger,"If the trace is deemed ‚Äúinteresting,‚Äù it is sampled and stored."
jaeger,"In this way, traces that are likely to coincide with system issues ‚Äî those showing anomalies, unexpected error codes, etc."
jaeger,‚Äî are captured.
jaeger,"Other features Weaveworks would like to see introduced include:
A means to intelligently search within trace URLs containing many lines of detail."
jaeger,This may become possible through Jupyter Notebooks; Jaeger wants to make traces work with this data-mining tool for user-driven custom searches and feature extraction (see issue #1639 for more information).
jaeger,A ‚Äúcookbook‚Äù of useful ways to work with trace data in AWS Elasticsearch on which Weaveworks runs its Jaeger implementation (such as the feature extraction technique described in Chapter 12 of Yuri Shkuro‚Äôs book Mastering Distributed Tracing).
jaeger,"Conclusion
Jaeger provides a versatile means to discover the root causes of system issues."
jaeger,"Targeted search allows it to display an individual request, so even small details can‚Äôt hide from it."
jaeger,And trace patterns and diagrams allow users to visualize data from different angles and in variable amounts.
jaeger,This is a big improvement over metrics that provide only a rough outline of complex systems and services.
jaeger,"And unlike traditional logging, Jaeger allows users to collect data selectively and economically."
jaeger,‚ÄúIt‚Äôs just a much better way to work.
jaeger,I can‚Äôt imagine working on build-and-run distributed systems without some way to figure out what‚Äôs going on after the fact.
jaeger,"It‚Äôs just much better technology ‚Äî doing that in the tracing style than in the old fashion of logging text files,‚Äù Boreham said."
jaeger,"Engineers can also use Jaeger in conjunction with logging, metrics and other tools."
jaeger,This enables them to come up with creative visibility and troubleshooting recipes on the fly.
jaeger,The variety of things that could break in complex systems meet their match in the variety of ways tracing can help fix them.
jaeger,"As Boreham concluded:
‚ÄúIf you don‚Äôt have a microscope, you can‚Äôt see bacteria; and if you don‚Äôt have a telescope, you can‚Äôt see Jupiter."
jaeger,Jaeger is like that ‚Äî both the big picture and the fine-grained details at the same time.‚Äù
jaeger,"Photo by Tim Johnson on Unsplash
Some time ago I wrote about ‚ÄúCustom links in Jaeger UI‚Äù (check it first if you haven‚Äôt got chance yet)."
jaeger,I explained there how deep linking makes life easier and can speed up troubleshooting session.
jaeger,This post extends it a little bit and provides a more detailed example for a particular use case: links between Jaeger and Kiali.
jaeger,Kiali is a tool which helps you manage and monitor your service mesh based on Istio.
jaeger,You can treat it as a console for Istio.
jaeger,"It gives you features like:
displaying topology graph of the mesh,
providing health status and metrics for your services,
changing configuration of the mesh (also validating it for you),
embedding distributed tracing UI from Jeager
Kiali provides you an embedded Jaeger UI with a possibility to jump to Jaeger page directly:

Jaeger UI inside Kiali
But what if we start in Jaeger and want to jump to Kiali and directly to a certain page (f.e."
jaeger,"workload details, or service graph)?"
jaeger,As I showed in the previous article it‚Äôs possible to configure Jaeger to create links based on span metadata.
jaeger,"Unfortunately, if you install Istio with default configuration the spans will get tags with values not suitable for creating such links (I‚Äôll show an example below)."
jaeger,"But Istio lets you modify telemetry configuration, also trace span metadata so we can tweak configuration to our needs."
jaeger,"‚ÄúOk, show me the code‚Äù
Below there‚Äôs a simple example of how to configure Istio and Jaeger to enable deep-linking to Kiali."
jaeger,"NOTE:
For the example, I used Istio v1.2.2, not sure if it will work with previous versions."
jaeger,F.e.
jaeger,"in v1.1 there was a separate CRD for tracespan, for v1.2 we use instance type for defining span metadata."
jaeger,"If you‚Äôd like to follow the example below, I assume that you :
have a running Kubernetes cluster with helm‚Äôs tiller installed
will download all Github gists displayed below to a working directory
will also git clone Istio repository into working directory (or at least copy istio/install and istio/sample folders)
First, let‚Äôs install:
Istio (using helm chart directly from Istio repository),
Kiali (can be installed as part of Istio helm chart),
Jaeger (we‚Äôll use jaeger-operator so we can customize UI configuration later)
example app (bookinfo app) so we can generate some traces."
jaeger,"First Istio:
# Install istio
helm install istio/install/kubernetes/helm/istio-init --name istio-init --namespace istio-system
helm upgrade istio istio/install/kubernetes/helm/istio --install \
--namespace istio-system \
--set pilot.traceSampling=100.0 \
--set kiali.enabled=true \
--set kiali.createDemoSecret=true \
--set kiali.dashboard.jaegerURL=http://localhost:16686 \
--set global.tracer.zipkin.address=jaeger-collector.observability.svc.cluster.local:9411
we set traceSampling to 100% so every request will be stored in Jaeger
kiali.createDemoSecret set to true will create secret with default admin/admin username/password for Kiali console
kiali.dashboard.jaegerURL is set to localhost because we will use kubectl port-forward for accessing all services in Kubernetes cluster
global.tracer.zipkin.address is set to Jaeger collector service which we will create in a minute
Next Jaeger:
# Install jaeger-operator
helm install stable/jaeger-operator --name jaeger-operator --namespace observability

# Install Jaeger CR from above snippet
kubectl apply -f jaeger1.yaml
And finally BookInfo app:
# Install Bookinfo example app
kubectl label namespace default istio-injection=enabled
kubectl apply -f ./istio/samples/bookinfo/platform/kube/bookinfo.yaml
Ok, when everything is up and running let‚Äôs make port-forwards to Bookinfo app, Jaeger UI and Kaili console:
kubectl port-forward svc/productpage 9080:9080
kubectl port-forward svc/jaeger-query 16686:16686 -n observability
kubectl port-forward svc/kiali 20001:20001 -n istio-system
and refresh page http://localhost:9080/productpage several times."
jaeger,"Next if we go to Jaeger UI (http://localhost:16686/search)and open one of traces/spans we‚Äôll see tags similar to those:

As we see on the above screenshot, span tags values don‚Äôt provide necessary data to create Kiali link ‚Äî f.e."
jaeger,"link for service details page contains a name of service and namespace like:
http://localhost:20001/kiali/console/namespaces/<namespaceName>/services/<serviceName>
Istio has a rich configuration model for telemetry data."
jaeger,Detailed description can be found here so I‚Äôll skip this part.
jaeger,To change span tags we need to add an instance based on compiled template tracespan.
jaeger,"And in the spanTags you can add arbitrary list of tags:

Also you have to define handler which will point to Jaeger endpoint (compatible with zipkin) and a rule which will bind the instance and the handler."
jaeger,"Let‚Äôs apply both configuration files:
kubectl apply -f tracespan.yaml
kubectl apply -f handler-rule.yaml
For more details about Istio custom resources please visit the docs pages: tracespan, zipkin, rule."
jaeger,"When we apply above configuration and produce once again some traces we can see that the tags in Jaeger UI were changed:

The last part are the links to Kiali."
jaeger,As described in the previous post we need to modify Jaeger CR definition and add an array of linkPatterns.
jaeger,"Here‚Äôs an example of how such links can be defined:

kubectl apply -f jaeger2.yaml
When you apply that file, Jaeger will create a new configmap and add that configmap to deployment spec (Jaeger pod will be recreated)."
jaeger,Because we use in-memory datastore for Jaeger traces we need to refresh once again bookinfo app productpage to produce some traces.
jaeger,And that‚Äôs it.
jaeger,"If you go to trace details view you will see new icons next to some of the tags and after clicking the icon you will see list of defined links pointing to Kiali:

Just click and you will see f.e."
jaeger,"service graph in Kiali with the destination workload (ratings-v1) marked:

You can even open Kaili pages directly from embedded Jaeger UI:

Hopefully it will be helpful in integrating those tools in your environments."
jaeger,If you have any questions/feedback please leave it here below or on Twitter.
jaeger,"Photo by JJ Ying on Unsplash
Jaeger is a great tool for distributed tracing developed originally by Uber and now governed by CNCF."
jaeger,"In this article, I‚Äôd like to show a little feature of Jaeger UI which I think is not well known but can be really useful in day to day work with Jaeger and other tools ‚Äî dynamic custom links based on span metadata (tags, process, logs)."
jaeger,"First of all: big thank you goes to Louis-√âtienne Dorval who gave a great talk on Kubecon EU 2019 (video/slides), where ‚ÄúLinks on tags‚Äù were mentioned on one of the slides."
jaeger,"After the talk, I started to search for the details."
jaeger,I checked Jaeger docs but I didn‚Äôt find any reference on how to implement it.
jaeger,Also searching the internet didn‚Äôt help.
jaeger,So I dug through the GitHub repository (both code and issues/PRs) and luckily found answers there.
jaeger,"‚ÄúCustom links ‚Äî why do I need them?‚Äù
Regardless of whether you are a developer or an SRE you use many tools during investigating problems in production environments or just analyzing how your system is working."
jaeger,"Traces, metrics, logs, repositories, wikis, etc."
jaeger,"That requires a lot of switching between tabs, windows, searching or drilling down through the menus."
jaeger,Possibility to just click in one tool to get to the other with specific context saves you a lot of precious time and enhance overall UX.
jaeger,"When working with Jaeger, on a traceview panel (let‚Äôs not go into the discussion if it‚Äôs the right place to work with traces‚Ä¶ ;-) ) we get a lot of metadata from the span tags/logs."
jaeger,What if we can jump directly from that screen to another tool to a relevant page (not just the main screen)?
jaeger,"Fortunately, Jaeger UI is fully capable to help us with it."
jaeger,"‚ÄúOk, so let‚Äôs add some links‚Äù
To define custom links we need to change file passed to --query.ui-config described here."
jaeger,"In that json file we need to add linkPatterns array like below (example taken from this PR):

For each link you have to add an element in a linkPatterns array with such parameters:
type: you decide in which metadata section your link will be added: process, tags, logs:

key ‚Äî name of tag/process/log attribute which value will be displayed as a link, f.e."
jaeger,"on the above example it can be hostname for process type
url ‚Äî the URL where the link should point to, it can be an external site or relative path in Jaeger UI
text ‚Äî text displayed in the tooltip for the link
Both url and text can be defined as templates where Jaeger UI will dynamically substitute values based on tags/logs data."
jaeger,"For those who‚Äôd like to give it a try, I added a step by step tutorial."
jaeger,I just assume that you have a Kubernetes cluster with Tiller installed.
jaeger,I used GKE (because of one of the examples below) but can be even minikube.
jaeger,I also assume you have basic knowledge about Jaeger.
jaeger,If not go to ‚ÄúGetting started‚Äù from docs where you will also find information about HotRod application.
jaeger,"First, let‚Äôs install Jaeger and HotRod app."
jaeger,I prefer to use jaeger-operator to manage Jaeger instances.
jaeger,"Let‚Äôs use the official helm chart:
helm install stable/jaeger-operator --name jaeger-operator
When the jaeger-operator pod is up and running add a Jaeger custom resource like on gist below:

kubectl apply -f ./jaeger.yaml
Jaeger-operator will pick up the Jaeger custom resource and install Jaeger components (with such simple definition all components will be deployed as one pod ‚Äî all-in-one strategy ‚Äî which is not suitable for production usage but perfect for such tutorials)."
jaeger,"And finally add HotRod app based on following gist (so we can use it to produce some traces):

kubectl apply -f ./hotrod.yaml
The nice thing about the jaeger-operator is that it can automatically ‚Äòinject‚Äô jaeger-agent as a sidecar to selected deployments."
jaeger,"All you need to do is just add an annotation like to the deployment:
""sidecar.jaegertracing.io/inject"": ""true""
Check if everything is up and running."
jaeger,"To access both Jaeger UI and HotRod app use kubectl port-forward:
kubectl port-forward svc/simplest-query 16686:16686
kubectl port-forward svc/hotrod 8080:8080
Hint: if you will follow the steps the port-forwarding may be broken when the Jaeger pod is recreated (f.e."
jaeger,because of ui-config change).
jaeger,In such case just run the command once again.
jaeger,Go to http://localhost:8080/ and do some actions.
jaeger,Then go to http://localhost:16686/ and click ‚ÄúFind traces‚Äù ‚Äî you should see a list of traces.
jaeger,"Ok, great."
jaeger,So now let‚Äôs add some link examples!
jaeger,When you check one of trace and span (f.e.
jaeger,for frontend service like below) there‚Äôs always a tag with key hostname with a value of HotRod app pod‚Äôs name.
jaeger,What if we can jump from Jaeger UI directly to GCP console page with pod details?
jaeger,"Ok, let‚Äôs do it."
jaeger,We can modify our Jaeger CR definition and add some configuration for ui ( example json presented at the beginning should be ‚Äòtranslated‚Äô to yaml).
jaeger,"Here‚Äôs an example of a modified config:

Let‚Äôs deploy it once again:
kubectl apply -f ./jaeger2.yaml
Of course, you should adjust a few details in the link (like GCP project name or GKE cluster name)."
jaeger,Let‚Äôs go once again to hotrod app and ‚Äòproduce‚Äô some traces.
jaeger,"Then in Jaeger UI on the details of selected span we can see a new icon next to hostname value with a tooltip:

And when clicked we‚Äôll be moved to GCP console to ‚ÄúPod details‚Äù page:

We can also use it to navigate in Jaeger itself."
jaeger,Let‚Äôs imagine we‚Äôre investigating one trace and would like to see other traces for the same customer (in hotrod app we can find a customer_id key inside logs).
jaeger,"Here‚Äôs a snippet of another link definition:

Once again update the Jaeger CR:
kubectl apply -f ./jaeger3.yaml
Hint: you need to recreate the Jaeger pod (scale down/up or just delete the pod) so new version of config-ui will be picked up."
jaeger,Go to HotRod app to produce some traces and then to Jaeger UI.
jaeger,You should see something like below ‚Äî link next to customer_id key.
jaeger,Click it and a new tab will be opened with filtered traces (field Tags in the left panel will be filled with a proper condition).
jaeger,"There many other possible use cases: links to Grafana dashboard presenting metrics of particular service, links to Kibana logs filtering additional events f.e."
jaeger,"based on request-id value from tags, links to GitHub repositories based on values of version."
jaeger,"Hopefully, this post will be a starting point for your Jaeger UI extension which will make it more integrated with other tools in your stack."
jaeger,If you liked what you read (or not at all) ‚Äî please leave me some feedback here or through Twitter.
jaeger,Thanks.
jaeger,Last week I documented what I hope is the simplest possible Trillian personality.
jaeger,"Yesterday, I documented adding an inclusion proof."
jaeger,"Earlier today, I documented building a gRPC-based client and server for the personality."
jaeger,Here is a small addition that adds metrics (stats) and traces.
jaeger,"OpenCensus Exporter
With the addition of a straightforward configuration for an OpenCensus Exporter using the OpenCensus Agent, we have the ability to configure the Agent to convert incoming stats|traces into a wide selection of 3rd-party services."
jaeger,"Here‚Äôs the Basic Personality server configuration:
oc, err := ocagent.NewExporter(
 ocagent.WithAddress(*ocagEndpoint),
 ocagent.WithInsecure(),
 ocagent.WithReconnectionPeriod(10*time.Second),
 ocagent.WithServiceName(serviceName),
)
if err != nil {
 log.Fatal(err)
}
defer oc.Stop()
And here‚Äôs the Agent‚Äôs configuration to receive incoming stats|traces on :55678 and export the stats to Prometheus (on :9100) and the route the traces to thezipkin service on its port :9411:
receivers:
  opencensus:
    address: "":55678""
exporters:
  jaeger:
    collector_endpoint: ""jaeger:14268/api/traces""
  prometheus:
    address: "":9100""
  zipkin:
    endpoint: ""zipkin:9411/api/v2/spans""
zpages:
    port: 9999
NB A potential source of confusion."
jaeger,These DNS names are provided by Docker Compose to the services running on the network it creates.
jaeger,These names are accessible to other services within the solution.
jaeger,"In this case, the OpenCensus Agent (itself known as opencensus-agent) is able to refer to these other services by their service names (jaefer ,zipkin) but only within the solution."
jaeger,"Externally, we need to port map these services onto an available port on localhost."
jaeger,"OpenCensus Agent
The OpenCensus Agent export as a Prometheus Exporter on the host on :9100 so you can query http://localhost:9100/metrics and hopefully see:

We can confirm the OpenCensus Agent by checking its logs:
docker-compose \
--file=deployment/docker-compose.yml \
logs opencensus-agent
Attaching to deployment_opencensus-agent_1
opencensus-agent_1          | {""level"":""info"",""ts"":1562357412.0980296,""caller"":""config/config.go:490"",""msg"":""Trace Exporter enabled"",""exporter"":""zipkin""}
opencensus-agent_1          | {""level"":""info"",""ts"":1562357412.0983222,""caller"":""config/config.go:497"",""msg"":""Metrics Exporter enabled"",""exporter"":""prometheus""}
opencensus-agent_1          | 2019/07/05 20:10:13 Running OpenCensus Trace and Metrics receivers as a gRPC service at "":55678""
opencensus-agent_1          | 2019/07/05 20:10:13 Running zPages on port 9999
The OpenCensus Agent is configured (:9999) to show zPages so we can interrogate that endpoint:

/debug/tracez
NB I would have expected to see upstream gRPC traces reflected by the Agent but they‚Äôre not."
jaeger,So this is one problem.
jaeger,"Prometheus
The OpenCensus Agent is now a scrape target (via the above Exporter) for the Prometheus server."
jaeger,"So the Basic Personality client and server gRPC metrics are exported to the OpenCensus Agent, which exports them as a Prometheus Exporter and they‚Äôre then captured by this server:

Zipkin

For some reason ‚Äî to be explored ‚Äî Zipkin either isn‚Äôt receiving or isn‚Äôt able to process the traces routed through the OpenCensus Agent that are generated by the automatic ocgrpc handler."
jaeger,"You can confirm the Zipkin service logs too though these are verbose and not included here:
docker-compose \
--file=deployment/docker-compose.yml \
logs zipkin
Jaeger
When Zipkin wasn‚Äôt showing traces, I added Jaeger (another trace monitoring tool) to see whether it was Zipkin, the upstream OpenCensus Agent, or something else."
jaeger,Jaeger is reported its own traces but no others.
jaeger,"So, there‚Äôs something either in my configuration or the OpenCensus Agent that‚Äôs not working:

Conclusion
An ‚Äòamuse bouche‚Äô for integration stats and traces into the Basic Personality."
jaeger,It would be more awesome if it worked perfectly ;-)
jaeger,"If you are not already familiar with Jaeger and Opentracing, you can read about it here."
jaeger,"Jaeger + Opentracing provides ready to use tracing services for distributed systems and is becoming widely used, de facto standard because of their simplicity and standardization."
jaeger,"Jaeger, the backend provided to the Opentracing API is responsible for the collection of spans, these spans are made with use of smart pointers that carry the timestamp, TraceID and other meta info like a specific tag/log associated with the span to uniquely identify it across the distributed system."
jaeger,"let‚Äôs get intuitive using Jaeger-client-cpp
I would suggest going through the excellent walkthrough of the HOTROD application before we begin ‚Ä¶
Okay, you are back!"
jaeger,Let‚Äôs get started!
jaeger,"To make use of Jaeger, follow the README.md and test the spans build in the example app."
jaeger,"You‚Äôll get to see two spans, by following the example App.cpp."
jaeger,"INFO: Initializing logging reporter
INFO: Reporting span 5b163b107a813958:a0e81b958c00c461:5b163b107a813958:1
INFO: Reporting span 5b163b107a813958:5b163b107a813958:0:1
The first INFO line specifies, that we have the reporting service enabled and hence the spans would be reported locally when you run your traced application."
jaeger,The second and third INFO are actually the spans generated.
jaeger,These spans can be seen in the Jaeger UI(you have to first initialize UI before running the traced code to see spans).
jaeger,"Use their all-in-one docker image(you will need docker installed for that, head here if you don‚Äôt already have docker) for hassle-free UI setup."
jaeger,How traced spans looks on Jaeger UI.
jaeger,Show me what Opentracing API along with Jaeger is capable of!
jaeger,"For that, you can refer tutorial-example-cpp that illustrates the use of Opentracing API."
jaeger,I can give a brief overview on it.
jaeger,"Configuring Jaeger
Jaeger comes with an option of setting up the tracing system according to the requirement."
jaeger,"By this, I mean you can customize capturing spans based on your need."
jaeger,"You can set if you want to enable logging, set the frequency of recorded spans by using samplers provided by Jaeger, do you want to persist those spans like for maybe billing you want to record the time spent on a service using tracing, for instance, if it‚Äôs a microservice like Netflix and you want to collect and store all the timestamp that spans carry so as to bill your customers you can forward your spans to database storage units."
jaeger,Configuration options for jaeger -client-cpp can be passed in the form of YAML file.
jaeger,An example of which can be seen here.
jaeger,"Setup the Tracer
To employ tracing to your code first step is to choose a Tracer backend compatible with Opentracing API, you can find available ones here."
jaeger,"We are going to use Jaeger and hence will replace mocktracer, with Jaeger specific initialization, and pass the config.yml file location for our customized configuration, after which our job with Jaeger is done!"
jaeger,From there Opentracing API is used to configure and add traces which are then collected by Jaeger backend and sent to Jaeger UI.
jaeger,Replace the mocktracer with Jaeger and we are good to go.
jaeger,You can make use of this code.
jaeger,"void setUpTracer(const char* serviceToTrace) {  
auto configYAML = YAML::LoadFile(""config file location""); 
auto config = jaegertracing::Config::parse(configYAML); 
tracer = jaegertracing::Tracer::make(serviceToTrace, config, jaegertracing::logging::consoleLogger()); 
opentracing::Tracer::InitGlobal(      std::static_pointer_cast<opentracing::Tracer>(tracer));
}
Parent, Child and Follow-up spans:
After we had setup the Tracer we should start creating spans to trace our application, for that taking inspiration from Jaeger-client-cpp example I have added a function that converts the context passed as a string to a span, this method returns a span which can be stored and passed to create subroutine context."
jaeger,"The parent span so obtained from tracedFunction() method is then used to pass into tracedSubroutine() function along with subroutine context, which creates child span."
jaeger,"Note: there can be only one active parent span in scope, either the span finish when the scope ends or you can use SpanName->Finish () method to destroy it explicitly."
jaeger,"Tags and Logs:
The purpose of tracing is to give as much meaningful contextual information in an easy to comprehend form; as Google developers describe it as making things observable."
jaeger,"We can add more context to our tracepoint using Tags and Logs, refer docs knowing more about them."
jaeger,"Span Context propagation by Inject and Extract methods:
Since we are working on distributed systems, with many remote machines coordinating with each other concurrently exchanging data, messages, updates; it becomes important to trace these subparts of the system as much as the core system itself."
jaeger,"Thus, Opentracing and Jaeger also supports off the wire context transfer, by which we mean the span context is gathered using the Inject method, the string so returned will be carrying the span context and hence the uniqueness of a span, which can then be transmitted and reproduced back to a span ready for tracking at the remote system, if Tracer is already not active initiate it at remote end and the use extract method to reconstruct the span."
jaeger,Voila!
jaeger,And the span‚Äôs reconstructed back!
jaeger,Marking those first traces and making it more intuitive to add traces.
jaeger,After a few hiccups with the use of unique pointers and adding jaeger libraries locally.
jaeger,I can now build Ceph with Jaeger!
jaeger,"I tested adding the initial span; in OSD input-output path(a part of Ceph) and after a bit tussle understanding how to make it work, I can now see the traced path by adding just 1 span!"
jaeger,No wonder it would be great to design useful tracepoints that can hopefully reform the way debugging is done in distributed systems like Ceph.
jaeger,"let me show you how those spans turn out for Ceph Object Storage Deamon(the one who manages and stores objects in Ceph cluster)

Final Words
The traces marked acts as a proof of concept that Jaeger can be employed efficiently in large distributed projects like Ceph."
jaeger,"My future challenge lies in providing meaning to this powerful tool, by designing the best outline for adding tracepoints, which requires a thorough understanding of Ceph, which is where I am beginning from."
jaeger,"Yet there will always lie the need for tracing for new code or some suspicious code at unfamiliar places, keeping all that in mind, I have abstracted Opentracing API in easy to use functions that can by anyone so that developers have to facility to add new traces themselves easily."
jaeger,"Making this system more decentralized along with a strong foundation of meaningful and general tracepoints, is where I want to bring this project to."
jaeger,Let‚Äôs see what lies ahead!
jaeger,Hey there!
jaeger,"o/
I am interning with Ceph for Outreachy Summer, 2019."
jaeger,You can read about my experience applying here.
jaeger,"I must say this is a realisation, there are just two states to developers."
jaeger,Working with large codebase like Ceph.
jaeger,My first conversation with my mentor was how should I go by studying this overwhelming codebase.
jaeger,He then gave me some outline on where to begin.
jaeger,"How to approach, moreover I got to learn the most, discussing and seeing how they see things, one of which was catching an error I was having while setting up my environment."
jaeger,"According to my mentor Josh Durgin,
An engineer must know how to read a codebase, it is so important that you can reach the call stack and debug at much deeper level."
jaeger,"As we enter the third week, I am gonna share how it has all been along with my experience of how to read Ceph source code and troubleshooting issues."
jaeger,"I‚Äôll describe it further, after a brief outline about the project, so that you get the context."
jaeger,What am I working on?
jaeger,"TL;DR I‚Äôll be working with Ceph on adding jaegertracing tracepoints, which will make Ceph more robust and easier to trace and hence debug
What is Ceph?"
jaeger,"Ceph is a large scale distributed storage system, that intelligently handles Peta byte scale of data, it is based on RADOS ( Reliable, Autonomic Distributed Object Store )."
jaeger,"Ceph is a huge codebase, with passionate people working on fast paced development, with daily report meeting/ discussion, community events, hackathon and an annual meet Cephalacon."
jaeger,Read more about Ceph here.
jaeger,What is distributed tracing?
jaeger,"With the increasing complexity of the existing system the need for debugging these complex systems arises, these can‚Äôt be sufficed with the mere print statements and tests."
jaeger,They need to have discrete distributed system of tracing.
jaeger,"A very good example of which could be seen in this picture, tracing a monolithic service makes things invisible even if one system fails all further operations can‚Äôt be traced, which fails the whole motto of tracing."
jaeger,"So the need of easy to integrate, discrete, standard and capable of generating insights tracing system arose in cloud community, but with no standardization, no system could provide the wholesome functionality that were needed."
jaeger,"Illustration by: Lev Polyakov
You can learn more about tracing reading about Dapper, Lightstep and Zipkin
Why Ceph chose to use distributed tracing?"
jaeger,With the coming of standard libraries that are well maintained with active contributors.
jaeger,"like Jaeger, the distributed tracing technology that was existing since a decade, but could not be used because of ease of standardization can now be easily integrated."
jaeger,"Ceph can reach to a much improved tracing system, as Ceph has a lot of background processes which the existing Lttng, Blkin, Babel trace and Zipkin compromised system does not do justice to and has a learning curve without much insights, contrasting to which Jaeger presents a nice UI representation of traces, which can then be used to gather insights."
jaeger,"If this could successfully be achieved, it could transform the way Ceph is being debugged."
jaeger,"Hence, making ‚ÄúCeph faster in face of failure‚Äù
This was the basic overview of the project now talking about the problems I faced till now:
Setting up the development environment
The most troublesome step in the whole process was building the project, although I had earlier build Ceph before applying, but it didn‚Äôt include the Jaeger Libraries that Ceph would need to add instrumentation, first thing was to figure that out."
jaeger,"I cleaned that code and locally installed the libraries, yet there were some issues that came up; I tried fixing them in dependencies code, but have to resort to commenting them from source and rebuilding as they were just some check, that did the trick."
jaeger,"Vstart troubleshoot
The most significant problem I came across was due to some conflicting code in Ceph, my build even after being successful was not starting, then my mentor oriented me about how to track that error down."
jaeger,"I not only solved the issue but also learned the whole process of debugging Ceph, which I‚Äôll add extensively in coming posts hopefully."
jaeger,"Communication and working in different time zones
My mentors belongs to EST time zone and I to IST, initially I had problem adjusting to EST time zone but I now prefer working those hours as; whenever I have an issue I would not have to wait a day to discuss it, I leave a message on slack and if I am still not able to solve it, then I ping my mentor, this way they also can be aware of what I am doing."
jaeger,Asking for help and why Ceph is awesome!
jaeger,"Working remotely teaches you the value of communication, it‚Äôs when you get stuck and want to just bang your head, you reach out."
jaeger,"The great thing about Ceph is it‚Äôs community, they are a bunch of compassionate people who are there for you, with communication being backbone for their growth."
jaeger,"I participate in daily meetings where we update about our progress and discuss issues if any, along with this I have really supportive mentors, Josh, Neha, Ali with whom I get my doubts over audio/video, irc, chat and mail."
jaeger,"My experience had been awesome till now and I hope it continues to be same, I‚Äôll write about where to look at when troubleshooting Ceph and write more about my experiences in coming posts."
jaeger,"Contributing to open source is a rewarding activity, but it can be overwhelming to begin with."
jaeger,"So I decided to compile a list of gotcha‚Äôs that would‚Äôve been useful for me when I got started in this journey, and hope it benefits others as well ‚Äî
Always ask before sending in the PR!"
jaeger,Ask if the changes being submitting are the right ones to make.
jaeger,"The maintainer could have very different expectations from the proposed solution, and its better to discuss the solution upfront rather than to spend days implementing it."
jaeger,Comment on the issue thread to save time and effort!
jaeger,Iterate quickly on feedback.
jaeger,"The faster the iteration, the better the chances for PR acceptance."
jaeger,(I have on average 3‚Äì4 feedback loops).
jaeger,"Faster doesn‚Äôt mean to make changes hastily, but the idea is to invest time while the reviewers/maintainers have recently discussed the issue."
jaeger,Subscribe to the project (ex: ‚Äúwatch‚Äù it on GitHub) and read all issues and PRs.
jaeger,"This helps in understanding the general context of the features being implemented, and related bugs."
jaeger,Multiple related bugs are often grouped and fixed through one feature implementation.
jaeger,Read and participate in code reviews of other PRs.
jaeger,The community is always welcoming of fresh eyes to help review code.
jaeger,Make atomic and specific changes in one PR.
jaeger,"Always write tests, as they help to understand the functionality better."
jaeger,No change is small.
jaeger,"Technical documentation is a huge thing, and often helps better with on-boarding than coding."
jaeger,Consider taking language tutorials if contributing in a new programming language.
jaeger,"I have often shot myself in the foot with inadequate language knowledge, and recommend even a basic language tutorial during the contributions."
jaeger,"Be patient, all good things take time and effort."
jaeger,Make notes and study the code.
jaeger,"Finally, finding the perfect project is a myth ‚Äî just start contributing!"
jaeger,"Having said that, there are some factors to consider while picking a project that make the overall contributor experience enjoyable."
jaeger,"Evaluate the project roadmap, the skills you expect to pick up as you contribute to the project, and ensure a friendly, open community."
jaeger,All the best on your journey in open source!
jaeger,"If you‚Äôre looking for a good project to start, do check out Jaeger (https://github.com/jaegertracing/jaeger)!"
jaeger,"For the past few months, I‚Äôve been working on a set of benchmarks for OpenTracing as part of my Outreachy internship."
jaeger,"Performance tests are tricky, but I believe that most tests are representing the usage of the libraries in the real world."
jaeger,The results I‚Äôll be presenting here came from performance tests still in progress.
jaeger,"The code is available in OpenTracing GitHub, and I‚Äôm open to hearing your suggestions on how to improve it."
jaeger,"Doing instrumentation allows us to understand the behavior of our applications, detect abnormalities, and proactively take actions before the final user of our applications gets affected."
jaeger,How we can achieve that?
jaeger,"In order to have the data of our transactions, we have to add traces to our application, by writing code, or using specific libraries in a ‚Äúblack box‚Äù way."
jaeger,If you need to familiarize with these concepts I recommend this article.
jaeger,"In a joint effort of some vendors, and with the support of CNCF, it was defined a standard specification, Opentracing, that allows writing our traces in a vendor-neutral way."
jaeger,"This means that I can add instrumentation to my application according to the standardized API, and now choose a specific tracer, but if in the future I decided to change for another tracer implementation for some reason I don‚Äôt have to rewrite the code."
jaeger,This post presents the benchmarks results of OpenTracing API for Java to understand how much is the performance overhead using instrumentation.
jaeger,OpenTracing API for Java is the base for all instrumentation libraries which use it under the hood.
jaeger,How the tests are built?
jaeger,We used Java Microbenchmark Harness (JMH) to build the tests.
jaeger,JMH is a toolkit created by OpenJDK.
jaeger,"To build your first test, you can use an archetype provided by JMH:
mvn archetype:generate \
    -DinteractiveMode=false \
    -DarchetypeGroupId=org.openjdk.jmh \
    -DarchetypeArtifactId=jmh-java-benchmark-archetype \
    -DgroupId=org.sample \
    -DartifactId=jmh-examples \
    -Dversion=1.0
This command creates a base project that includes the required libraries and building plugins required for JMH."
jaeger,"These are fragments of an example of a benchmark application, each test we want to perform have to be annotated with @Benchmark and we can annotate additionally indicating which mode we want to use with @BenchmarkMode."
jaeger,"In this example, we have a benchmark method by each tracer implementation we are trying to measure."
jaeger,"Sometimes you may want to initialize some variables that your benchmark code needs, but which you don‚Äôt want to be part of the code your benchmark measures."
jaeger,Such variables are called ‚Äústate‚Äù variables.
jaeger,"In this example, in the StateVariables the spring context is initialized and we set the variable that contains the controller we need to use in each test."
jaeger,"Also in each iteration, we shut down the spring context."
jaeger,"In order to inject the right tracer for each test, we use spring profiles, that allow us to do that putting system properties before initialized the application."
jaeger,With this project configuration (Main.java) the results are written in the directory results using JSON format.
jaeger,"JMH results
To visualize graphically the results, we use JMH Visualizer."
jaeger,"JMH Visualizer
Type of tests
For each scenario, we‚Äôve built two types of tests: measuring the Throughput and the Sample Time."
jaeger,"SampleTime metrics
X-axis: represents each execution result."
jaeger,Y-axis: represents how long time it takes for the benchmark method to execute.
jaeger,"Throughput metrics
X-axis: represents each execution result."
jaeger,Y-axis: represents the number of operations per second (the number of times per second the benchmark method could be executed).
jaeger,"Results
Simple java
These tests measure the cost of a simple string concatenation using two constant strings ‚ÄúHello‚Äù and ‚Äúworld‚Äù with an iteration number i."
jaeger,The instrumentation code is added manually.
jaeger,"The tests compare a not-instrumented scenario with tests using instrumentation with the different tracers create a span, set a tag with the name of the tracers and log the resultant message of the concatenation."
jaeger,"Simple Java ‚Äî Sample Time
Let‚Äôs analyze the numbers: the values for No-instrumentation and NoopTracer are very close and equals in some cases."
jaeger,"MockTracer is not a good comparison, because it‚Äôs not intended to be used in a productive environment, keeping the values of span in RAM and these affect the results."
jaeger,"So, for this and the other scenarios let‚Äôs compare the No-instrumentation with Jaeger tracer."
jaeger,"| No-Inst  | Jaeger   | % Jaeger | Sample Time degradation | 
|----------|----------|----------|-------------------------| 
| 1.14E-07 | 6.29E-07 | 554%     | 454%                    | 
| 1.27E-07 | 7.27E-07 | 573%     | 473%                    | 
| 1.33E-07 | 7.01E-07 | 526%     | 426%                    | 
| 1.29E-07 | 7.18E-07 | 558%     | 458%                    | 
| 1.51E-07 | 7.56E-07 | 500%     | 400%                    |
According to these numbers, we can see that Sample Time increases ~440% in a simple java scenario."
jaeger,"Simple Java ‚Äî Throughput
| No-Inst    | Jaeger    | % Jaeger | Throughput degradation | 
|------------|-----------|----------|------------------------| 
| 17,491,646 | 1,820,168 | 10.41%   | 89.59%                 | 
| 17,330,040 | 1,784,527 | 10.30%   | 89.70%                 | 
| 17,185,759 | 1,732,435 | 10.08%   | 89.92%                 | 
| 17,350,257 | 1,741,779 | 10.04%   | 89.96%                 | 
| 17,222,531 | 1,695,528 | 9.845%   | 90.16%                 |
We can see the Throughput decreases by around 90% in a simple java scenario."
jaeger,"Spring Boot
These tests use an example spring boot application containing a basic billing process."
jaeger,The instrumentation code is added manually in each Traced* spring service.
jaeger,"The application is initialized for each test iteration, and using profiles, the right tracer is injected."
jaeger,The different tests measure the process of issuing an invoice in a not-instrumented scenario and instrumented with different tracers.
jaeger,The tests are performing the operation calling to the Spring services directly.
jaeger,"Spring Boot ‚Äî Sample Time
| No-Inst     | Jaeger      | % Jaeger | Sample Time degradation | 
|-------------|-------------|----------|-------------------------| 
| 1.16836E-06 | 3.47787E-06 | 298%     | 198%                    | 
| 1.16306E-06 | 3.60596E-06 | 310%     | 210%                    | 
| 1.18259E-06 | 3.51904E-06 | 298%     | 198%                    | 
| 1.17731E-06 | 3.5273E-06  | 300%     | 200%                    | 
| 1.21728E-06 | 3.544E-06   | 291%     | 191%                    |
The Sample Time increases ~200% in a Spring Boot scenario."
jaeger,"Spring Boot ‚Äî Throughput
| No-Inst | Jaeger  | % Jaeger | Throughput degradation | 
|---------|---------|----------|------------------------| 
| 954,744 | 311,765 | 32.65%   | 67.35%                 | 
| 927,196 | 300,623 | 32.42%   | 67.58%                 | 
| 931,335 | 307,140 | 32.98%   | 67.02%                 | 
| 951,730 | 301,834 | 31.71%   | 68.29%                 | 
| 919,047 | 303,105 | 32.98%   | 67.02%                 |
The Throughput decreases ~67% in Spring Boot scenario."
jaeger,"Spring Cloud
These tests use the petclinic sample spring-based application."
jaeger,The instrumentation is made automatically using the library opentracing-spring-cloud-starter.
jaeger,"The application is initialized for each test iteration and using profiles, the right tracer is injected in."
jaeger,The different tests measure the process of finding a pet owner by id in a not-instrumented scenario and instrumented with different tracers.
jaeger,The tests are performing the operation calling to the Spring services directly.
jaeger,"Spring Cloud ‚Äî Sample Time
| No-Inst     | Jaeger      | % Jaeger | Sample Time degradation | 
|-------------|-------------|----------|-------------------------| 
| 0.000139312 | 0.000150995 | 108%     | 8%                      | 
| 0.00013936  | 0.000148031 | 106%     | 6%                      | 
| 0.000142766 | 0.000146859 | 103%     | 3%                      | 
| 0.000146021 | 0.000150718 | 103%     | 3%                      | 
| 0.000146468 | 0.000148991 | 102%     | 2%                      |
The Sample Time increases ~4% in a Spring Cloud scenario."
jaeger,"Spring Cloud ‚Äî Throughput

| No-Inst | Jaeger | % Jaeger | Throughput degradation | 
|---------|--------|----------|------------------------| 
| 7,160   | 6,691  | 93.45%   | 6.55%                  | 
| 6,990   | 6,523  | 93.32%   | 6.68%                  | 
| 7,012   | 6,794  | 96.89%   | 3.11%                  | 
| 7,112   | 6,235  | 87.67%   | 12.33%                 | 
| 7,097   | 6,257  | 88.16%   | 11.84%                 |
The Throughput decreases ~8% in Spring Boot scenario."
jaeger,"JDBC
These tests use a sample spring boot application containing a basic course management process."
jaeger,The instrumentation is made automatically using the library opentracing-jdbc.
jaeger,"The application is initialized for each test iteration, and using profiles, the right tracer is injected."
jaeger,The different tests measure the process of getting the list of all courses in a not-instrumented scenario and instrumented with different tracers.
jaeger,The tests are performing the operation calling to the Spring services directly.
jaeger,"JDBC‚Äî Sample Time
| No-Inst     | Jaeger      | % Jaeger | Sample Time degradation | 
|-------------|-------------|----------|-------------------------| 
| 1.32359E-05 | 1.52948E-05 | 116%     | 16%                     | 
| 1.31049E-05 | 1.44857E-05 | 111%     | 11%                     | 
| 1.27248E-05 | 1.44507E-05 | 114%     | 14%                     | 
| 1.38321E-05 | 1.47132E-05 | 106%     | 6%                      | 
| 1.31739E-05 | 1.53496E-05 | 117%     | 17%                     |
The Sample Time increases ~13% in a JDBC scenario."
jaeger,"JDBC‚Äî Throughput
| No-Inst | Jaeger | % Jaeger | Throughput degradation | 
|---------|--------|----------|------------------------| 
| 74,880  | 71,348 | 95.28%   | 4.72%                  | 
| 75,847  | 70,432 | 92.86%   | 7.14%                  | 
| 78,737  | 66,674 | 84.68%   | 15.32%                 | 
| 76,764  | 72,769 | 94.80%   | 5.20%                  | 
| 76,987  | 70,942 | 92.15%   | 7.85%                  |
The Throughput decreases ~8% in JDBC scenario."
jaeger,"Servlet Filter
These tests use a servlet example application to process a GET request and return an HTML page with information of the request a random number assigned."
jaeger,"Using Undertow Deployment API the servlet is deployed, and a new instance off Undertow server is launched."
jaeger,The instrumentation is made automatically using the library opentracing-web-servlet-filter.
jaeger,"Using system properties, in each test, the tracer implementation is specified."
jaeger,The tracer is registered in GlobalTracer on startup using an application listener.
jaeger,The tests consist of making a simple request to get the hello world page in a not-instrumented scenario and instrumented with different tracers.
jaeger,"Servlet Filter ‚Äî Sample Time
| No-Inst     | Jaeger      | % Jaeger | Sample Time degradation | 
|-------------|-------------|----------|-------------------------| 
| 0.000145355 | 0.000153801 | 106%     | 6%                      | 
| 0.000152293 | 0.000147829 | 97%      | -3%                     | 
| 0.000145998 | 0.000147199 | 101%     | 1%                      | 
| 0.000151192 | 0.000145962 | 97%      | -3%                     | 
| 0.000147946 | 0.000149599 | 101%     | 1%                      |

Servlet Filter ‚Äî Throughput
| No-Inst | Jaeger | % Jaeger | Throughput degradation | 
|---------|--------|----------|------------------------| 
| 6,741   | 6,822  | 101.20%  | -1.20%                 | 
| 6,827   | 6,811  | 99.77%   | 0.23%                  | 
| 6,824   | 6,912  | 101.29%  | -1.29%                 | 
| 6,747   | 6,757  | 100.15%  | -0.15%                 | 
| 6,876   | 6,641  | 96.58%   | 3.42%                  |
The metrics show no evidence of overhead, as the deltas of Throughput and Sample Time are not representative (0% and 0.2%respectively)."
jaeger,"JAX-RS
These tests use a sample jax-rs with spring boot application containing a basic course management process."
jaeger,The instrumentation is made automatically using the library opentracing-jaxrs2-discovery.
jaeger,"This application exposes a JAX-RS endpoint for the CourseResource.The application is initialized for each test iteration, and using profiles, the right tracer is injected."
jaeger,The tracer is registered in GlobalTracer at startup using an application listener.
jaeger,The tests consist of client rest call to get the list of all courses in a not-instrumented scenario and instrumented with different tracers.
jaeger,"JAX-RS ‚Äî Sample Time
| No-Inst     | Jaeger      | % Jaeger | Sample Time degradation | 
|-------------|-------------|----------|-------------------------| 
| 0.000204294 | 0.000217782 | 107%     | 7%                      | 
| 0.000210961 | 0.000217579 | 103%     | 3%                      | 
| 0.000211709 | 0.000209426 | 99%      | -1%                     | 
| 0.000208181 | 0.000215236 | 103%     | 3%                      | 
| 0.0002043   | 0.000209104 | 102%     | 2%                      |

JAX-RS ‚Äî Throughput
| No-Inst | Jaeger | % Jaeger | Throughput degradation | 
|---------|--------|----------|------------------------| 
| 4,629   | 4,607  | 99.52%   | 0.48%                  | 
| 4,532   | 4,870  | 107.46%  | -7.46%                 | 
| 5,034   | 4,727  | 93.90%   | 6.10%                  | 
| 4,569   | 4,931  | 107.92%  | -7.92%                 | 
| 4,594   | 5,059  | 110.12%  | -10.12%                |
The metrics show no evidence of overhead, as the deltas of Throughput and Sample Time are not representative (3% and -3.7%respectively)."
jaeger,"Conclusions
In simple java scenarios, the Throughput decreases ~90% and the Sample Time increases ~440%."
jaeger,"This case does not represent a real use case, but it provides a good baseline of the theoretical limits of the tools involved."
jaeger,The big overhead that we see here when using a real tracer is indeed expected and a sign that the benchmark is sane.
jaeger,"In scenarios that include calls through a framework (Spring boot, Spring Cloud, JDBC), on average, the Throughput decreases 12% and the Sample Time Increases 14%."
jaeger,"In the scenarios with client calls through HTTP (Servlet Filter, JAX-RS), the metrics show no evidence of overhead, as the deltas of Throughput and Sample Time are not representative."
jaeger,"Based on these results, we don‚Äôt see that the use of instrumentation presents a considerable impact on distributed applications,
considering it proportional to the cost of frameworks and networking required."
jaeger,The overhead comes from the actual tracer and is closely related to how they work and how they are configured.
jaeger,"The next logical step is to create benchmarks for concrete tracers, such as Jaeger‚Äôs, to understand how much of the overhead can be controlled via configuration options such as sampling."
jaeger,Tracking/maintaining micro services were became complex for new-comer.
jaeger,"Opentracing protocol provide us a good choice to tracing diversity system that triggered from font-end to back-end (web api, service, sql‚Ä¶)."
jaeger,Combined with Jaeger with powerful query syntax and interface with system flow graph would give us great help on it.
jaeger,The article just simply demonstrate how to introduce Jaeger into .Net Core application and if you are interested the advance features on Jaeger please refer to official website and do more research on its architecture.
jaeger,So you could understand why Uber reply on Jaeger for system tracing and monitoring.
jaeger,"Installed Jaeger through below command (the all-in-one packaged jaeger-agent, jaeger-collector, jaeger-query/ui all together):
docker run -d --name jaeger -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14268:14268 -p 9411:9411 jaegertracing/all-in-one:1.11
Note that Jaeger that running on docker only support Linux containers only
And default storage was in memory

Docker with Jaeger
Let‚Äôs Open Jaeger UI on local: http://localhost:16686/search

Jaeger-UI
Next, installed jaeger-client inside the demo application."
jaeger,"Nuget packages
For the client side we need Jaeger and OpenTracing.Contrib.NetCore library

Let‚Äôs fired the application to see how easily we could send our tracing information into Jaeger collector."
jaeger,"Waiting for downloading completed, refresh Jaeger UI page, we could discovery new service appearance and trigger ‚ÄúFind Trace‚Äù for more detail."
jaeger,"Search for target service
As dig into the tracer, we have logged down every down event for more information: operating time, Tag‚Ä¶etc."
jaeger,"In the Kubernetes/OpenShift community everyone is talking about Istio service mesh, so I wanted to share my experience about the installation and running a sample microservice application with Istio on OpenShift 3.11 and 4.0."
jaeger,Service mesh on OpenShift is still at least a few month away from being available generally to run in production but this gives you the possibility to start testing and exploring Istio.
jaeger,I have found good documentation about installing Istio on OCP and OKD have a look for more information.
jaeger,"To install Istio on OpenShift 3.11 you need to apply the node and master prerequisites you see below; for OpenShift 4.0 and above you can skip these steps and go directly to the istio-operator installation:
sudo bash -c 'cat << EOF > /etc/origin/master/master-config.patch
admissionConfig:
  pluginConfig:
    MutatingAdmissionWebhook:
      configuration:
        apiVersion: apiserver.config.k8s.io/v1alpha1
        kubeConfigFile: /dev/null
        kind: WebhookAdmission
    ValidatingAdmissionWebhook:
      configuration:
        apiVersion: apiserver.config.k8s.io/v1alpha1
        kubeConfigFile: /dev/null
        kind: WebhookAdmission
EOF'
        
sudo cp -p /etc/origin/master/master-config.yaml /etc/origin/master/master-config.yaml.prepatch
sudo bash -c 'oc ex config patch /etc/origin/master/master-config.yaml.prepatch -p ""$(cat /etc/origin/master/master-config.patch)"" > /etc/origin/master/master-config.yaml'
sudo su -
master-restart api
master-restart controllers
exit       

sudo bash -c 'cat << EOF > /etc/sysctl.d/99-elasticsearch.conf 
vm.max_map_count = 262144
EOF'

sudo sysctl vm.max_map_count=262144
The Istio installation is straight forward by starting first to install the istio-operator:
oc new-project istio-operator
oc new-app -f https://raw.githubusercontent.com/Maistra/openshift-ansible/maistra-0.9/istio/istio_community_operator_template.yaml --param=OPENSHIFT_ISTIO_MASTER_PUBLIC_URL=<-master-public-hostname->
Verify the operator deployment:
oc logs -n istio-operator $(oc -n istio-operator get pods -l name=istio-operator --output=jsonpath={.items..metadata.name})
Once the operator is running we can start deploying Istio components by creating a custom resource:
cat << EOF >  ./istio-installation.yaml
apiVersion: ""istio.openshift.com/v1alpha1""
kind: ""Installation""
metadata:
  name: ""istio-installation""
  namespace: istio-operator
EOF

oc create -n istio-operator -f ./istio-installation.yaml
Check and watch the Istio installation progress which might take a while to complete:
oc get pods -n istio-system -w

# The installation of the core components is finished when you see:
...
openshift-ansible-istio-installer-job-cnw72   0/1       Completed   0         4m
Afterwards, to finish off the Istio installation, we need to install the Kiali web console:
bash <(curl -L https://git.io/getLatestKialiOperator)
oc get route -n istio-system -l app=kiali
Verifying that all Istio components are running:
$ oc get pods -n istio-system
NAME                                          READY     STATUS      RESTARTS   AGE
elasticsearch-0                               1/1       Running     0          9m
grafana-74b5796d94-4ll5d                      1/1       Running     0          9m
istio-citadel-db879c7f8-kfxfk                 1/1       Running     0          11m
istio-egressgateway-6d78858d89-58lsd          1/1       Running     0          11m
istio-galley-6ff54d9586-8r7cl                 1/1       Running     0          11m
istio-ingressgateway-5dcf9fdf4b-4fjj5         1/1       Running     0          11m
istio-pilot-7ccf64f659-ghh7d                  2/2       Running     0          11m
istio-policy-6c86656499-v45zr                 2/2       Running     3          11m
istio-sidecar-injector-6f696b8495-8qqjt       1/1       Running     0          11m
istio-telemetry-686f78b66b-v7ljf              2/2       Running     3          11m
jaeger-agent-k4tpz                            1/1       Running     0          9m
jaeger-collector-64bc5678dd-wlknc             1/1       Running     0          9m
jaeger-query-776d4d754b-8z47d                 1/1       Running     0          9m
kiali-5fd946b855-7lw2h                        1/1       Running     0          2m
openshift-ansible-istio-installer-job-cnw72   0/1       Completed   0          13m
prometheus-75b849445c-l7rlr                   1/1       Running     0          11m
Let‚Äôs start to deploy the microservice application example by using the Google Hipster Shop, it contains multiple microservices which is great to test with Istio:
# Create new project
oc new-project hipster-shop

# Set permissions to allow Istio to deploy the Envoy-Proxy side-car container
oc adm policy add-scc-to-user anyuid -z default -n hipster-shop
oc adm policy add-scc-to-user privileged -z default -n hipster-shop

# Create Hipster Shop deployments and Istio services
oc create -f https://raw.githubusercontent.com/berndonline/openshift-ansible/master/examples/istio-hipster-shop.yml
oc create -f https://raw.githubusercontent.com/berndonline/openshift-ansible/master/examples/istio-manifest.yml

# Wait and check that all pods are running before creating the load generator
oc get pods -n hipster-shop -w

# Create load generator deployment
oc create -f https://raw.githubusercontent.com/berndonline/openshift-ansible/master/examples/istio-loadgenerator.yml
As you see below each pod has a sidecar container with the Istio Envoy proxy which handles pod traffic:
[centos@ip-172-26-1-167 ~]$ oc get pods
NAME                                     READY     STATUS    RESTARTS   AGE
adservice-7894dbfd8c-g4m9v               2/2       Running   0          49m
cartservice-758d66c648-79fj4             2/2       Running   4          49m
checkoutservice-7b9dc8b755-h2b2v         2/2       Running   0          49m
currencyservice-7b5c5f48fc-gtm9x         2/2       Running   0          49m
emailservice-79578566bb-jvwbw            2/2       Running   0          49m
frontend-6497c5f748-5fc4f                2/2       Running   0          49m
loadgenerator-764c5547fc-sw6mg           2/2       Running   0          40m
paymentservice-6b989d657c-klp4d          2/2       Running   0          49m
productcatalogservice-5bfbf4c77c-cw676   2/2       Running   0          49m
recommendationservice-c947d84b5-svbk8    2/2       Running   0          49m
redis-cart-79d84748cf-cvg86              2/2       Running   0          49m
shippingservice-6ccb7d8ff7-66v8m         2/2       Running   0          49m
[centos@ip-172-26-1-167 ~]$
The Kiali web console answers the question about what microservices are part of the service mesh and how are they connected which gives you a great level of detail about the traffic flows:

Detailed traffic flow view:

The Isito installation comes with Jaeger which is an open source tracing tool to monitor and troubleshoot transactions:


Enough about this, lets connect to our cool Hipster Shop and happy shopping:

Additionally there is another example, the Istio Bookinfo if you want to try something smaller and less complex:
oc new-project myproject

oc adm policy add-scc-to-user anyuid -z default -n myproject
oc adm policy add-scc-to-user privileged -z default -n myproject

oc apply -n myproject -f https://raw.githubusercontent.com/Maistra/bookinfo/master/bookinfo.yaml
oc apply -n myproject -f https://raw.githubusercontent.com/Maistra/bookinfo/master/bookinfo-gateway.yaml
export GATEWAY_URL=$(oc get route -n istio-system istio-ingressgateway -o jsonpath='{.spec.host}')
curl -o /dev/null -s -w ""%{http_code}\n"" http://$GATEWAY_URL/productpage

curl -o destination-rule-all.yaml https://raw.githubusercontent.com/istio/istio/release-1.0/samples/bookinfo/networking/destination-rule-all.yaml
oc apply -f destination-rule-all.yaml

curl -o destination-rule-all-mtls.yaml https://raw.githubusercontent.com/istio/istio/release-1.0/samples/bookinfo/networking/destination-rule-all-mtls.yaml
oc apply -f destination-rule-all-mtls.yaml

oc get destinationrules -o yaml
I hope this is a useful article for getting started with Istio service mesh on OpenShift."
jaeger,"Task at hand
So, it began with a new work assignment."
jaeger,The ask was to setup an observability platform for a cloud based product that can be leveraged to consume the LTM (Logs-Traces-Metrics) of microservices.
jaeger,"After some preliminary investigative google searches, and discussions with technical stalwarts, it was decided that we will go ahead with Jaeger to take care of traces."
jaeger,"High-level Design
At a high level, the idea was to deploy Jaeger agent and collector to collect the traces from our microservices and shipping them off to a cloud-based off-premise observability platform."
jaeger,"The traces were captured as files, base64 encoded and dumped to a remote server, wherein we decided to hook up Apache Nifi to read in the file content, base64 decode it and pass it on to Jaeger Collector instance running InfluxDB as backend storage (instead of the default Cassandra/ElasticSearch)."
jaeger,The off-premise observability stack was to be deployed on a Kubernetes cluster.
jaeger,"(I will skip the logs and metrics section for this writeup)
Deployment Options
When it comes to Jaeger deployment there were multiple options or rather I should say strategies."
jaeger,Here‚Äôs what the official Jaeger site says around deployment.
jaeger,There were a few good blogs that explained the pros and cons of the various strategies.
jaeger,"But to summarize, here‚Äôs what we got:
Deploy Jaeger manually using deployment
Deploying Jaeger operator
Deploying Jaeger using Helm charts
Support for Influx DB
Sadly, I would say, our deployment strategies all went for a toss when it came to deploying Jaeger with Influx DB."
jaeger,Jaeger supports external storage using gRPC plugins (this is the one for Influx).
jaeger,There are docker images that bundle jaeger all-in-one with a sample microservice and influx db instance (all running as local processes in a single container) and thus enable the proof-of-concept.
jaeger,"But when it comes to production level setup, we couldn‚Äôt rely on them."
jaeger,"We were able to download the source code for the gRPC plugin, build it and use the compiled binary along with a Jaeger instance but it was‚Äôt fitting our deployment strategies."
jaeger,Reason?
jaeger,Jaeger operator didn‚Äôt support external storage configuration options when deploying Jaeger.
jaeger,"Same for, Helm, it didn‚Äôt support the external storage option either."
jaeger,"Experiments we did
Along the way, we kept trying and experimenting."
jaeger,"Here‚Äôs a summary of what we attempted (sharing the notes):
Experiment #1: Deploying Jaeger all-in-one using Helm charts
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm repo update
helm install <custom-jaeger-release-name> jaegertracing/jaeger
kubectl get pods --all-namespaces
export POD_NAME=$(kubectl get pods --namespace default -l ""app.kubernetes.io/instance=jaeger,app.kubernetes.io/component=query"" -o jsonpath=""{.items[0].metadata.name}"")
kubectl port-forward --namespace default $POD_NAME 8080:16686
Once up, we could expose the UI using the following port-forward (we extract the POD_NAME in the first command and use that in the second one):
export POD_NAME=$(kubectl get pods --namespace default -l ""app.kubernetes.io/instance=jaeger,app.kubernetes.io/component=query"" -o jsonpath=""{.items[0].metadata.name}"")
kubectl port-forward --namespace default $POD_NAME 8080:16686
Finally, one could view the UI at: http://127.0.0.1:8080/
Experiment #2: Deploying Jaeger using Jaeger operator
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm repo update
helm install <jaeger-operator-custom-release-name> jaegertracing/jaeger-operator
We jaeger operator successfully deployed, we created a deployment.yaml to deploy a jaeger instance."
jaeger,"The following was the content of the deployment.yaml:
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simplest
This deployment.yaml was then deployed using kubectl command:
kubectl apply -f ./jaeger_simplest.yaml
The following pods could be seen up and running:

Experiment #3: Running jaeger all-in-one binary as a process using SPAN_STORAGE_TYPE=rpc-plugin and integrating influxDB as its internal storage (non-K8s approach)
Firstly, download jaeger bundle from https://github.com/jaegertracing/jaeger/releases/download/v1.21.0/jaeger-1.21.0-linux-amd64.tar.gz."
jaeger,"Extract it with the below command:
tar -xf <bundlename>.tar.gz
You will see binaries for all-in-one, collector, query, agent in the extracted folder."
jaeger,"Next, clone the gRPC Influx DB plugin:
git clone https://github.com/influxdata/jaeger-influxdb.git 
Build it as described on the page: https://github.com/influxdata/jaeger-influxdb."
jaeger,"On a new terminal spin up Influx DB instance, best way to do it is using the standard docker image:
docker run -d -p 8086:8086 -v $PWD:/var/lib/influxdb influxdb
Create tracing db in there, this database will be used later on by the Jaeger client:
docker exec -it <influx-db-container> bash
influx
create database tracing
Finally, to start Jaeger with Influx DB, run this command preferably from the root of the repo cloned above:
SPAN_STORAGE_TYPE=grpc-plugin <path to extracted jaeger bundle>/jaeger-all-in-one --grpc-storage-plugin.binary <root of jaeger-influxdb-dir>/jaeger-influxdb --grpc-storage-plugin.configuration-file <root of jaeger-influxdb-dir>/config-example-v1.yaml
Jaeger traces itself and hence you will be able to see some traces in the Influx DB after a few minutes:
docker exec -it <influx-db-container> bash
influx
use tracing
select * from span

Experiment #4: Running jaeger-query as a container (with storage configured as grpc-plugin) and influxdb as another container
Under jaeger-influxdb repo (the repo that we cloned in Experiment #3), set config-example-v1.yaml as:
influxdb.host: http://influxdb:8086
influxdb.database: tracing
Next, we create a docker network using the command below and use that to launch this container :
docker network create mynetwork
We launch the Influx db as a container on the same mynetwork as below:
docker run -d -p 8086:8086 -v $PWD:/var/lib/influxdb ‚Äî name influxdb ‚Äî net=mynetwork influxdb
NOTE: It has persistent storage as the PWD is mounted."
jaeger,"Moreover, this db instance has traces from Approach 4 captured and will be retained and can be viewed in the database."
jaeger,"Next, we run the jaeger-query docker image and pass in the SPAN_STORAGE_TYPE and GRPC_STORAGE_PLUGIN_BINARY to that container by mounting the current directory onto the container, as shown with the command below:
docker run -d -p 16686:16686 -v ‚Äú${PWD}:/tmp‚Äù -e SPAN_STORAGE_TYPE=grpc-plugin -e GRPC_STORAGE_PLUGIN_BINARY=/tmp/cmd/jaeger-influxdb/jaeger-influxdb-linux -e GRPC_STORAGE_PLUGIN_CONFIGURATION_FILE=/tmp/config-example-v1.yaml ‚Äî net=mynetwork ‚Äî name jaeger-query jaegertracing/jaeger-query:latest
NOTE: in the command above:
-v ‚Äú${PWD}:/tmp‚Äù ‚Üí mounts the current directory i.e."
jaeger,"the root directory of jaeger-influxdb plugin repo to the /tmp folder on the jaeger-query container
it uses our custom defined docker network called mynetwork."
jaeger,This enables it to interact with the Influx DB server.
jaeger,"Conclusion
After all the experimentation, we were not able to figure out a way to deploy Jaeger with Influx DB on a Kubernetes cluster using a deployment strategy (either Jaeger operator or Helm) that matched our product/tech stack requirements."
jaeger,"Hence, we decided to drop the plan of using InfluxDB and went ahead with the default database Cassandra with Jaeger."
jaeger,Service mesh provides a dedicated network for service-to-service communication in a transparent way.
jaeger,"Istio aims to help developers and operators address service mesh features such as dynamic service discovery, mutual transport layer security (TLS), circuit breakers, rate limiting, and tracing."
jaeger,Jaeger with Istio augments monitoring and tracing of cloud-native apps on a distributed networking system.
jaeger,This article explains how to get started with Jaeger to build an Istio service mesh on the Kubernetes platform.
jaeger,"Spinning up a Kubernetes cluster
Minikube allows you to run a single-node Kubernetes cluster based on a virtual machine such as KVM, VirtualBox, or HyperKit on your local machine."
jaeger,"Install Minikube and use the following shell script to run it:
#!/bin/bash
export MINIKUBE_PROFILE_NAME=istio-jaeger
minikube profile $MINIKUBE_PROFILE_NAME
minikube config set cpus 3
minikube config set memory 8192
# You need to replace appropriate VM driver on your local machine
minikube config set vm-driver hyperkit
minikube start
In the above script, replace the ‚Äî vm-driver=xxxoption with the appropriate virtual machine driver on your operating system (OS)."
jaeger,"Deploying Istio service mesh with Jaeger
Download the Istio installation file for your OS from the Istio release page."
jaeger,"In the Istio package directory, you will find the Kubernetes installation YAML files in install/ and the sample applications in sample/."
jaeger,"Use the following commands:
$ curl -L https://git.io/getLatestIstio | sh -
$ cd istio-1.0.5
$ export PATH=$PWD/bin:$PATH
The easiest way to deploy Istio with Jaeger on your Kubernetes cluster is to use Custom Resource Definitions."
jaeger,"Install Istio with mutual TLS authentication between sidecars with these commands:
$ kubectl apply -f install/kubernetes/helm/istio/templates/crds.yaml
$ kubectl apply -f install/kubernetes/istio-demo-auth.yaml
Check if all pods of Istio on your Kubernetes cluster are deployed and running correctly by using the following command and review the output:
$ kubectl get pods -n istio-system
NAME                                      READY     STATUS      RESTARTS   AGE
grafana-59b8896965-p2vgs                  1/1       Running     0          3h
istio-citadel-856f994c58-tk8kq            1/1       Running     0          3h
istio-cleanup-secrets-mq54t               0/1       Completed   0          3h
istio-egressgateway-5649fcf57-n5ql5       1/1       Running     0          3h
istio-galley-7665f65c9c-wx8k7             1/1       Running     0          3h
istio-grafana-post-install-nh5rw          0/1       Completed   0          3h
istio-ingressgateway-6755b9bbf6-4lf8m     1/1       Running     0          3h
istio-pilot-698959c67b-d2zgm              2/2       Running     0          3h
istio-policy-6fcb6d655f-lfkm5             2/2       Running     0          3h
istio-security-post-install-st5xc         0/1       Completed   0          3h
istio-sidecar-injector-768c79f7bf-9rjgm   1/1       Running     0          3h
istio-telemetry-664d896cf5-wwcfw          2/2       Running     0          3h
istio-tracing-6b994895fd-h6s9h            1/1       Running     0          3h
prometheus-76b7745b64-hzm27               1/1       Running     0          3h
servicegraph-5c4485945b-mk22d             1/1       Running     1          3h
Building sample microservice apps
You can use the Bookinfo app to learn about Istio‚Äôs features."
jaeger,"Bookinfo consists of four microservice apps: productpage, details, reviews, and ratings deployed independently on Minikube."
jaeger,"Each microservice will be deployed with an Envoy sidecar via Istio by using the following commands:
// Enable sidecar injection automatically
$ kubectl label namespace default istio-injection=enabled
$ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
// Export the ingress IP, ports, and gateway URL
$ kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
$ export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?"
jaeger,"(@.name==""http2"")].nodePort}')
$ export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?"
jaeger,"(@.name==""https"")].nodePort}')
$ export INGRESS_HOST=$(minikube ip)
$ export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT
Accessing the Jaeger dashboard
To view tracing information for each HTTP request, create some traffic by running the following commands at the command line:
$ while true; do
  curl -s http://${GATEWAY_URL}/productpage > /dev/null
  echo -n ."
jaeger,";
  sleep 0.2
done
You can access the Jaeger dashboard through a web browser with http://localhost:16686 if you set up port forwarding as follows:
kubectl port-forward -n istio-system $(kubectl get pod -n istio-system -l app=jaeger -o jsonpath='{.items[0].metadata.name}') 16686:16686 &
You can explore all traces by clicking ‚ÄúFind Traces‚Äù after selecting the productpage service."
jaeger,"Your dashboard will look similar to this:

You can also view more details about each trace to dig into performance issues or elapsed time by clicking on a certain trace."
jaeger,"Conclusion
A distributed tracing platform allows you to understand what happened from service to service for individual ingress/egress traffic."
jaeger,"Istio sends individual trace information automatically to Jaeger, the distributed tracing platform, even if your modern applications aren‚Äôt aware of Jaeger at all."
jaeger,"In the end, this capability helps developers and operators do troubleshooting easier and quicker at scale."
jaeger,Daryl sucks down antacids in the car as I take a pull from the vodka.
jaeger,For some reason I feel disappointed after the swig.
jaeger,Something doesn‚Äôt feel right.
jaeger,Like something‚Äôs missing.
jaeger,"I think about having some of the Jaeger, but I‚Äôll wait till I feel desperate."
jaeger,Last time I had that stuff I puked black and it looked like hell was coming out of me.
jaeger,"I don‚Äôt know Deshawn super well, so I‚Äôm not taking any more pulls until we‚Äôre inside."
jaeger,"I wonder if Deshawn and Carla are together, then I wonder why I wonder that, then decide I don‚Äôt care about anything."
jaeger,"It‚Äôs the kind of loop I‚Äôm used to, so that‚Äôs kind of good."
jaeger,Sometimes there‚Äôs a flash in my head of a computer on fire or a pixelated image of fire on a computer screen.
jaeger,Sometimes other things are on fire.
jaeger,"I get other flashes of nothingness, a void of pitch dark but there‚Äôs something alive about it, like a subtle movement but I can‚Äôt tell if it‚Äôs really there."
jaeger,Who knows if it‚Äôs a weird thing or just me being paranoid.
jaeger,"I take another small sip of the vodka and I hate it, so me and Daryl head to the door."
jaeger,"There‚Äôs, like, seven or ten people there and I don‚Äôt know most of ‚Äôem."
jaeger,Carla‚Äôs got her hair in these little bun horns and her brother‚Äôs JNCOs.
jaeger,Deshawn dresses like a nerd but somehow he‚Äôs cool about it.
jaeger,"I always thought he looked kind of like a pug in the face too, but also somehow in a cool way."
jaeger,I can tell I‚Äôm thinking too much.
jaeger,"Daryl says, ‚Äú‚ÄòEy, Carla."
jaeger,Deshawn.
jaeger,Howsit goin‚Äô?‚Äù I‚Äôm busy trying to shut the screen door without it slamming on me and making me look a doofus.
jaeger,"‚ÄúIt‚Äôs good, man."
jaeger,"Yeah, it‚Äôs real good."
jaeger,"Welcome to my place,‚Äù says Deshawn."
jaeger,"‚ÄúOh, yeah, hey, man."
jaeger,"How‚Äôs , uh‚Ä¶here‚Äôs the Jaeger,‚Äù I say, looking down at my own dumb hand holding the bottle."
jaeger,I‚Äôve done worse.
jaeger,‚ÄúNice!
jaeger,"Thanks, man!"
jaeger,"You wanna do a bomb, or‚Ä¶?‚Äù
‚ÄúNah, maybe later."
jaeger,"I got vodka too, here.‚Äù
Carla says, ‚ÄúHell, yeah!"
jaeger,"You go, boy!‚Äù Carla loves vodka."
jaeger,She loves everything.
jaeger,I think she‚Äôs the only person in my life that hugs me.
jaeger,"Daryl‚Äôs tried but I dodge him hard, but I let Carla hug me hello and good-booze right now."
jaeger,"It‚Äôs nice and I don‚Äôt feel nervous, but that doesn‚Äôt last long."
jaeger,"‚ÄúYou want some with pop or something, or straight shots, like‚Ä¶‚Äù
‚ÄúUm, um, uuuuhh."
jaeger,Hmm.
jaeger,Ummmmm‚Ä¶‚Äù I blank out for a second.
jaeger,"It might be my regular thing, I don‚Äôt know."
jaeger,"I sink back into my head and see the computer fire from before, both of them, and the void and the orb too."
jaeger,But they‚Äôre all for split seconds this time.
jaeger,"Is it happening or am I just remembering it, or just thinking about it?"
jaeger,"‚ÄúAll of it,‚Äù I say out loud, breaking free."
jaeger,‚ÄúFucking all.
jaeger,Right.
jaeger,Man!
jaeger,Let‚Äôs go!
jaeger,"Daryl, you in,‚Äù says Carla."
jaeger,"‚ÄúInna sec, prob‚Äôly."
jaeger,"My belly‚Äôs stuffed with tacos and fries right at the moment.‚Äù
‚ÄúAlright."
jaeger,Good on you.
jaeger,"Knowing yourself.‚Äù
Carla throws Daryl a peace sign and pours me and her shots."
jaeger,"We throw them back and I hate them, but I like being with Carla."
jaeger,She‚Äôs sparkle in a dumb world.
jaeger,She gets me a grape pop to make a drink.
jaeger,I remember that time in high school I drank so much Canadian whiskey and grape pop and whiskey and threw up and it was so close to black I thought I was dying because I forgot I‚Äôd been drinking grape.
jaeger,"It‚Äôs an odd thing to give a shit about, but I don‚Äôt wanna throw up dark tonight, but I don‚Äôt say anything to Carla and I make my drink too strong."
jaeger,Maybe it‚Äôs for the best.
jaeger,This brosky needs to chill.
jaeger,"‚ÄúHey, you all, let‚Äôs take this to the basement,‚Äù says Deshawn."
jaeger,Have you ever wondered how GOJEK always manages to find you a driver when you need one?
jaeger,Do you notice how your driver is always just right around the corner to pick you up?
jaeger,"Well, it‚Äôs not magic; it‚Äôs GOJEK‚Äôs Marketplace team with a hefty dose of AI & technology."
jaeger,The Marketplace team is responsible for making sure that its millions of customers are paired with the right drivers.
jaeger,This supply and demand matching is the core problem that the GOJEK platform tackles every day.
jaeger,"And GOJEK is in the business of giving the best at what matters, including giving the best experience for its users."
jaeger,"From the moment the user clicks the ‚Äúorder‚Äù button to the second their driver shows up at their door, we want them to feel like it‚Äôs a match made in GOJEK heaven."
jaeger,But what does it mean to be paired with the right driver?
jaeger,"‚ÄúPeople want to get matched to a driver that is nearby, and drivers want the same."
jaeger,"But the definition of ‚Äònearby‚Äô changes based on the type of product and the time of day,‚Äù Andrew Brinson, Senior Vice President at GOJEK‚Äôs Mobility Marketplace told me recently."
jaeger,"‚ÄúWe‚Äôre matching millions of orders weekly across Indonesia and Southeast Asia, being off by a few minutes is huge!‚Äù

Andrew Brinson, SVP Mobility Marketplace
To make it even more challenging, customer preference also changes depending on the time of day and the type of service."
jaeger,"After work, you might be willing to wait 10‚Äì15 minutes for your GO-RIDE or GO-CAR driver to pick you up."
jaeger,"But during the morning rush hour, 10 minutes might just be too long because you don‚Äôt want to be late for work."
jaeger,The same goes for the type of service.
jaeger,It would be understandable to wait 25 to 30 minutes for your GO-FOOD order to arrive because the restaurant might need time to cook your favorite dish.
jaeger,And it‚Äôs okay to wait even more than one hour for the GO-SEND driver to deliver your package to your mom across the city.
jaeger,But waiting more than 30 minutes for a GO-RIDE is much too long!
jaeger,The Marketplace team must also make sure that it manages the availability of drivers on the road effectively.
jaeger,"‚ÄúSo for every minute the drivers spend online, we want to make sure they‚Äôre making the most money when they‚Äôre doing trips and completing orders,‚Äù Andrew said."
jaeger,"To aid in the matching of orders, the Mobility Marketplace also looks at pricing, customer & driver incentives, and system stability across our tech stack."
jaeger,"The team has individuals across product engineering, data science, business intelligence, strategy & operations in each of GOJEK‚Äôs offices."
jaeger,So how does the Marketplace team make sure you get the right driver?
jaeger,"Jaeger is ready to serve your supply and demand needs
Using technology and AI, GOJEK‚Äôs Marketplace team decides which drivers are matched with which customers."
jaeger,"Remember, they have to take into account so many factors and must balance the needs of both drivers and customers."
jaeger,"Yes, this job is as challenging as it sounds."
jaeger,And this was one of the first problems that GOJEK‚Äôs Data Science team had to solve.
jaeger,The team‚Äôs first solution was a stand-alone Machine Learning (ML) model and web service to rank drivers.
jaeger,"It worked well for a while, until it didn‚Äôt."
jaeger,A single ML model has a difficult time in balancing multiple business objectives.
jaeger,The team then built a new system for multi-objective allocation that combines ML models and real-time features with a high degree of flexibility and manual configuration.
jaeger,"The new system is called Jaeger, named after the world-saving humanoid mechas in Pacific Rim."
jaeger,"Jaeger is made possible thanks to the work of GOJEK‚Äôs Data Science Platform team, which have built many of the foundational blocks for the system."
jaeger,Jaeger is a system of modular and easily extendible components.
jaeger,"The system consists of four components, Feast, Lasso, Meister and Babel."
jaeger,"Each component serves a different purpose, each just as crucial as the other."
jaeger,"After Jaeger‚Äôs launch, it was obvious just how big of an impact the new system had on GOJEK‚Äôs business."
jaeger,"The smarter allocation decisions enabled 1 million additional completed trips within weeks of the system‚Äôs launch, with significant improvements seen in dispatch time, cancellation rates, driver utilization, and income, just to name a few."
jaeger,And this is just the beginning for Jaeger.
jaeger,GOJEK will continue to develop new and existing models.
jaeger,"If you want to read more about Jaeger, click here."
jaeger,"Solving tomorrow‚Äôs problems today
The biggest challenge for the Marketplace team is GOJEK‚Äôs rapid growth."
jaeger,They have to make sure that the system they design at the start of each year is ready to handle something 2 to 3 times bigger at the end of the year.
jaeger,"‚ÄúThe biggest tradeoff is solving today‚Äôs problems while knowing that the solution for today‚Äôs problems is almost certainly not going to work in the future,‚Äù Andrew said."
jaeger,"‚ÄúThe problems in the future might be much meaner, much bigger in the next 6 to 12 months!‚Äù
The scale of the Marketplace team‚Äôs work continues to grow by the second, and this year, it is estimated that GOJEK would process billions of orders from its different streams of services."
jaeger,It‚Äôs a scale that no other companies have even been able to achieve.
jaeger,"To tackle future problems, Mobility Marketplace leverages automation ‚Äî algorithms & AI to make decisions."
jaeger,"Keeping these at the core of our product design, Marketplace can build flexible systems able to handle billions of annual orders."
jaeger,"While Andrew is satisfied with the work that his team has done so far, he acknowledged that there was much more work to do, such as improving services in GO-SEND and GO-SHOP to make the marketplace much more efficient."
jaeger,"If you think you have what it takes to solve problems at scale, GOJEK is your playground."
jaeger,GOJEK will continue to grow and its problems will only become more complex.
jaeger,Click here if you think you‚Äôre up for the challenge!
jaeger,"‚Äî
So, what do you say?"
jaeger,Does juggling GOJEK‚Äôs supply and demand sound like a challenge you‚Äôre up for?
jaeger,Click here to ignite your power with GOJEK and help us keep the world in balance!
jaeger,Shout out to Peter Richens for writing this article on how GOJEK uses Machine Learning to match drivers and riders.
jaeger,Illustration by Athiyah Alatas
jaeger,"*.pb.go files can be generated using the following command ‚Äî
docker run --rm -v $(pwd):$(pwd) -w $(pwd) znly/protoc \
  --gogo_out=plugins=grpc,Mgoogle/protobuf/timestamp.proto=github.com/gogo/protobuf/types,Mgoogle/protobuf/duration.proto=github.com/gogo/protobuf/types,Mgoogle/protobuf/empty.proto=github.com/gogo/protobuf/types,Mgoogle/api/annotations.proto=github.com/gogo/googleapis/google/api,Mmodel.proto=github.com/jaegertracing/jaeger/model:/home/git/go/src/github.com/jaegertracing/jaeger/proto-gen/api_v2 \
  -Imodel/proto -Ivendor/github.com/gogo/protobuf/ -Ivendor/github.com/grpc-ecosystem/grpc-gateway/ \
  model/proto/api_v2.proto
For the generation for .pb files, the following can be used ‚Äî
docker run --rm -v $(pwd):$(pwd) -w $(pwd) znly/protoc \
  --include_imports \
  --include_source_info \
  --descriptor_set_out=service.pb \
  -Imodel/proto -Ivendor/github.com/gogo/protobuf \
  -Ivendor/github.com/grpc-ecosystem/grpc-gateway \
 model/proto/api_v2.proto
Generating swagger documentation ‚Äî
docker run --rm -v $(pwd):$(pwd) -w $(pwd) znly/protoc \
  --swagger_out=logtostderr=true:."
jaeger,"\
  -Imodel/proto -Ivendor/github.com/gogo/protobuf \ model/proto/api_v2.proto"
jaeger,"Introduction
Recently, there has been a lot of discussion around OpenTracing."
jaeger,"We‚Äôll start this blog by introducing OpenTracing, explaining what it is and why it is gaining attention."
jaeger,"Next, we will discuss distributed tracing system Jaeger and how it helps in troubleshooting microservices-based distributed systems."
jaeger,We will also set up Jaeger and learn to use it for monitoring and troubleshooting purposes.
jaeger,"Drift to Microservice Architecture

Microservice Architecture has now become the obvious choice for application developers."
jaeger,"In the Microservice Architecture, a monolithic application is broken down into a group of independently deployed services."
jaeger,"In simple words, an application is more like a collection of microservices."
jaeger,"When we have millions of such intertwined microservices working together, it‚Äôs almost impossible to map the inter-dependencies of these services and understand the execution of a request."
jaeger,"In case of a failure in a monolithic application, it is much easier to understand the path of a transaction and do the root cause analysis with the help of logging frameworks."
jaeger,"But in a microservice architecture, logging alone fails to deliver the complete picture."
jaeger,Is this service the first one in the call chain?
jaeger,How do I span all these services to get insight into the application?
jaeger,"With questions like these, it becomes a significantly larger problem to debug a set of interdependent distributed services in comparison to a single monolithic application, making OpenTracing more and more popular."
jaeger,"OpenTracing
What is Distributed Tracing?"
jaeger,"Distributed tracing is a method used to profile and monitor applications, especially those built using a microservices architecture."
jaeger,Distributed tracing helps pinpoint where failures occur and what causes poor performance.
jaeger,How OpenTracing Fits Into This?
jaeger,"The OpenTracing API provides a standard, vendor-neutral framework for instrumentation."
jaeger,"This means that if a developer wants to try out a different distributed tracing system, then instead of repeating the whole instrumentation process for the new distributed tracing system, the developer can simply change the configuration of the Tracer."
jaeger,"Here are some basic terminologies of Opentracing:
Span ‚Äî It represents a logical unit of work that has an operation name, the start time of the operation, and the duration."
jaeger,Trace ‚Äî A Trace tells the story of a transaction or workflow as it propagates through a distributed system.
jaeger,It is simply a set of spans sharing a TraceID.
jaeger,Each component in a distributed system contributes its own span.
jaeger,"OpenTracing is a way for services to ‚Äúdescribe and propagate distributed traces without knowledge of the underlying OpenTracing implementation.‚Äù
Let us take the example of a service like renting a movie on iTunes (or other movie rental service)."
jaeger,"A service like this requires many other microservices to check that the movie is available, proper payment credentials are received, and enough space exists on the viewer‚Äôs device for download."
jaeger,"If either one of those microservice fail, then the entire transaction fails."
jaeger,"In such a case, having logs just for the main rental service wouldn‚Äôt be very useful for debugging."
jaeger,"However, if you were able to analyze each service you wouldn‚Äôt have to scratch your head to troubleshoot which microservice failed and what made it fail."
jaeger,"In real life, applications are even more complex and with the increasing complexity of applications, monitoring the applications has been a tedious task."
jaeger,"Opentracing helps us to easily monitor:
Spans of services
Time taken by each service
Latency between the services
Hierarchy of services
Errors or exceptions during execution of each service."
jaeger,"Jaeger: A Distributed Tracing System by Uber
Jaeger, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies."
jaeger,"It is used for monitoring and troubleshooting microservices-based distributed systems, including:
Distributed transaction monitoring
Performance and latency optimization
Root cause analysis
Service dependency analysis
Distributed context propagation
Major Components of Jaeger
Jaeger Client Libraries ‚Äî Jaeger clients are language-specific implementations of the OpenTracing API."
jaeger,"Agent ‚Äî The Jaeger agent is a network daemon that listens for spans sent over UDP, which it batches and sends to the collector."
jaeger,It is designed to be deployed to all hosts as an infrastructure component.
jaeger,The agent abstracts the routing and discovery of the collectors away from the client.
jaeger,Collector ‚Äî The Jaeger collector receives traces from Jaeger agents and runs them through a processing pipeline.
jaeger,"Currently, the pipeline validates traces, indexes them, performs transformations, and finally, stores them."
jaeger,"Jaeger‚Äôs storage is a pluggable component which currently supports Cassandra, Elasticsearch, and Kafka."
jaeger,Query ‚Äî Query is a service that retrieves traces from storage and hosts a UI to display them.
jaeger,"Ingester ‚Äî Ingester is a service that reads from Kafka topic and writes to another storage backend (Cassandra, Elasticsearch)."
jaeger,"Running Jaeger in a Docker Container
First, install Jaeger Client on your machine:

2."
jaeger,"Now, let‚Äôs run Jaeger backend as an all-in-one Docker image."
jaeger,"The image launches the Jaeger UI, collector, query, and agent:

TIP: To check if the docker container is running, use: Docker ps."
jaeger,"Once the container starts, open http://localhost:16686/ to access the Jaeger UI."
jaeger,"The container runs the Jaeger backend with an in-memory store, which is initially empty, so there is not much we can do with the UI right now since the store has no traces."
jaeger,"Creating Traces on Jaeger UI
1."
jaeger,"Create a Python program to create Traces:
Let‚Äôs generate some traces using a simple python program."
jaeger,You can clone the Jaeger-Opentracing repository given below for a sample program that is used in this blog.
jaeger,"The Python program takes a movie name as an argument and calls three functions that get the cinema details, movie showtime details, and finally book a movie ticket."
jaeger,"It creates some random delays in all the functions to make it more interesting, as, in reality, the functions would take a certain time to get the details."
jaeger,"Also, the function throws random errors to give us a feel of how the traces of a real-life application may look like in case of failures."
jaeger,"Here is a brief description of how OpenTracing has been used in the program:
Initializing a tracer:

Using the tracer instance:

Starting new child spans using start_span:

Using Tags:

Using Logs:

2."
jaeger,"Run the python program:

Now, check your Jaeger UI, you can see a new service ‚Äúbooking‚Äù added."
jaeger,Select the service and click on ‚ÄúFind Traces‚Äù to see the traces of your service.
jaeger,Every time you run the program a new trace will be created.
jaeger,You can now compare the duration of traces through the graph shown above.
jaeger,You can also filter traces using ‚ÄúTags‚Äù section under ‚ÄúFind Traces‚Äù.
jaeger,"For example, Setting ‚Äúerror=true‚Äù tag will filter out all the jobs that have errors, as shown:

To view the detailed trace, you can select a specific trace instance and check details like the time taken by each service, errors during execution and logs."
jaeger,"The above trace instance has four spans, the first representing the root span ‚Äúbooking‚Äù, the second is the ‚ÄúCheckCinema‚Äù, the third is the ‚ÄúCheckShowtime‚Äù and last is the ‚ÄúBookShow‚Äù."
jaeger,"In this particular trace instance, both the ‚ÄúCheckCinema‚Äù and ‚ÄúCheckShowtime‚Äù invocation have reported an error, indicated by the error=true tag."
jaeger,"Conclusion
In this blog, we‚Äôve described the importance and benefits of OpenTracing, one of the core pillars of modern applications."
jaeger,We also explored how distributed tracer Jaeger collect and store traces while revealing inefficient portions of our applications.
jaeger,"It is fully compatible with OpenTracing API and has a number of clients for different programming languages including Java, Go, Node.js, Python, PHP, and more."
jaeger,"Let‚Äôs say your services get thousands of requests per second, you log enormously and you don‚Äôt miss any exception in your logging system."
jaeger,"Suddenly, the operation team sent you a message pointing to an error for a customer with id X on production and you couldn‚Äôt understand why all the people around you are over-stressed‚Ä¶ and then the penny dropped."
jaeger,The customer X is actually a friend of the boss!
jaeger,"(true story)
Ok‚Ä¶ Let‚Äôs see what you can do:
You searched X on your logging system and waited forever as there are TBs of logs."
jaeger,"Then you tried it again with a more detailed query such asuserId=X not in this and that but in this at time t , and got the resu‚Ä¶ oh, another problem!"
jaeger,Error: wrong query syntax.Your teammate said that you need to replace not in thiswith in not this.
jaeger,"After you also fixed that and waited about 10 secs, 24 results appeared on the screen!"
jaeger,Now you are ready to analyze them.
jaeger,"‚Ä¶ 10 minutes later‚Ä¶
You figured out that ServiceA called service ServiceB and as method LongRunningProcess in ServiceB took 3 seconds, service A returned 500."
jaeger,"After all, you are glad to find the bug in about 20 minutes."
jaeger,Let‚Äôs replay the process assuming that you use Open Tracing and Jaeger.
jaeger,"You visited Jaeger UI on your browser
You wrote userId=X to tags and set the date
You clicked search and the result is below:

Example request that Jaeger traced
In couple of seconds, you can understand that LongRunningProcess took actually 3 seconds, and as a result, ServiceA returned 500."
jaeger,"Open tracing is an open standard for distributed tracing, and Jaeger is the tool that implements the standard."
jaeger,Please check the Jaeger architecture from it‚Äôs official documentation beforehand.
jaeger,"Today, we are gonna create 2 APIs and 1 console client for our demo environment using .net core."
jaeger,I will also use a simple wrapper that I wrote as it brings simplicity in my opinion.
jaeger,Let‚Äôs start!
jaeger,"Clone the Repo & Prepare your environment
If you have .net core and docker installed on your workspace, you are ready to go."
jaeger,"Get the docker image for Jaeger and run it:
docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.6
Clone the repo I prepared for this article: https://github.com/skynyrd/opentracing-with-jaeger
We have one .net core solution containing 4 projects: ConsoleClient , ServiceA , ServiceB and JaegerWrapper."
jaeger,We are going to walk thru all of them.
jaeger,Let‚Äôs start with JaegerWrapper to understand the dynamics of the Jaeger client.
jaeger,JaegerWrapper: For syntactic sugar ‚Äî Because why not?
jaeger,"In order to use Jaeger client, we first need to understand how traces work in our code."
jaeger,"A trace is a data/execution path through the system, and can be thought of as a directed acyclic graph of spans."
jaeger,"A span represents a logical unit of work in Jaeger that has an operation name, the start time of the operation, and the duration."
jaeger,Spans may be nested and ordered to model causal relationships.
jaeger,‚Äî Official Jaeger docs.
jaeger,"In an application, we need to have a Tracer that manages our spans."
jaeger,I strongly recommend having one tracer in a microservice for simplicity.
jaeger,"After creating the Tracer and registering it, the jaeger client library starts to analyze the controllers in the system by default, even we don‚Äôt need to create a singleTraceand Span for that, all created by the OpenTracing.Contrib.NetCore library."
jaeger,"However, if we want to analyze a specific method, or add some additional tag/log to our spans, we need to create a Trace and bind a Span to it."
jaeger,"Important Note: If you create and activate a span when there is another active span in the system, it becomes a child."
jaeger,You can see it in the diagram above; parent spans are expandable.
jaeger,"I wrote a simple builder for this purpose and JaegerWrapper is a class library that contains it, you can use/copy if you like."
jaeger,"_traceBuilder
  .WithSpanName(""LongRunningProcess"")
  .WithTag(new StringTag(""exampleTag""), ""exampleValue"")
  .TraceIt(() =>
  {
    Thread.Sleep(3000);
  });
To give an example, this code block is for LongRunningProcess span represented by a yellow horizontal bar in the diagram above."
jaeger,We added exampleTag: exampleValue to it and we can even add more complex structures using WithLog method.
jaeger,Time consumed by TraceIt is published as a span duration in the GUI.
jaeger,"In the example, I used a simple Thread.Sleep(3000) , but you can also return something (Func instead of Action) e.g."
jaeger,":
var result = _traceBuilder
              ...
              .TraceIt(() => 
              {
                 return ""something""
              }
Passing across the APIs
If you are going to HTTP call a service and you want to preserve your span lifetimes, you need to notify the other service somehow."
jaeger,"For the most cases you would like to use the OpenTracing.Contrib.NetCore package to automate the configurations, but if you are curious, here is the logic behind that:
Jaeger solves it with HTTP headers that are going to append to the request."
jaeger,"You can also use JaegerWrapper for more abstraction:

Still using the OpenTracing.Contrib.NetCore is the clearest option for the APIs."
jaeger,"Configuration for WebAPIs
For ServiceA and ServiceB we need to register the services for Jaeger:
// In ConfigureServices method of Startup class:
GlobalTracer.Register(Tracer);
services.AddOpenTracing();
If you also want to use the wrapper, you can simply add these:
var serviceProvider = services.BuildServiceProvider();
services.AddScoped<ITraceBuilder>(t => 
    new TraceBuilder(serviceProvider.GetService<ITracer>()));
Example Calls
Have a look at AWorldController of ServiceA, we call ServiceB there but didn‚Äôt use any JaegerClient or JaegerWrapper method."
jaeger,"This is because we added OpenTracing.Contrib.NetCore library and it traces our requests in the black box, magically."
jaeger,"private static async Task<dynamic> GetBObject(string id)
{
    var httpClient = new HttpClient
    {
        BaseAddress = new Uri(""http://localhost:7334"")
    };

    var result = await httpClient.GetAsync($""/bworld/id/{id}"");

    if (result.IsSuccessStatusCode)
    {
        return await result.Content.ReadAsAsync<dynamic>();
    }
    
    throw new Exception(""uncovered area."
jaeger,""");
}
And check the Main method of the ConsoleClient."
jaeger,"This time, as this is not a WebAPI, we manually traced our call using JaegerWrapper."
jaeger,"traceBuilder.WithSpanName(""MainWork"")
    .WithHttpCall(client, url, HttpMethod.Get)
    .TraceIt(() =>
    {
        var response = client.GetAsync(url).Result;

        if (!response.IsSuccessStatusCode)
            throw new Exception(""uncovered area for the demo."
jaeger,""");

        var responseBody = response.Content.ReadAsStringAsync().Result;
        Console.WriteLine(responseBody);
    });
I used Zipkin instead of Jaeger on production couple of years ago, thus I don‚Äôt want to write anything about the performance."
jaeger,But I can say that Zipkin was quite performant.
jaeger,"If you have production experience with Jaeger, please comment below, I‚Äôm curious about it!"
jaeger,Thanks for reading.
jaeger,"Jaeger Integration in Kiali
Kiali has the ability to show traces obtained from Istio."
jaeger,"Jaeger collects traces for monitoring and troubleshooting microservices-based distributed systems , and both Istio and Kiali use the data that Jaeger provides."
jaeger,Originally this was done via a separate tab in the UI.
jaeger,But that turned out to be impractical.
jaeger,So the Kiali team has been working with the Jaeger team on the Jaeger integration.
jaeger,"By improving the Jaeger UI components to make them embeddable, there is better integration between a Kiali selection and a Jaeger selection, making it easier to enrich Jaeger with Kiali information."
jaeger,This enhancement consists of changes in the URL API to personalize the component to be presented from Jaeger UI similar to the Google Maps API.
jaeger,You can view this enhancement in Jaeger in the version 1.8.2 of the project and the related documentation is available here.
jaeger,"This enhanced integration between Jaeger and Kiali should be available in the next release of Istio, when Jaeger is updated to version 1.9."
jaeger,In the meantime we would like to show you what it will look like in future versions.
jaeger,In the main menu the Distributed Tracing link will show us the search component of Jaeger (see the image above).
jaeger,"This enhancement let us pass parameters like service, lookback ‚Ä¶ to the API and get the related traces, allowing us to have a better integration with Jaeger."
jaeger,These allow us to perform the same search for Jaeger within Kiali.
jaeger,"Search traces
In the image above we can see a toolbar (1) with the options to find the traces of our services, we have to filter by namespace and service to use the finder and set the optional parameters like lookback ( 1 hour by default), tags, min/max duration of the trace and the limit results ( 20 by default) to have our results, these options are the same offered by Jaeger UI."
jaeger,"The results (2) are displayed in an iframe inside Kiali UI, we can interact with the results and see a specific trace."
jaeger,"Trace view inside Kiali
In the image below we can see the details of a service, and now the traces tab shows us the number of error traces in the last hour, this enhancement with the metrics and the information of the service improves the observability in Kiali helping us to investigate and troubleshoot the problems we have in our service."
jaeger,"Traces tab with the number of traces errors for a service
Inside this tab we can see all the information about the error traces, we can also search/filter by tags and min/max duration."
jaeger,"Trace Errors in the last hour for a service
The demo about how it will look in Kiali is in the sprint 15 video in YouTube
https://youtu.be/X_pWmb4IyW0?t=385
With this feature we can focus in the observability by correlating this, for example it may be possible to stand on a node in the graph, do a right-click and then select ‚Äútraces involving this node‚Äù."
jaeger,"Photo by Noah Holm on Unsplash
Mule is an open source(ish) integration platform by Mulesoft, now owned by Salesforce."
jaeger,Cloud native is a particular approach of designing applications specifically for the cloud.
jaeger,In this post we explore how we could create Mule applications in a cloud native manner by taking advantage of open source tools and frameworks available outside of the Anypoint Platform.
jaeger,"A quick look at Cloud Native
There are a couple of good introductions to what cloud native represents, I particularly recommend Stackify‚Äôs summarization of a few different takes."
jaeger,"For now we‚Äôll go with Cloud Native Computing Foundation‚Äôs definition:
Cloud native computing uses an open source software stack to deploy applications as microservices, packaging each part into its own container, and dynamically orchestrating those containers to optimize resource utilization."
jaeger,Cloud native technologies enable software developers to build great products faster.
jaeger,"Some name-dropping coming up‚Ä¶
The CNCF is basically a collaborative incubator for open source software aimed for cloud applications, and is backed by some of the bigger names in tech: Google, Red Hat, AWS, IBM, Oracle, Pivotal, Microsoft, Samsung, and the list goes on."
jaeger,"Most notably the CNCF hosts the Kubernetes project, originally created by Google and probably the name that comes to mind when we talk about orchestrating containers at scale."
jaeger,"Other worthy project mentions are Envoy by Lyft, GRPC by Google, and Jaeger by Uber (more of this in a bit)."
jaeger,"Effectively we want to maximize scalability and reusability by using a microservices architectural style exploiting Linux control groups and namespaces (read containers) and, perhaps most importantly, the growing list of open source software that help manage the many challenges the style presents."
jaeger,"The status quo ‚Äî Anypoint Platform
Let‚Äôs consider an organization that can fulfill all of its software needs from out of the box applications, which is increasingly the case."
jaeger,All the software they‚Äôll ever need to develop and manage will be integration.
jaeger,Buy versus build.
jaeger,The most radical possible solution for constructing software is not to construct it at all.
jaeger,"‚Äî Frederick P. Brooks, Jr.
‚ÄúBuy versus build‚Äù is a powerful and proven proposition for increasing productivity."
jaeger,This is why Mulesoft‚Äôs products are as successful as they are.
jaeger,Salesforce thought so in their 6.5 billion dollar acquisition.
jaeger,"Mule itself is great piece of software engineering, from its roots in Staged Event Driven Architecture and Enterprise Integration Patterns to its new implementation in Mule 4 using Reactive extensions and non-blocking IO with Pivotal‚Äôs Reactor."
jaeger,"If you need enterprise integration, I recommend Mule."
jaeger,Do checkout Mule Made Easy.
jaeger,Anypoint Platform and its extended ecosystem is no different.
jaeger,"API Designer, Runtime Manager for backed by CloudHub or Runtime Fabric, and Monitoring possibly offer all you could need for integration applications."
jaeger,Obviously no other platform will be as closely integrated with Mule applications as Mulesoft ‚Äòs own.
jaeger,It was built for them.
jaeger,So why would we consider another platform?
jaeger,"Because as Brooks notes in No Silver Bullet ‚ÄúThe key issue, of course, is applicability."
jaeger,"Can I use an available off-the-shelf package to perform my task?‚Äù As soon as an organization builds a cloud native non-integration application, for whatever reason, they now have to manage two platforms."
jaeger,"While the argument could be made that Anypoint Platform is technically cloud native, we can‚Äôt use it for any other type of application."
jaeger,It would be great if instead we could make use of Mule in a platform where we can take advantage of those free and open source frameworks and tools to provide an uniform management experience for all cloud native applications.
jaeger,"Visibility ‚Äî OpenTracing and Jaeger
One of the main challenges with microservices is visibility of component interactions because of the distributed nature of the system."
jaeger,OpenTracing is a free and open source framework that aims to help alleviate this problem.
jaeger,"Basically every application can be instrumented to automatically create or augment existing traces, and propagate them when interacting with external components."
jaeger,"OpenTracing has been adopted by JEE WildFly 14, and instrumentation has been created for various other frameworks such as Spring Boot, Spring Cloud, Apache Camel, and a few others."
jaeger,"Jaeger offers a particular free and open source implementation of the OT framework, Datadog and LightStep being others."
jaeger,Here‚Äôs a good practical introduction to Jaeger by Yuri Shkuro from Uber.
jaeger,With some guidance from the excellent engineers behind OpenTracing we‚Äôve built OpenTracing instrumentation for Mule 4 with Jaeger as the default Tracer implementation.
jaeger,Although far from mature the instrumentation supports HTTP calls which make the biggest part of microservices interactions.
jaeger,"Container orchestration ‚ÄîA Docker-less Openshift
Maybe the most important challenge with the microservices style is creating the significant number of container images, how and where to run the containers, and how to manage them through their lifecycle."
jaeger,This is the where container runtimes and orchestration platforms help.
jaeger,"Replacing the Docker runtime ‚Äî CRI-O
Antonio Murdaca from Red Hat has a great article on the difference between Docker and CRI-O runtimes."
jaeger,"Basically Kubernetes needed to provide users with a way to replace the default Docker runtime, and so the Container Runtime Interface was born with CRI-O being a Kubernetes incubated and community driven implementation."
jaeger,See Why CRI-O?
jaeger,and Using the CRI-O Container Engine docs for a bit more depth.
jaeger,"In a nutshell CRI-O aims to be lightweight, more securable, and truly open source."
jaeger,"Replacing the Docker tool-bench ‚ÄîBuildah and Podman
We still need to build and test container images before we deploy them to a runtime."
jaeger,Luckily Docker images follow the Open Container Inititive‚Äôs image specification.
jaeger,"Part of the decision to replace Docker came from learning about Red Hat‚Äôs simple and OCI compliant tools, Buildah and Podman."
jaeger,Here‚Äôs a quick intro from CNCF Ambassador Daniel Oh.
jaeger,It was definitely interesting to find out Mulesoft partnered with Docker after I had committed to replace Docker in my work bench.
jaeger,"With the help of those tools and the community we‚Äôve created small, secure, and up to date OCI images for application developers to use when deploying containerized Mule 4 applications."
jaeger,"Openshift ‚Äî Enterprise Kubernetes
Kubernetes is unarguably the de facto standard for container orchestration."
jaeger,"Openshift is sort of a Red Hat flavored enterprise grade kube distribution, with okd being its free and open source upstream project."
jaeger,Here‚Äôs a great article on the differences with kube.
jaeger,"While the images described above in will work on any container platform, they are biased towards Openshift."
jaeger,"Running an okd clusterwith CRI-O, plus integrated Jenkins capabilities, and other abstractions like Image Streams, all for the price of free is perhaps the main selling point."
jaeger,"IBM believed in Red Hat‚Äôs product too, a 34 billion dollar belief."
jaeger,"For Openshift we‚Äôve built application templates that provide a way to deploy Mule applications with just a few clicks, no maven plug-in needed or special setup of a Jenkins instance."
jaeger,"First there is the Source To Image Template, you just point to a git repository containing your Mule 4 application code and Openshift will take care of retrieving, building, and deploying your application to the platform."
jaeger,No Jenkinsfile necessary.
jaeger,Openshift will also track changes in the repository and keep the deployed image up to date with the latest code and optionally with the latest Mule runtime.
jaeger,A quick and simple form of continuous deployment.
jaeger,"Continuous Integration and Deployment‚Äî Jenkins integrated Openshift
With many independently developed applications comes the trade-off that it is now much more involved to ensure that any code change in one application does not break others, or worse ‚Äî the system as a whole."
jaeger,Continuous integration and deployment is a technique to manage this problem.
jaeger,"Many CI/CD tools exist, Jenkins being one of the most popular ones."
jaeger,"And yes, it is open source."
jaeger,"I briefly mentioned above the integration of Jenkins into Openshift, and while I won‚Äôt take a deep dive into Jenkins or the Openshift integration itself I‚Äôll show how we‚Äôve taken advantage of it."
jaeger,"We‚Äôve built a Pipeline Template, which does require a Jenkinsfile in your source code but allows you to define a CI/CD pipeline as complex as needed and which is integrated into the Openshift web console."
jaeger,I find this makes it easier for developers to own their applications from the Anypoint Studio canvas through to deployment given a single integrated interface.
jaeger,Most notably there are variants of both this template and the simpler source to image template that include our Jaeger instrumentation and configuration.
jaeger,"This provides a cloud native Mule application that‚Äôs just a few clicks away while addressing the challenges of orchestration, integration and deployment, and visibility."
jaeger,"TL;DR
Mulesoft‚Äôs Mule is probably the best enterprise integration framework available, and the Anypoint Platform is its natural home."
jaeger,"But if we needed to kick our mules together with other applications or just wanted to explore possibilities outside of Anypoint ‚Äî open source projects like Jaeger, Openshift, and Jenkins can help create a uniform and competent platform."
jaeger,"In addition, the images and templates we‚Äôve created provide a starting point for you to build and deploy cloud native Mule 4 applications with minimal effort, and potentially for free (outside of infrastructure costs)."
jaeger,Did I mention open source is great?
jaeger,I wanted to explore distributed tracing on our Kubernetes cluster with Jaeger so I setup a simple proof of concept.
jaeger,This tutorial demonstrates how to setup the Jaeger all-in-one deployment on a non-prod cluster with traces generated from a .NET core application.
jaeger,I included a quick overview of Jaeger at the end of this article.
jaeger,"Kubernetes Deployment
You can get the all-in-one deployment yaml from here to which I made a few modifications."
jaeger,"I still wanted some degree of security despite this being in our non-prod cluster, so instead of exposing a load balancer jaeger-query service I wrote an ingress that uses basic auth."
jaeger,"Jaeger deployment components aggregated into one
There are three components to Jaeger that are aggregated into one pod for the all-in-one deployment."
jaeger,"The Jaeger Collector which receives traces from Jaeger agents and validates, indexes, performs transformations, and stores them."
jaeger,"The Jaeger Agent runs as a network daemon or a sidecar and distributes traces to the collector, and finally Jaeger Query which retrieves traces from storage and displays them in the UI."
jaeger,"These components should be split up in a production environment, and each one can be configured separately."
jaeger,"Exposing Jaeger UI with Treafik Ingress
The absence of a service type will result in a default ClusterIP service, and we can expose jaeger-query (the Jaeger UI) via a Traefik ingress."
jaeger,Notice that we also include the argument query.base-path=/jaeger in the Jaeger deployment so that we can use the ingress path myhost.com/jaeger .
jaeger,You can read more about that here: https://github.com/jaegertracing/jaeger-ui/issues/42.
jaeger,".NET Core App Jaeger Instrumentation
You need two NuGet package to use Jaeger."
jaeger,"OpenTracing.Contrib.NetCore
Jaeger
We will use dependency injection to get an instance of an ITracer

Startup.cs ITrace Dependency Injection
We create an ITracer from a Jeager.Configuration."
jaeger,"This allow us to tweak the Jaeger service name, agent host, agent port, sampler type, and sampler host/port via environment variables."
jaeger,The following are the environment variables required for the service deployment.
jaeger,"JAEGER_SERVICE_NAME: my-service-name
JAEGER_AGENT_HOST: jaeger-agent.monitoring.svc
JAEGER_AGENT_PORT: 6831
JAEGER_SAMPLER_TYPE: const
JAEGER_SAMPLER_MANAGER_HOST_PORT: jaeger-agent.monitoring.svc:5778
We rely on our cluster DNS to resolve the hostname jaeger-agent.monitoring.svc .We can use an ITracer to create spans ."
jaeger,Spans represent a unit of work or time in your application.
jaeger,They can be nested and encapsulate tags and logs.
jaeger,Use DI in your controller to access the ITracer singleton public MyController(ITracer tracer) and create a span with a span builder.
jaeger,Spans implement IDisposable and will automatically be marked as finished.
jaeger,Or you can manually start and stop a span with the following.
jaeger,We can also make use of Tags which are a way to organize spans and provide additional metadata.
jaeger,That‚Äôs all that‚Äôs required to setup tracing.
jaeger,You should see start seeing them show up as you make requests to your services.
jaeger,"Traces from all-in-one deployment at myhostname.com/jaeger
Quick Jaeger Overview
Jaeger is a CNCF distributed tracing system released by Uber that enables debugging, monitoring, and analysis of your services, and is based on OpenTracing api."
jaeger,"It uses distributed context propagation, which essentially is the basis of distributed tracing, to assign metadata to requests as they propagate through your system."
jaeger,"Here are some advantages of using Jaeger:
Performance and latency analysis
Service Dependency analysis; you can view a DAG of your system in the UI
Logs associated with each span
Organization of logs into calling hierarchy
Cost attribution
Useful UI and libraries in Go, Node, C#, and others."
jaeger,"Different levels of sampling can be configured to reduce load: constant, probabilistic, rate limiting, and remote."
jaeger,"Other Cool Things
Traefik has a Jaeger integration that you can find here: https://docs.traefik.io/configuration/tracing/
Can output prometheus metrics on number of spans started, finished, etc."
jaeger,Working autogenerated DAGs
jaeger,"Here at RiksTV (www.rikstv.no), we are always looking for ways to improve or insights into how our apps are doing."
jaeger,"We currently have a well-working Elastic stack set up, but we‚Äôre definetely seeing shortcomings in just relying on logs."
jaeger,That‚Äôs not Elasticsearch‚Äôs fault btw.
jaeger,"We‚Äôve also looked at several of the commercial offerings, but none of them seem to‚Ä¶ click."
jaeger,"Some are super-expensive, and some are just‚Ä¶ weird (looking at you, Azure App Insights)."
jaeger,"Before I move on, it might be an idea to spend a few sentences of what problem we‚Äôre trying to solve: As apps become more and more distributed ‚Äî either in the form of containers or just plain ol‚Äô vms ‚Äî traditional logging is becoming an increasingly lacking way of keeping track of application health."
jaeger,"Even with centralized logging, it‚Äôs almost impossible to figure out how the log statements from different apps fit together."
jaeger,This is where distributed tracing comes in.
jaeger,"The idea is simply to have some ‚Äòthing‚Äô that follows the operation around, all the way from the network edge and into the ‚Äúcore‚Äù of the application."
jaeger,"This ‚Äòthing‚Äô enables us to group related bits of information together, and present it in a meaningful way."
jaeger,"There‚Äôs a ton of activity in the open-source space around tracing and instrumentation, so I decided to have a closer look."
jaeger,"OpenTracing can be thought of as a standard for distributed tracing, which is implement in various tools such as Jaeger and Zipkin."
jaeger,"Commercial actors (New Relic, Datadog, others) are also implementing OpenTracing support in their APM products."
jaeger,"You might actually get quite far without touching your application code at all ‚Äî projects such as the Traefik load balancer and several of the more popular service mesh projects can emit OpenTracing-compatible data, which can be picked up by Jaeger or similar."
jaeger,"That said, I think it‚Äôs safe to say that tracing is only as good as the effort you put into it."
jaeger,"If you want real instrumentation, you‚Äôre going to have to put tracing calls in your code."
jaeger,"I did this exercise on one of our internal endpoints, and for a relatively simple rest service a few lines of extra code takes you surprisingly far."
jaeger,"Anyway, I wanted to show how all of this fits together, so I put together a little ‚Äúall-in-one‚Äù demo using Traefik, Jaeger and a simple Flask (http://flask.pocoo.org/) app."
jaeger,If you‚Äôre interested in taking a closer look at tracing I hope this can serve as a decent starting point.
jaeger,You‚Äôll find the repo at https://github.com/trondhindenes/Traefik-Flask-Opentracing-Blogpost.
jaeger,"The the repo readme should contain all the needed instructions, but here‚Äôs an overall description of what gets set up:
Jaeger: Traces need to be sent somewhere so they can be stored, visualized and filtered."
jaeger,"Jaegers ‚Äúall-in-one‚Äù containers makes it super-easy to get up and running with all you need, including the agent which receives the actual traces from your various components."
jaeger,Jaeger also has the ‚Äújaeger query‚Äù which is the web ui you‚Äôll use to investigate traces.
jaeger,Traefik: As of version 1.6.0 the Traefik load balancer can emit traces to a Jaeger agent.
jaeger,"The repo includes a working setup for two microservices configured in Traefik, with tracing enabled and ready to go
Code instrumentation: In my example app, I‚Äôm using the Flask microframework, along with a few opentracing libraries for instrumenting data from inside the running app."
jaeger,"This allows traces from specific parts of your code, which can provide a ton of useful information if done right."
jaeger,"If you‚Äôre interested, I encourage you to clone the repo and walk thru the readme."
jaeger,It shouldn‚Äôt take more than a few minutes to have a well-working tracing demo up and running on your machine.
jaeger,"A Distributed Tracing walk-through with Jaeger, Istio and Kiali
This is a second of a three-parts series."
jaeger,"Previously, we‚Äôve seen how Istio and Envoy help on tracing, how to propagate traces and create spans."
jaeger,"Tracing in Kiali
Kiali is in a sweet spot to leverage tracing."
jaeger,"Thanks to Istio and Envoy, there is a nice consistency between traces and metrics."
jaeger,The source and destination workloads identified in the traffic metrics can be clearly correlated with trace spans.
jaeger,"You may wonder, is that useful?"
jaeger,Isn‚Äôt it redundant information?
jaeger,It‚Äôs actually super useful.
jaeger,"Metrics offer a large, aggregated view of the data, whereas traces offer sharp insight with traceable causality."
jaeger,"Metrics are the wide-angle lens, tracing is the 600mm zoom lens."
jaeger,"Both are useful, and correlating the two allows not only to jump from one to the other, but also to map a single trace over a graph topology, to evaluate the performance of spans in a trace based on the wider picture that metrics offer, and probably more that we haven‚Äôt yet thought about."
jaeger,"Configuration
First of all, to ensure you have the best experience with tracing, make sure that Kiali is well configured; both in_cluster_url and url should be set in the external_services.tracing section of the CR / ConfigMap."
jaeger,"The first is used by Kiali to connect to Jaeger internally, and the second adds useful links in the UI to jump from Kiali to Jaeger in different ways."
jaeger,"If you have any troubles with the configuration, please make sure to read the related FAQ."
jaeger,"Quality of traces
There are two indicators in Kiali that will help evaluate the ‚Äúquality‚Äù of a trace, visible on the Tracing page."
jaeger,"The first and most obvious are some explicit representations of traces showing errors, as shown in the pictures below:


On the left, an error span due to a 503 response."
jaeger,"On the right, traces with errors are displayed in red on the chart."
jaeger,"As per OpenTracing conventions, Kiali will check if there are some spans in a trace that are tagged with the error key."
jaeger,Note that it is up to the creator of the span to flag it as having errors or not.
jaeger,It can often lead to debatable arguments.
jaeger,"For instance, Envoy considers 5xx responses as errors, but not 4xx, even from the client side span."
jaeger,Kiali strictly relies on the error tag to decide whether there‚Äôs an error or not.
jaeger,"The second indicator of quality in Kiali is the trace or span performance, based on comparisons of their durations using different approaches."
jaeger,"You can see several matrices, as heatmaps, that show how a trace or span performed."
jaeger,We‚Äôre going to explore them more in detail next.
jaeger,"Color-based indicators of performance allow rapid eye-catching of problems, combined with matrix representations to not dilute the information too much in over-aggregated views."
jaeger,"Metrics-based comparisons
The first approach is a matrix showing how the trace performed in comparison with aggregated metrics on several intervals (last 10 minutes, 60 minutes and 1 hour) crossed with different aggregation statistics (average, 50th, 90th and 99th percentile)."
jaeger,"As we‚Äôve seen, a trace is a collection of spans."
jaeger,So this view is actually an average of comparisons of each span duration versus the metrics for the same source / destination services.
jaeger,"You can view the per-span detail in the other tab, where you can spot which span individually performed well or not."
jaeger,"Similar matrices per span
The heatmaps are presented only for Envoy-generated spans, because they‚Äôre the ones where we can safely assume a consistency with the metrics."
jaeger,You can filter the spans list to show only Envoy spans: select ‚ÄúFilter by Component‚Äù > ‚ÄúProxy‚Äù.
jaeger,Clicking on a heatmap expands it.
jaeger,Note also that the spans contain pod information.
jaeger,"It‚Äôs only in traces that you can have this level of detail of the traffic, since metrics are more aggregated and don‚Äôt (always) carry the pod name."
jaeger,"There is a caveat in the trace-to-metrics comparison you should be aware of: since metrics don‚Äôt have the level of granularity that traces offer, we cannot restrict the comparison with metrics to the requests that hit precisely the same endpoint / path as the spans did."
jaeger,"So for instance, if a service ‚ÄúFoo‚Äù exposes the endpoints ‚ÄúGET /foo‚Äù and ‚ÄúPOST /bar‚Äù, and the two have quite different processing times, and also depending on their call frequencies, this will introduce a bias in trace-to-metrics comparisons."
jaeger,"Similar traces comparisons
For that reason, the second type of heatmap displayed is interesting, it‚Äôs a trace-to-traces comparison."
jaeger,"Trace-to-traces comparison
For a given trace, Kiali tries to detect which ones, among the traces displayed on screen, are similar enough to be relevant for comparison."
jaeger,"Internally, a similarity score is computed using the number of spans they contain and the occurrences of operation name in the spans."
jaeger,"Similar traces are compared based on their full duration (from start time of the root span, to the end time of the latest span) and also based on the average span duration."
jaeger,"These two values can differ a lot, for example when spans run in parallel, or when there‚Äôs dead time between spans."
jaeger,"Interactions with Jaeger UI
Since Kiali works with Jaeger and assumes the Jaeger UI should be available in the nominal case, we have made the choice to have complementary views of tracing, with different approaches."
jaeger,In any given situation you may find that the Jaeger UI is more relevant to get some particular information.
jaeger,"For instance, unlike Jaeger, Kiali doesn‚Äôt show the full list of tags per span."
jaeger,"Instead, it presents a concise summary, mostly based on known tags created by Envoy."
jaeger,"So, to ease the interactions between the two tools, Kiali shows a couple of external links, contextual to their scope:
for the whole traces query per service
for a specific trace
for a specific span
to the trace comparison view


On the left, external links from a trace detail."
jaeger,"On the right, the equivalent from a span detail."
jaeger,"That ‚ÄúCompare with similar traces‚Äù link is an interesting one, it allows to compare two traces more deeply."
jaeger,You can read this article to learn about it.
jaeger,"Traces comparison in Jaeger UI
When coming from Kiali, the comparison view will be pre-populated with the selected trace, plus the ones detected as similar (using the algorithm previously mentioned)."
jaeger,"It is also possible to have links the other way around, from Jaeger to Kiali, as described in this article (some information there reflects old versions of Istio and must be adapted, though the configuration on Jaeger UI side is still valid)."
jaeger,"Topology
And to finish with the overview of Tracing in Kiali, there is of course the trace overlay on top of the graph topology."
jaeger,"You can either see it while coming from a trace selected in the Tracing page (link ‚ÄúView on graph‚Äù), or by clicking a node directly from the graph, opening the Traces tab from the side panel, then choosing one from a list."
jaeger,"When a trace is selected, it offers the possibility to navigate back to the Tracing page when clicking on its name."
jaeger,"Quickly visualize the path of a trace in the global topology
The trace panel in this view offers a quick summary of trace and span details, plus some links to the related spans (parent and children) in order to navigate in the trace and quickly locate their nodes in the graph."
jaeger,"In the next and final part, we will discuss about tracing in other, non-HTTP scenarios."
jaeger,"To wait, grab some tea/coffee and have a chat with us, on our Slack channel, mailing list, Twitter (me) or the eternal IRC."
jaeger,"Update: As of Istio 1.0.0, prometheus scrape requests are automatically excluded from tracing."
jaeger,Hopefully most people now understand the benefits that distributed tracing can provide when diagnosing issues in a distributed (e.g.
jaeger,microservices based) application.
jaeger,"Istio has now made it very easy to benefit from distributed tracing, by providing most of the capabilities as part of the infrastructure, with applications only having to take responsibility for propagating the trace context to any outbound requests."
jaeger,"However, if we also want to capture application metrics from our services using Prometheus, we find that Istio will unfortunately record trace instances each time Prometheus scrapes metrics from our services."
jaeger,This can add up to a large number of unnecessary trace instances.
jaeger,"For example, after installing a couple of services on Istio, configured with both Jaeger and Prometheus, we find a series of trace instances being recorded before even any real ‚Äúbusiness‚Äù invocation of the service has been performed:

If we look at the details for one of these trace instances we see that it has been created as the result of a request to the /metrics endpoint:

Although the OpenTracing framework instrumentations can be configured to ignore requests to certain endpoints, such as in the case of java-spring-web used by my example services, it is currently not possible to configure the Istio proxy to ignore tracing on specific endpoints."
jaeger,This post will show a quick way to disable trace instances resulting from Prometheus scrape requests.
jaeger,The first step is to deploy a NGINX proxy that will add a specific header to the scrape request.
jaeger,"The header is ‚ÄúX-B3-Sampled: 0‚Äù, and will instruct the tracer used within the Istio proxy not to sample this request."
jaeger,"Unfortunately Prometheus does not provide a mechanism for adding such a header to the scrape request, so instead we use the NGINX proxy."
jaeger,"This can be deployed using the following command:
kubectl create -f prometheus-nginx.yml -n istio-system
The second step is to update the Prometheus scrape configuration(s) to use the NGINX proxy."
jaeger,"If using the ‚Äòaddon‚Äô Prometheus template provided by Istio, this would involve adding the proxy_url property in the following two locations:
    # scrape config for service endpoints."
jaeger,"- job_name: 'kubernetes-service-endpoints'
      proxy_url: 'http://prometheus-nginx:9191'

    ...

    # Example scrape config for pods
    - job_name: 'kubernetes-pods'
      proxy_url: 'http://prometheus-nginx:9191'

    ...
Once these changes are deployed, the only traces reported for the example services will now be the real invocation of the services:

with the details of this trace instance being shown in the first image of the blog post."
jaeger,"Hopefully a more general solution will be provided in Istio in the near future, to enable specific endpoints to be excluded from tracing."
jaeger,"But until that time, this provides a short term solution to minimise the unnecessary tracing data being generated by the Istio service mesh."
jaeger,"It has been several months since we announced Jaeger 1.0 in December, it is time for the next update."
jaeger,We want to try publishing this newsletter more often from now on.
jaeger,"As always, everyone is welcome to join our bi-weekly video calls for discussions about project direction, current work, and decisions about open issues and pull requests."
jaeger,"Jaeger Project Updates
Several new releases of Jaeger have been published, up to v1.4.1."
jaeger,For a full list of changes please see the change log.
jaeger,"Some highlights include:
UI: Revamped design using Ant instead of Semantic UI
UI: Enhanced tag search input using logfmt syntax
UI: Ability to run at custom URL prefix and/or behind a reverse proxy
UI: Ability to view unadjusted and pretty-formatted traces as JSON
Binary distribution of Jaeger components, including Windows executables
Great performance improvements for Elasticsearch backend
And we have a new official client library, Jaeger tracer for C# and .NET, which originated as https://github.com/Chatham/LetsTrace/ and has since been donated to Jaeger project."
jaeger,It is still in active development.
jaeger,"Last, but not least, we have a brand new website https://jaegertracing.io/, many thanks to Luc Perkins."
jaeger,Interns!
jaeger,We welcome Prakriti Bansal as our new Outreachy intern for Jaeger and OpenTracing projects.
jaeger,"Content from the Community
InfoQ ‚Ä¢ Debugging Containerized Microservices
Idit Levine, founder of Solo.io, presented at QCon about Debugging Containerized Microservices."
jaeger,"She shared her open source project Squash, which is OpenTracing-native."
jaeger,"In her talk, she went over the concepts and also did some live demoing, including Jaeger‚Äôs HotROD!"
jaeger,"JavaLand 2018 ‚Ä¢ Finding Performance Bottlenecks with Distributed Tracing by Juraci Paix√£o Kr√∂hling
Microservices are now the standard for new architectures."
jaeger,"Their distributed nature makes it harder to determine the causes of a performance bottleneck, as one can‚Äô¬ít just watch a single process and see the big picture."
jaeger,"In this talk, you‚Äô¬íll learn how to instrument a business application (Spring Boot, Vert.x, Wildfly Swarm) with the OpenTracing API and use a tracing backend solution like Jaeger and/or a metrics solution like Prometheus to find, fix, and measure performance improvements to our distributed application."
jaeger,"Ways to Engage
There are many opportunities to learn or help others learn about distributed tracing and Jaeger."
jaeger,Below are some of the upcoming events.
jaeger,Please reach out if you can attend and/or want to be more involved.
jaeger,"May 2‚Äì4, KubeCon + CloudNativeCon Europe in Copenhagen
Wednesday, May 2 ‚Ä¢ 11:10‚Äì11:45 ‚Ä¢ A Survey of the OSS Tracing Ecosystem, Ben Sigelman & Ted Young (LightStep) (Beginner Skill Level)
Wednesday, May 2 ‚Ä¢ 14:45‚Äì15:20 ‚Ä¢ Jaeger Project Intro, Juraci Kr√∂hling (Red Hat) (Any Skill Level)
Thursday, May 3 ‚Ä¢ 11:10‚Äì11:45 ‚Ä¢ Jaeger Project Deep Dive, Juraci Kr√∂hling (Red Hat) (Intermediate Skill Level)
Thursday, May 3 ‚Ä¢ 14:00‚Äì14:35 ‚Ä¢ How we used Jaeger and Prometheus to Deliver Lightning-Fast User Queries, Bryan Boreham (Weaveworks) (Intermediate Skill Level)
June 12‚Äì15, DockerCon, San Francisco, CA
Wednesday, Jun 13 ‚Ä¢ 3:30 PM ‚Äî 6:00 PM ‚Ä¢ Cloud Native Projects SIG
June 18‚Äì20, Developer Week, New York, NY
Wednesday, June 20 ‚Ä¢ 1:00pm‚Äì1:25pm ‚Ä¢ Better Logging for Microservices with OpenTracing, Yuri Shkuro (Uber Technologies)
July 16‚Äì19, O‚ÄôReilly‚Äôs OSCON, Portland OR
Monday, July 16 ‚Ä¢ 1:30pm‚Äì5:00pm: Introduction to OpenTracing: Follow your requests from mobile and web clients to microservices and monoliths, Priyanka Sharma (LightStep ), Ted Young (LightStep), Ben Sigelman (LightStep)
We Would Love to Hear From You
Want to share a Jaeger-related update in the newsletter?"
jaeger,Email us at jaeger-tracing@googlegroups.com or drop by the chat room.
jaeger,"We‚Äôd also love feedback as always, so don‚Äôt hesitate to drop us a line!"
jaeger,‚Äî The Jaeger Team
jaeger,"Urvika Gola, former Outreachy intern, hacks on the open source Android application, Lumicall, with former Google Summer of Code intern, Pranav Jain."
jaeger,(Photo CC-BY-NC-SA Sage Sharp.)
jaeger,"The OpenTracing and Jaeger projects are glad to participate in the next Outreachy internship program, under the ‚ÄúCNCF Tracing‚Äù umbrella."
jaeger,We are really excited to announce that an intern has been selected!
jaeger,Prakriti Bansal (@PikkiBot) will be helping us improve the documentation for both projects.
jaeger,We are grateful to all the contributions we received from all applicants: it‚Äôs been tough to select only one among so many qualified candidates!
jaeger,"Welcome to the team, Prakriti!"
jaeger,"As a kid I loved Voltron, an anime about a giant robot fighting giant monsters."
jaeger,"I also love Robotech, another animated show that featured a city sized spaceship that could turn into a giant robot."
jaeger,So why is it I just can‚Äôt buy into the giant robots and monsters of ‚ÄòPacific Rim: Uprising‚Äô?
jaeger,"This is the sequel to Guillermo Del Toro‚Äôs ‚ÄòPacific Rim‚Äô, and honestly I didn‚Äôt buy into the original either."
jaeger,This movie gives us a quick refresher on what happened in that one.
jaeger,"Kaiju, the giant monsters, emerge out of an interdimensional rift at the bottom of the Pacific Ocean."
jaeger,"In response, we humans create giant robots known as Jaegers, so massive it takes two pilots to operate them."
jaeger,"That right there, the two pilots thing, just never jived with me."
jaeger,"The pilots have to be ‚Äúrift compatible‚Äù, because they kinda mind meld together which allows them to control the jaeger in sync."
jaeger,We are told this is because the sheer size of a jaeger would melt the brain of a single pilot.
jaeger,"So the sheer feat of designing this massive robot was doable, but they just couldn‚Äôt crack the nut of piloting?"
jaeger,"And instead they went with what seems like the most difficult route possible by not only creating a mind meld, but then making it where compatibility was an issue?"
jaeger,"I know this is all first film problems, but I couldn‚Äôt swallow it then and I can‚Äôt with this one either."
jaeger,"Now I could maybe suspend my disbelief with the mind meld aspect, but ‚ÄòUprising‚Äô throws down a whopper almost right from the start."
jaeger,This young girl (maybe 16 or so?)
jaeger,has built her own mini jaeger in a wharehouse by salvaging scrap parts off other downed jaegers.
jaeger,By herself.
jaeger,Without seemingly the aid of so much as a fork lift.
jaeger,"This thing stands at least 30 feet tall, has massive steel plates all over it, not to mention the complexities of its mechanics and electronics."
jaeger,And she built it.
jaeger,Riiiiiiight.
jaeger,I get what they were going for here.
jaeger,"This is the kid building the hot rod in the garage, but it‚Äôs the scale of things that completely throws logic out the window."
jaeger,The car analogy carries into another aspect of the movie.
jaeger,"Through a series of circumstances, this girl winds up at a base where true jaegers are, and she stands in awe of them, calling out there names."
jaeger,"It‚Äôs as if she is saying ‚Äúwow, a Lamborghini Diablo, and there‚Äôs a Shelby Cobra, and that‚Äôs a Ferrari!‚Äù except it we the audience have no clue why she is so enamored by Gypsy Avenger, Guardian Bravo, Bracer Phoenix, or Saber Athena."
jaeger,"The movie wants these jaegers to be characters, but to me they were just the one with a turbine in the chest, the one with a ball mace for a hand, etc."
jaeger,"But fine, what are we here watching this movie for?"
jaeger,Robot versus monster fights.
jaeger,And the movie gives us those.
jaeger,"Actually if you watch the trailers for this movie, you‚Äôll see extended glimpses of every single one of these fights."
jaeger,There literally isn‚Äôt a single surprise to be had because of those trailers.
jaeger,"Once more, suspension of disbelief got too much for me as while battling amongst buildings, the cities get practically leveled."
jaeger,"We see shots of people running in the streets, but there‚Äôs some serious amount of civilian casualty going on that nobody in command or in the jaegers cares one bit about."
jaeger,"Lately the Marvel and DC movies have shined a light on this aspect, and it‚Äôs hard to go back to dismissing it in the name of cool looking destruction shots."
jaeger,"Even more on the ‚Äúnope, that‚Äôs just not believable‚Äù scale is when a monster or jaeger comes out of water near Santa Monica pier and Sydney Harbor."
jaeger,"No wake, no waves, they just arrive right there at the shore."
jaeger,"In the case of Santa Monica, I know the water is nowhere deep enough to have hidden a kaiju as massive as the one that emerges."
jaeger,"Yeah, that‚Äôs the kind of stuff I started thinking about while watching this because honestly there‚Äôs not a single three dimensional character in the movie to focus on."
jaeger,"It‚Äôs rebellious teen, angry Russian, hot shot pilot, reluctant pilot, and nothing more."
jaeger,"When some die, I couldn‚Äôt have cared less."
jaeger,"This movie is very obviously crafted for an international audience, so maybe they figured basic character tropes would be enough."
jaeger,"But as you can tell by this point of my review, I haven‚Äôt even mentioned the names of characters or the actors, because they just don‚Äôt matter."
jaeger,"It‚Äôs all about the robots, except I couldn‚Äôt connect with those either."
jaeger,"With this type of movie, what you see is what you get."
jaeger,"‚ÄòPacific Rim: Uprising‚Äô promises robot on monster action, and it‚Äôs there on display for you."
jaeger,"For me, the problem is it became mind numbing noise and empty spectacle."
jaeger,"It‚Äôs not well thought out sci-fi, it‚Äôs what a 10 year old would plot with their robot toys."
jaeger,I was hoping more for what a mature adult would plot with those same toys.
jaeger,"According to ‚ÄúGoogle Dapper‚Äù a Large-Scale Distributed Systems Tracing Infrastructure, there are some more extensive open source projects can help us to using it within very convenient steps."
jaeger,What does ‚ÄúGoogle Dapper‚Äù going to solve?
jaeger,We do need trace latency and root-cause of frontend and backend services even errors.
jaeger,Dapper planed to solve tracing problem of remote procedure calls and then summary to trace tree as image left part to right part.
jaeger,And then OpenTracing comes in.
jaeger,OpenTracing implements APIs and interfaces base on ‚ÄúDapper‚Äù to help programers add trace code with low coupling library and produce public format tracing data.
jaeger,After all we can get tracing result as picture.
jaeger,"The OpenTracing Data Model
Causal relationships between Spans in a single Trace


        [Span A]  ‚Üê‚Üê‚Üê(the root span)
            |
     +------+------+
     |             |
 [Span B]      [Span C] ‚Üê‚Üê‚Üê(Span C is a `ChildOf` Span A)
     |             |
 [Span D]      +---+-------+
               |           |
           [Span E]    [Span F] >>> [Span G] >>> [Span H]
                                       ‚Üë
                                       ‚Üë
                                       ‚Üë
                         (Span G `FollowsFrom` Span F)
Common function calls
def top_level_function():
    span1 = tracer.start_span('top_level_function')
    try:
        ."
jaeger,.
jaeger,.
jaeger,"# business logic
    finally:
        span1.finish()
def function2():
    span2 = get_current_span().start_child('function2') \
        if get_current_span() else None
    try:
        ."
jaeger,.
jaeger,.
jaeger,"# business logic
    finally:
        if span2:
            span2.finish()
In fact, with OpenTracing‚Äôs workout, we did can start our tracing tasks, but there are ‚ÄúZipkin‚Äù and ‚ÄúJaeger‚Äù to be introduced."
jaeger,"Zipkin, it is a distributed tracing system too, has dependency-free library, and spring-boot server."
jaeger,But could be roll as a ‚ÄúTracer‚Äù to OpenTracing.
jaeger,"// All data are recorded against the same endpoint, associated with your service graph
localEndpoint = Endpoint.newBuilder().serviceName(""tweetie"").ip(""192.168.0.1"").build()
span = Span.newBuilder()
    .traceId(""d3d200866a77cc59"")
    .id(""d3d200866a77cc59"")
    .name(""targz"")
    .localEndpoint(localEndpoint)
    .timestamp(epochMicros())
    .duration(durationInMicros)
    .putTag(""compression.level"", ""9"");

// Now, you can encode it as json
bytes = SpanBytesEncoder.JSON_V2.encode(span);
Zipkin supply lots of modules to fit sorts of platform and programing languages supported includes AWS, GCP, Azure, Java, .NET, Node.js, Go, Fingle(Twitter rpc), Python, Spark, Php, js."
jaeger,Zipkin-UI support web interface for standard query support.
jaeger,"For example, with Docker-Zipkin and Zipkin .Net client Lib, we can illustrates well done job by Zipkin."
jaeger,"## to start zipkin docker and UI
$ docker-compose -f docker-compose.yml -f docker-compose-ui.yml up
## start compiled .net example frontend and backend web server
dotnet zipkin4net-master/Examples/aspnetcore/frontend.dll
dotnet zipkin4net-master/Examples/aspnetcore/backend.dll

with Zipkin library enhanced server/service
Jaeger\ÀàyƒÅ-g…ôr\, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies."
jaeger,"Uber Engineering starts use Zipkin and evolving new distributed tracing system for high scalability, to serve thousands of micro-services."
jaeger,So Jaeger extends more complex architecture for larger scale of requests and performance.
jaeger,"In particular, the Zipkin model did not support two important features available in the OpenTracing standard and Jaeger client libraries: a key-value logging API and traces represented as more general directed acyclic graphs rather than just trees of spans."
jaeger,"example image from LightStep [x]PM (Product)
When really steps in, there still some better choice, good example from the post ‚ÄúTracing http request in go with opentracing‚Äù."
jaeger,Following are some digests when implement to backend server with Golang.
jaeger,"Entry Point (Service backend)
// Jaeger tracer can be initialized with a transport that will
// report tracing Spans to a Zipkin backend
// zipkinURL point to server
transport, err := zipkin.NewHTTPTransport(
      *zipkinURL,
      zipkin.HTTPBatchSize(1),
      zipkin.HTTPLogger(jaeger.StdLogger),
)
if err != nil {
      log.Fatalf(""Cannot initialize HTTP transport: %v"", err)
}
// create Jaeger tracer
tracer, closer := jaeger.NewTracer(
      ""TracerName"",
      jaeger.NewConstSampler(true), // sample all traces
      jaeger.NewRemoteReporter(transport, nil),
)
// Close the tracer to guarantee that all spans that could
// be still buffered in memory are sent to the tracing backend
defer closer.Close()
Other just useful method for tag , log and error."
jaeger,// Adds a tag to the span.
jaeger,"// 
// Tag values can be numeric types, strings, or bools."
jaeger,"// The behavior of other tag value types is undefined at the 
// OpenTracing level."
jaeger,"SetTag(key string, value interface{}) Span
// LogFields is an efficient and type-checked way to record
// key:value 
// logging data about a Span, though the programming interface 
// is a little more verbose than LogKV()
LogFields(fields ...log.Field)
// set error flag of span
ext.Error.Set(span, true)
We don‚Äôt need to care about span relations for HTTP requests, and can get good enough tracing event and detail by Zipkin-UI."
jaeger,Just remember to take care about privacy or secret data leaks if hosted at public domains.
jaeger,I continue to be very interested in the potential of OpenCensus and have been interested in evaluating Uber‚Äôs Jaeger project.
jaeger,Particularly now that Jaeger is a CNCF project.
jaeger,"So, I‚Äôm going to take the Orijtech‚Äôs Cloud Spanner instrumented by OpenCensus post, tweaked to use Cloud Datastore (purely to show another storage service), tweaked to use Jaeger (rather than Stackdriver) and running locally under containers, then deployed to Kubernetes and, if I‚Äôm good, deployed to App Engine Flex too."
jaeger,Let‚Äôs get started!
jaeger,"Setup
We‚Äôll need Google Cloud Platform Project with Billing enabled."
jaeger,"In order to use Cloud Datastore, you must enable the Datastore service and create an App Engine app (this is a vestigial requirement):
GOOGLE_PROJECT_ID=[[YOUR-GOOGLE-PROJECT]]
BILLING=[[YOUR-BILLING-ID]]
gcloud projects create ${GOOGLE_PROJECT_ID}
gcloud beta billing projects link ${GOOGLE_PROJECT_ID} \
--billing-account=${BILLING}
gcloud services enable datastore.googleapis.com \
--project=${GOOGLE_PROJECT_ID}
gcloud app create \
--region=us-central \
--project=${GOOGLE_PROJECT_ID}
When we use containers (locally and on Kubernetes Engine), we‚Äôll want to authenticate using a Service Account."
jaeger,Please see my others posts for the steps to generate a GCP Service Account and key and for uploading the Service Account to Kubernetes.
jaeger,"In this post, the Service Accounts needs only permissions to access Datastore."
jaeger,"So, assuming you have a Service Account with an email address of ${ROBOT}, the command you‚Äôll need to issue is:
gcloud projects add-iam-policy-binding ${GOOGLE_PROJECT_ID} \
--member=serviceAccount:${ROBOT} \
--role=roles/datastore.user
Local
Please review the Orijtech Cloud Spanner instrumented by OpenCensus post as ‚Äî with all credit to them ‚Äî the code I‚Äôm using below is derived almost entirely from their code."
jaeger,"I‚Äôm using Go 1.10.
main.go:

NB: In lines 50‚Äì53, the OpenCensus Jaeger Exporter is configured."
jaeger,"This code has 4 (3 explicit; 1 optional|implicit) environment variable requirements: GOOGLE_PROJECT_ID, JAEGER_HOST, JAEGER_PORT; the optional|implicit variable is GOOGLE_APPLICATION_CREDENTIALS and this configures Application Default Credentials."
jaeger,"In order to run this code locally, we need access to a Jaeger deployment."
jaeger,"Fortunately, this is trivial."
jaeger,"Jaeger provides a Docker image to get us going:
docker run \
--detach \
--env=COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
--publish=5775:5775/udp \
--publish=6831:6831/udp \
--publish=6832:6832/udp \
--publish=5778:5778 \
--publish=16686:16686 \
--publish=14268:14268 \
--publish=9411:9411 \
jaegertracing/all-in-one:latest
In our case, we won‚Äôt use the majority of the ports that Jaeger provides so, if you‚Äôd prefer, you could get away with (and to monitor interactively):
docker run \
--interactive \
--tty \
--publish=16686:16686 \
--publish=14268:14268 \
jaegertracing/all-in-one:latest
NB: Jaeger documents the many service endpoints here."
jaeger,We‚Äôre using the jaeger.thrift directly from clients endpoint (14268) and the Web UI (16686).
jaeger,"To generate some Traces to monitor in Jaeger, let‚Äôs run the Golang code provided above."
jaeger,"You‚Äôll need to configure the environment variables to do so:
GOOGLE_PROJECT_ID=[[YOUR-GOOGLE-PROJECT]]
GOOGLE_APPLICATION_CREDENTIALS=[[YOUR-CLIENT-JSON]]
JAEGER_HOST=localhost
JAEGER_PORT=14268
and then:
go run main.go
should generate:
2018/03/27 07:12:55 ProjectID: ${GOOGLE_PROJECT_ID}
2018/03/27 07:12:55 Jaeger: http://localhost:14268
To generate some traces, curl the endpoint of the Golang httpd server:
curl http://localhost:8080
This should return 3 object references:
[0xc42023c1e0 0xc42023c240 0xc42023c2a0]
If you wish, you may check that 3 Dogs have been created in Datastore:

Cloud Console: Datastore ‚ÄúQuery By Kind‚Äù
Which is mostly just a side-effect for the main event of generating some OpenCensus Traces that are recorded in Jaeger."
jaeger,"Return to your Jaeger UI and hit refresh:
http://localhost:16686

Jaeger UI
You should see 2 traces."
jaeger,One will corresponds to the PutMultiDatastore call and one named <trace-without-root-span> that corresponds to the handle function and it‚Äôs call to addDogs.
jaeger,You may wish to terminate the Jaeger container and clear its trace history before the next step.
jaeger,"Containerize
In order to get onto Kubernetes Engine, we‚Äôll need to containerize the Golang app."
jaeger,"Because we‚Äôre now moving to containers, you‚Äôll also need to ensure that you reference the Service Account (key) that was generated during ‚ÄúSetup‚Äù:
GOOGLE_APPLICATION_CREDENTIALS=[[YOUR-CLIENT-JSON]]
Here‚Äôs a template Dockerfile:

NB: I‚Äôm committed to using dumb-init by Yelp (link) in my containers but you may remove lines 6, 9 if you would prefer not to use it."
jaeger,Don‚Äôt forget to copy ca-certificates.crt into your working directory.
jaeger,"We‚Äôll build a static binary of the Golang program, generate the Docker image and push this to our project‚Äôs Container Registry with:
IMAGE=""jaeger-datastore""
CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main ."
jaeger,docker build --tag=gcr.io/${GOOGLE_PROJECT_ID}/${IMAGE} .
jaeger,"gcloud docker -- push gcr.io/${GOOGLE_PROJECT_ID}/${IMAGE}
To run the image locally under Docker, we need to configure the environment variables and pass in the Service Account key:
docker run \
--interactive \
--tty \
--net=host \
--volume=$PWD/${ROBOT}.key.json:/key.json \
--env=GOOGLE_PROJECT_ID=${GOOGLE_PROJECT_ID} \
--env=GOOGLE_APPLICATION_CREDENTIALS=/key.json \
--env=JAEGER_HOST=localhost \
--env=JAEGER_PORT=14268 \
--publish=${SINK}:8080 \
gcr.io/${GOOGLE_PROJECT_ID}/${IMAGE}
All being well, the output should be the same as when running the code locally:
2018/03/27 14:58:12 ProjectID: dazwilkin-180326-jaeger
2018/03/27 14:58:12 Jaeger: http://localhost:14268
And, you should be able to curl the endpoint as before:
curl localhost:8080
[0xc420600120 0xc4206001e0 0xc420600240]
And, you should see Traces generated in Jaeger."
jaeger,OK!
jaeger,I recommend you terminate both containers before continuing to free up ports and to keep-it-simple.
jaeger,"Kubernetes Engine
Is it wrong that I am excited to create a Kubernetes cluster!?"
jaeger,I‚Äôll leave the cluster provisioning to you.
jaeger,"As I‚Äôve said before, if you are willing to do so, please create a Regional Cluster to get used to this model."
jaeger,I‚Äôm continuing to encourage myself to use the Cloud Console‚Äôs Workloads and Discovery displays but can‚Äôt quit wean myself from the Kubernetes Dashboard.
jaeger,I‚Äôll assume you‚Äôre auth‚Äôd against a cluster such that you can kubectl cluster-info and receive is running responses from your cluster and its services.
jaeger,The Jaeger folks provide a quick-hit to deploy Jaeger to a Kubernetes cluster for non-production use.
jaeger,"I‚Äôm going to use this all-in-one which will deploy Jaeger into the default namespace:
kubectl create \
--filename=https://raw.githubusercontent.com/jaegertracing/jaeger-kubernetes/master/all-in-one/jaeger-all-in-one-template.yml
All being well, I‚Äôve edited the results (removing PORTS and AGE) to pretty-print it in Medium:
kubectl get services \
--selector=app=jaeger \
--namespace=default
NAME               TYPE           CLUSTER-IP      EXTERNAL-IP
jaeger-agent       ClusterIP      None            <none>
jaeger-collector   ClusterIP      10.43.254.117   <none>
jaeger-query       LoadBalancer   10.43.243.76    35.203.181.245
zipkin             ClusterIP      None            <none>
NB: The jaeger-query service is exposed through a Network LB (see Console output below)."
jaeger,"You can see the external endpoint listed above (in my case 35.203.181.245) or you can obtain this directly using:
JAEGER_QUERY=$(\
  kubectl get services/jaeger-query \
  --output=jsonpath=""{.status.loadBalancer.ingress[0].ip}"")
echo ${JAEGER_QUERY)
35.203.181.245

Network LB
Alternatively, using Cloud Console:

Cloud Console: Deployment details ‚Äújaeger-deployment‚Äù
Or:

Kubernetes Dashboard: Deployment ‚Äújaeger-deployment‚Äù
You may browse ${JAEGER_QUERY} to view the Jaeger UI from the Jaeger deployment on Kubernetes:

Jaeger UI served by Kubernetes
This deployment creates a jaeger-agent service."
jaeger,"In truth, I‚Äôm continuing to learn how to best employ this."
jaeger,"Meanwhile, in the deployment (see below) of the Cloud Datastore Golang code, the code is configured to send Trace data to the jaeger-collector service (jaeger-collector.default.svc on the service‚Äôs port 14268)."
jaeger,"jaeger-datastore-deployment-service.yaml:

NB: You must replace [[GOOGLE_PROJECT_ID]] in lines 20 and 35 with the value of your GCP Project ID."
jaeger,The container talks to the Jaeger collector service on port 14268.
jaeger,"You should then be able to:
kubectl apply --filename=jaeger-datastore-deployment-service.yaml
And:
kubectl get services \
--selector=app=jaeger-datastore \
--namespace=default
NAME               TYPE       CLUSTER-IP      PORT(S)
jaeger-datastore   NodePort   10.43.244.252   8080:30254/TCP
NB: In my case, the service created by the apply command has mapped the jaeger-datastore (our Golang code) port 8080 to a NodePort 30254."
jaeger,"Your NodePort will probably be different but you may determine this with:
NODE_PORT=$(\
  kubectl get services/jaeger-datastore \
  --output=jsonpath=""{.spec.ports[0].nodePort}"")
echo ${NODE_PORT}
30254
We‚Äôre going to take advantage of a useful ‚Äòhack‚Äô (in its positive sense) to access the Golang httpd service without exposing it on a public IP address."
jaeger,We can access the service via a NodePort and the next step is to port-forward from our localhost to this NodePort via any of the GCE VMs powering the cluster.
jaeger,"For simplicitly, let‚Äôs grab the 1st node:
NODE_HOST=$(\
  kubectl get nodes \
  --output=jsonpath=""{.items[0].metadata.name}"")
echo ${NODE_HOST}
gke-cluster-01-default-pool-66a5f47e-b70s
Lastly, we‚Äôll use this Kubernetes Node name which matches the GCE VM ID and the Node Port with gcloud ssh to create the port-forward:
gcloud compute ssh ${NODE_HOST} \
--project=${GOOGLE_PROJECT_ID} \
--ssh-flag=""-L ${NODE_PORT}:localhost:${NODE_PORT}""
And, if everything‚Äôs working correctly, you should now (from your localhost) be able to access the Golang httpd service as:
curl http://localhost:${NODE_PORT}
Let‚Äôs ensure that everything‚Äôs working as we expect."
jaeger,You may use either Cloud Console of the Kubernetes Dashboard to view the logs of each of the containers in the jaeger-datastore pod.
jaeger,"But, here‚Äôs how you may do this via the command-line."
jaeger,"Let‚Äôs first identify the pod:
POD=$(\
  kubectl get pods \
  --selector=app=jaeger-datastore \
  --namespace=default \
  --output=jsonpath=""{.items[0].metadata.name}"")
echo ${POD}
jaeger-datastore-74cc944d56-jv66z
The Pod contains 1 container: jaeger-datastore."
jaeger,"Let‚Äôs check its logs:
kubectl logs ${POD} jaeger-datastore
2018/03/27 16:32:05 ProjectID: [[GOOGLE_PROJECT_ID]]
2018/03/27 16:32:05 Jaeger: http://jaeger-collector.default.svc:14267
Alternatively, it may be preferable to deploy the Jaeger Agent as a sidecar (alongside the Golang container) within a Pod."
jaeger,"However, to do this, you will need to make a config change to the OpenCensus Jaeger Exporter in the Golang code."
jaeger,"main.go

NB: The only changes are to lines 47 and 50."
jaeger,"Because we changed the source, you will need to rebuild the code, rebuild the Docker image and push it to GCR."
jaeger,"For simplicity, I‚Äôm not renaming the image but, to ensure your Deployment uses this, latest version, grab the sha-256 hash from the push command."
jaeger,"In my case, this begins 3e79:
The push refers to a repository [gcr.io/my-project/jaeger-datastore]
5a9e3a3eb5ed: Pushed 
af42768a716b: Layer already exists 
b766c6dab1e1: Layer already exists 
latest: digest: sha256:3e7912f3d8e48aabb5ce5df357fd43ebbb4f353b175a24f5a7926d3df15cc1d7 size: 947
Then, we will need to revise the Deployment (see below) but I‚Äôm retaining the same Deployment and Service names so that we may re-apply it:
jaeger-datastore-deployment-service.yaml:

NB: As before, replace [[GOOGLE_PROJECT_ID]] with the your Google Cloud Platform Project ID in lines 20 and 35."
jaeger,"In line 20, replace [[YOUR-SHA256]] with the value generated when you pushed the image to GCR."
jaeger,"Then:
kubectl apply --filename=jaeger-datastore-deployment-service.yaml
The Pod now contains 2 containers: jaeger-datastore and jaeger-agent."
jaeger,"Let‚Äôs check each container‚Äôs logs:
kubectl logs ${POD} jaeger-datastore
2018/03/27 16:32:05 ProjectID: [[GOOGLE_PROJECT_ID]]
2018/03/27 16:32:05 Jaeger: localhost:6831
and:
kubectl logs $POD jaeger-agent \
| jq --raw-output "".msg""
Enabling service discovery
Registering active peer
Starting agent
Not enough connected peers
Trying to connect to peer
Connected to peer
It‚Äôs nothing much more than eye-candy but, here‚Äôs the result in the Jaeger UI of using the sidecar Jaeger Agent:

Jaeger UI: jaeger-datastore
and drilling down into the PutMulti trace:

Jaeger UI: PutMulti
Aside: Prometheus
Jaeger is instrumented for Prometheus."
jaeger,In fact each of the constituent services provides a metrics endpoint (link).
jaeger,"Since we already have the Query service exposed (so that we can view the UI in the browser), let‚Äôs use that."
jaeger,"Previously we used the following to determine the endpoint for the Jaeger (Query) UI:
JAEGER_QUERY=$(\
  kubectl get services/jaeger-query \
  --output=jsonpath=""{.status.loadBalancer.ingress[0].ip}"")
echo ${JAEGER_QUERY)
35.203.181.245
Instead of browsing http://${JAEGER_QUERY} to view the UI, browse http://${JAEGER_QUERY}/metrics and you should see something similar to:

If you wish to consume this endpoint from a Prometheus service, you‚Äôll need to add an endpoint (not this one!)"
jaeger,to your prometheus.yml targets.
jaeger,"Within the Cluster and assuming you deployed Jaeger to the default namespace (as we did here), the service‚Äôs URL will be http://jaeger-query.default.svc/metrics."
jaeger,"Conclusion
In other posts, I‚Äôve focused on using Stackdriver Trace as the consuming service."
jaeger,"In this post, we‚Äôve explored ‚Äî the rather delightful ‚Äî Jaeger (which also serves a prometheus metrics endpoint; I guess I need another post on using Prometheus instead of Stackdriver Monitoring)."
jaeger,We deployed Jaeger to Kubernetes and then deployed a service that consumed the Jaeger Collector service directly and then used the Jaeger Agent directly (indirectly to the Jaeger Collector service).
jaeger,The latter appears to be the more flexible model.
jaeger,"Stackdriver Profiler
Earlier this week (yesterday?"
jaeger,"), Google released Stackdriver Profiler."
jaeger,"Since I had a Kubernetes cluster running and so Golang code at hand, I decided to revise the code, redeploy and see what happened:

Stackdriver Profiler
You must enable the Stackdriver Profiler service and grant the service account that your code is using (the one used to create the Kubernetes secret) a role for the agent:
GOOGLE_PROJECT_ID=[[YOUR-GOOGLE-PROJECT]]
ROBOT=[[YOUR-ROBOT-NAME]]
gcloud services enable cloudprofiler.googleapis.com \
--project=${GOOGLE_PROJECT_ID}
gcloud projects add-iam-policy-binding ${GOOGLE_PROJECT_ID} \
--member=serviceAccount:${ROBOT}@${GOOGLE_PROJECT_ID}.iam.gserviceaccount.com \
--role=roles/cloudprofiler.agent
Give it a few minutes to process the results on first use."
jaeger,"A Distributed Tracing walk-through with Jaeger, Istio and Kiali
You‚Äôve heard that Istio, like other service meshes, brings automated tracing between your microservices?"
jaeger,"Fair enough, that‚Äôs correct."
jaeger,"Still, it doesn‚Äôt do all of the job."
jaeger,"We‚Äôre going to cover this, and see also where Kiali will help."
jaeger,"Wait, what is distributed tracing, anyway?"
jaeger,"Distributed tracing is a technology to trace logical / business transactions in a running software, including transactions that spread over network calls involving different hosts or processes."
jaeger,"Tracing a transaction means catching all events, or actions, following some causality or sequential relationships."
jaeger,"In Tracing jargon, a single event or action is denoted as a ‚ÄúSpan‚Äù."
jaeger,"A ‚ÄúTrace‚Äù is the interrelated collection of Spans, occurring along a timeline, with parental relationships and a single root."
jaeger,So that‚Äôs a tree.
jaeger,Spans are associated with a duration.
jaeger,"For instance, with an HTTP call from service A to service B, service A could generate a span with a duration that stands for the network roundtrip time."
jaeger,"Service B can also generate a span, with a duration that stands for the server processing time."
jaeger,"Typically, these two spans would belong to the same trace."
jaeger,"The parental relationship can be made if service A injects some headers in the HTTP request, and service B reads these headers to retrieve the trace context."
jaeger,This is the context propagation.
jaeger,"All the spans are collected and sent to a server such as Jaeger, and then can be retrieved and visualized with some tooling, like Jaeger UI itself, or Kiali."
jaeger,"So, Istio does all of that for me?"
jaeger,"Yes, Istio and Envoy do automatically what I described above as an example."
jaeger,"Because the Envoy sidecars are in a privileged position to catch all traffic between your services, and because they know well the topology of your microservices, they can do a pretty good job."
jaeger,"When a service emits an HTTP request, the Envoy sidecar will create a span with some appropriate meta-data and inject the required headers."
jaeger,"On inbound requests, Envoy reads the headers to extract context and, if any, creates a child span (if there were no context, a span can still be created, but without any parent, meaning it‚Äôs a new trace)."
jaeger,So every mesh-internal request generates a two-span trace.
jaeger,Note that TCP traffic isn‚Äôt traced automatically by Envoy.
jaeger,We will cover this point in the third and last part of this story.
jaeger,"Two-span trace in Kiali, but the actual business transaction is incomplete
But you want more than these two-span traces, right?"
jaeger,"You want to correlate an incoming connection of service B to an outgoing connection to service C, for instance, you want to tie two individual requests together."
jaeger,That‚Äôs where you come into play.
jaeger,"Envoy cannot do that for you, because, unless it runs some complicated ML-based thingy (probably error prone by the way) it cannot guess what happens between its in and out bounds."
jaeger,"From its point of view, this is the black box where your application stands."
jaeger,Whether or not a call to C was a consequence of that previous call from A is up to you to decide.
jaeger,Let‚Äôs see how to do that.
jaeger,"How to propagate the context, then?"
jaeger,"So, this is one of the few occasions where you need to write some code to fully leverage what a service mesh can offer in terms of observability."
jaeger,"The good news is, there‚Äôs nothing very difficult here."
jaeger,"Even without the help of any library, you can still code the required steps, as you simply need to extract a couple of headers from the incoming request, and inject them back into the outgoing request."
jaeger,"Envoy documents which headers are necessary to propagate depending on the tracing backend; in the case of Jaeger, use B3 trace headers, they are compatible."
jaeger,Another necessary header is the x-request-id created by Envoy.
jaeger,"Which gives us:
x-b3-traceid
x-b3-spanid
x-b3-parentspanid
x-b3-sampled
x-b3-flags
x-request-id
Alternatively, all of the headers prefixed with x-b3 can be grouped into a single b3 header, more compressed."
jaeger,"For more information about these headers, check https://github.com/openzipkin/b3-propagation."
jaeger,"You can see an example here, coded in go, of header propagation."
jaeger,"As you can see, it‚Äôs quite easy to do."
jaeger,This is used in a demo application built for Istio and Kiali.
jaeger,"After you do that, you can see the Envoy generated spans linked together:

Full business transaction in Kiali

Detail of a span created by Envoy, in Jaeger UI
Using a client library
Propagating context as shown above should ‚Äújust work‚Äù."
jaeger,"However, there are some advantages to using a client library instead."
jaeger,"Jaeger provides a bunch of them to propagate context in your favorite language, without leaving you to deal with the specification details of OpenTracing or Zipkin B3."
jaeger,"More importantly, you might want at some point to create your own spans."
jaeger,Imagine that you want to measure and trace some computational task that is part of a trace initiated by Envoy.
jaeger,You can definitely do that.
jaeger,"Here is an example, this time in Java, using the Jaeger client + OpenTracing (dependency on module io.jaegertracing / jaeger-client)."
jaeger,"The first step is to create a Tracer object, which depends on the tracing backend."
jaeger,"For instance, with Jaeger, you can create it as follow:
Tracer tracer = Configuration.fromEnv().getTracer();
See here the environment variables used for configuration."
jaeger,"Typically, with Istio, you need this kind of env setup on your pods:
    spec:
      containers:
      - ...
        env:
        - name: JAEGER_SERVICE_NAME
          value: myapp.mynamespace
        - name: JAEGER_SAMPLER_TYPE
          value: ratelimiting
        - name: JAEGER_SAMPLER_PARAM
          value: ""1""
        - name: JAEGER_PROPAGATION
          value: b3
        - name: JAEGER_ENDPOINT
          value: http://jaeger-collector.istio-system.svc/api/traces
Ideally, you should set JAEGER_SERVICE_NAME to <app>.<namespace>, where <app> is the application name (same as the app label set on pods) and <namespace> the namespace where you deploy it."
jaeger,"This is not exactly mandatory, but it will be consistent with how Envoy generates spans, and will help Kiali to correlate the spans with the appropriate apps / workloads / services."
jaeger,JAEGER_SAMPLER_TYPE and JAEGER_SAMPLER_PARAM define the sampling strategy.
jaeger,"Here, we define a simple rule to keep only 1 percent of the spans."
jaeger,"But keep in mind that only the root span of a trace can define the sampler used across subsequent spans, so, perhaps that is something you want to configure in Envoy as well."
jaeger,"To learn more about sampling, I warmly recommend reading this article from Juraci Paix√£o Kr√∂hling: The role of sampling in distributed tracing."
jaeger,JAEGER_ENDPOINT must point to the Jaeger collector service.
jaeger,"Beware that it‚Äôs not always exposed by default in Istio, you may have to create a service to expose it, generally targeting port 14268:
apiVersion: v1  
kind: Service  
metadata:  
  name: jaeger-collector  
  namespace: istio-system  
  labels:  
    app: jaeger  
spec:  
  type: ClusterIP  
  ports:  
    - name: http-query  
      port: 80  
      protocol: TCP  
      targetPort: 14268  
  selector:  
    app: jaeger
Now, here is how to extract a SpanContext from headers:
    SpanContext parentContext =
       tracer.extract(Format.Builtin.HTTP_HEADERS,
                      new TextMap() {
         @Override
         public Iterator<Map.Entry<String, String>> iterator() {
           return headers.iterator();
         }
         @Override
         public void put(String key, String value) {
           throw new UnsupportedOperationException();
         }
       });
And to inject it back:
    tracer.inject(spanContext,
                  Format.Builtin.HTTP_HEADERS,
                  new TextMap() {
          @Override
          public Iterator<Map.Entry<String, String>> iterator() {
            throw new UnsupportedOperationException();
          }
          @Override
          public void put(String key, String value) {
            headers.accept(key, value);
          }
        });
These two snippets give an idea, they may have to be adapted to whatever headers object you can manipulate."
jaeger,"For more examples in different languages, check the OpenTracing guides."
jaeger,"Depending on your framework, perhaps there‚Äôs already some mechanisms in place to inject / extract spans and make them accessible to your app, which saves you from doing this."
jaeger,"For instance, in this demo application using Vert.X, the vertx-opentracing module extracts and injects spans automatically, and provides a getter and setter to the active span stored in a local context that makes it easy to propagate across a stack of calls."
jaeger,"Finally, you can use the OpenTracing client API to create your own spans:
Span span = tracer.buildSpan(""Doing something"")  
      .withTag(""foo"", foo)  
      .withTag(""bar"", bar)  
      .asChildOf(parentContext)  
      .start();
    span.log(""Log any relevant info throughout span lifetime"");
    // ... Do something
    span.finish();
Use tags to enrich the span with any meta-data you find relevant, and logs for even more information as you would do with a usual logger."
jaeger,"Once the traces propagation is set up, Tracing in Kiali takes another dimension."
jaeger,"Traces here are bigger, involving a mix of Envoy and custom spans."
jaeger,You can have hundreds of spans in a trace without a problem.
jaeger,"In the next parts, we will review more in detail the capabilities that Kiali offers on Tracing, and also cover some more atypical scenarios."
jaeger,"In the meantime, you can reach out on our Slack channel, mailing list, Twitter (me) or, last but not least, IRC."
jaeger,"Photo by Prateek Katyal from Pexels
I am currently working as an intern in the Jaeger (under CNCF Tracing Projects) as a part of the Outreachy Internship Program."
jaeger,Outreachy is three months paid remote internship program for the under-represented group.
jaeger,Their main goal is to support everyone who wants to get into tech and get them more involved with open source.
jaeger,"Organisations like Linux kernel, Apache, CNCF, Fedora, Mozilla, and many more take part in this program and the internship projects may include programming, user experience, documentation, data science or community event planning, and many more."
jaeger,They allocate an experienced mentor from open source to each intern.
jaeger,"More information about the eligibility criteria, the timeline, and time commitment can be found on their website."
jaeger,There is no experience required to apply as well as to work on their project.
jaeger,It‚Äôs a very good opportunity for anyone to get industry-level exposure and start their career.
jaeger,"Reasons to apply for Outreachy
Many of us may think is it worth doing it?"
jaeger,Or why not directly apply for a job instead of an internship?
jaeger,"Yes, it‚Äôs definitely worth doing it."
jaeger,Internship fills the gap between academics and jobs.
jaeger,Everyone needs a mentor while starting their way into the tech or open-source.
jaeger,"With this internship opportunity, you have access to the open-source community, their open chat channels, and have a mentor who is committed to helping you with anything."
jaeger,They are always just one message away.
jaeger,The other reason why I would encourage anyone eligible to take part in Outreachy is the learning and experience involved.
jaeger,You get the chance to work with open source communities and most importantly with people who have actually developed these real-world projects.
jaeger,These open-source projects are used by big organizations and being a contributor adds a huge plus point to your resume and also you learn how to work in a team.
jaeger,I am pretty sure by contributing to open source you will have much more confidence when you start your job career because you have been already involved in big projects.
jaeger,"Challenges involved & Ways to overcome
Like cracking any other job getting into Outreachy is also not that easy and we have a long way to go."
jaeger,Since it‚Äôs a big internship program you need to compete with candidates from all over the world.
jaeger,"In order to get ahead of everyone, you need to prepare yourself and get everything planned."
jaeger,Start early: Failure to start early means you are giving other applicants the chance to get ahead of you.
jaeger,I would say just fill-up the form as soon as possible and start working on your skill sets.
jaeger,Keep an eye on the application deadline and submit as early as possible.
jaeger,Gain required knowledge: Most of the projects are listed on the Outreachy website from the very beginning of the application.
jaeger,Going through this list and shortlisting the projects of your skill sets and interest as early as possible will give you a good advantage over others.
jaeger,"Since these projects are mostly hosted in GitHub or GitLab, I would recommend to go through them and have a basic understanding."
jaeger,"If you don‚Äôt have any idea about git, go through the free courses available and get your hands dirty."
jaeger,It will be used in any project you get involved in.
jaeger,Ask questions: Asking questions not only solves your doubt but also shows your interest in the project which maintainers look for.
jaeger,It also gives you the chance to look at the project from a fresh eye and find possible improvements that you can work upon later.
jaeger,"All these open-source projects have public communication mediums like google groups, IRC, Slack, Gitter, and other ways where one can ask for help."
jaeger,"Generally, applicants feel a little shy to ask questions in such channels which I would say one should overcome as early as possible."
jaeger,"Ways to increase your selection probability
Outreachy application involves a three-phase: initial application phase and contribution phase and final application."
jaeger,"The initial application involves verifying your eligibility, looking at your time commitment, and also consider your experience as a minor or underrepresented in tech which you have to explain properly in an essay."
jaeger,The contribution phase is the main or deciding phase for your internship.
jaeger,"In order to increase your chances of being selected follow the following steps:
Select projects: There are many participating organisations with multiple projects and their descriptions."
jaeger,Choose the project that interest you and you are comfortable with the skill sets required.
jaeger,Organisations receive much more applications than the available seats.
jaeger,"So, don‚Äôt settle with just one project."
jaeger,"During the contribution phase, go through the list of projects several times and decide your project list to contribute."
jaeger,Some projects have more candidates than others.
jaeger,"Hence, to be on the safer side, find organizations that are taking more interns and apply to those."
jaeger,Be consistent.
jaeger,Dedicate few hours each day for the contributions.
jaeger,You can work on multiple pull requests parallelly and make sure to follow the reviewer‚Äôs feedback in a timely fashion.
jaeger,"Reviewers have to review multiple PRs, hence not working actively on the PR feedbacks can delay your work."
jaeger,"Make best use of contribution period
What comes under contribution: Every addition whether its code, unit or integration tests, bug fixes, code reviews or documentation is a contribution."
jaeger,Contribute in every way you can.
jaeger,Show your skill-sets in as many fields as possible.
jaeger,Updating documentation as part of the pull request where you‚Äôre adding some feature is considered nice.
jaeger,"Similarly, adding unit-tests for all edge cases as part of the bug-fix is also great."
jaeger,Try to make a contribution that has a high impact on the project.
jaeger,"Try to do code review in other‚Äôs pull request where you can, it is much appreciated by the maintainers."
jaeger,"Answering user‚Äôs queries in the IRC, Slack, Gitter channel wherever you can is also a type of contribution."
jaeger,These all ultimately increases your chance to get selected as the maintainers keep an eye on everything.
jaeger,Familiarization with the project: Familiarizing with the project you‚Äôre going to contribute is one of the most important and time taking part.
jaeger,"Hence, doing it as early as possible will give an advantage over other candidates."
jaeger,Take your time to go through the documentation to understand the fundamental concepts of the project.
jaeger,Try running the project locally on your computer to get a practical look and feel of the project.
jaeger,Read the contributor guidelines.
jaeger,Each open-source project has a dedicated page for it.
jaeger,"Find a suitable task to start your contribution process: To find a suitable task, you can look at the list of open issues and search for issues that are relatively easy to solve."
jaeger,"Projects use different labels for easy tasks, ‚ÄúGood first issue‚Äù, ‚ÄúEasy‚Äù, ‚ÄúBeginners‚Äù are some generic tags used by most of the projects."
jaeger,"Being new to the project, finding the tasks can be difficult."
jaeger,Assign yourself any task in which you even have the slightest of an idea about how to start.
jaeger,Create an initial pull request for the task you chose earlier: None of the pull requests are perfect in the first attempt.
jaeger,There are always flaws either in code quality or missing unit tests and in many more ways.
jaeger,"Once you open a PR, the project maintainers will review your pull request and give you feedback to improve upon."
jaeger,Always give a short description of the changes you are doing as part of the pull request which will help the reviewer to understand about your change.
jaeger,"Iterate upon your pull request: To maintain the overall code quality of the project, maintainers only merge a pull request once it meets the minimal standard of code quality."
jaeger,A pull request can take from days to weeks to even months to get merged.
jaeger,"As an applicant, it‚Äôs very important to be active in your submitted pull requests in terms of updating pull request with the changes suggested as part of feedbacks."
jaeger,Don‚Äôt leave your pull request in the middle even if it is taking a longer time than usual.
jaeger,That shows your dedication towards getting your contribution merged.
jaeger,"Once your PR is merged, don‚Äôt forget to say ‚ÄúThank you‚Äù."
jaeger,Don‚Äôt feel sad in case your PR isn‚Äôt merged due to some of the other reasons.
jaeger,Keep in mind that that the reviewer has a very major role in getting your PR merged.
jaeger,So do acknowledge that by saying some kind words.
jaeger,"In short, these are the guidelines."
jaeger,Start with the small contribution like fixing the typo in documentation or comments in code but do start and be consistent with your work.
jaeger,"Try to communicate as early as possible, like working on feedback and updating pull request as soon as you can."
jaeger,Be active on communication channels and help others.
jaeger,Most importantly enjoy the work you are doing and learn through the journey.
jaeger,Final Application: For the final application you have to record at least one contribution to any project (This part is well explained in the Outreachy website).
jaeger,Wait For The Result: You can only give your best in the contribution phase and wait for the result.
jaeger,The majority of the candidate doesn‚Äôt get selected in their first attempt and I too got it on my second attempt.
jaeger,The good news is this program happens twice a year so the next chance to apply again is not that far.
jaeger,Keep an eye on the Outreachy website so that you don‚Äôt miss the chance.
jaeger,So don‚Äôt feel sad in case you can‚Äôt make it but don‚Äôt stop trying.
jaeger,"Good luck for your journey ahead
Outreachy provides you an opportunity to contribute to open-source projects."
jaeger,"The journey to opensource is a bit difficult in the beginning but in long run, it‚Äôs very rewarding."
jaeger,Open-source contributions add a huge plus point to your resume and will help in every job interview you apply in your career.
jaeger,So I would encourage you to try for it.
jaeger,"Last but not the least, try to give your best and enjoy while learning and keep contributing."
jaeger,"Ashmita Bohara
Follow
15



15"
jaeger,"In integration scenarios and complex, heterogeneous application architectures track and tracing integration-instances is important."
jaeger,"Red Hat Fuse, based on Apache Camel, supports OpenTracing, which can be connected with Jaeger."
jaeger,There is a community Jaeger operator for Kubernetes and OpenShift.
jaeger,"Red Hat also provides a certified Red hat OpenShift Jaeger operator, for easy install of Jaeger."
jaeger,It is also part of the Red Hat OpenShift Service Mesh offering.
jaeger,"So, it would be sensible to use Jaeger as a server application to support the tracing in your application."
jaeger,"Conclusively, Red Hat confirms the importance of the Jaeger offering."
jaeger,"However, it turns out that to make it work in the latest versions, Fuse 7.7 and 7.8, is not obvious."
jaeger,That is where this article is about.
jaeger,"Create your application

In Code Ready Studio create a default SpringBoot application, as described in this story."
jaeger,Use Code Ready Studio 12.18 to work with Fuse 7.8 by default.
jaeger,"And use the following properties in the wizard:

Deployment platform: OpenShift/Kubernetes (assumed that you want to deploy your application to Openshift or Kubernetes eventually, otherwise choose Standalone)
Runtime Environment: Spring Boot
Camel Version: 2.23.2.fuse-780036-‚Ä¶ (Default)
On the last page choose the simple log template for the service and choose Finish."
jaeger,"Annotate the Spring Boot Main class
The Red Hat Fuse documentation states that the only thing you should do to enable tracing in a Spring Boot service is to annotate the Application class with the @CamelOpenTracing annotation:

Annotate Application class
This requires the camel-opentracing-starter dependency in the pom.xml."
jaeger,"Dependencies and the version-mess
Red Hat Fuse and Camel should support OpenTracing by default."
jaeger,An article that describes quite nicely how to enable it can be found here.
jaeger,"You would need to add the following dependencies:
camel-opentracing-starter
jaeger-client
opentracing-agent
But, it turned out not to be that obvious."
jaeger,"For instance, the opentracing agent is no longer being developed anymore:

Through trial and error, my colleague found out that the latest Fuse version that supports OpenTracing using Jaeger, was Fuse 7.4."
jaeger,"I found that the Red Hat Fuse 7.8 Resolved Issues confirms this:

This issue confirms that it worked in Fuse 7.4, but broke in 7.6."
jaeger,"Since it is in the resolved issues list of the 7.8 documentation, I expected it to work right away."
jaeger,The issue contains a reproducer.zip with a project that reproduces this issue.
jaeger,I used the pom.xml from that zip to build up my list of dependencies.
jaeger,Then I searched in the Effective Pom tab for the versions of the artifacts in the same group and therefore closely related.
jaeger,"From the Effective POM you can conclude that the default io.opentracing version would be 0.31.0.redhat-00008:

This version did not work."
jaeger,"Logging will fail with the exception:
java.lang.NoSuchMethodError: ‚Äòio.opentracing.Span io.opentracing.ScopeManager.activeSpan()‚Äô

I browsed the Red Hat Maven repository for the io.opentracing libraries and found besides version 0.31.0.redhat-00008 also version 0.33.0.redhat-00001:

The same way I found that the latest io.opentracing.contrib.opentracing-tracerresolver version is 0.1.8.redhat-00001:

So, I used those versions in my maven dependencies."
jaeger,"I created properties for those versions to be able to change them at the top of the pom.xml, and move them to the parent POM."
jaeger,"Having found a working set, I‚Äôm used to check and validate the minimal set of dependencies and also validate the actual set of versions."
jaeger,"Also, I found it useful to abstract the versions into maven properties."
jaeger,"In the end I found the following set necessary and working:

Run and Test
Start Jaeger as a Docker Container
Run Jaeger as a Docker container:

Then run the application with the maven goal spring-boot:run :

The sample Spring Boot application will fire off an instance every few seconds (by default 1 second, but I increased the interval to 15s):

The Jaeger console can be accessed through the url:
http://localhost:16686/search
For every timer://foo firing, a Jaeger trace is created."
jaeger,"Since we started the application with -DJAEGER_SERVICE_NAME=demo, the Service pop-list on the search page, will be populated with this value."
jaeger,"Then with the button Find Traces the current instances can be listed:

Selecting a trace and expand it will show:

As can be seen, I changed the log from the default message, to view changes in my tries."
jaeger,"Conclusion
Yes, the actual problem that broke the OpenTracing support in Fuse 7.5 or 7.6 is solved using Fuse 7.8."
jaeger,"But, not with the default io.opentracing and io.opentracing.contrib versions."
jaeger,"The main reason to write this story is not so much on how to implement it, but to trace back my steps on how I found the proper working dependencies."
lightstep,"Last month I published a tutorial on how to implement Zipkin-based distributed tracing using the Kubernete-native Ambassador API gateway and the Java OpenTracing ‚ÄòMicrodonuts‚Äô application, and after a few requests I wanted to loop back around now and add LightStep support to this."
lightstep,"Introducing LightStep [x]PM
For those new to LightStep, it is a SaaS-based distributed tracing platform (and more) that is aiming to provide the next generation of Application Performance Monitoring (APM) ‚Äî [x]PM."
lightstep,"If you‚Äôre interested, I wrote about some of the history in the distributed tracing and APM spaces on InfoQ recently."
lightstep,"The satellite-based architecture of the LightStep platform is interesting, as is the UI and diagnostic tooling provided, and I encourage the interested reader to check out their comprehensive docs."
lightstep,"In essence, the LightStep [x]PM data processing pipeline has two major components: the Satellites, which are standalone software appliances running within a customer‚Äôs network or VPC, and the LightStep Engine, the SaaS component."
lightstep,All spans generated by instrumented clients and servers are sent to a pool of satellites where they are processed and temporarily stored during trace assembly.
lightstep,"The LightStep Engine queries the satellites, records aggregate information about spans, directs the assembly process, and stores traces durably."
lightstep,"You can experiment with the SaaS platform via the LightStep website, and you will need to create an account and get an access token in order to programmatically send span data to LightStep."
lightstep,"Configuring the OpenTracing Java ‚ÄòMicrodonuts‚Äô Application
If you clone my fork of the java-opentracing-walktrough GitHub repo and list the directory contents, you should see something similar to this:
$ git clone git@github.com:danielbryantuk/java-opentracing-walkthrough.git
...
$ cd java-opentracing-walkthrough
$ ls
Dockerfile                      README.md                       kubernetes-ambassador           microdonuts
LICENSE                         client                          kubernetes-ambassador-lightstep
Most of the content is the same from my original tutorial, and you can read this if you want more details."
lightstep,The primary additions for the LightStep integration are located within the kubernetes-ambassador-lightstep folder.
lightstep,"If you navigate to here and list the contents, you should see something similar to this:
cd kubernetes-ambassador-lightstep/
$ ls
ambassador-rbac.yaml    ambassador-service.yaml lightstep-config.yaml   lightstep-tracing.yaml  microdonut.yaml         tracing-config.yaml
The LightStep tracing config is located within the lightstep-tracing.yaml file."
lightstep,"If you open this YAML file within your favourite editor, this is what you should see:
---
apiVersion: v1
kind: Service
metadata:
  name: lightstep
  annotations:
    getambassador.io/config: |
      ---
      apiVersion: ambassador/v0
      kind: TracingService
      name: tracing
      service: ""my-collector-grpc.mydomain.com:443""
      driver: lightstep
      config: {
          access_token_file: /config/lightstep_api_key.txt
      }
spec:
  type: ExternalName
  externalName: my-collector-grpc.mydomain.com
You‚Äôll recognise the Ambassador annotation and most of the TracingService details from the previous tutorial, but you‚Äôll also notice that in addition to changing the driver from zipkin to lightstep, I have also defined the TracingService to report the traces to an external URI (my-collector-grpc.mydomain.com, which is where my LightStep trace collector is running outside of the Kubernetes cluster) and specified an access_token_file property within the TracingService config."
lightstep,"The observant among you will have most likely been pondering, ‚Äúhow do we get the /config/lightstep_api_key.txt file into Ambassador?"
lightstep,Great question.
lightstep,"Ambassador simply runs as a container within a pod, which is in turn defined within a Deployment, just like any other Kubernetes service."
lightstep,Therefore you can mount a ConfigMap as a volume into the Ambassador container with the relevant data.
lightstep,"Let‚Äôs first define a ConfigMap, an example of which you can find in the lightstep-config.yaml file:
---
kind: ConfigMap
apiVersion: v1
metadata:
    name: lightstep-config
data:
    lightstep_api_key.txt: <your key here>
If you are following along, and have a LightStep account, then replace <your key here> with your actual key text."
lightstep,"With the ConfigMap defined, you can now map this into the Ambassador container."
lightstep,"If you look back into the ambassador-rbac.yaml file, you can see at the bottom of the config the volumeMounts and volumes defined (note the ‚Ä¶ shows where I have truncated the config to improve readability here):
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: ambassador
spec:
  replicas: 3
  template:
    ...
    spec:
      serviceAccountName: ambassador
      ...
        volumeMounts:
        - name: lightstep-config-volume
          mountPath: /config
      restartPolicy: Always
      volumes:
      - name: lightstep-config-volume
        configMap:
          name: lightstep-config
With all of these pieces of the puzzle complete, you can now deploy Ambassador with LightStep Tracing into Kubernetes."
lightstep,"I‚Äôm going to use Google‚Äôs hosted GKE service (with pre-emptible VMs, just to keep the cost low), but you can use whatever flavour of Kubernetes that works for you."
lightstep,"$ gcloud container clusters create ambassador-tracing-demo --preemptible
..."
lightstep,Creating cluster ambassador-tracing-demo...done.
lightstep,"...
$ kubectl create clusterrolebinding cluster-admin-binding-new \
--clusterrole cluster-admin --user < my GCP user name>
clusterrolebinding ""cluster-admin-binding-new"" created
$ kubectl apply -f lightstep-config.yaml,ambassador-rbac.yaml
configmap ""lightstep-config"" created
service ""ambassador-admin"" created
clusterrole ""ambassador"" created
serviceaccount ""ambassador"" created
clusterrolebinding ""ambassador"" created
deployment ""ambassador"" created
Let‚Äôs now go ahead and deploy the LightStep tracing config:
$ kubectl apply -f lightstep-tracing.yaml 
service ""lightstep"" created
You can now deploy a simple httpbin Service to the cluster, which instructs Ambassador to proxy requests from the /httpbin/ route to the external httpbin.org website."
lightstep,"$ kubectl apply -f ambassador-service.yaml 
service ""ambassador"" created
Now you can query Kubernetes for the Ambassador Service LoadBalancer external IP address."
lightstep,"Here is what I saw:

I can see that Ambassador is exposed on the external IP of 35.239.206.165, and so I can make a request to my httpbin service, querying for the IP by specifying the ‚Äòip‚Äô endpoint in the httpbin API, like so:
$ curl 35.239.206.165/httpbin/ip
{
  ""origin"": ""146.148.98.46""
}
You can curl your Ambassador httpbin endpoint a few times in order to make sure you have created a few traces."
lightstep,"If you now log in to your LightStep account and navigate to the LiveView, you should see something similar to this:

This view provides an good overview of current traces, both the latency via the histogram in the top half of the page, and the additional individual trace information in the lower half of the page."
lightstep,"You can click on the individual traces to get additional information on the trace:

Let‚Äôs now deploy the MicroDonut application and associated ConfigMap with our configuration tracing."
lightstep,"You‚Äôll note now that I have updated the Java application‚Äôs tracing config to send its trace data to LightStep, separate from the work we have already done to configure Ambassador."
lightstep,"The tracing-config.yaml file now contains this:
---
kind: ConfigMap
apiVersion: v1
metadata:
    name: tracing-config
data:
    tracer_config.properties: |
        public_directory=../client
        // Selector for the below config blocks
        tracer=lightstep
        // Jaeger config
        jaeger.reporter_host=localhost
        jaeger.reporter_port=5775
        // Zipkin config
        zipkin.reporter_host=zipkin
        zipkin.reporter_port=9411
        // LightStep config
        lightstep.collector_host=< your lightstep collector host >
        // The collector_protocol value is either ""http"" or ""https""
        lightstep.collector_protocol=http
        lightstep.collector_port=8081
        lightstep.access_token=< your access token >
If you are following along, you will need to replace <your access token > with you actual text token."
lightstep,"Let‚Äôs deploy this into Kubernetes:

You should now be able to access the MicroDonut app via your web browser via the Ambassador external IP and the route /microdonut/ e.g."
lightstep,":

Before you get too hungry, you can order some virtual donuts by clicking on the images, and pressing the ‚Äúorder‚Äù button that is displayed below the images."
lightstep,"Do this a few times to generate a few traces, and navigate to the LightStep LiveView:

That‚Äôs it!"
lightstep,"Now you can explore and experiment with Ambassador, LightStep, and MicroDonuts."
lightstep,"Conclusion
You can learn more about Ambassador at https://www.getambassador.io, and about the Ambassador Distributed Tracing feature in the Ambassador docs."
lightstep,Visit https://go.lightstep.com/Try-xPM.html to try LightStep today!
lightstep,"If you have any questions, please join our Slack, drop us a line in the comments below, or @getambassadorio on Twitter."
lightstep,Acknowledgements (a Big Thanks!)
lightstep,I would like to express a big thanks to Alex Gervais from AppDirect for all of his help during this work.
lightstep,"Not only did Alex provide guidance, but he has previously done most of the work on the open source Ambassador Tracing contributions, and also fixed a recent bug with the integrations."
lightstep,"Many thanks also to the LightStep team, who gave us access to a trial account and also provided useful feedback on the article as it was being written."
skywalking,"Apache SkyWalking, the observability platform, and open-source application performance monitor (APM) project, today announced the general availability of its 8.1 release that extends its functionalities and provides a transport layer to maintain the lightweight of the platform that observes data continuously."
skywalking,"Background
SkyWalking is an observability platform and APM tool that works with or without a service mesh, providing automatic instrumentation for microservices, cloud-native and container-based applications."
skywalking,"The top-level Apache project is supported by a global community and is used by Alibaba, Huawei, Tencent, Baidu, and scores of others."
skywalking,"Transport traces
F or a long time, SkyWalking has used gRPC and HTTP to transport traces, metrics, and logs."
skywalking,"They provide good performance and are quite lightweight, but people kept asking about the MQ as a transport layer because they want to keep the observability data continuously as much as possible."
skywalking,"From SkyWalking‚Äôs perspective, the MQ based transport layer consumes more resources required in the deployment and the complexity of deployment and maintenance but brings more powerful throughput capacity between the agent and backend."
skywalking,"In 8.1.0, SkyWalking officially provides the typical MQ implementation, Kafka, to transport all observability data, including traces, metrics, logs, and profiling data."
skywalking,"At the same time, the backend can support traditional gRPC and HTTP receivers, with the new Kafka consumer at the same time."
skywalking,Different users could choose the transport layer(s) according to their own requirements.
skywalking,"Also, by referring to this implementation , the community could contribute various transport plugins for Apache Pulsar, RabbitMQ."
skywalking,"Automatic endpoint dependencies detection
The 8.1 SkyWalking release offers automatic detection of endpoint dependencies."
skywalking,"SkyWalking has long offered automatic endpoint detection, but endpoint dependencies, including upstream and downstream endpoints, are critical for Ops and SRE teams‚Äô performance analysis."
skywalking,The APM system is expected to detect the relationships powered by the distributed tracing.
skywalking,While SkyWalking has been designed to include this important information at the beginning the latest 8.1 release offers a cool visualization about the dependency and metrics between dependent endpoints.
skywalking,It provides a new drill-down angle from the topology.
skywalking,"Once you have the performance issue from the service level, you could check on instance and endpoint perspectives:

SpringSleuth metrics detection
In the Java field, the Spring ecosystem is one of the most widely used."
skywalking,"Micrometer , the metrics API lib included in the Spring Boot 2.0, is now adopted by SkyWalking‚Äôs native meter system APIs and agent."
skywalking,"For applications using Micrometer with the SkyWalking agent installed, all Micrometer collected metrics could then be shipped into SkyWalking OAP."
skywalking,"With some configurations in the OAP and UI , all metrics are analyzed and visualized in the SkyWalking UI, with all other metrics detected by SkyWalking agents automatically."
skywalking,"Notable enhancements
The Java agent core is enhanced in this release."
skywalking,"It could work better in the concurrency class loader case and is more compatible with another agent solution, such as Alibaba‚Äôs Arthas."
skywalking,"With the logic endpoint supported, the local span can be analyzed to get metrics."
skywalking,One span could carry the raw data of more than one endpoint‚Äôs performance.
skywalking,"GraphQL, InfluxDB Java Client, and Quasar fiber libs are supported to be observed automatically."
skywalking,Kubernetes Configmap can now for the first time be used as the dynamic configuration center- a more cloud-native solution for k8s deployment environments.
skywalking,"OAP supports health checks, especially including the storage health status."
skywalking,"If the storage (e.g., ElasticSearch) is not available, you could get the unhealth status with explicit reasons through the health status query."
skywalking,Opencensus receiver supports ingesting OpenTelemetry/OpenCensus agent metrics by meter-system.
skywalking,"Additional resources
Please reach out to learn@tetrate.io in case of any questions or feedback ."
skywalking,A deep dive walking through the SpringSleuth metrics detection will be out from Tetrate in August.
skywalking,"Apache SkyWalking founder Sheng Wu and SkyWalking core contributor Hongtao Gao are Tetrate engineers, and Tevah Platt is a content writer for Tetrate."
skywalking,"Tetrate helps organizations adopt open source service mesh tools, including Istio, Envoy, and Apache SkyWalking, so they can manage microservices, run service mesh on any infrastructure, and modernize their applications."
skywalking,"Apache SkyWalking, the observability analysis and application performance monitoring (APM) tool, shattered its own performance record with its recent 6.1 release."
skywalking,"Designed especially for microservices, cloud native and container based architecture, SkyWalking provides distributed tracing, service mesh telemetry analysis, metric aggregation and workload visualization."
skywalking,"Following SkyWalking‚Äôs integration with Istio and Envoy-based Service Mesh at the end of 2018, our colleague, Hongtao Gao, set a performance baseline with his blog post SkyWalking performance in Service Mesh scenario."
skywalking,"Using an 8 CPU, 16GB VM test environment, SkyWalking was found to support 25K telemetry data per second, or 100K data per second in a 3-node cluster using elasticsearch as storage."
skywalking,"This performance was acceptable, considering most containers wouldn‚Äôt support over 400 tps/qps payload."
skywalking,"The testing showed that, turning only server-side telemetry (which is the default setting in Istio 1.0+), we could support about 200 service instances in a 3-node cluster."
skywalking,"But the target for performance is always ‚Äúas high as possible.‚Äù After the 6.0.0 GA release, I contributed several pull requests to SkyWalking to optimize the thread model and batch mechanism."
skywalking,"Retesting SkyWalking‚Äôs updated version under the same conditions, we found a single node could support nearly 100k telemetry data per second, like the old 3-node cluster did."
skywalking,"After we scaled out to 3 nodes, 276k telemetry data per second was supported."
skywalking,The results confirmed SkyWalking could support 3x times the performance as its GA release.
skywalking,"In theory, if we still consider 400 tps per service instance, then over 500 service instances would be supported."
skywalking,This is the limit test.
skywalking,"Real world variations would affect performance, such as the number of endpoints, endpoint grouping rule and TTL (removal of data from storage)."
skywalking,But it would not change the 3X performance improvement as such factors would equally apply in the GA deployment.
skywalking,"For the lastest on SkyWalking, follow us on Twitter, join the #skywalking channel at Apache Slack and subscribe to the mailing list."
skywalking,Learn more about SkyWalking features from our post on the v6 release.
stagemonitor,"Stagemonitor is an opensource solution for performance monitoring of Java applications.It provides insights about the call stack ,Method execution time, page load time,JVM,JDBC, Request metrics and helps to better understand and improve the performance of applications."
stagemonitor,Stagemonitor can be used for both development and production environments.It imposes a very low overhead on the application.
stagemonitor,"Stagemonitor for Development

hybris storefront with Stagemonitor widget
For development environments, Stagemonitor provides a widget which is injected into the webpage which is being monitored.This widget gives the details about the Call stack, time spent in each method,Web Requests and JVM metrics."
stagemonitor,"Stagemonitor widget-Call Tree tab
Call Tree tab provides the call stack and the time spent in each method."
stagemonitor,"Stagemonitor widget-Request tab
Request tab shows the total Page load time and also shows time taken for network,Server processing and DOM Processing."
stagemonitor,"Stagemonitor widget-Metrics tab
Metrics tab provides the details about the JDBC,JVM and Web Requests."
stagemonitor,"Stagemonitor for Production
Stagemonitor can be configured to send the performance metrics to time series databases like ElasticSearch, Grafana.This allows the flexibility to monitor requests/metrics over a period of time and helps in understanding the application performance issues."
stagemonitor,Multiple application instances running on different hosts can be monitored at a time using Stagemonitor.
stagemonitor,"Elasticsearch ‚Äî JVM Metrics
Integrating with hybris
Download and install the below extension and add entry in the localextensions.xml ."
stagemonitor,This extension contains all the dependencies and properties for running stagemonitor.
stagemonitor,"stagemonitor.zip
Stagemonitor hybris extension drive.google.com
2."
stagemonitor,The stagemonitor.properties file at the below path is where the configuration can be controlled.
stagemonitor,"${HYBRIS_BIN_DIR}/bin/custom/stagemonitor/resources/stagemonitor.properties
stagemonitor.instrument.include=org.training, de.hybris
stagemonitor.profiler.active = true
stagemonitor.web.widget.enabled=true
stagemonitor.applicationName=Electronics storefront
stagemonitor.instanceName=Electronics storefront
stagemonitor.active=true
stagemonitor.web.widget.enabled=true
stagemonitor.requestmonitor.http.collectHeaders=true
stagemonitor.requestmonitor.collectRequestStats=true
stagemonitor.profiler.logCallStacks=true
stagemonitor.profiler.active=true
stagemonitor.instrument.jdbc.dataSource.implementations=com.mysql.jdbc.jdbc2.optional.MysqlDataSource, org.apache.tomcat.jdbc.pool.DataSource, org.apache.tomcat.dbcp.dbcp.PoolingDataSource, org.apache.tomcat.jdbc.pool.DataSourceProxy, org.apache.commons.dbcp2.PoolingDataSource, org.apache.commons.dbcp.PoolingDataSource, org.springframework.jdbc.datasource.AbstractDriverBasedDataSource, org.hsqldb.jdbc.jdbcDataSource, org.apache.commons.dbcp.BasicDataSource, de.hybris.platform.jdbcwrapper.HybrisDataSource
#stagemonitor.elasticsearch.url= http://localhost:9200
3."
stagemonitor,The tomcat general options property needs to be modified to include the below java agent.
stagemonitor,"tomcat.generaloptions=
-javaagent:${HYBRIS_BIN_DIR}/bin/custom/stagemonitor/lib/byte-buddy-1.5.7.jar
4."
stagemonitor,"Once hybris is restarted after the above changes, stagemonitor starts collecting the metrics and depending on the configuration, either the widget can be used from the browser or the the metrics can be sent to the Elasticsearch server for further analysis."
tanzu,"New Kubernetes versions:
1.20.5
1.19.9
1.18.17
Workload clusters no longer use the Tanzu Mission Control Extension Manager."
tanzu,OIDC authentication no longer uses dex .
tanzu,Running tanzu cluster create --dry-run generates a workload cluster template from a configuration file without requiring a management cluster.
tanzu,"Bill of Materials (BoM) handling supports custom registry sources for individual images, overriding default registry."
tanzu,Users can upgrade add-ons independently of upgrading Tanzu Kubernetes Grid.
tanzu,"(vSphere) Supports routable, no-NAT IP addresses for workload cluster pods, enabling traceability and auditing."
tanzu,(vSphere v6.7) Installer interface includes access and configuration options for NSX-T Advanced Load Balancer.
tanzu,(vSphere) Supports deploying multiple MachineDeployment and KubeadmControlPlane objects without changing overlay file.
tanzu,"(Azure) New cluster configuration variables:
AZURE_CUSTOM_TAGS applies Azure tags to cluster resources."
tanzu,AZURE_ENABLE_PRIVATE_CLUSTER and AZURE_FRONTEND_PRIVATE_IP run workload clusters as private clusters with internal load balancers.
tanzu,AZURE_ENABLE_NODE_DATA_DISK optionally provisions a data disk for worker nodes.
tanzu,AZURE_CONTROL_PLANE_ and AZURE_NODE_ variables for DATA_DISK_SIZE_GIB and OS_DISK_SIZE_GIB configure data and OS disk sizes for control plane and worker nodes.
tanzu,AZURE_CONTROL_PLANE_OS_DISK_STORAGE_ACCOUNT_TYPE and AZURE_NODE_OS_DISK_STORAGE_ACCOUNT_TYPE specify storage account for control plane and worker node disks.
tanzu,(Azure) Future-compatibility cluster configuration variable AZURE_ENABLE_ACCELERATED_NETWORKING enables Azure accelerated networking when TKRs support it.
tanzu,(Currently Azure TKRs do not support Azure accelerated networking.
tanzu,Source -> TKG documentation.
tanzu,"Photo by James Pond on Unsplash
This article is a demo of getting Tanzu Data (SCDF/Gemfire/Postgresql/MySQL) for K8S on a ‚Äúnon-supported‚Äù platform."
tanzu,Why?
tanzu,"If you have the license to run Tanzu Postgresql, you don‚Äôt need to worry about the k8s control plane."
tanzu,Why bother?
tanzu,"I want to understand how Tanzu Data interacts with the K8S control plane,e.g., how to setup network policy/service mesh to secure Tanzu Data and automate Tanzu Data releases to my K8S operation lifecycle."
tanzu,"First, if you don‚Äôt have a K8S cluster (1.16+), you can follow my GitHub https://github.com/vmware-ysung/cks-centos create one in GCE or consider using kubespray, kind, or kop."
tanzu,"Once the cluster is ready, you can ‚Äúpre-requisite‚Äù your k8s env for Tanzu Data."
tanzu,"These pre-requisites include 1) accessing GCR, Nexus, Harbor, or Dockerhub from your cluster so that k8s can pull images from those repositories, 2) cert-manager installed 3) helm v3 in your local env."
tanzu,I use my terraform/ansible/kubeadm to deploy one control-plane and three worker nodes env with cert-manager and Nginx ingress.
tanzu,"It should look like this:
ysung@ysung-a01 kubectl % k get nodes
NAME          STATUS   ROLES                  AGE   VERSION
cks-master1   Ready    control-plane,master   24h   v1.20.0
cks-worker1   Ready    <none>                 24h   v1.20.0
cks-worker2   Ready    <none>                 24h   v1.20.0
cks-worker3   Ready    <none>                 24h   v1.20.0
ysung@ysung-a01 kubectl % k get svc
NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
kubernetes                          ClusterIP   10.96.0.1       <none>        443/TCP    7h16m
pg-instance-1                       ClusterIP   10.97.198.100   <none>        5432/TCP   6h11m
pg-instance-1-agent                 ClusterIP   None            <none>        <none>     6h11m
postgres-operator-webhook-service   ClusterIP   10.103.143.54   <none>        443/TCP    6h13m
Next, let‚Äôs get the images from network.pivotal.io (You need to register and agree on the license)."
tanzu,"In network.pivotal.io, search for ‚ÄúPostgres for Kubernetes‚Äù and download the file (postgres-for-kubernetes-v1.0.0.tar.gz) to your desktop, then unzip the file."
tanzu,"ysung@ysung-a01 Downloads % tar zxvf postgres-for-kubernetes-v1.0.0.tar.gz
x postgres-for-kubernetes-v1.0.0/
x postgres-for-kubernetes-v1.0.0/images/
x postgres-for-kubernetes-v1.0.0/images/postgres-instance
x postgres-for-kubernetes-v1.0.0/images/postgres-instance-id
x postgres-for-kubernetes-v1.0.0/images/postgres-instance-tag
x postgres-for-kubernetes-v1.0.0/images/postgres-operator
x postgres-for-kubernetes-v1.0.0/images/postgres-operator-id
x postgres-for-kubernetes-v1.0.0/images/postgres-operator-tag
x postgres-for-kubernetes-v1.0.0/operator/
x postgres-for-kubernetes-v1.0.0/operator/crds/
x postgres-for-kubernetes-v1.0.0/operator/crds/postgres-instance.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-cluster-role-binding.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-cluster-role.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-mutating-webhook-configuration.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-self-signed-issuer.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-service-account.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-serving-cert.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-validating-webhook-configuration.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator-webhook-service.yaml
x postgres-for-kubernetes-v1.0.0/operator/templates/postgres-operator.yaml
x postgres-for-kubernetes-v1.0.0/operator/values.yaml
x postgres-for-kubernetes-v1.0.0/operator/Chart.yaml
x postgres-for-kubernetes-v1.0.0/pg-instance-example.yaml
x postgres-for-kubernetes-v1.0.0/s3-secret-example.yaml
x postgres-for-kubernetes-v1.0.0/sample-app/
x postgres-for-kubernetes-v1.0.0/sample-app/Dockerfile
x postgres-for-kubernetes-v1.0.0/sample-app/spring-music.yaml
x postgres-for-kubernetes-v1.0.0/sample-app/start.sh
Inside the directory, you can load the images to your local docker, tag the local/remote docker image, then push them to remote gcr, nexus, harbor, or dockerhub."
tanzu,"ysung@ysung-a01 Downloads % cd postgres-for-kubernetes-v1.0.0
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % ls
images    operator   pg-instance-example.yaml s3-secret-example.yaml  sample-app
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % clear
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % docker load -i ./images/postgres-operator
805802706667: Loading layer [==================================================>]  65.61MB/65.61MB
3fd9df553184: Loading layer [==================================================>]  15.87kB/15.87kB
7a694df0ad6c: Loading layer [==================================================>]  3.072kB/3.072kB
fd7061d31ad3: Loading layer [==================================================>]  5.632kB/5.632kB
4b4bd574e49b: Loading layer [==================================================>]  401.9kB/401.9kB
e152edc8bead: Loading layer [==================================================>]  44.66MB/44.66MB
Loaded image: postgres-operator:v1.0.0
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % docker load -i ./images/postgres-instance
070c04821d66: Loading layer [==================================================>]  273.3MB/273.3MB
07a8a652fcf1: Loading layer [==================================================>]  32.04MB/32.04MB
9ab2a722e995: Loading layer [==================================================>]  20.48kB/20.48kB
18c84f97a1eb: Loading layer [==================================================>]  2.048kB/2.048kB
77381640e952: Loading layer [==================================================>]  433.7kB/433.7kB
3ba6bbc85c04: Loading layer [==================================================>]  26.62kB/26.62kB
9b3241d6c479: Loading layer [==================================================>]  26.62kB/26.62kB
Loaded image: postgres-instance:v1.0.0
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % docker images ""postgres-*""
REPOSITORY          TAG       IMAGE ID       CREATED       SIZE
postgres-operator   v1.0.0    0c0838dfb622   7 weeks ago   108MB
postgres-instance   v1.0.0    3224e25506df   7 weeks ago   361MB
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % docker push gcr.io/vmware-ysung/postgres-operator:v1.0.0
The push refers to repository [gcr.io/vmware-ysung/postgres-operator]
e152edc8bead: Layer already exists
4b4bd574e49b: Layer already exists
fd7061d31ad3: Layer already exists
7a694df0ad6c: Layer already exists
3fd9df553184: Layer already exists
805802706667: Layer already exists
v1.0.0: digest: sha256:3af37b693cae737f4e2b89d2e086b295d8db66d8fbe074cc2531cce096ff4bbf size: 1571
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % docker push gcr.io/vmware-ysung/postgres-instance:v1.0.0
The push refers to repository [gcr.io/vmware-ysung/postgres-instance]
9b3241d6c479: Layer already exists
3ba6bbc85c04: Layer already exists
77381640e952: Layer already exists
18c84f97a1eb: Layer already exists
9ab2a722e995: Layer already exists
07a8a652fcf1: Layer already exists
070c04821d66: Layer already exists
7a694df0ad6c: Layer already exists
3fd9df553184: Layer already exists
805802706667: Layer already exists
v1.0.0: digest: sha256:8117fe2bd7d8b121a91bf3615c3665cc8bad808b4cb8f9397d77b82fbbc076df size: 2407
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 %
Once the images are ready in your gcr repository, you need a ‚Äúdocker-registry‚Äù type secret in your k8s cluster, so your k8s resource can pull images."
tanzu,"Here is the example:
ysung@ysung-a01 cks_kubeadm % k get secret
NAME                  TYPE                                  DATA   AGE
default-token-2dwfj   kubernetes.io/service-account-token   3      53m
ysung@ysung-a01 cks_kubeadm % k create secret docker-registry regsecret --docker-server=gcr.io --docker-username=_json_key --docker-password=""$(cat ~/.ssh/vmware-ysung.json)""
secret/regsecret created
ysung@ysung-a01 cks_kubeadm % k describe secret regsecret
Name:         regsecret
Namespace:    default
Labels:       <none>
Annotations:  <none>
Type:  kubernetes.io/dockerconfigjson
Data
====
.dockerconfigjson:  5568 bytes
Now we are ready to deploy Tanzu SQL Postgres."
tanzu,There are two components of Postgres for K8S: Postgres operator and Postgres instance.
tanzu,"We first deploy operator, then we direct operator how our Postgres instance should look like using the YAML file."
tanzu,Go back to the Tanzu SQL Postgres folder you just unzipped.
tanzu,Review the ‚Äúvalues.yaml‚Äù file in the operator subdirectory.
tanzu,"Ensure that the dockerRegistrySecretName matches the one you just created, and the operatorImageRepository/postgresImageRepository matches the URIs you did push."
tanzu,"ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % cd operator
ysung@ysung-a01 operator % ls
Chart.yaml crds  templates values.yaml
ysung@ysung-a01 operator % cat values.yaml
---
# specify the url for the docker image for the operator, e.g."
tanzu,"gcr.io/<my_project>/postgres-operator
operatorImageRepository: gcr.io/vmware-ysung/postgres-operator
operatorImageTag: v1.0.0
# specify the docker image for postgres instance, e.g."
tanzu,"gcr.io/<my_project>/postgres-instance
postgresImageRepository: gcr.io/vmware-ysung/postgres-instance
postgresImageTag: v1.0.0
# specify the name of the docker-registry secret to allow the cluster to authenticate with the container registry for pulling images
dockerRegistrySecretName: regsecret
Now we are ready to deploy Postgres Operator."
tanzu,"ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % helm install postgres-operator operator/
W1219 13:10:37.912424   27721 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W1219 13:10:39.968536   27721 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
NAME: postgres-operator
LAST DEPLOYED: Sat Dec 19 13:10:41 2020
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
Wait for a couple seconds to get operator ‚ÄúREADY‚Äù."
tanzu,"ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % k get all
NAME                                     READY   STATUS    RESTARTS   AGE
pod/postgres-operator-55cb44f597-p7hwg   1/1     Running   0          40s
NAME                                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/kubernetes                          ClusterIP   10.96.0.1       <none>        443/TCP   63m
service/postgres-operator-webhook-service   ClusterIP   10.103.143.54   <none>        443/TCP   40s
NAME                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/postgres-operator   1/1     1            1           40s
NAME                                           DESIRED   CURRENT   READY   AGE
replicaset.apps/postgres-operator-55cb44f597   1         1         1       40s
Once the Postgres Operator is ready, we can create a Postgres instance using a YAML manifest like this:
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % cat pg-instance-1.yaml
apiVersion: sql.tanzu.vmware.com/v1
kind: Postgres
metadata:
  name: pg-instance-1
  namespace: default
spec:
  memory: 800Mi
  cpu: ""0.8""
  storageClassName: fast
  storageSize: 100M
  pgConfig:
     dbname: dev1
     username: pgadmin
  serviceType: ClusterIP
  highAvailability:
     enabled: false
  backupLocationSecret:
     name:
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % k apply -f pg-instance-1.yaml
postgres.sql.tanzu.vmware.com/pg-instance-1 created
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % k get pod
NAME                                 READY   STATUS              RESTARTS   AGE
pg-instance-1-0                      0/1     Init:0/1            0          5s
pg-instance-1-monitor-0              0/1     ContainerCreating   0          5s
postgres-operator-55cb44f597-p7hwg   1/1     Running             0          2m17s
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % k get pod -w
NAME                                 READY   STATUS    RESTARTS   AGE
pg-instance-1-0                      1/1     Running   0          34s
pg-instance-1-monitor-0              1/1     Running   0          34s
postgres-operator-55cb44f597-p7hwg   1/1     Running   0          2m46s
For testing, you can use ‚Äúkubectl exec‚Äù to run psql in the pod once the pod is ready."
tanzu,"ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % k get pod
NAME                                 READY   STATUS    RESTARTS   AGE
pg-instance-1-0                      1/1     Running   0          3m28s
pg-instance-1-monitor-0              1/1     Running   0          3m28s
postgres-operator-55cb44f597-p7hwg   1/1     Running   0          5m40s
ysung@ysung-a01 postgres-for-kubernetes-v1.0.0 % k exec -it pg-instance-1-0 -- psql
psql (11.9 (VMware Postgres 11.9.3))
Type ""help"" for help."
tanzu,"postgres=# \q
As you can see in the following, there is a ClusterIP service, pg-instance-1."
tanzu,Other resources can use this service to connect to our Postgres instance.
tanzu,"Next article, I will show you how to set up another deployment to connect the Postgres instance."
tanzu,Stay tuned.
tanzu,"ysung@ysung-a01 kubectl % k get svc
NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
kubernetes                          ClusterIP   10.96.0.1       <none>        443/TCP    7h16m
pg-instance-1                       ClusterIP   10.97.198.100   <none>        5432/TCP   6h11m
pg-instance-1-agent                 ClusterIP   None            <none>        <none>     6h11m
postgres-operator-webhook-service   ClusterIP   10.103.143.54   <none>        443/TCP    6h13m"
tanzu,"Introduction
Asmentioned on the cloud-init website ‚Äî Cloud-init is the industry standard multi-distribution method for cross-platform cloud instance initialization."
tanzu,"It is supported across all major public cloud providers, provisioning systems for private cloud infrastructure, and bare-metal installations."
tanzu,"Meanwhile, VMware has been providing Guest OS customization on their vSphere platform for quite some time."
tanzu,"While Windows Guest OS customization, using Sysprep, has been the de-facto standard for Windows VMs on vSphere, Linux OSs have been tricky."
tanzu,"For Linux Guest OS customization, vSphere has relied on VMware Tools and its capability of leveraging initialization Perl scripts to configure the guest OS."
tanzu,"While this has worked quite well, this process does not allow us to leverage the full feature sets that cloud-init, with its modular approach, provides."
tanzu,"It is also not in line with the direction other cloud providers have been adopting, leading to image management issues."
tanzu,"While there is support for cloud-init with VMware tools on some Linux Guest OSs, there are documented issues due to race conditions between the cloud-init and the VMware tools during the guest initialization process."
tanzu,This issue prevents us from seamlessly using the cloud images provided by the Linux vendors.
tanzu,"As we move to a standard image management solution across a multi-cloud environment, this issue becomes critical."
tanzu,This article offers a working solution to enable cloud-init on an Ubuntu Focal cloud image within a vSphere 7 environment.
tanzu,You can easily tweak the process for other versions as well as cloud images from other Linux distribution.
tanzu,The process is composed of three stages.
tanzu,"The first stage downloads the OVA from the vendor‚Äôs website, perform specific configurations, and creates a virtual machine within the vSphere environment."
tanzu,The second stage configures and prepares the virtual machine for cloud-init configuration.
tanzu,"Finally, the last step converts the virtual machine to an OVA file (within a content library) to be used for future deployments."
tanzu,I use the well-known govc command-line interface to automate some of the steps.
tanzu,Users can perform those steps manually if required.
tanzu,Stage 1.
tanzu,"Setting up govc
While I will not go too deep in details on setting up govc, I will share a sample configuration file govc uses to interact with my vCenter server."
tanzu,"Once govc binary is installed on your workstation, this file is sourced before moving to the next step."
tanzu,Modify the govc parameters as per your environment.
tanzu,"## source ~/.govenv
export GOVC_URL=vcenter.lab.local
export GOVC_HOST=
export GOVC_USERNAME=""administrator@vsphere.local""
export GOVC_PASSWORD=""VMware1!"""
tanzu,"export GOVC_INSECURE=true
export GOVC_DATACENTER=Pacific-Datacenter
export GOVC_DATASTORE=vsanDatastore
export GOVC_NETWORK=""DVPG-Management Network""
export GOVC_RESOURCE_POOL=
Download the Ubuntu Focal LTS OVA image (modify if you need a different OVA version)."
tanzu,"wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.ova
Export the OVA configuration file to a temporary file calledconfig.json."
tanzu,Modify this file before moving to the next stage.
tanzu,"govc import.spec focal-server-cloudimg-amd64.ova > config.json
The resultant config.json file needs to be modified as per the environment where this OVA will be imported."
tanzu,"‚Äî
Note:
The first command listed below modifies the disk to a thin provisioned disk."
tanzu,This step is optional.
tanzu,The second command specifies the network the imported virtual machine is connected to.
tanzu,"This setting is essential, as this network should be connected to the Internet to pull down patches and binaries and help with some additional configurations."
tanzu,The last command in the section sets the password for the Ubuntu user of the virtual machine created in the future step.
tanzu,"This is important, as this allows one to log in initially to the VM using ubuntuand then change it to a secure password."
tanzu,"sed -i 's/flat/thin/g' config.json
sed -i 's/""Network"": """"/""Network"": ""DVPG-Management Network""/g' config.json
sed -i '/""Key"": ""password""/{N;s/     ""Value"": """"/     ""Value"": ""VMware1!"
tanzu,"""/g}' config1.json
Import the OVA and create a new virtual machine."
tanzu,Power on the virtual machine.
tanzu,The first command imports the OVA using the config.json modified in the previous step to create a new virtual machine.
tanzu,"The second command gets the name/path of the newly created virtual machine, to be used by govc in the last command to power on the virtual machine."
tanzu,"govc import.ova --options=config.json focal-server-cloudimg-amd64.ova
export VM=$(govc ls /Pacific-Datacenter/vm|grep ubuntu-focal)
govc vm.power -on ${VM}
This completes stage 1."
tanzu,Stage 2.
tanzu,"In this stage, we modify the OS of the guest virtual machine created in the previous step."
tanzu,This step requires console access to the virtual machine and setting up virtual machine networking.
tanzu,"Next, we update all the packages, install packages that we may require for our golden images, and set up some customization required for cloud-init to work within a vSphere environment."
tanzu,We then clean up logs and configuration files and shut down the machine to create a template.
tanzu,"Depending on the environment, you may have to manually type these commands on a vSphere console or SSH into the virtual machine and run these commands through a script."
tanzu,"Based on your environment, modify the netplan configuration file to set the IPv4/IPv6 networking stack."
tanzu,This may not be required in an environment that has DHCP enabled.
tanzu,"sudo vi /etc/netplan/50-cloud-init.yaml
sudo netplan apply
Update the virtual machine."
tanzu,"During this stage, open-vm-tools may get updated."
tanzu,This is an important step.
tanzu,"sudo apt update
#(update open-vm-tools)
sudo apt upgrade -y
IMPORTANT: Install the vSphere specific cloud-init configuration workaround."
tanzu,"This step provides a cloud-init data source for pulling meta, user, and vendor data from VMware vSphere‚Äôs GuestInfo interface."
tanzu,"curl -sSL https://raw.githubusercontent.com/vmware/cloud-init-vmware-guestinfo/master/install.sh > /tmp/install.sh
sudo chmod +x /tmp/install.sh
sudo /tmp/install.sh
Perform the cleanup of the cloud-init environment and log files, and shut down the virtual machine."
tanzu,"sudo cloud-init clean
sudo cloud-init clean -l 
sudo shutdown -h now
Modify the virtual hardware setting on the vCenter console."
tanzu,"While the govc cli can perform these settings, I have not automated them currently."
tanzu,This will be updated with scripts as soon as I have them automated.
tanzu,"Update the virtual hardware compatibility to vSphere 7.0
Make sure that the CDROM is configured for pass-thru client device."
tanzu,This is important as future image deployments may fail.
tanzu,"Within the vApp settings, make sure that ISO is unchecked for the OVF environment transport."
tanzu,"Remove all OVF properties like instance-id, hostname, seedfrom, user-data etc."
tanzu,Stage 3.
tanzu,"Now that we have configured our virtual machine, which is used as the starting point for future virtual machine deployments using cloud-init, we can now generate a template from this virtual machine."
tanzu,I will be using the content library to store the newly generated template.
tanzu,"In the first step, I create a local content library and use govc to upload the template to this content library."
tanzu,"If you already have a content library available, you can use the second command to upload the template to this content library directly."
tanzu,"export library=$(govc library.create local)
govc library.clone -ovf -vm ${VM} ${library} ubuntu-focal-image
This completes the necessary steps to prepare a Ubuntu Linux virtual machine template to use cloud-init for guest customizations."
tanzu,"Validation
We can now create a new virtual machine from the OVA template previously created and uploaded in the content library."
tanzu,"For cloud-init configuration to work correctly, we need to provide base64 encoded meta-data and user-data values to the virtual machine created from these templates."
tanzu,The sample configurations for the user data and meta-data have been provided in this example.
tanzu,"sample metadata.yaml
instance-id: ""vmsvc-cloudinit-0""
local-hostname: ""vmsvc-cloudinit-0""
network:
  version: 2
  ethernets:
    ens192:
      addresses: [192.168.4.58/24]
      gateway4: 192.168.4.1
      dhcp6: false
      nameservers:
        addresses:
          - 192.168.4.1
        search:
          - lab.local
      dhcp4: false
      optional: true
sample userdata.yaml
#cloud-config
write_files:
- path: /etc/sysctl.d/60-disable-ipv6.conf
  owner: root
  content: |
    net.ipv6.conf.all.disable_ipv6=1
    net.ipv6.conf.default.disable_ipv6=1
runcmd:
- netplan --debug apply
- sysctl -w net.ipv6.conf.all.disable_ipv6=1
- sysctl -w net.ipv6.conf.default.disable_ipv6=1
- apt-get -y update
- add-apt-repository universe
- apt-get install -y nginx
- apt-get -y clean
- apt-get -y autoremove --purge
timezone: UTC
system_info:
  default_user:
    name: ubuntu
    lock_passwd: false
    sudo: [""ALL=(ALL) NOPASSWD:ALL""]
disable_root: false
ssh_pwauth: yes
chpasswd:
  list: |
# mkpasswd -m sha-512 VMware1!"
tanzu,"ubuntu:$6$eExyHryb$yJ3T3mUSpNCGQmcnV6DGDSGEDmMmlzkldxTGb4oHIQiTpvve3OhaaQBWHxSL9b8.6EyONH.SYFtSpR5DLJK641
# mkpasswd -m sha-512 VMware1!"
tanzu,root:$6$EK42YS/aa$NpHnqwBhdCEu0pIGlkOBl6e5ZFYUHovTjXaqSGGcOs1eYeHfuY38PBdcKFql4xVoxrIAUePDbBnPajEasyy8r.
tanzu,"expire: false
package_upgrade: true
package_reboot_if_required: true
power_state:
  delay: now
  mode: reboot
  message: Rebooting the OS
  condition: if [ -e /var/run/reboot-required ]; then exit 0; else exit 1; fi
In this step, we deploy a new virtual machine testubuntu and then pass the base64 encoded values of the sample userdata.yaml and metadata.yaml files."
tanzu,"govc library.deploy /local/ubuntu-focal-image testubuntu
export NEW_VM=$(govc ls /Pacific-Datacenter/vm|grep testubuntu)
export METADATA=$(cat metadata.yaml|base64 -w0 ;echo)
export USERDATA=$(cat userdata.yaml|base64 -w0 ;echo)
govc vm.change -vm ""${NEW_VM}"" \
  -e guestinfo.metadata=""${METADATA}"" \
  -e guestinfo.metadata.encoding=""base64"" \
  -e guestinfo.userdata=""${USERDATA}"" \
  -e guestinfo.userdata.encoding=""base64""
govc vm.power -on ""${NEW_VM}""
In this example, once powered on, the new testubuntu virtual machine has a hostname of vmsvc-cloudinit-0."
tanzu,A default nginx website was available on port 80 of IP address 192.168.4.58.
tanzu,I was able to log in to the virtual machine using ubuntuuser with VMware1!
tanzu,password.
tanzu,VMware Tanzu Mission Control is a centralized management platform for consistently operating and securing your Kubernetes infrastructure and modern applications across multiple teams and clouds.
tanzu,"In this blog post, we will look into how Data protection can be enabled for Kubernetes clusters that are managed by VMware Tanzu Misson Control."
tanzu,"In the rest of this article, we will refer to VMware Tanzu Mission Control as TMC."
tanzu,TMC uses Velero as the backup/restore tool and currently(as of 20.11.2020) AWS is the only public cloud provider that is supported for uploading the backup data.
tanzu,Velero is used for both kubernetes resource backup as well as persistent volume backup.
tanzu,"For persistent volume backup, Velero is configured to use Restic and Velero is installed & configured without any user intervention when Data protection is enabled on a Kubernetes cluster."
tanzu,"NOTE: Contents (images/md) of this article can be found on https://github.com/mcelep/blog/tree/master/tmc-data-protection
Requirements
In order to follow the tutorial, you need:
A TMC account
A Kubernetes cluster attached to your TMC account
An AWS account where you are authorized to create a cloudformation stack, IAM roles, S3 bucket
AWS CLI
Bash shell
jq : a CLI tool to parse json data
Enable data protection on a K8S cluster
You can follow the steps below to enable data protection on a K8S cluster."
tanzu,"Create a data protection account on TMC
As mentioned earlier, Velero will require an S3 bucket so let‚Äôs have TMC provide us a cloudformation stack."
tanzu,Let‚Äôs create a data protection account first.
tanzu,Click on the Administration link from the menu.
tanzu,"This should take you to a screen that looks like the image below:
admin_account
Now click on CREATE ACCOUNT CREDENTIAL and this should bring up a drop down menu:
account_creation_drop_down
From this menu, select AWS data protection credential and it should take you to the following screen:
create_aws_dp_provider_credential
Give your credential a name, I‚Äôve picked mc-aws-data-protection in this example."
tanzu,"Before you can move to the next step, you will need to click on GENERATE TEMPLATE."
tanzu,This will initiate downloading of a cloudformation stack template file.Check your browser‚Äôs designated download folder to see the newly downloaded file.
tanzu,"Now you are in the second step of the wizard:
create_aws_dp_provider_credential_step2
In this step, we have to create a AWS CloudFormation stack based on the template we just downloaded."
tanzu,We can do this either by the AWS Console or via the AWS CLI.
tanzu,We will do it via the AWS CLI in this step.
tanzu,"Before we execute the AWS CLI command to execute stack creation, make sure you‚Äôre logged on to your AWS account and use credentials that are authorized to create Cloudformation stacks, IAM ManagedPolicies, S3 Buckets, IAM Roles."
tanzu,"When you run the command below, you should get some data back(an empty array or an array with stack elements):
aws cloudformation describe-stacks
If the command above works successfully, you are ready to execute the command below:
STACK_NAME=tmc-mc-data-protection aws cloudformation create-stack --template-body=""$(<mc-aws-data-protection.template)"" --stack-name ""$STACK_NAME"" --capabilities CAPABILITY_NAMED_IAM
The result of this command is a json that looks like this:
{
    ""StackId"": ""arn:aws:cloudformation:us-east-2:XYZ:stack/tmc-mc-data-protection/ABC""
}
Cloudformation stacks are generated asynchronously so getting an ID back does not mean that stack creation is successfully completed."
tanzu,"So run the following command to check the status of stack creation:
STACK_NAME=tmc-mc-data-protection aws cloudformation describe-stacks --stack-name=""$STACK_NAME""  | jq '.Stacks[0].StackStatus'
""CREATE_IN_PROGRESS""
If the status you get is CREATE_IN_PROGRESS, from the command above, wait some seconds and then try again, you should eventually get a CREATE_COMPLETE status back."
tanzu,"If you get a ROLLBACK_COMPLETE status instead, analyse what went wrong by looking at the events of the specific stack:
STACK_NAME=tmc-mc-data-protection aws cloudformation describe-stack-events --stack-name=""$STACK_NAME""
Assuming the CloudFormation stack is successfully created, now let‚Äôs find out the role ARN created as a part of the stack:
‚ùØ aws iam get-role --role-name=VMwareTMCProviderCredentialMgr | jq '.Role.Arn'
""arn:aws:iam::XYZ:role/VMwareTMCProviderCredentialMgr""
Now you can copy the ARN value into the field provided in the 3rd step and click on CREATE CREDENTIAL:
create_aws_dp_provider_credential_step3
Once the account is created, it will be listed under accounts with the name you provided:
dp-account
And now we can use this data protection account to enable data protection on a TMC managed/attached cluster."
tanzu,"Enable data protection on a K8S cluster
Click on the Clusters tab from the menu:
clusters
and then select the cluster you want to enable data protection on, in this example I pick a cluster called mc-tkgm-1:
cluster
On the bottom of this screen, there is a section called Data Protection."
tanzu,"Go ahead and click on ENABLE DATA PROTECTION and select the newly created data protection account:
A process will be kicked off in the background to install and configure Velero in the background and once Velero is enabled you should see the Data Protection section updated with the following info: ‚ÄúRun a backup to protect your cluster data‚Äù."
tanzu,You are now ready to schedule a one time or a periodic backup for a specific namespace or for the entire cluster!
tanzu,Have fun!
tanzu,NOTE: TMC Steps explained in this article can also be automated via the TMC CLI which can be downloaded from Automation Center section of TMC.
tanzu,Here are my 5 charts that best summarize VMworld 2020.
tanzu,"I would be easier to do this in 25 or 50 charts, but the appeal of this excercise is to make some choices."
tanzu,"Here are mine:
Chart 1 ‚Äî Dominating Kubernetes (part 1)
Based on a complete full text analysis of all 861 sessions listed in the official VMworld 2020 agenda, these are the trends that bubbled up."
tanzu,Bar chart showing the key topics at VMworld 2020: 1.
tanzu,"Kubernetes, 2."
tanzu,"Hybrid, 3."
tanzu,"AI, 4."
tanzu,"Edge, 5."
tanzu,"5G (data source: agenda)
Chart shows the topic importance of all 871 sessions at VMworld 2020."
tanzu,"Key Observations
Kubernetes: dominating (yes, I chose this term very deliberately) Kubernetes is the first prerogerative for VMware in 2020 and beyond."
tanzu,VMware used to be built on dominating the hypervisor.
tanzu,The modern hypervisor equivalent is Kubernetes.
tanzu,"Ergo, VMware needs to dominate the deployment and lifecycle management of Kubernetes."
tanzu,"Hybrid: ‚ÄúHybrid‚Äù refers to the consistent and unified foundation where VMware offers compute, network, storage, and operations management independently of whether the application runs on Tanzu Kubernetes Grid in the corporate data center or on EKS, GKE, or AKS in the cloud."
tanzu,"Artificial intelligence (AI) ‚Äî part 1: The launch of vRealize AI might not have been the largest topic of VMworld 2020, but it was a very important one."
tanzu,VMware is quietly putting the pieces together for realizing its vision of self-driving operations.
tanzu,"Artificial intelligence (AI) ‚Äî part 2: The NVIDIA partnership (project Monterey) and the SaltStack acquisition are important puzzle pieces for VMware‚Äôs overall AI-strategy: SaltStack can be used to take action, based on AI predictions and it can also become VMware‚Äôs key to unlocking the mass rollout of AI capabilities."
tanzu,"Chart 2 ‚Äî Complete overview of VMworld 2020
This automatically generated topic map shows how the VMware portfolio fits together."
tanzu,Topic chart based on all 871 sessions of the official VMworld 2020 agenda.
tanzu,"Key observations:
Carbon Black and NSX address application-aware security."
tanzu,Tanzu ties together vSphere and Kubernetes management.
tanzu,"vRealize, now including SaltStack brings automation, operations management, and visibility."
tanzu,Dell EMC provide a home for the VMware cloud within the data center.
tanzu,AWS is VMware‚Äôs closest hybrid cloud partner today.
tanzu,Hybrid cloud is the field VMware wants to dominate.
tanzu,"Chart 3 ‚Äî Dominating Kubernetes (part 2): Twitter Hashtag Popularity

Twitter chart based on all tweets (blue), retweets (orange), and likes (green)
Key Observations
Kubernetes ‚Äòwins Twitter‚Äô within a VMworld 2020 context in terms of number Tweets, Retweets, and Likes."
tanzu,Data protection is the number 2 topic in terms of Retweets.
tanzu,"VMware on AWS, Tanzu, and AI are the next trend topics following in terms of Twitter popularity within a VMworld context."
tanzu,"Chart 4 ‚Äî VMware‚Äôs Tweets that Received the Most Retweets

Bold labels = Twitter names, Standard labels: Hashtags, Box size = total number of retweets, Data Source: all 5,818 tweets during VMworld 2020 until October 1, 2020, 9:21am."
tanzu,"Key Observations
The vmwarecloudaws account overall received the highest number of retweets."
tanzu,vmwarensx was number 2.
tanzu,"HCP2590: This is the VMworld session code for: ‚ÄúVMware Cloud on AWS: Hybrid Cloud Operations for the vSphere Admin‚Äù
Pat Gelsinger‚Äôs two big topics were AI and 5G."
tanzu,"Tanzu, as expected, focused on DevOps, observability, and app modernization."
tanzu,Sanjay focused on security.
tanzu,Chart 5 ‚Äî SaltStack vs. Terraform vs.
tanzu,"Chef vs. Puppet vs. Ansible vs. Pulumi: GitHub Stars

Data source: GitHub stars for Ansible, Chef, Pulumi, Puppet, SaltStack, and Terraform from October 1, 2020."
tanzu,"Key Observations
SaltStack is on a faster growth trajectory than Chef and Puppet."
tanzu,"The project is the clear number 3 in automation, behind Ansible and Terraform, based on GitHub Stars."
tanzu,"About Tanzu Portfolio
VMWare assembled Tanzu Portfolio of products to help clients in their cloud native journey."
tanzu,"When I started reading about Tanzu, the very first confusion i had to understand Tanzu Kubernetes Grid deployment models and after reviewing multiple blog posts, I have been able to understand."
tanzu,"Shortly, I will be explaining but before that, lets understand the various Tanzu products."
tanzu,"Tanzu Products
First, Lets understand the Tanzu Kubernetes Grid (TKG) Concept and it‚Äôs architecture:
‚ÄúVMware Tanzu Kubernetes Grid provides Enterprise organizations with a consistent, upstream compatible, regional Kubernetes substrate across SDDC, Public Cloud, and Edge environments that is ready for end-user workloads and ecosystem integrations."
tanzu,"TKG builds on trusted upstream and community projects and delivers an engineered and supported Kubernetes platform for end users and partners.‚Äù
Architecture

TKG Architecture & Components
VMware offers TKG in two flavours 1."
tanzu,TKG 2.
tanzu,TKG plus.
tanzu,"While TKG and TKG plus are intended to achieve same purpose but the differences mainly is that TKG plus provide production ready Kubernetes cluster along with monitoring, logging, registry and security options."
tanzu,"To know the difference between TKG and TKG plus, read the below KB article from VMware:
https://kb.vmware.com/s/article/78173
TKG Evolution

TKGI, TKG & TKG plus Evolution
That‚Äôs all in this post, In the next post, I will discuss about remaining Tanzu products & their deployment model."
tanzu,"I have been introduced to VMware in early days of my career and there used to be wow factor with VMware (VMotion, HA and DRS and getting to know the Internals of VMware)."
tanzu,I took a loan from HDFC to complete my VCP certification in 2008.
tanzu,"Do you need to take a loan to get certified :) ( These days you can do it as low as 100‚Äì200$, training and examination cost is 2000$ in 2008)."
tanzu,So happy to attend the VMware conferences in Chennai and one time received below from Krishnan- the Apac Technical coordinator.
tanzu,"I have built VMware clusters on IBM x3850 and testing on my laptop at least 10‚Äì20 times( High end laptops at that time with 8 GB RAM and VMware Worksattion) to test and validate each & every scenario before, I deploy it in production."
tanzu,"The early success came to our internal IT, when we migrated HRMS system of 16,000 employees to VMware and it worked like a charm and tested HA with fun."
tanzu,"I have got the oppurtunity for the next 2008‚Äì2014 years on variours VMware products ‚Äî VMware Lab Manager, vCloud Director, ESXi, Vrealize suite and lately with Vrealize Automation and NSX ( Vsheild Manager)."
tanzu,"Slowly, The innovation of VMware slipped during 2015‚Äì2019 and I thought VMware have slowed down after NSX flagship."
tanzu,There are very few highlights with each VMworld‚Ää‚Äî‚ÄäOpenstack VMO and with version 1‚Ää‚Äî‚ÄäKubernetes and not impressed as before and started thinking that VMware will die.
tanzu,VMware realized and did M&A and got back on track.
tanzu,"Which helped VMware to come back with lot of new innovations which includes
VMware HCX ‚Äî Hybrid extension ‚Äî Cloud Mobility ( VM migrations across clouds)
VMware on AWS ( Now on Azure, Oracle, GCP and IBM clouds)
Tanzu Kubernetes Grid
Aquring Carbon Black
VMware dimensions ‚Äî edge solution
Now, VMware gained my love back and I am happy to create new solutions to solve Business problems."
tanzu,Solve Hybrid & Edge & cloud problems and you will be there forever.
tanzu,"on VSphere 7.0 using CNI Storage / Metal LB / Kustomize

PreReq :
TKG cluster on VS7
Large Datastore
TKG cli installed
Management plane created
Summary of steps :
Create a TKG cluster
Prep the Cluster for CSI Storage
Prep the Cluster for Metal LB
Install Kustomize
Download the Deployment / Svc / PVC yaml descriptors
Deploy via Kustomize
First : TKG Cluster create
We start by creating a cluster for our app."
tanzu,"You might alternatively choose to create a namespace on a given cluster, but I went ahead and created a Dev cluster for our Wordpress deployment which will host the app all by itself."
tanzu,"tkg create cluster some-cluster -plan=dev
Cluster creation as you see is simple command and TKG cli is the way to initiate it."
tanzu,You can also upgrade / scaleup / delete via the cli.
tanzu,NOTE: you will log into a cluster to do any more apply / changes.
tanzu,So make sure to do that.
tanzu,"Prep the Cluster for CSI Storage:
Create tags on Datastore by right clicking on the Tags and Custom attributes section and following the steps to add."
tanzu,Assign the tags with all-storage policy.
tanzu,We could be selective in future.
tanzu,2.
tanzu,"Create VM Policy

At the end validate if you are able to see the policy."
tanzu,"Our policy is showing as ‚Äúfork8s‚Äù
Create Storage Class : Assuming you have logged into the TKG Cluster with Kubectl lets create the Storage Class ."
tanzu,Observe the storagepolicyname.
tanzu,It should point to what we created via VCenter.
tanzu,"kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
 name: k8s-storagepolicy
 annotations:
 storageclass.kubernetes.io/is-default-class: ‚Äútrue‚Äù
provisioner: csi.vsphere.vmware.com
parameters:
 storagepolicyname: ‚Äúfork8s‚Äù
Validate if it got applied
ravij@tkg-gui:~/RAVIDIR/TKG/wordpress$ kubectl get sc
NAME                          PROVISIONER              RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
k8s-storagepolicy (default)   csi.vsphere.vmware.com   Delete          Immediate           false                  7d21h
Create Persistant Volume Claim : Create one for Mysql and another for Wordpress ."
tanzu,Here is the one for Mysql.
tanzu,Apply this similarly for Wordpress too.
tanzu,So you should end up with 2 PVC yamls one for Mysql and other for Wordpress php.
tanzu,"apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-storagepolicy-pvc
  labels:
    app: wordpress
spec:
  storageClassName: k8s-storagepolicy
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20G
Validate the PVC for Mysql / Wordpress."
tanzu,"These PVC will get used in our Deployment yaml
Prep the Cluster for Metal LB
Now that our TKG cluster is prepped with Storage using CSI plugin, lets get a LB installed which will expose our Wordpress app."
tanzu,"We use MetalLB and these steps
kubectl create ns metallb-system
kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.9.2/manifests/metallb.yaml -n metallb-system
kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=""$(openssl rand -base64 128)""
Let us configure the MetalLB with the pool of IP from our DHCP / Allocated segment ."
tanzu,Here we use the 192.168.178.230 as the starting IP and take next 20 ips.
tanzu,"# cat > metallb-configmap.yaml << EOF
apiVersion: v1
kind: ConfigMap
metadata:
namespace: metallb-system
name: config
data:
config: |
address-pools:
- name: default
protocol: layer2
addresses:
- 192.168.178.230-192.168.178.250
EOF 
Apply the yaml with
kubectl apply -f metallb-configmap.yaml
NOTE: In my case i had the ip scheme as 192.168.178.1 ."
tanzu,Modify this range per your network subnet.
tanzu,"Create a Wordpress directory
cd wordpress  { important } 
Install Kustomize
I pretty much curled the binary into this directory and added permissions to run it."
tanzu,"kubernetes-sigs/kustomize/master/hack/install_kustomize.sh‚Äù | bash
What is Kustomize ?"
tanzu,"kustomize lets you customize raw, template-free YAML files for multiple purposes, leaving the original YAML untouched and usable as is."
tanzu,Create Secret { copy this section and paste it on unix/linux/powershell command line as is.
tanzu,"It will create a file with contents }
cat <<EOF >./kustomization.yaml
secretGenerator:
- name: mysql-pass
  literals:
  - password=welcome
EOF
NOTE : Change the default password ."
tanzu,"Download Mysql and Wordpress app yaml
MYSQL: 
curl -LO https://k8s.io/examples/application/wordpress/mysql-deployment.yaml
WORDPRESS:
curl -LO https://k8s.io/examples/application/wordpress/wordpress-deployment.yaml
Edit the Kustomization to add both Yamls
cat <<EOF >>./kustomization.yaml
resources:
  - mysql-deployment.yaml
  - wordpress-deployment.yaml
EOF
Modify the YML to delete PVC sections."
tanzu,The downloaded YAML files have section for PVC.
tanzu,We created the required PVC in earlier steps .
tanzu,Delete out the PVC section from this YAML for both MYSQL and WORDPRESS yamls.
tanzu,"Deploy app the TKG cluster
NOTE: Cd out of the wordpress directory and apply the files in it."
tanzu,At this point you should have the secret kustomization file and the mysql and wordpress yaml files.
tanzu,Make sure to delete the PVC sections in theyaml and apply it.
tanzu,"kubectl apply -k ./
kubectl get po 
Get the LB IP address
kubectl get svc 
NAME      TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)
wordpress LoadBalancer  100.71.130.121  192.168.3.231 80:32024/TCP
The Ip 192.168.3.231 was allocated from the Metal LB pools."
tanzu,To get to the Wordpress app open this ip on a browser.
tanzu,It will open into a WordPress set up page where you enter config.
tanzu,"After a few next steps, it should allow you to create a Post."
tanzu,"For correctness, I should title this with ‚ÄúWhy Tanzu Observability by Wavefront?‚Äù =p
After almost a two-year hiatus (and as a result of me finally having some time to pause and reflect on the larger story of Wavefront), we return to the fundamental question of Why Wavefront?"
tanzu,"(shamelessly borrowed from our ex-colleague Matthew Zeier)
Why Wavefront?"
tanzu,"Our ex-Director of Operations, Matthew Zeier (whom we all refer to as mrz) explains the platform through a series of answers to the question ‚ÄúWhy Wavefront?‚Äù."
tanzu,"To engineers who have operated any software at scale, the concept of measuring something and observing it overtime shouldn‚Äôt be a new concept."
tanzu,The question one should ask is why could one build a company and a business around it.
tanzu,"If one is familiar with the plethora of ‚Äúmonitoring‚Äù solutions (the gamut spans from open source tools like graphite to commercial ones such as New Relic), another question that one could ask is whether there is any white space for building something and having customers pay ‚Äúadditional‚Äù money for it (let‚Äôs face it, most shops already have some sort of monitoring)."
tanzu,"When we started ideating about Wavefront, logs (free-form, unstructured text, mostly indexed) were the primary means of observing a production system (generated by logging frameworks or System.out.println())."
tanzu,There were some nascent efforts in the open-source world to build time-series databases (Graphite and OpenTSDB come to mind).
tanzu,"Still, they were very much limited to infrastructure metrics (CPU, memory, disk, and network usage)."
tanzu,The idea of using time-series to observe code is just starting to percolate in the developer world with things like Yammer metrics.
tanzu,"This trend was somewhat driven by the log-less culture in Google (where logs refer to structured, binary blobs, while stdout logs are discarded rapidly after collection)."
tanzu,"As engineers moved around companies, they started to influence their new companies on how to operate their respective software stacks."
tanzu,"It‚Äôs the dawn of a metrics ‚Äúdecade,‚Äù and we are mostly still in this industry-wide journey of recognizing what should be collected, named, visualized, alerted, and retained in the world of time-series data for operations."
tanzu,Wavefront was a journey that four of us undertook in 2013 without knowing full-well whether we could in-fact build something fundamentally better than the open-source offerings or whether there would be a market large enough to sustain a business.
tanzu,"We, however, knew that the multi-billion dollar IT monitoring market existed even back then, and hence it was primarily a question of ‚Äúcan we build it?‚Äù and not so much ‚Äúif we can build it, will they come?‚Äù (meaning if we could build something substantially better, we believe we can displace existing players at the very least)."
tanzu,Why Metrics?
tanzu,The word ‚Äúmetric‚Äù is heavily overloaded as you‚Äôll discover even in the Wavefront domain.
tanzu,Metrics in the general business sense are numerical (or quantitative) measurements that one could rely on to make decisions.
tanzu,They are different from qualitative (often subjective) opinions that somewhat rely on someone having the right ‚Äúhunch‚Äù or a unique ‚Äúeye‚Äù for things.
tanzu,"As the movie Moneyball suggests, we are no longer living in a world where data-driven decisions are either impossible due to the sheer scale of the data volume or because of the lack of collection mechanisms (having the relevant probes)."
tanzu,"We are also able to crunch data at planet-scale and derive insights that could drive decisions as to, for instance, whether a movie script would get the green-light to production or should be shelved."
tanzu,"Similar quantitative measurements also meant that in the computer software and service industry, operators of complex computer systems no longer have to guess at problems or look at second-order or third-order effects to judge whether a bug exists or pinpoint a performance issue."
tanzu,"Even with voluminous logging, one would be surprised at how bad humans are at computing rates of occurrences or even simple ratios between two sets of events by staring at log lines flying by."
tanzu,"Worse yet, certain attempts to pre-compute rates, ratios or aggregations (and then logged as text) meant that analyzing systems at scales is impossible at best and misleading at worst (the classic example of pre-computing local p95 and averaging or computing the max across a population of systems come to mind)."
tanzu,"In a nutshell, metrics are simply timestamped measurements that we can name."
tanzu,"They can be logged as textual content for sure, but, as anybody will discover, storing them in their ‚Äúnative‚Äù format (hence with restrictions on what a single ‚Äúpoint‚Äù ought to look like) can lend themselves to blistering fast retrieval, vastly reduced storage requirements, and post hoc analysis that shoving a bunch of textual content around could not do."
tanzu,"Metrics are not restricted, of course, to just the bare observations that a probe might collect."
tanzu,"In the examples above of local pre-computations, the derived data themselves are also timestamped (examples include the rate of occurrences of a particular event, for instance, as well as the p95 of sampled events that have numerical properties, say, the latency of a request)."
tanzu,"The trade-off here is that the ‚Äúcloser‚Äù to the source of a metric, the more likely it lends itself to meaningful analysis post hoc."
tanzu,An example of this is that while it is possible to measure CPU usage per second and send the information to a time-series database.
tanzu,"It is, at best, a second-order approximation to potential performance issues on the machine."
tanzu,"A much better way to isolate the problem is to measure, on a per-request level, the number of CPU seconds expended by all threads to service the request, the actual time spent in critical components, as well as the number of times these components were called."
tanzu,"Errors can also be similarly observed accurately by components themselves emitting error metrics (in the form of counters typically) instead of measuring HTTP error rates after the whole request chain has failed, and the error has percolated upstream."
tanzu,Why Metrics #1: Metrics allow surgical measurements of event occurrences in a system.
tanzu,"Such measurements are possible because of the proliferation of metrics libraries for different languages (e.g., Dropwizard Metrics, Spring Micrometer for Java, and go-metrics for Go, for instance)."
tanzu,"Such measurements are typically collected in three flavors: gauges, counters, and histograms."
tanzu,"Gauges
Perhaps the easiest to understand, a gauge is like the speedometer of your car."
tanzu,"We can, in fact, sample the speed of your car every second, or even every millisecond, and there would be a valid, timestamped value."
tanzu,"Hence, metric systems have to decide how often we need to collect and report the values with the idea that the more frequently that we do, the more insight we may be able to glean from the data (for instance, sub-minute microbursts of traffic will require per-second level metrics in order to detect)."
tanzu,"Examples of gauges include things like CPU utilization (sometimes in aggregate by usage type or further by cores), number of elements in a cache, or the number of active users in a system (as determined by unexpired sessions for instance)."
tanzu,One property of gauges is that their values can be integral or floating-point and that their values can go up or down.
tanzu,"Counters
Counters are perhaps a special form of gauges that never goes down."
tanzu,"Before we explore this particular metric type, it is helpful to understand that time-series analysis often involves computing rates."
tanzu,"For instance, the rate of requests against a system or the rate of errors of a particular method call against a component in Java."
tanzu,"Traditionally, systems have computed rates by intercepting occurrences of an event and emitting a rate (/s) over different time-windows (such as the rate of occurrence of an event per second over the last minute, the last 5 minutes or the last 15 minutes)."
tanzu,Such computations usually involve a timer of sorts on the process itself so that a rolling-window calculation can be done with the relevant bins discarded over time.
tanzu,"As systems matured and the need to compute rates of occurrences beyond fixed time windows, the concept of cumulative counters came into purview."
tanzu,"Instead of locally computing rates, occurrences of events are simply added together and the aggregate value emitted (for instance, the total-lifetime calls to a component, or the total life-time CPU-seconds spent in executing a portion of a request tree)."
tanzu,"An added benefit of storing monotonically increasing counters is the ability to detect ‚Äúresets‚Äù and infer that a process has died, and the data (for instance, when it takes part in an aggregation) is incorrect until another collection interval has elapsed after the reset is detected."
tanzu,It also provides an easy way to know the life-time occurrences of events in a single process (the integral of all the rates emitted if you will).
tanzu,"To compute rates, a time-series database will have to be combined with an analytics engine that can take pairwise values and divide that by time elapsed."
tanzu,"The simplest analogy could involve counters and timestamps as two columns on a spreadsheet in Microsoft Excel and rates as a new column with the formula to combine two cells, dividing against time to produce a rate."
tanzu,"Why Metrics #2: Metrics can be analyzed as a stream of numbers whereby local pre-computations can be eliminated in favor of post hoc analysis
At this point, I should mention that there is a special atom within Wavefront known as the Delta Counter (emitted with the metric name prefixed with the delta symbol: Œî)."
tanzu,"This was introduced for large scale aggregations of ‚Äúdeltas‚Äù, whereby the aforementioned cumulative counters might not make sense."
tanzu,"For instance, if we were to compute the rate of requests across all mobile phones on a platform with millions of users, while we can model them each as singular monotonically increasing series (with much of them being ephemeral as the app might become active only minutes every day), it would be better for each session to send timestamped ‚Äúdeltas‚Äù (e.g., +5 at 12:30:00PM; another +2 at 12:30:05PM for instance) and allow the time-series database to ‚Äúbin‚Äù them appropriately and produce global rates accurately and quickly."
tanzu,"Often times, this is used to reduce the ‚Äúindividuality‚Äù of a time-series."
tanzu,"However, it is indeed possible to send both and retain the ability to look at individual user session‚Äôs request patterns, for instance, over time while having the ability to access pre-computed delta counters to look at rates over large populations (for instance, for a particular version and platform)."
tanzu,"Why Metrics #3: Metrics can be pre-aggregated to produce lightning-fast aggregations at scale as long as the data type and operation are monoids
In the statement above, we introduce the concept of monoids, a fancy way of saying that the axiom of associativity (a ‚Ä¢ b) ‚Ä¢ c = a ‚Ä¢ (b ‚Ä¢ c) holds and the identity element e ‚Ä¢ a = a ‚Ä¢ e = a exists."
tanzu,"In practice for metrics, we find that the implementation of delta counters, histograms, and HLL (HyperLogLog) benefit from monoidic operations because large-scale aggregations are possible without having to deal with the ordering of data, without needing any state information along the way, and operations can be replicated across the wire without any concept of existing values."
tanzu,"Histograms
With the concept of monoids out of the way, we introduce the concept of histograms in the context of metrics."
tanzu,Histograms are ways to analyze distributions.
tanzu,They are oftentimes visualized with bins and counts (think the population of a state in the US broken down by age groups).
tanzu,"To compute a histogram, one would need a numerical property that exists for all members of a group (for the population, that would be their age; for a computer system, that could be the latency of a request, the size of a payload, the number of database calls needed to service a request, etc.)."
tanzu,Collecting this data turns out to be rather easy (oftentimes just ‚ÄúI saw something with a value of X‚Äù).
tanzu,"However, the reporting of such data isn‚Äôt as straightforward."
tanzu,"Revisiting the topic of local aggregations, metrics libraries will often produce statistical measurements of the distribution over-time."
tanzu,"The statistical summaries include mean, median, min, max, p25, p90, p95, p99, p99, etc., as well as rates in all its pre-computed flavors (after all we are observing events that happened to have a property we would like to compute a distribution of)."
tanzu,"One classic problem that is perhaps immediately obvious to the reader is that the distribution itself can change rapidly over time, and such summaries might vary wildly depending on how we draw the ‚Äúboundaries‚Äù of what we need to store in memory before we compute the results."
tanzu,"As such, it is common practice to use decaying samples (i.e., older samples contribute less to the statistical summaries) or simply outright discard the data and emit these statistical summaries at some predefined intervals (every minute for instance)."
tanzu,"Collection and reporting of these statistical summaries aside, local computations suffer from similar issues as counters (albeit more pronounced) since the only summaries that are easily combinable across distributions are probably the {sum, count}, which does, in fact, allow one to compute the global mean, total counts, total sum, and rates."
tanzu,"Any other statistical summaries, however, cannot be combined across processes without us first storing all observed measurements."
tanzu,"For example, to compute the p99 latency of a system that consists of 2 machines, one does need to collect the latencies of all requests, sort them by duration, and pick the p99 element."
tanzu,The maximum or average of the two local p99s are not at all the true p99.
tanzu,"Because of this limitation, Wavefront (as well as some competitors, although this is not yet a common feature of observability platforms), allows customers to ingest histograms in the form of centroids and counts."
tanzu,"Simply put, this is a data structure that can, in some cases, store every observation (say you have only 30 distinct values for latencies as measured in milliseconds; you can represent that distribution in perfect accuracy by sending us those 30 centroids and counts over the course of a minute, an hour or even a day)."
tanzu,"Those time bins are predefined by us, but because of the mergeability of the data-type, we can compute 5-minute histograms in real-time."
tanzu,"And, because we have the raw observations, we can also compute the true p99 in those 5 minutes."
tanzu,"This also means we can merge independently collected histograms across machines and produce the true p99 of a population of systems, all observing the same events passing through them."
tanzu,"However, as the astute reader would note, the number of centroids might be much larger than 30 (the default accuracy is 32 in the system today)."
tanzu,This is where TDigests comes in.
tanzu,"In his paper on TDigests, Dunning describes the need for a histogram compression algorithm that maintains tighter errors bounds towards the extreme percentiles of distributions (with e = q (1-q), hence the error can be up to 25% for the median)."
tanzu,"By prioritizing the extreme percentiles, the argument is that the ability to compute p99, p999 and even p9999 is more valuable than the median (a fact that‚Äôs largely true as analysis of running systems often involves looking at those extremes and trying to understand what‚Äôs going on, rather than understanding the behavior of the system between p50 and p60)."
tanzu,"As the histogram data-structure and the merging of them are monoidic, one can emit histograms from a large variety of sources and any metrics platform, like Wavefront, can aggregate them upon ingestion (this is hidden from the user), producing combined distributions that, while continuing to sacrifice accuracies in the middle of the distribution, capturing accurate percentile measurements."
tanzu,"Why Metrics #4: Metrics can capture high-fidelity distribution statistics that are time-series in nature but allows for accurate post hoc population analysis and statistical summaries
The statement above is important because where-as metrics are by definition ‚Äúdetached‚Äù from individual events (they are summaries of occurrences), their strength is that we can very quickly look at trends and understand the distribution that contributes to those trends, alert upon them, visualize them, and because of that, allows the operator of complex systems a way to look at what‚Äôs going on underneath the hood without having to peer into every event itself."
tanzu,"It gives you the forest so you can spot the trees, so to speak."
tanzu,"Why Metrics #5: Metrics are summarizations of events that allow an operator to quickly isolate a problem or make informed inferences about what‚Äôs going on
An example of the above is the ‚Äúthere exists‚Äù question."
tanzu,It is often important to know whether something definitively happened in the system or it didn‚Äôt.
tanzu,Many bugs and code push happen because developers think that the code is not being executed and/or that an error condition has occurred somewhere.
tanzu,Traditional logging or even distributed tracing would require full retention of all requests before one can definitively prove that.
tanzu,"With metrics, it is relatively easy, as long as the code in question emits a single metric, to prove that a code path has never been executed or that there was not a change in the way that it is called, compared to the rest of the population, say, before and after a code push."
tanzu,"Distributed Tracing
Having just perhaps pointed out the inadequacies of having distributed tracing, there are perhaps obvious reasons why one would need distributed tracing: the need to look into individual requests (including every downstream call) and isolate what‚Äôs going on between components in a complex system."
tanzu,"It is an offering that was added to the platform shortly after histograms were introduced (hence the 3rd atom of the platform, so to speak), and it represents yet another angle to observing a running system."
tanzu,"Distributed tracing has been around for more than a decade when we decided to embrace it (fun story, we originally thought we could build Google‚Äôs Dapper as a SaaS service only to realize that without frameworks that came later, such as OpenTelemetry, we could only not infer causal relationships and can only compute probabilities across spans, something that we thought wasn‚Äôt useful enough to warrant building a platform for in 2013)."
tanzu,"There were libraries and tooling such as Zipkin and Jaeger that allowed users to annotation their code to emit spans, store them for future analysis, and visualize them in ways that allow one to look at flame graphs."
tanzu,"The reason for us entering into the foray was two-fold: a) we did not want to fight the logging battle yet (something that we eventually did in 2020) and b) having built a planet-scale ingestion engine, a query language for metrics, enterprise features around policies, security, HA, DR, and backup, etc., we thought we would have a shot at claiming territory by taking the core engine and allowing the ingestion of spans (which, if one were to look at them as metrics, are similar to values being durations and timestamps being the starting time of operations)."
tanzu,"Another strength of the platform for us venturing into distributed tracing is the fact that we also happen to have first-class support for metrics, counters (introduced in late 2019), and histograms."
tanzu,"Anecdotal evidence suggests that while teams think they need tracing, the utilization of these platforms is abysmally low."
tanzu,One possible issue is that alerting on traces largely involves derived metrics (if one only has traces) and a platform with only traces is unlikely to see other data points to determine whether there is a real issue (you‚Äôd also need to build all the analytical features of Wavefront in order to support various use cases).
tanzu,"This meant that derived metrics are just duplicated in a customer‚Äôs metric system (visualized, alerted, and analyzed no doubt), while traces are consulted only when necessary."
tanzu,"For Wavefront, as we have long-term retention of data (contractually at 18 months), and our charging model gives away span for free while charging only on the derived metrics (controllable by the user as to the dimensions that we collect): the alerting problem is solved (one would alert on the metrics), the analytics problem is solved (we can convert spans back to metrics and one can slice-and-dice the data to your heart‚Äôs content; the derived metrics are also stored for 18 months, so you have a ‚Äúgentler‚Äù cliff when the data is purged), the ROI problem is solved (spans are free, and one would need to pay for the metrics anyways if running anything of substance), and the usage problem is solved (we can link the data from the metrics you‚Äôre looking at to traces that might be of interest, increasing the chances that during an outage, an engineer might be prompted to ‚Äújump‚Äù to the relevant traces that shows the root-cause)."
tanzu,"Intermission
As I begin my fourth year at VMware, having recently moved back to Hong Kong temporarily, I hope to be writing more, mentoring more, and yes, building more."
tanzu,"2020 is a seminal year for many, I consider myself very blessed that I still get to do the things I love, with people I love."
tanzu,"Back in VMWorld 2019, VMware made an exciting announcement ‚Äî Project Pacific ‚Äî to bring the best of the proven enterprise virtualization platform vSphere and the defacto Container Orchestration engine Kubernetes into an integrated Modern Application Platform."
tanzu,"The new platform, vSphere7 or commonly refers as vSphere with Kubernetes, is generally available since April 2020."
tanzu,"To keep up the real sense of Kubernetes is a ‚ÄúPlatform Platform,‚Äù vSphere 7 with Kubernetes gives a Platform for its users to run multi form-factor modern workloads, say‚Ä¶Kubernetes Clusters (Tanzu Kubernetes Cluster Service), Container Workloads as Native vSphere Pods, and VMs."
tanzu,The Kubernetes APIs gives additional flexibility for the vSphere Admins to define Name Space as a Unit of Management and provision it to the platform users to consume the resources via the Kubernetes declarative model.
tanzu,"Since the new Construct called vSphere Pod, which gives the flexibility to run Kubernetes Native Workload (Container Pods) directly on Esxi, is a new kid in the block, it may be a good idea to explore its unique use cases."
tanzu,"In this Multi-Part Series, I am trying to declutter the Compute resource characteristics of vSphere Pods in vSphere with Kubernetes platform."
tanzu,Understanding the Compute resource patterns in vSphere Pods is one of the essential criteria to choose the right workloads to deploy as vSphere Pods.
tanzu,"To analyze the characteristics of the Native vSphere Pod object of the vSphere with Kubernetes platform, I am impersonating a DevOps engineer than a vSphere Admin."
tanzu,"As a DevOps persona, I walk through the resource model of the vSphere Pods to do some fact checks and recommend it as the best platform for specific containerized workloads."
tanzu,What is a vSphere Pod?
tanzu,"The all-new Object in vSphere with Kubernetes, which enables the users to run Containers natively on ESXi hosts, is called vSphere Native Pod, a.k.a vSphere Pod."
tanzu,"In a nutshell, vSphere Pod is a virtual machine that is highly optimized to boot a Linux kernel ‚Äî Container Runtime Executive (CRX) to run containers."
tanzu,The CRX agent includes only just enough para-virtualized devices like vSCSI and VMXNET3.
tanzu,"During the Pod initialization, the super-thin `kernel` (CRX) does a fast and secure boot process."
tanzu,After the CRX initialization.
tanzu,"the containers, part of the Pod, will run in quick succession
Fig:1 vSphere Pod
vSphere Pod Architecture
vSphere Pod Architecture
Considering the objective of the article, doing a quick cut to dissect the compute resource characteristic of the vSphere Pod."
tanzu,You may follow the referral URLs for a deep dive into vSphere Pod internals.
tanzu,What is the default resource allocation of a vSphere Pod?
tanzu,Let‚Äôs take the Kubernetes native way to check the compute resources `visible` from the Containers is using the Kubernetes downwardAPIs.
tanzu,I created a tiny (also a bit crude!!!)
tanzu,"`PHP web app,` which could display its compute resource Request and Limits from the downward API."
tanzu,Requests are what the Container is guaranteed while scheduling it to a node.
tanzu,Limit limits the Container from goes above a configurable value of the resources.
tanzu,"Since the Test Pod is a single Container Pod, the resource values are quite easy to correlate as the Pod resource."
tanzu,"CPU and Memory resource `request` and `limit` parameters of the Container can get via the following downward API `resourceField Ref.‚Äô
."
tanzu,"requests.cpu
."
tanzu,"requests.memory
."
tanzu,"limits.cpu
."
tanzu,"limits.memory
The data from the downwardAPIs can consume as an environment variable or as downward API volume inside the Pod."
tanzu,"Scenario 1:
In the first scenario, the test app deploys as a vSphere Pod and has no custom resource request or limit configured."
tanzu,It means the Container can use the default resources allocated to the vSphere Pod.
tanzu,"Since each of the vSphere Pod has its own `kernel,` to schedule the resources between its processes, the Pod‚Äôs resource limit is the limit of the resources the Containers of the Pod can consume."
tanzu,"The following command will deploy the test application in a namespace, `vsphere-pod-resource-test`: ( What a meaningful name!!!)"
tanzu,"kubectl create -f https://raw.githubusercontent.com/emailtovinod/vsphere-pod-resource/master/resource-test-app-deploy.yaml -n vsphere-pod-resource-test
To access the Application externally using the browser, use the following command to create a service of type `loadbalancer`:
kubectl create -f https://raw.githubusercontent.com/emailtovinod/vsphere-pod-resource/master/resource-test-app-svc.yaml -n vsphere-pod-resource-test
Find the IP of the loadbalancer service :
kubectl get svc -n vsphere-pod-resource-test
The test Application has the necessary instrumentation to display the resources allocated to the Pod via the URL:
http://<loadbalancer ip>/resource.php
Fig:2 vSphere Pod Resources
vSphere Pod Default Resource
vSphere Pod Default Compute Resources
As you can see here, since there is no `resource request,` the value of CPU and Memory values are showing as Zero."
tanzu,"vSphere Pod default value of CPU is `1000 millicores` ( 1 Core) or in plain, 1CPU Core, and the memory limit is 512 MB."
tanzu,"If there is no custom/default resource specification for the Containers, it is the limit of the resources the containerized processes run as the vSphere Pod could consume."
tanzu,"Scenario 2:
Let us do a second scenario to check the default resource allocation of a Pod deployed in a Kubernetes Conformant cluster."
tanzu,Create an application deployment using the same manifest in a Tanzu Kubernetes Cluster (TKC) service or any other conformant Kubernetes Cluster.
tanzu,It provides us a clear distinction between the resource patterns of vSphere Pods and Pods running on a conformant cluster.
tanzu,Follow the steps to deploy a test Application Pod in a Kubernetes Conformant cluster.
tanzu,"Create a Namespace to deploy the Application:
kubectl create namespace pod-resource-test
The following command deploys the test Application:
kubectl create -f https://raw.githubusercontent.com/emailtovinod/vsphere-pod-resource/master/resource-test-app-svc.yaml
Access the test application WebUI via the loadbalancer IP:
http://<loadbalancer ip>/resource.php
The following diagram shows the default resource of the Pod showing via the downward APIs of Tanzu Kubernetes Cluster."
tanzu,"Fig:3 Default Pod Resources
Default Container Resources of the Test App
Default Container Resources of the Test App
As discussed earlier, there is no resource request for the Container, hence the value `0` for both CPU and Memory request."
tanzu,But the CPU and Memory limit of the Pod in the conformant cluster is showing significantly higher value.
tanzu,"If you carefully observe the limit values of CPU and Memory, you could find that these values are nothing but the total resources available in the Node on which the Pod is running."
tanzu,What does that mean?
tanzu,Can the Pod use all the Node resources?
tanzu,"The Obvious answer is `It depends.`
To further declutter the `depends` clause, we need to go a little bit deeper."
tanzu,"The Resource Quality of Service (QoS)
Kubernetes‚Äô resource allocation model classifies the resource Quality of Service (QoS) of the Pods deployed without any resources specification as `Best Effort.` `Best Effort` is the lowest priority resource QoS."
tanzu,"[Ref.https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/]
The other two levels of resource QoS are `Burstable` and `Best Effort.`
The second most resource allocation priority goes to Burstable QoS, where the Containers have requests and optional limits (not equal to 0) specification."
tanzu,The highest resource priority ‚Äî Guaranteed QoS` assigns to Container Pods deployed with limit and optional requests (not equal to 0) values.
tanzu,"At a high level, the Completely Fair Scheduler (CFS ) C-Group bandwidth controller of the Linux kernel enforces the CPU `limit ` of the Containers."
tanzu,"If the Node doesn‚Äôt have enough CPU resources to share with the Pods scheduled in it, Pods with `best effort QoS Class` are the ones suffer first from CPU throttling or even Pod eviction from the Node."
tanzu,"If there is not enough memory to allocate to all the Pods scheduled in a node, the Applications running as `Best Effort Class` Pods get terminated by OOM (Out of Memory) killer."
tanzu,"Linux CGroup and Application Behaviour
Linux Application containers rely on the Linux Kernel CGroup subsystem to manage the compute resources."
tanzu,"The CGroup provides a unified interface for the Containers to limit, audit, and control the resources."
tanzu,It means the CGroup subsystem in Linux configures the resource allocation of the processes as per the Pod template specifications.
tanzu,"Applications and CGroup Awareness
In the third scenario, update the vSphere Pod deployment with a custom resource parameter."
tanzu,"Scenario 3:
The following command will set a custom resource limit of 1 CPU and 1 GiB of Memory for the vSphere Pod:
Note: If you are specifying only limit and no request values for the Containers, the limit assigns as request value too."
tanzu,"kubectl set resources deployment rm-demo-app limits=cpu=1,memory=1Gi -n vsphere-pod-resource-test
You may verify the values from the WebUI of the Application, which is displaying using the downwardAPIs."
tanzu,Fig:4 vSphere Pod Resources with the Limit spec.
tanzu,vSphere Pod with Custom Resource Limit Spec.
tanzu,"vSphere Pod with the Custom Resource Limit Spec
Here we use Native Linux Tools to check the Compute Resources of the Pod to explore some interesting facts."
tanzu,"As you see in the earlier steps, hence the test Application Pod has only one Container, its resource Specification is equal to that of the Pod."
tanzu,"Use `nproc` and `free` commands to check the memory and CPU resources of the Container of the vSphere Pod:
You may see the following Output, showing the CPU and Memory resources of the vSphere Pod."
tanzu,"Fig 5: nproc command output from the vSphere Pod
nproc Output from the vSphere Pod Container
`nproc` Output from the vSphere Pod Container
Fig 6: free command output from the vSphere Pod
free Output from the vSphere Pod Container
free Output from the vSphere Pod Container
You may note that the output of the Linux Native tools and the Application displayed via Kubernetes downwardAPI are the same as the values, we set as the Container Resource Limits."
tanzu,"Since the test application Pod has only one Container, it is equal to the resource availability of the Containerized process."
tanzu,As the last scenario in the series go ahead and set the resource limit for Pod deployed in the conformant Kubernetes Cluster.
tanzu,"Scenario 4:
To check the resource behavior of the Pods running in the Conformant cluster, set a resource limit of 1 CPU and 1 GiB of Memory using the following command:
kubectl set resources deployment rm-demo-app limits=cpu=1,memory=1Gi -n pod-resource-test
The command will update the Pod template and a new Pod will create."
tanzu,"After a few seconds, the new resource values will appear in the test Application WebUI."
tanzu,Fig 7: Pod Resources with the Limit spec.
tanzu,"Pod with the Custom Resource Limit Spec
Pod with the Custom Resource Limit Spec
As did with vSphere Pod, use native Linux tools `nproc` and `free` to check the CPU and Memory showing inside the Container
Fig 8: nproc command output from the Pod
nproc command output from the Pod
`nproc` command output from the Pod running in the Tanzu Kubernetes Cluster
Fig 9: free command output from the vSphere Pod
free command output from the Pod
`free` command output from the Pod running in the Tanzu Kubernetes Cluster
Although we set the same resource parameters for the Container of the vSphere Pod and the Container of the Pod running in the Conformant cluster, nproc and free Commands showing 2CPU and 3947 MiB of Memory, respectively for the later."
tanzu,Why are the Native Linux tools showing a vast difference between its output from vSphere Pod and the Pod in the Tanzu Kubernetes Cluster?
tanzu,Here comes the `CGroup Awareness` factor of the tools and applications running within a Linux Application Container.
tanzu,"As you already know, Containers resource parameters configured via the Cgroup subsystem."
tanzu,"Both `free ` and `nproc` using `Procfs` to find the information, not the Cgroup subsystem."
tanzu,"For those who new to Linux, Procfs or ‚Äú/proc‚Äù is a particular filesystem under Linux that presents process information and kernel parameters."
tanzu,"Fig 10: K8S Node Resource Share Model
K8S Node Resource Share Model
K8S Node Resource Share Model in a Conformant Cluster
In simple term, the tools which are not Cgroup_Aware( Since those tools came into existence much before Cgroup) give a skip to the Cgroup settings and show the total compute resources of the Node on which it currently scheduled."
tanzu,Is that the ` legacy tools` problem alone?
tanzu,Not really.
tanzu,Consider a typical example of Java Virtual Machines (JVM)- Version 8 and below.
tanzu,"While the JVM is running as Container or otherwise, JVM ergonomics sets the default values for the garbage collector, heap size, and runtime compiler."
tanzu,"These values are consuming from Linux `sysfs` of the Node, not from the CGroup subsystem of Linux."
tanzu,Sysfs is a bit modern and structured than procfs in which ‚Äúsysfs‚Äù mounted on /sys as a way of exporting information from the kernel to various applications.
tanzu,"As a workaround, you can provide custom JVM settings as per the Container resource using Kubernetes API objects like Config Map and downWard APIs."
tanzu,( Demonstration of it is not in the scope of this article).
tanzu,"But the fact of the matter is, these additional requirements adds overhead in the deployment process."
tanzu,"To avoid complexity, most of the production environments do not bother to adopt that pattern."
tanzu,"But the caveat here is, even though JVM configures its default values as per the resource information fetch from sysfs, the Linux Kernel resource scheduler will enforce the compute resource parameters allocated to the Container using CGroup subsystem."
tanzu,It commonly leads to frequent `OOM` errors in the application execution environment.
tanzu,"Even worse, the cluster Operators end up in Over allocation of resources to the Container to mitigate the OOM errors."
tanzu,How vSphere Pod helps here?
tanzu,"As we observed, since there is a dedicated Linux Kernel to manage, each of the vSphere Pods‚Äô resource scheduling, the compute resource values reported via Linux sysfs and Procfs are the same as that of the total Compute resources configure using Linux CGroup."
tanzu,"( In case of multi-container pods, the sum of the resources specification of all its Containers provides the Pod‚Äôs resource)."
tanzu,It is a huge advantage for the SREs /DevOps engineers planning to run the non- CGroup aware application as Containers and manages them using Kubernetes APIs.
tanzu,"Whenever a Critical workload has precious resource requirements, vSphere Pod is an ideal destination without the concerns of the CGroup based resource control model."
tanzu,It is apart from the other unique resource allocation characteristics of vSphere Pods like NUMA node placement etc.
tanzu,Probably a subject for another article.
tanzu,"Conclusion
The article‚Äôs objective is to demonstrate one of the resource patterns of the vSphere Pod and how it makes it an idle solution for some of the Workloads."
tanzu,"Now, you may ask, Well, Is it an `Anti-Pattern` of sort for some other workloads?"
tanzu,"You guessed it, right !!!"
tanzu,"If you look at the default minimum resource allocation of the vSphere Pod, it is 1 CPU and 512 MB of Memory."
tanzu,( Not considering the storage aspect here).
tanzu,"At least in the current version of the platform, though you can configure the default CPU and Memory values for the container, the vSphere Pod level resources cannot set less than the default ones."
tanzu,vSphere Pods only supports increasing the values higher than the default one using the resource request and limits.
tanzu,You may notice that the defaults compute resources of the vSphere Pods turn out to be over-provisioning for most of the Cloud Native stateless workloads and could easily overshoot the `resource budget` of the cluster.
tanzu,Here comes the flexibility of `vSphere with Kubernetes` platform.
tanzu,"To run more optimized Cloud Native workloads and the Developer Environments, you can deploy Tanzu Kubernetes Cluster (TKC) Services ‚Äî a conformant Kubernetes cluster ‚Äî in a Supervisor cluster Namespace and use it side by side with the vSphere Pods."
tanzu,I would like to show you quickly probably the best Kubernetes for SMBs or anyone currently using VMware platform.
tanzu,"Every large cloud usually uses a hypervisor, not a bare hardware (Azure uses HyperV and on top of it there are all services)."
tanzu,If you‚Äôve got VMware ESXi and vCenter you can easily add new hardware and increase computing capacity.
tanzu,You don‚Äôt need to worry about physical migration.
tanzu,Thanks to vMotion you can migrate even running VMs between hardware boxes in the same data center.
tanzu,This is very big advantage.
tanzu,Enterprises usually were installing Red Hat OpenShift on top virtualized RHEL.
tanzu,Now there is another option: you can have Kubernetes exposed directly by the VMware platform and integrated seamlessly with you network (NSX-T).
tanzu,"You‚Äôve got one consistent ecosystem, controlled from one place."
tanzu,"Now, lots of pictures."
tanzu,Network and storage provisioned in Kubernetes is delivered by VMware platform.
tanzu,In your cluster you see k8s nodes and pods.
tanzu,When you create a cluster you decide about the sizing.
tanzu,"Basic k8s cluster would be for 2000 pods, with 4 vCPUs, 16 GB vRAM."
tanzu,You configure network and storage in simple steps.
tanzu,Kubernetes artifacts are visible in well know UI.
tanzu,Linux-based VMware Photon OS powers k8s nodes.
tanzu,See: https://vmware.github.io/photon/.
tanzu,Photon OS is derived from Red Hat OS and uses rpms.
tanzu,Hello pods.
tanzu,Instead of kubelet you‚Äôve got spherelet running directly on ESXi.
tanzu,"You can see pods, deployments, daemon sets, etc."
tanzu,‚Äî everything visible in kubectl get all.
tanzu,And you can see yaml files.
tanzu,But you can‚Äôt edit as in OpenShift.
tanzu,To manage k8s from command line you need dedicated Linux VM.
tanzu,Ubuntu would work fine.
tanzu,LoadBalancer is handled by VMware platform.
tanzu,"Cool, right?"
tanzu,"Kubernetes is not the bleeding edge version (as of writing the newest is 1.18), but 2 minor releases behind."
tanzu,"It‚Äôs quite OK.

Network for k8s is handled by NSX-T. It‚Äôs really cool."
tanzu,You can see pods in NSX-T network topology.
tanzu,List of NAT entries.
tanzu,Your pods can be guarded by the default firewall.
tanzu,IDS for pods?
tanzu,Why not.
tanzu,Docker image registry.
tanzu,Here it is.
tanzu,With logs for governance.
tanzu,Quay or Harbor?
tanzu,I would prefer one with better vulnerability scanning inside images.
tanzu,To sum up ‚Äî a really nice offering thanks to the holistic approach (as it can be seen on pictures).
tanzu,"Introduction
vSphere 7 with Tanzu is transforming the way people are approaching modernizing their on-prem application delivery."
tanzu,"With the native integration of Kubernetes within the platform, the doors have opened to deliver the new application stack within the vSphere environment."
tanzu,Gone are those days when you could only deploy VMs within the vSphere platform.
tanzu,"With the integration of Tanzu, you can now natively deploy new objects like pods, load balancers, Kubernetes clusters alongside VMs."
tanzu,"With the release of the much-awaited VM Operator feature (version 7.0u2a), the DevOps persona can even leverage standard Kubernetes processes and CLIs to deploy VMs along with pods."
tanzu,"In this article, with an easy-to-follow example, I will discuss how the DevOps persona can leverage their Kubernetes tool of choice to deploy an application stack consisting of Kubernetes clusters, VMs, pods, registries, and load balancers."
tanzu,"New Workload Concept
As mentioned previously, a few years back, the developers requested VMs to be provisioned for application deployments."
tanzu,"The vSphere Admins deployed the VMs and then handed over controls to the developers, who deployed applications on these VMs."
tanzu,"The entire process took days to weeks, and every layer of the infrastructure was treated as pets."
tanzu,This led to automation in VM deployments.
tanzu,"With the introduction of Kubernetes, the Operations team was responsible for setting up and managing the Kubernetes clusters."
tanzu,"The DevOps persona (in some cases, the same group of individuals) would then deploy the containerized applications on these Kubernetes clusters."
tanzu,"In most cases, the applications, through containerization, had become cattle, but unfortunately, the underlying infrastructure was still being treated as pets."
tanzu,This brought its own sets of challenges.
tanzu,"As processes matured, the operations team also started looking at options to treat the Kubernetes infrastructure as cattle."
tanzu,Cluster API was one of those trailblazing projects that helped alleviate some of the heaving liftings of the day-to-day Kubernetes cluster lifecycle management.
tanzu,Now the DevOps persona could create and manage their Kubernetes infrastructure in the same declarative way they managed their application deployments.
tanzu,"As we started the next phase of the app modernization journey, we discovered that the next set of applications was quite sticky or complex."
tanzu,"They have numerous points of interaction, with monolithic stateful VM interactions leading to extreme difficulty in containerization."
tanzu,A sample application with hooks into multiple infrastructure components.
tanzu,How do we modernize such an application?
tanzu,How do we treat this entire setup as cattle and have a declarative YAML to deploy and maintain the desired state of the said application?
tanzu,"vSphere with Tanzu to the rescue
Existing and new customers of vSphere can benefit immensely from the new features that have now been natively integrated into vCenter."
tanzu,"There are numerous articles on the web summarizing and detailing how the native integration of Kubernetes, Cluster API, Harbor, and other CNCF technologies within vSphere is delivering value to the customer."
tanzu,"With a simple click of a button (well, maybe a short wizard), the vSphere admin can now convert the existing vSphere clusters to a Supervisor Cluster that understands the Kubernetes language."
tanzu,This Supervisor Cluster can directly deliver numerous cloud-native services for consumption by the DevOps persona.
tanzu,"Some of these services are ‚Äî
Container Registry using Harbor
Kubernetes Cluster LCM using Cluster API
Load Balancer Services
Authentication Services
Ability to run containers natively of ESXi
Namespace and resource management
Virtual Machine LCM using VMOperator
And many more to come."
tanzu,Let's now look at how a DevOps persona can leverage these services and features to deploy a complicated application using simple declarative configuration files.
tanzu,"Scenario
We will use an elementary example that could quickly become complicated if multiple restrictions are enforced on its deployment criteria."
tanzu,Let us use the standard Kubernetes WordPress deployment for our sample application.
tanzu,"In this example, a MySQL pod is deployed(from its image in Dockerhub) using a persistent volume and exposed thru a service."
tanzu,A WordPress pod (using its image from Dockerhub) is deployed that accesses the MySQL DB service.
tanzu,"The WordPress app is exposed thru a LoadBalancer service on port 80, which the user can access."
tanzu,Let us assume some common restrictions are imposed on the DevOps team.
tanzu,The vSphere team does not want the DevOps team to exceed the resource quota in a shared infrastructure environment.
tanzu,The DevOps team needs to manage the LCM of the Kubernetes environment securely.
tanzu,The users are not allowed to download images from Dockerhub due to security restrictions.
tanzu,The MySQL DB is quite large and/or needs substantial computing resources.
tanzu,Containerizing the MySQL DB may not be an option due to these or some other security restrictions.
tanzu,These are some conventional restrictions and requirements that you would encounter in any IT organization and quickly complicate the application‚Äôs architectural patterns.
tanzu,"Now, the DevOps team is responsible for deploying their Kubernetes cluster."
tanzu,They need to provide an internal container registry.
tanzu,Their database needs to stay on a VM whose lifecycle needs to be managed securely.
tanzu,All these components need to reside within their boundaries without exceeding the allocated quota securely.
tanzu,Can all this be managed with simple YAML files that the team can operate in a GitOps way?
tanzu,The answer is yes.
tanzu,"Solution
Platform setup
The journey starts with the vSphere admin enabling the Workload Management on a vSphere 7 U2a or greater environment."
tanzu,This enables all the features that we earlier discussed on the Cluster.
tanzu,The vSphere admin also creates the required content libraries to make the VM images available for consumption by the DevOps users within their namespaces.
tanzu,"Their content creators have provided these images through subscribed content libraries ‚Äî e.g., Vmware provides images for Tanzu Kubernetes Cluster images and VM images."
tanzu,"Next, the vSphere admin enables the Harbor registry service on the Supervisor Cluster."
tanzu,This feature is available if you are using NSX as the networking stack.
tanzu,"(For non-NSX based networking stack, a similar solution can be enabled using VM operators)."
tanzu,"As you can see from the image below, this process installs several pods on the ESXi servers and configures a Harbor endpoint accessible to the end-users for consumption."
tanzu,The vSphere admin can also view these objects using the kubectl CLI as these are nothing but Kubernetes objects residing on the Supervisor Cluster.
tanzu,"$ kubectl vsphere login --server wcp.navlab.io --vsphere-username administrator@vsphere.local --insecure-skip-tls-verify
$ kubectl get svc -n vmware-system-registry-756328614                              
NAME                                 TYPE           CLUSTER-IP    EXTERNAL-IP      PORT(S)             AGE
harbor-756328614                     LoadBalancer   10.96.0.109   192.168.10.163   443:31012/TCP       11m
harbor-756328614-harbor-core         ClusterIP      10.96.0.202   <none>           80/TCP              10m
...
$ kubectl get pods -n vmware-system-registry-756328614 -o wide                     
NAME                                                 READY   STATUS    RESTARTS   AGE   IP            NODE               NOMINATED NODE   READINESS GATES
harbor-756328614-harbor-core-74dc84785-jhw54         1/1     Running   0          16m   10.244.0.24   watson.navlab.io   <none>           <none>
harbor-756328614-harbor-database-0                   1/1     Running   0          16m   10.244.0.18   watson.navlab.io   <none>           <none>
Finally, the vSphere admin enables the self-service namespace on the Supervisor cluster."
tanzu,"With this option, the administrator can templatize the resources and access of future namespaces that each DevOps user can create and consume on the Supervisor cluster."
tanzu,That is all the upfront preparation that is needed.
tanzu,Now the infrastructure is handed over to the DevOps team to deploy their applications within this environment.
tanzu,"Application Deployment
The DevOps user can now login to the Supervisor cluster using and start interacting with it to create objects using the Kubernetes API/CLI."
tanzu,The first step is to create a namespace where the application will reside.
tanzu,"The namespace created inherits all the quotas, limits, and RBAC enforced within the template during the previous step."
tanzu,"If the integrated Harbor registry (see above) is set up, the creation of the namespaces automatically triggers the creation of projects with the associated RBAC within the Harbor environment."
tanzu,"$ kubectl vsphere login --server wcp.navlab.io --vsphere-username nverma@vsphere.local --insecure-skip-tls-verify
$ cat ns.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: demo1
$ kubectl create -f ns.yaml
namespace/demo1 created
The next two steps are manual (and hopefully will be automated by the vSphere product team)."
tanzu,The newly created namespaces need to have a set of VMclasses and Content Libraries bound to them.
tanzu,This is currently possible through the Center interface.
tanzu,"$ kubectl get virtualmachineclassbinding -n demo1                                  
NAME                 VIRTUALMACHINECLASS   AGE
best-effort-large    best-effort-large     4m56s
best-effort-medium   best-effort-medium    4m56s
best-effort-small    best-effort-small     4m56s
best-effort-xsmall   best-effort-xsmall    4m55s
$ kubectl get contentsourcebindings -n demo1                                       
NAME                                   CONTENTSOURCE
9c54ca6c-fdf3-4ed8-b628-1a622641ebb7   9c54ca6c-fdf3-4ed8-b628-1a622641ebb7
9f4c1210-2c9b-46d2-81ad-f8f5139e4e74   9f4c1210-2c9b-46d2-81ad-f8f5139e4e74
The next step would be to deploy the MySQL database that would be running on a CentOS VM (At the time of writing this article, VMware provides CentOS-based OVA for VM deployments using VMOperator."
tanzu,This is delivered through the Cloud Marketplace.
tanzu,Documentation is available on their website on how to consume the Marketplace image through content libraries).
tanzu,The first step is to build a cloud-init.yaml file.
tanzu,Documentation on how to build a cloud-init file can be referenced here.
tanzu,"A sample file for MySQL automation could be similar to this ‚Äî
#cloud-config
chpasswd:
    list: |
      centos:password
    expire: false
groups:
  - docker
users:
  - default
  - name: centos
    ssh-authorized-keys:
      - ssh-rsa AAAAB3Nz...m50YwPyUFoUAUOXaqM6J8sXJd1THHFXBd/9jmnI60abFj50hqNuk62cN9kHW55HSO/L/Llz/PZyuk0wTbfqzc8BRA3Z0YiLo+I/LIc0= nverma@bastion0
    sudo: ALL=(ALL) NOPASSWD:ALL
    groups: sudo, docker
    shell: /bin/bash
# Enable password based authentication if needed
# ssh_pwauth: True
network:
  version: 2
  ethernets:
      ens192:
          dhcp4: true
package_update: true
packages:
  - mysql-server
  - net-tools
runcmd:
  - systemctl enable mysqld
  - systemctl start mysqld
  - sudo mysql -e ""CREATE DATABASE wordpress;""
  - sudo mysql -e ""CREATE USER 'wordpress_user'@'%' IDENTIFIED BY 'password';""
  - sudo mysql -e ""GRANT ALL ON wordpress."
tanzu,"* TO 'wordpress_user'@'%'""
  - sudo mysql -e ""FLUSH PRIVILEGES;""
  - sed -i '$abind-address=0.0.0.0' /etc/my.cnf.d/mysql-server.cnf
  - systemctl restart mysqld
  - firewall-offline-cmd --add-port=3306/tcp
  - firewall-cmd --reload
The base64 encoded cloud-init.yaml value [cat cloud-init.yaml |base64 -w0;echo] file is added to the VM deployment configuration file."
tanzu,Details on how to build the specification file are available on VMware‚Äôs website.
tanzu,"# vm.yml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
  namespace: demo1
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 4Gi
  storageClassName: nav-gold-policy
  volumeMode: Filesystem
---
apiVersion: vmoperator.vmware.com/v1alpha1
kind: VirtualMachine
metadata:
  labels:
    vm-selector: mysql-centosvm
  name: mysql-centosvm
  namespace: demo1
spec:
  imageName: centos-stream-8-vmservice-v1alpha1-1619529007339
  className: best-effort-small
  powerState: poweredOn
  storageClass: nav-gold-policy
  networkInterfaces:
  - networkType: nsx-t
    networkName: """"
  volumes:
  - name: my-centos-vol
    persistentVolumeClaim:
      claimName: mysql-pvc
  readinessProbe:
    tcpSocket:
      port: 22
  vmMetadata:
    configMapName: centos-cloudinit
    transport: OvfEnv
---
apiVersion: v1
kind: ConfigMap
metadata:
    name: centos-cloudinit
    namespace: demo1
data:
  user-data: [insert your base64 encoded cloud-init.yaml value here]  
  hostname: centos-mysql
---
apiVersion: vmoperator.vmware.com/v1alpha1
kind: VirtualMachineService
metadata:
  name: mysql-vmservices
spec:
  ports:
  - name: ssh
    port: 22
    protocol: TCP
    targetPort: 22
  - name: mwsql
    port: 3306
    protocol: TCP
    targetPort: 3306
  selector:
    vm-selector: mysql-centosvm
  type: LoadBalancer
The MySQL VM and its associated components are deployed."
tanzu,"It takes around 3‚Äì4 minutes to deploy, power on, and execute the cloud-init process before the VM is ready for use."
tanzu,"$ kubectl apply -f vm.yml -n demo1                                               
persistentvolumeclaim/mysql-pvc created
virtualmachine.vmoperator.vmware.com/mysql-centosvm created
configmap/centos-cloudinit created
virtualmachineservice.vmoperator.vmware.com/mysql-vmservices created
$ kubectl get svc -n demo1                                                         NAME               TYPE           CLUSTER-IP    EXTERNAL-IP      PORT(S)                       AGE
mysql-vmservices   LoadBalancer   10.96.0.147   192.168.10.162   22:31887/TCP,3306:30863/TCP   14m
Verification ‚Äî
To verify that the MySQL VM was successfully created and accessible, you can ssh from the host whose RSA key was shared in the cloud-init."
tanzu,yaml.
tanzu,Login to the VM to validate MySQL is successfully listening on port 3306.
tanzu,"$ ssh centos@192.168.10.162                                                                          
[centos@centos-mysql ~]$ netstat -an
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN
..."
tanzu,Awesome !!
tanzu,Now we need to deploy the WordPress application.
tanzu,"Before we do that, we need to create a Kubernetes cluster."
tanzu,This is also a straightforward operation using Cluster-API running on the Supervisor cluster.
tanzu,"# cluster.yaml
---
apiVersion: run.tanzu.vmware.com/v1alpha1
kind: TanzuKubernetesCluster
metadata:
  name: workload-vsphere-tkg1
  namespace: demo1
spec:
  distribution:
    version: v1.18.15
  topology:
    controlPlane:
      count: 1
      class: best-effort-medium
      storageClass: nav-gold-policy
      volumes:
        - name: etcd
          mountPath: /var/lib/etcd
          capacity:
            storage: 4Gi
    workers:
      count: 2
      class: best-effort-medium
      storageClass: nav-gold-policy
      volumes:
        - name: containerd
          mountPath: /var/lib/containerd
          capacity:
            storage: 30Gi
  settings:
    network:
      services:
        cidrBlocks: [""198.51.100.0/24""]
      pods:
        cidrBlocks: [""192.0.2.0/22""]
    storage:
      classes: [""nav-gold-policy""]
      defaultClass: nav-gold-policy
Use the above file to create the cluster."
tanzu,"Depending on the number of nodes requested, it may take anywhere from 5‚Äì10 minutes for the cluster creation to be completed."
tanzu,"For automation purposes, you could watch the status of the Tanzu Kubernetes Cluster (tkc) object to verify if the Kubernetes cluster is up and ready for consumption."
tanzu,"$ kubectl apply -f cluster1.yaml -n demo1                                          tanzukubernetescluster.run.tanzu.vmware.com/workload-vsphere-tkg1 created
$kubectl get tkc -n demo1                                                                                                 
NAME                    CONTROL PLANE   WORKER   DISTRIBUTION                      AGE   PHASE     TKR COMPATIBLE   UPDATES AVAILABLE
workload-vsphere-tkg1   1               2        v1.18.15+vmware.1-tkg.1.600e412   13h   running   True             [1.19.7+vmware.1-tkg.1.fc82c41]
Once the cluster is ready, we are now prepared to deploy the WordPress application to the cluster."
tanzu,"As stated in the pre-requisites, we cannot pull the WordPress image directly from Dockerhub."
tanzu,We need to host the image in the private Harbor registry set up as vSphere pods running directly on the ESXI servers (see above).
tanzu,"From a jump host that has access to the internet, download the WordPress image, tag it with the Harbor registry name and then upload it to the registry as per the sample commands below ‚Äî
$ docker login https://192.168.10.163                                   Username: nverma@vsphere.local
Password:
WARNING!"
tanzu,Your password will be stored unencrypted in /home/nverma/.docker/config.json.
tanzu,Configure a credential helper to remove this warning.
tanzu,"See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store
Login Succeeded
$ docker pull wordpress:5.7-apache                                              5.7-apache: Pulling from library/wordpress
f7ec5a41d630: Pull complete
..."
tanzu,"Status: Downloaded newer image for wordpress:5.7-apache
docker.io/library/wordpress:5.7-apache
$ docker images
docker images                                                             REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE
wordpress                         5.7-apache          7fda6c241024        4 days ago          551MB
...
$ docker tag 7fda6c241024 192.168.10.163/demo1/wordpress:5.7-apache
# Note the IP address of the Harbor registry is the same as the one in the screenshot above."
tanzu,# A project called demo1 was automatically created when the namespace was deployed.
tanzu,"This is the project where we will be uploading the image
$ docker push 192.168.10.163/demo1/wordpress                                    
The push refers to repository [192.168.10.163/demo1/wordpress]
623e5ea375d9: Pushed
...
5.7-apache: digest: sha256:ff25d3a299dc7778cdc51793f899f4a5a745cc78a00632fb466f59d96cbf83b5 size: 4709

Harbor interface showing the Wordpress uploaded image."
tanzu,"Now that the image has been uploaded to the local Harbor repository, we can use standard Kubernetes methods to deploy the WordPress application."
tanzu,"First, we log in to the newly deployed Kubernetes cluster and modify the Kubeconfig active context."
tanzu,A secret object that contains the credentials to the private registry is also created.
tanzu,"$ kubectl vsphere login --server wcp.navlab.io --vsphere-username nverma@vsphere.local --insecure-skip-tls-verify --tanzu-kubernetes-cluster-name workload-vsphere-tkg1 --tanzu-kubernetes-cluster-namespace demo1
...
$ kubectl config use-context workload-vsphere-tkg1
Switched to context ""workload-vsphere-tkg1""."
tanzu,"$ kubectl create secret docker-registry regcred --docker-server=192.168.10.163 --docker-username=nverma@vsphere.local --docker-password=""my vsphere.local password"" --docker-email=nverma@vsphere.local
If this is the first time connecting to the TKC, you may want to relax the pod security policy as per your requirements."
tanzu,This is documented on Vmware‚Äôs website.
tanzu,The sample YAML (referenced from the Kubernetes documentation and modified to meet the current requirements) that will be used by the DevOps to deploy WordPress is shown below.
tanzu,The application is exposed through a service-type LoadBalancer on port 80.
tanzu,Note how the MySQL service (running on a VM in the previous step) is referenced with the MYSQLDB_SERVICE_HOST environment variable.
tanzu,The MYSQLDB service is configured as a selector-less service to directly access the load balancer service of the VM exposed in the previous steps.
tanzu,"# wordpress.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  ports:
    - port: 80
  selector:
    app: wordpress
    tier: frontend
  type: LoadBalancer
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wp-pv-claim
  labels:
    app: wordpress
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  selector:
    matchLabels:
      app: wordpress
      tier: frontend
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: frontend
    spec:
      containers:
      - image: 192.168.10.163/demo1/wordpress:5.7-apache
        name: wordpress
        env:
        - name: WORDPRESS_DB_HOST
          value: ""$(MYSQLDB_SERVICE_HOST)""
        - name: WORDPRESS_DB_PASSWORD
          value: ""password""
        - name: WORDPRESS_DB_USER
          value: ""wordpress_user""
        ports:
        - containerPort: 80
          name: wordpress
        volumeMounts:
        - name: wordpress-persistent-storage
          mountPath: /var/www/html
      volumes:
      - name: wordpress-persistent-storage
        persistentVolumeClaim:
          claimName: wp-pv-claim
      imagePullSecrets:
      - name: regcred
---
apiVersion: v1
kind: Service
metadata:
  name: mysqldb
spec:
  ports:
  - name: mysql
    port: 3306
    protocol: TCP
---
apiVersion: v1
kind: Endpoints
metadata:
  name: mysqldb
subsets:
- addresses:
  - ip: 192.168.10.162
  ports:
  - name: mysql
    port: 3306
    protocol: TCP
Once you apply the above YAML and let the application startup on the new cluster, the WordPress application would be accessible on port 80."
tanzu,"$ kubectl apply -f wordpress.yaml                     
service/wordpress created
persistentvolumeclaim/wp-pv-claim created
deployment.apps/wordpress created
service/mysqldb created
endpoints/mysqldb created
$ kubectl get svc -A                                 
NAMESPACE     NAME         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                  AGE
default       mysqldb      ClusterIP      198.51.100.47    <none>           3306/TCP                 3m57s
default       wordpress    LoadBalancer   198.51.100.230   192.168.10.165   80:32379/TCP             3m57s
...
Accessing our application on port 80 within a web browser, we get our familiar WordPress admin page!!!"
tanzu,"Conclusion
As discussed at the beginning of the article, using the new concepts and tighter integrations of Kubernetes with vSphere, we can deliver complex workloads within the vSphere with the Tanzu environment."
tanzu,The below picture shows how our new architecture looks.
tanzu,"Note that to keep this article brief, we did not introduce an additional integration point of a VM App (shown in gray)."
tanzu,This could easily be achieved by concepts similar to how the Database VMs were deployed.
tanzu,This entire setup was contained within the demo1 namespace and hence adhered to all the constraints imposed on the namespace.
tanzu,Disclaimer: Everything in this post is taken from my initial investigation and proof of concept work in my lab.
tanzu,I think it may be helpful for others but know that this is not intended to be a production-ready architecture.
tanzu,I‚Äôve seen some cool Tweets about Octant for visualizing Kubernetes workloads recently and had to check it out for myself for the Kubernetes clusters I have on my Dell Technologies Cloud Platform (DTCP) lab which is comprised of VMware Cloud Foundation (VCF) 4.0 on VxRail HCI.
tanzu,Thanks to Vineeth and Ben for getting my attention!
tanzu,"While I‚Äôm probably more at home with kubectl, there are a lot of cool benefits to visualizing your Kubernetes objects, especially when it comes to debugging."
tanzu,So I jumped in to see what Octant was was all about.
tanzu,"As I looked at the installation steps, which are all client side, my first reaction was that it seemed kind of painful to access it from anything other than localhost."
tanzu,"After I thought about it a bit though, as a developer tool driven by your current config context, it made sense to run it locally most of the time."
tanzu,"Still, I wanted to come up with an easier way to make it available outside of a single machine since I often times do demos for people or need to provide them easy access."
tanzu,"I started by trying to just run the binary on my Ubuntu machine with OCTANT_LISTENER_ADDR specified to allow connecting outside of localhost:
$ OCTANT_LISTENER_ADDR=0.0.0.0:80 ./octant --kubeconfig ~/.kube/config --disable-open-browser
But I kept getting this permission error:
unable to start runner: use OCTANT_LISTENER_ADDR to set host:port: failed to create net listener: listen tcp 0.0.0.0:80: bind: permission denied
I tried running it as root but got other errors and quickly got frustrated with the usual ‚Äúmy system is slightly different than what they have in the documentation or any tutorials I can find‚Äù problem."
tanzu,"A more savvy Linux user could probably figure all that out, but this was when I decided to just build a container and run it that way because it always seems to ‚Äújust work‚Äù for me."
tanzu,"Build an Octant Container
The first step was to build an Octant container because I couldn‚Äôt find one available anywhere."
tanzu,"I grabbed the latest pre-built Linux binary, octant_0.13.1_Linux-64bit.tar.gz, and stuck it in the same directory where my Dockerfile would reside."
tanzu,The Dockerfile can be very short since I‚Äôm just sticking the binary in there and running it.
tanzu,"FROM alpine:3.12
COPY ."
tanzu,/.
tanzu,WORKDIR /.
tanzu,"EXPOSE 80
CMD OCTANT_LISTENER_ADDR=0.0.0.0:80 ./octant --kubeconfig ./.kube/config --disable-open-browser
It‚Äôs important to note that I use the ‚Äî-kubeconfig flag to tell Octant where to look for the kubeconfig file."
tanzu,To test it out I built the config file (which I got from ~/.kube/config on my local machine) into the container image.
tanzu,"This config file is populated with the connection information for all the Kubernetes clusters you have access to, in my case the vSphere Supervisor cluster which I connected to with the downloaded vSphere Kubectl binary (more on this later):
$ kubectl vsphere login --server=100.80.26.1 --insecure-skip-tls-verify
Later in the post I‚Äôll show you how I externalized it with a ConfigMap in Kubernetes so I don‚Äôt have to rebuild the image every time I changed my kubectl configuration (i.e."
tanzu,connecting to a new cluster).
tanzu,"Here‚Äôs what my directory tree looks like right now:
$ tree -a
."
tanzu,"‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .kube
‚îÇ   ‚îî‚îÄ‚îÄ config
‚îî‚îÄ‚îÄ octant
1 directory, 3 files
Next, I build my container locally and test it out to make sure I can run it as a single container from my local machine."
tanzu,$ sudo docker build -t davidadams3/octant:0.1 .
tanzu,"$ sudo docker run --name octant -d -p 80:80 davidadams3/octant:0.1
Now, putting in the IP or hostname of my local machine (not localhost) allows me to access Octant from anywhere that has a route to this machine!"
tanzu,This is a viable solution as is if I just want an easy way to access Octant from somewhere other than localhost so feel free to stop here if that makes your life easier.
tanzu,"Otherwise, you can keep reading to see how I ran my new container on Kubernetes and externalized the Kubeconfig file."
tanzu,"Run it on Kubernetes
As previously mentioned, I‚Äôm doing this on my VCF 4.0 setup so I am able to leverage all the goodness it offers for building and operating your private or hybrid cloud."
tanzu,If you‚Äôre not familiar with VCF and VxRail you can check it out here.
tanzu,For an introduction to all the new Kubernetes capabilities VCF 4.0 brings I‚Äôd recommend Cormac Hogan‚Äôs blog.
tanzu,"It‚Äôs worth the time to get familiar with it all the new capabilities, but I won‚Äôt rehash that here since Cormac does a great job with that."
tanzu,"I‚Äôm picking up here with vSphere for Kubernetes already enabled, a namespace created, a TKG cluster created and the Kubectl + vSphere plugin CLI."
tanzu,Previously I talked about moving the kubeconfig file out of the image because I knew I could use a Kubernetes ConfigMap to mount it to the container and make it much more flexible.
tanzu,So the first step was to remove the file from the directory tree where I built my container image from and rebuild the container then push it up to my preferred Docker registry.
tanzu,After that‚Äôs done we need to create our ConfigMap object now.
tanzu,This file is automatically created in a hidden file in your home directory when kubectl is connected to your cluster(s) and that‚Äôs how Octant is able to get your cluster info.
tanzu,So if you haven‚Äôt already you need to login to your Supervisor cluster and/or your TKG cluster depending on which one you want visualize in Octant.
tanzu,You‚Äôll be prompted for credentials to connect.
tanzu,For the rest of the demo I‚Äôm going to stay logged into the Supervisor cluster since that‚Äôs where I plan to deploy Octant as a vSphere pod.
tanzu,"$ kubectl vsphere login --server=100.80.26.1 --insecure-skip-tls-verify
$ kubectl vsphere login --server=100.80.26.1 --insecure-skip-tls-verify --tanzu-kubernetes-cluster-namespace=test-01 --tanzu-kubernetes-cluster-name=tkg-cl-01
Now your ~/.kube/config file has the connection information required and can be the source for your ConfigMap
$ kubectl create configmap octant-config --from-file ~/.kube/config
Now we are able to create the Kubernetes deployment and service to expose it externally."
tanzu,The service is type LoadBalancer which is possible because vSphere with Kubernetes configures everything required with NSX-T during the deployment including the pool of ingress IPs I provided.
tanzu,"This is a really nice feature which delivers the same type of experience you‚Äôd get from a public cloud managed Kubernetes experience (GKE, AKS, EKS, etc.)."
tanzu,"apiVersion: v1
kind: Service
metadata:
  name: octant-service
  labels:
    run: octant
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    name: http
  selector:
    run: octant
The deployment object is also quite straight forward but note that we have to create a volume for the ConfigMap and mount it into the directory the Octant container is expecting it to be (from the Dockerfile above it‚Äôs /.kube/config)."
tanzu,"apiVersion: apps/v1
kind: Deployment
metadata:
  name: octant-deployment
spec:
  selector:
    matchLabels:
      run: octant
  replicas: 1
  template:
    metadata:
      labels:
        run : octant
    spec:
      containers:
      - name: octant
        image: docker.io/davidadams3/octant:0.1
        imagePullPolicy: Always
        volumeMounts:
        - name: config
          mountPath: /.kube
        ports:
        - containerPort: 80
      volumes:
        - name: config
          configMap:
            name: octant-config
I put this all together in a single octant-deployment.yaml file:
apiVersion: v1
kind: Service
metadata:
  name: octant-service
  labels:
    run: octant
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    name: http
  selector:
    run: octant
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: octant-deployment
spec:
  selector:
    matchLabels:
      run: octant
  replicas: 1
  template:
    metadata:
      labels:
        run : octant
    spec:
      containers:
      - name: octant
        image: docker.io/davidadams3/octant:0.1
        imagePullPolicy: Always
        volumeMounts:
        - name: config
          mountPath: /.kube
        ports:
        - containerPort: 80
      volumes:
        - name: config
          configMap:
            name: octant-config
Apply the yaml with Kubectl."
tanzu,"$ kubectl apply -f octant-deployment.yaml
service/octant-service created
deployment.apps/octant-deployment created
Checking the deployment I can see the Octant pod is ready and available."
tanzu,"$ kubectl get deployments
NAME                READY   UP-TO-DATE   AVAILABLE   AGE
kuard               1/1     1            1           19h
octant-deployment   1/1     1            1           33m
Now I just need to check for the automatically assigned EXTERNAL-IP for the service, in this case 100.80.26.3 and it can be accessed on port 80."
tanzu,"$ kubectl get services
NAME                              TYPE           CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
kuard-service                     LoadBalancer   10.96.0.29    100.80.26.2   80:32681/TCP     18h
octant-service                    LoadBalancer   10.96.0.203   100.80.26.3   80:31177/TCP     40s
tkg-cl-01-control-plane-service   LoadBalancer   10.96.1.96    100.80.26.4   6443:31498/TCP   140m
We now have Octant running in vSphere Pod on the Supervisor cluster!"
tanzu,Thanks for reading this far and I‚Äôd like to re-iterate what I mentioned in the disclaimer at the beginning: I‚Äôm not convinced (yet) that this is the best way to deploy Octant but it was a fun exercise to work through so I thought I would share it.
tanzu,The obvious concern is around security and sharing access to your Kubernetes clusters without any sort of login screen (since it leverages the kubeconfig file for access to your clusters).
tanzu,I‚Äôll do a little more tinkering to see if there are more features in Octant I‚Äôm not taking advantage of in this regard.
tanzu,"Either if you are publishing a personal blog using WordPress or you want to have a nice .com domain for your portfolio, it‚Äôs vital to make sure your readers will have a secure connection to your website."
tanzu,This used to be a cumbersome process in the old days of web hosting.
tanzu,"First, you would have to generate a certificate request (signed by your private key) and send this over with a bunch of other forms to a certification authority like Verisign, and it would take a few days for you to receive a certificate you could use on your website."
tanzu,"With that in hand, you would have to figure out how to configure your application server to use it."
tanzu,"Then you would have to figure out how to set it up properly, how to keep your private key secure and all the stuff that comes with it."
tanzu,"With all of that set-up, you would finally have a website that you can access with HTTPS via SSL/TLS, just to find out that in a few months you would have forgotten to renew it and out of the sudden your website wouldn‚Äôt be trusted anymore."
tanzu,"When that happened, you would have to go through the process all over again."
tanzu,"A bit of a pain in the ****, isn‚Äôt it?"
tanzu,"This is the pain we‚Äôre trying to solve with Traefik, Let‚Äôs Encrypt and cert-manager."
tanzu,"But first, let‚Äôs understand what they are and how they will be used."
tanzu,"Traefik
From Traefik own‚Äôs website:
Traefik is a leading modern reverse proxy and load balancer that makes deploying microservices easy."
tanzu,Traefik integrates with your existing infrastructure components and configures itself automatically and dynamically.
tanzu,Traefik is a Cloud Native Edge Router that will work as an ingress controller to your Kubernetes cluster.
tanzu,"It will be responsible to make sure that when the traffic from your web application hits your Kubernetes cluster, it will go to the right Service."
tanzu,"Also, it makes it very easy to assign an SSL/TLS certificate to your web application."
tanzu,"Let‚Äôs Encrypt
From Let‚Äôs Encrypt own‚Äôs website:
Let‚Äôs Encrypt is a free, automated, and open certificate authority brought to you by the nonprofit Internet Security Research Group (ISRG)."
tanzu,Let‚Äôs Encrypt provides an automated way to request and renew SSL/TLS certificates using the ACME protocol ‚Äî they describe the process quite well on their website if you are interested in how it works.
tanzu,"cert-manager
From cert-manager GitHub repo:
cert-manager builds on top of Kubernetes, introducing certificate authorities and certificates as first-class resource types in the Kubernetes API."
tanzu,This makes it possible to provide ‚Äòcertificates as a service‚Äô to developers working within your Kubernetes cluster.
tanzu,We will use cert-manager to manage Let‚Äôs Encrypt certificated as an automated process within the Kubernetes cluster.
tanzu,"We could use a Traefik native integration to Let‚Äôs Encrypt to achieve a similar thing that cert-manager is doing, but on version 2 of Traefik, you can‚Äôt have an HA deployment of it while using the integration."
tanzu,You can find more details of this here if you are interested.
tanzu,"Also, with cert-manager you can do this for any other reason you might need a valid SSL/TLS certificate."
tanzu,"For that reason, I decided to use cert-manager instead."
tanzu,"Installing Traefik
You‚Äôll need Helm (I have used Helm 3 ‚Äî so not Tiller required)."
tanzu,"You should just need the Helm cli for that, but instructions on how to install Helm can be found here."
tanzu,"First, let‚Äôs create a configuration file for the helm chart since we want to customise some of the settings part of the chart."
tanzu,"Create a values.yml file with the following content:
additionalArguments:
  - ""--log.level=DEBUG""
  - ""--entrypoints.websecure.http.tls""
  - ""--providers.kubernetesIngress.ingressClass=traefik-cert-manager""
  - ""--ping""
  - ""--metrics.prometheus""
The most important setting here is what ingressClass to look for when using Traefik and the default to TLS."
tanzu,Everything else are things to help you debug if you encounter issues.
tanzu,A detailed list of the settings you can configure can be found here.
tanzu,Let‚Äôs now add the Helm repository and install Traefik on the traefik namespace.
tanzu,"helm repo add traefik https://containous.github.io/traefik-helm-chart
helm repo update
kubectl create namespace traefik
helm install --namespace traefik traefik traefik/traefik --values values.yaml
You should be able to check if everything worked by trying to access the Traefik dashboard."
tanzu,"You can expose it using a port-forward with the following command:
kubectl port-forward -n traefik $(kubectl get pods -n traefik --selector ""app.kubernetes.io/name=traefik"" --output=name) 9000:9000
Now head to http://127.0.0.1:9000/dashboard/ and you should be able to see the Traefik dashboard."
tanzu,"The Traefik Helm chart will create a service of type LoadBalancer, that should expose a port via LoadBalancer if you are using EKS (AWS), GKE (GCP) or AKS (Azure) or if you‚Äôre using TKG on AWS (VMware)."
tanzu,"If you are not using any of these options, you might have to find a way to expose the services."
tanzu,What I personally do on my Raspberry Pi at home is to use MetalLB.
tanzu,"That should allow you to use a routable IP range and then you could configure your router with a port-forward, but I won‚Äôt cover this as part of this post."
tanzu,"Installing cert-manager
You‚Äôll also need Helm to install cert-manager but before installing the chart, you‚Äôll need to apply the CRDs (Custom Resource Definitions) first as stated on the cert-manager docs."
tanzu,There‚Äôs also an option to install them as part of the Helm chart but I opted for the separate option for no particular reason.
tanzu,"First, let‚Äôs install the CRDs:
kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.15.2/cert-manager.crds.yaml
Now let‚Äôs create the namespace, add the Helm repository and install it:
kubectl create namespace cert-manager
helm repo add jetstack https://charts.jetstack.io
helm repo update
helm install cert-manager jetstack/cert-manager --namespace cert-manager --version v0.15.2
To check if the installation succeeded you can check if the pods are running:
kubectl get pods --namespace cert-manager
You should see three pods running: cert-manager, cert-manager-cainjector and cert-manager-webhook."
tanzu,"Configure your DNS provider to point to your Traefik service
I‚Äôm going to use the domain secure.alexguedes.com for this exercise, but you‚Äôll need to configure your DNS provider to point this domain to the IP address of the LoadBalancer created by Traefik."
tanzu,"You can see the IP address of the LoadBalancer created with the following command:
kubectl -n traefik get svc
Use the EXTERNAL-IP field when configuring your DNS provider."
tanzu,"If you try to open the URL now, you should see Traefik coming back with a 404 error message 404 page not found."
tanzu,This happens because we haven‚Äôt configured the Ingress rules for the application.
tanzu,We will do this at a later stage after we deploy the web service.
tanzu,"Deploy a website with Nginx
In case you don‚Äôt have a website running, here‚Äôs an example of how you can deploy a sample one."
tanzu,"I‚Äôm using a ConfigMap to change the index.html file of it, but you could use any type of volume you wish."
tanzu,"Create an 01-nginx.yaml file with the following content:
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: secure-alexguedescom-nginx
  name: secure-alexguedescom-nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      run: secure-alexguedescom-nginx
  template:
    metadata:
      labels:
        run: secure-alexguedescom-nginx
        app: secure-alexguedescom-nginx
    spec:
      containers:
      - image: nginx
        name: secure-alexguedescom-nginx
        ports:
        - containerPort: 80
        volumeMounts:
        - mountPath: /usr/share/nginx/html
          name: alexguedescom-volume
      volumes:
      - name: alexguedescom-volume
        configMap:
          name: nginx-index-html
---
apiVersion: v1
kind: Service
metadata:
  labels:
    name: secure-alexguedescom-nginx
  name: secure-alexguedescom-nginx
spec:
  ports:
    - port: 80
  selector:
    app: secure-alexguedescom-nginx
---
apiVersion: v1
data:
  index.html: |-
    <!doctype html>
    <html>
      <head>
        <title>Welcome to your secure web page using Nginx</title>
      </head>
      <body>
        <p>This will be a secure web page at the end of the tutorial!</p>
      </body>
    </html>
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: nginx-index-html
This will create a Deployment, a Service and a ConfigMap when you apply this to your Kubernetes cluster."
tanzu,"To apply, lets first create a namespace and then apply the yaml created."
tanzu,"kubectl create namespace secure-alexguedescom
kubectl apply -f 01-nginx.yaml
You should be able to see the nginx pod running inside the secure-alexguedescom namespace."
tanzu,"kubectl get pods --namespace secure-alexguedescom
Creating a Staging certificate with Let‚Äôs Encrypt
Now that we have our web site running with Nginx, we need to create a certificate to be used with it."
tanzu,This is where cert-manager comes to play.
tanzu,"Let‚Äôs Encrypt has two different services, one for staging and one for production."
tanzu,"The production one has some protections like rate-limiting etc, so let‚Äôs start with the staging one while we try our configuration and then move to the production one."
tanzu,The first thing we have to do is to create a ClusterIssuer object.
tanzu,"This configures the staging service from Lets Encrypt so we can request certificates:
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: letsencrypt-staging
spec:
  acme:
    # You must replace this email address with your own."
tanzu,"# Let's Encrypt will use this to contact you about expiring
    # certificates, and issues related to your account."
tanzu,"email: your@email.com
    server: https://acme-staging-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      # Secret resource used to store the account's private key."
tanzu,"name: your-own-very-secretive-key
    solvers:
      - http01:
          ingress:
            class: traefik-cert-manager
Create a staging-cluster-issuer.yaml with the content and apply to your cluster."
tanzu,"Since we‚Äôre using an Object of type ClusterIssuer, this will be available to the whole cluster."
tanzu,"If you want to restrict access to this Issuer to only an specified namespace, you should look at the Issuer object."
tanzu,This should be enough configuration for us to start requesting certificates.
tanzu,"To request a certificate for your domain, you‚Äôll need to create a Certificate object that will look like this:
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: secure-alexguedescom-cert
  namespace: secure-alexguedescom
spec:
  commonName: secure.alexguedes.com
  secretName: secure-alexguedescom-cert
  dnsNames:
    - secure.alexguedes.com
  issuerRef:
    name: letsencrypt-staging
    kind: ClusterIssuer
Make sure you apply this to the same namespace you‚Äôre deploying your website to (I have used the metadata namespace for that as part of the YAML), because we will need to configure it as part of the Ingress rule later on."
tanzu,"Now let‚Äôs apply that with kubectl:
kubectl apply -f secure-alexguedescom-staging-cert.yaml
Now let‚Äôs check if the cert has been generated by describing the certificate:
kubectl -n secure-alexguedescom describe certificate secure-alexguedescom-cert
If everything worked, you should see at the bottom of the describe output the following:
Events:
  Type    Reason        Age   From          Message
  ----    ------        ----  ----          -------
  Normal  GeneratedKey  66s   cert-manager  Generated a new private key
  Normal  Requested     66s   cert-manager  Created new CertificateRequest resource ""secure-alexguedescom-cert-153924917""
  Normal  Issued        40s   cert-manager  Certificate issued successfully
The new certificate and key will be stored as a Kubernetes secret as part of the same namespace."
tanzu,"Using the newly created staging certificate with your website
Now that we have a working nginx service and we have a certificate that we want to use as part of our Ingress, lets create an IngressRoute on Traefik that says that all traffic originating on secure.alexguedes.com will land onto that service."
tanzu,"Create a YAML called traefik-ingressroute.yaml with the following content:
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: secure-alexguedescom-ingress-https
  namespace: secure-alexguedescom
spec:
  entryPoints:
    - websecure
  routes:
    - match: Host(`secure.alexguedes.com`)
      kind: Rule
      services:
        - name: secure-alexguedescom-nginx
          port: 80
  tls:
    secretName: secure-alexguedescom-cert
If you now try to access your web domain, which in my case is https://secure.alexguedes.com you‚Äôll see that it now has an non-trusted certificate issued by Fake LE Intermediate X1."
tanzu,This is because we used the staging server to issue that certificate.
tanzu,"This tells us that all the configuration worked, and we can move on onto issuing a trusted cert using Let‚Äôs Encrypt production servers."
tanzu,"Creating a Production certificate with Let‚Äôs Encrypt
We will now add another ClusterIssuer, but this time using the Let‚Äôs Encrypt production servers."
tanzu,"Firt we will need to create a ClusterIssuer with the following content:
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    # You must replace this email address with your own."
tanzu,"# Let's Encrypt will use this to contact you about expiring
    # certificates, and issues related to your account."
tanzu,"email: your@email.com
    server: https://acme-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      # Secret resource used to store the account's private key."
tanzu,"name: your-own-very-secretive-key
    # Add a single challenge solver, HTTP01 using nginx
    solvers:
      - http01:
          ingress:
            class: traefik-cert-manager
Then apply this configuration to your Kubernetes cluster:
kubectl apply -f cluster-issuer-prod.yaml
Now we have two different ClusterIssuers: letsencrypt-staging and letsencrypt-prod."
tanzu,"Lets delete the previous certificate created with the staging Issuer, and create a production one instead."
tanzu,"To delete the previous created certificates, use the following command:
kubectl -n secure-alexguedescom delete certificate secure-alexguedescom-cert
kubectl -n secure-alexguedescom delete secrets secure-alexguedescom-cert
Now let‚Äôs issue a new production certificate:
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: secure-alexguedescom-cert
  namespace: secure-alexguedescom
spec:
  commonName: secure.alexguedes.com
  secretName: secure-alexguedescom-cert
  dnsNames:
    - secure.alexguedes.com
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
Now let‚Äôs apply that with kubectl:
kubectl apply -f secure-alexguedescom-prod-cert.yaml
Now let‚Äôs check if the cert has been generated by describing the certificate:
kubectl -n secure-alexguedescom describe certificate secure-alexguedescom-cert
If everything worked, you should see at the bottom of the describe output the following (like we did with the staging cert):
Events:
  Type    Reason        Age   From          Message
  ----    ------        ----  ----          -------
  Normal  GeneratedKey  3s    cert-manager  Generated a new private key
  Normal  Requested     3s    cert-manager  Created new CertificateRequest resource ""secure-alexguedescom-cert-153924917""
  Normal  Issued        1s    cert-manager  Certificate issued successfully
Now if you head back to your domain, in my case https://secure.alexguedes.com, you should be able to see now that you have a valid certificate (some browsers will still show the only certificate until you close and open the browser, for example with Chrome, if you want to see this working without doing that, use an Incognito window)."
tanzu,"Extra: Redirect your http requests to https
Now that you have a fully working website with SSL/TLS, all the connectivity can be secure in transit."
tanzu,"But you might have noticed that if you try to open your website without https, you‚Äôll get a 404 from Traefik."
tanzu,That‚Äôs because we‚Äôre only serving traffic via 443 with https.
tanzu,To create a redirect for all http (port 80) traffic to https (port 443) you‚Äôll need to create a Traefik Middleware rule that redirects traffic to https and also another Ingress route with a web entrypoint that uses that Middleware.
tanzu,"This is what the configuration looks like:
apiVersion: traefik.containo.us/v1alpha1
kind: Middleware
metadata:
  name: https-only
  namespace: secure-alexguedescom
spec:
  redirectScheme:
    scheme: https
    permanent: true
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: secure-alexguedescom-ingress-https
  namespace: secure-alexguedescom
spec:
  entryPoints:
    - websecure
  routes:
    - match: Host(`secure.alexguedes.com`)
      kind: Rule
      services:
        - name: secure-alexguedescom-nginx
          port: 80
  tls:
    secretName: secure-alexguedescom-cert
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: secure-alexguedescom-ingress-http
  namespace: secure-alexguedescom
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`secure.alexguedes.com`)
      middlewares:
        - name: https-only
      kind: Rule
      services:
        - name: secure-alexguedescom-nginx
          port: 80
Now if you head to http endpoint of your web site, which in my case is http://secure.alexguedes.com you‚Äôll see that you‚Äôll get a redirect to https."
tanzu,Questions?
tanzu,You can find all the yamls on my GitHub repo if you just want to follow the guide and apply them.
tanzu,"https://github.com/alexguedes/traefik-cert-manager-sample
If you have any questions, please reach out in the comments and I‚Äôll try my best to help out."
tanzu,Are you managing multiple Kubernetes clusters and find impossible to make sense of the multiple contexts part of your kubeconfig file?
tanzu,"Don‚Äôt worry, you‚Äôre not alone!"
tanzu,"I‚Äôm a Solutions Engineer at VMware Tanzu which is the Modern Application Platform business unit and we‚Äôre all about how you Build, Run and Manage modern workloads with Kubernetes at the core of everything we do."
tanzu,"When you work in pre-sales like me and have to spin multiple Kubernetes up and down for proof of concepts, out of the sudden you realise your kubeconfig file looks like a mess and you can‚Äôt figure out which cluster is what (or which ones haven‚Äôt been destroyed yet)."
tanzu,I‚Äôm going to cover two tricks I have found out to be very useful to me when managing multiple Kubernetes clusters and multiple configuration files.
tanzu,How to access multiple Kubernetes clusters using multiple kubeconfig files and how to easily switch between Kubernetes contexts.
tanzu,I‚Äôll start with managing multiple contexts and config files.
tanzu,"The Kubernetes documentation describes it quite well how to do this:
Configure Access to Multiple Clusters
This page shows how to configure access to multiple clusters by using configuration files."
tanzu,"After your clusters, users‚Ä¶
kubernetes.io

But the problem I see with this approach is that not always you‚Äôll configure your kubeconfig files that way."
tanzu,"Several systems out there it will give you the option to download the configuration to access the cluster and while you can just append this to your existing kubeconfig file, this very quickly will get messy."
tanzu,"One example of that is Tanzu Mission Control, which allows you to provision and manage the lifecycle of multiple Kubernetes clusters across your VMware estate and across multiple clouds."
tanzu,"This will not only allow you to download your kubeconfig file, but will also allow you to have visibility of your multiple Kubernetes clusters, their workloads and will also give you the ability to define policies like network and security."
tanzu,"I much rather have multiple kubeconfig files, one for each cluster I‚Äôm managing and name those files with some information that tells me which cluster the file belongs to."
tanzu,This is easily achieved by using kubeconfig --kubeconfig=/path/to/my/kubeconfig/file/cluster1.
tanzu,But that is not a great solution for me since it‚Äôs time-consuming having to pass your configuration every time you want to check which pods are running on a cluster.
tanzu,"What I have done to simplify having multiple kubeconfig files was to use a cool capability of the $KUBECONFIG environment variable, which allows us to specify multiple kubeconfig files separated by using colons."
tanzu,"It should look like that when you have multiple config files:
$KUBECONFIG=/Users/aguedes/.kube/contexts/kubeconfig-cluster-1.yml:/Users/aguedes/.kube/contexts/kubeconfig-cluster-2.yml
This will allow me to switch between the cluster-1 and cluster-2 contexts using kubectl config use-context cluster-1for example."
tanzu,"This solves my problem of allowing me to have multiple config files, but still fairly manual since every time I restart my terminal or if I have a new kubeconfig (or I have to remove an old one) I have to set that environment variable again."
tanzu,"For that, I use a very simple bash script that scans the directory for new files and automatically adds them to the $KUBECONFIG environment variable:
#!/usr/bin/env bash
# If there's already a kubeconfig file in ~/.kube/config it will import that too and all the contexts
DEFAULT_KUBECONFIG_FILE=""$HOME/.kube/config""
if test -f ""${DEFAULT_KUBECONFIG_FILE}""
then
  export KUBECONFIG=""$DEFAULT_KUBECONFIG_FILE""
fi
# Your additional kubeconfig files should be inside ~/.kube/config-files
ADD_KUBECONFIG_FILES=""$HOME/.kube/config-files""
mkdir -p ""${ADD_KUBECONFIG_FILES}""
OIFS=""$IFS""
IFS=$'\n'
for kubeconfigFile in `find ""${ADD_KUBECONFIG_FILES}"" -type f -name ""*.yml"" -o -name ""*.yaml""`
do
    export KUBECONFIG=""$kubeconfigFile:$KUBECONFIG""
done
IFS=""$OIFS""
Then you can source that script by typing source load-k8s-configs.sh on your Mac terminal and that will load all your kubeconfig files as part of your $KUBECONFIG environment variable."
tanzu,"If you want to have this loaded every time you open the terminal, you can add source /path/to/script/load-k8s-config.sh to your bash_profile file inside your home directory."
tanzu,"With that, you should be able to switch between contexts with ease, but we have one more problem!"
tanzu,The filename you give to your config files are not necessarily the name of the context and you still need to know that by remembering the multiple parameters of the kubectl configcommand or by checking the multiple config files you have.
tanzu,"That‚Äôs a hassle we don‚Äôt want, do we?"
tanzu,That‚Äôs where kubectx and the second trick comes into play!
tanzu,It allows you to easily check all available contexts and switch between them by typing kubectx context-name and that‚Äôs it!
tanzu,It also comes with some other tools around switching between namespaces and an interactive mode if you like that type of stuff.
tanzu,Check the Git repository out: https://github.com/ahmetb/kubectx.
tanzu,"You can install it using krew:
kubectl krew install ctx
kubectl krew install ns
Or you can find instructions on the GitHub repository on how to install using other methods like Homebrew for Macs."
tanzu,"Once installed, you can start switching!"
tanzu,"(I stole the gif from the kubectx GitHub repository)

For more details about Tanzu Mission Control and the VMware Tanzu Portfolio, please check on VMware‚Äôs website."
tanzu,"VMware Tanzu Portfolio
Modernize your applications and infrastructure to deliver better software to production, continuously."
tanzu,"tanzu.vmware.com

Happy config switching to you all!"
tanzu,"If you have any questions, please reach out!"
tanzu,William Lam‚Äôs great deployment script triggered the idea of setting up a vSphere 7 and Kubernetes (VCF 4) environment completely nested on top of our development vSphere environment.
tanzu,"While the deployment itself worked very well to deploy the nested vSphere 7 environment, you need to fulfill some important requirements before you can enable the Kubernetes part (VMware Cloud Foundation 4 ‚Äî VCF)."
tanzu,"This blog post is going to cover these requirements as well as some tips and tricks to work with your fresh VCF 4 environment, the Workload Management and the Tanzu Kubernetes Grid (TKG) cluster."
tanzu,"Automated Deployment
Requirements
William proposes the following requirements to run his script:
https://github.com/lamw/vghetto-vsphere-with-kubernetes-external-nsxt-automated-lab-deployment
Additional requirements
In case you want to continue enabling Workload Management (VCF) within your nested environment we would further recommend the following ‚Äî otherwise your SupervisorControlPlaneVM won‚Äôt be completely initialized."
tanzu,configure MTU size 1600 or higher on every virtual and physical swith on the communication path from the NSX T0 uplink to your Internet gateway (sNAT).
tanzu,That includes the underlying (where the nested environment is deployed) and the nested vSwitch/dvSwitch!
tanzu,"Accept Security Promiscuous mode and Forged transmits setting on your Portgroups
Configure a PFsense (or something similar) to act as a Gateway including SNAT for your NSX T0 Uplinks

Run the script
Simply is to clone the GitHub repository, change the script according to the README.md and run it using the PowerCLI."
tanzu,"When the script successfully deployed your nested ESXi, the vCSA, the NSX Management and the NSX Edge, you can go ahead and connect to your newly deployed vCSA 7."
tanzu,"Enable the Workload Management

To enable the workload management and deploy the Kubernetes environment by doing so, simply select Workload Management in your vSphere client Menu."
tanzu,"Let‚Äôs enable the Workload Management
The wizard guides you through the most important steps and most people can select tiny as a deployment size."
tanzu,To simplify the guideline we used all the network settings William is using in his script.
tanzu,You need to make sure that your gateway has an adapter and ip address in the Management and Workload network (Ingress and Egress) to be sure that container images can be downloaded later on.
tanzu,"Furthermore, make sure to enable SNAT in your Gateway and to configure the firewall."
tanzu,The next important step is to select the correct Datastore for all your images and related data.
tanzu,"After starting the enablement, its time to get a coffee because that process can take some time."
tanzu,"Deployment trouble

The first couple of minutes are pretty boring and you can ignore some of the errors."
tanzu,But it doesn‚Äôt hurt to check the events of the first SuperVisorControlPlaneVM that will be powered on.
tanzu,"That one is the Kubernetes Master and if this deployment fails, not much will happen in the future."
tanzu,"If you see some entries like this
burst of ‚Äòcom.vmware.vc.guestOperations.GuestOperation‚Äô started
in the Events of the first powered on SupervisorControlPlaneVM, you can be pretty sure that the deployment is progressing well and the communication between the nested ESXi and the VCF VMs works."
tanzu,Don‚Äôt be impatient!
tanzu,Some of the errors are absolutely normal and can be ignored if these don‚Äôt last for more than 15‚Äì20 minutes.
tanzu,You can also test the environment during the install by pinging the NSX T0 uplinks.
tanzu,"When the master VM is configured, the other 2 SupervisorControlPlane VMs will start as well and all configurations is copied over to them."
tanzu,"Create your first namespace

When you select the Namespaces tab, you can create your first namespace to deploy demo applications or just test a bit."
tanzu,"Let‚Äôs create the Namespace test

Add permissions and storage
Connect to the Control Plane

The main tool to work with the Kubernetes platform is kubectl that can be downloaded by visiting the Control Plane IP using your browser or simply click Open under Link to CLI Tools."
tanzu,"Download kubectl and the vsphere plugin, so you can directly connect to your vSphere based Kubernetes deployment:
# Login to Kubernetes 
kubectl vsphere login --server=https://controlplane-ip -u administrator@vsphere.local --insecure-skip-tls-verify 
# select the test namespace - it safes you typing -n test after each command 
kubectl config use-context test 
# show all existing resources 
kubectl get all
If you haven‚Äôt deployed anything yet, you simply see No resources found in test namespace."
tanzu,We‚Äôre going to change that.
tanzu,"Run a test Pod
Let‚Äôs test, if we can access the internet to pull images by creating a demo nginx pod."
tanzu,"# deploy nginx for testing 
kubectl run nginx --image=nginx 
# ignore the warning as we're just testing: 
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version."
tanzu,Use kubectl run --generator=run-pod/v1 or kubectl create instead.
tanzu,"deployment.apps/nginx created 
# check the deployment status 
kubectl get all
Seems to work!"
tanzu,"If it doesn‚Äôt work for you, try these commands to get details:
# get information about nginx deployment 
kubectl describe deployment.apps/nginx 
# get pods with label/value run=nginx and return full configuration kubectl get pods -l run=nginx -o yaml


You can track all events and the configuration files in your vSphere client as well."
tanzu,"# delete the pod 
kubectl delete pods -l run=nginx 
# check for pods again and you'll find a new pod with a low AGE kubectl get pods -l run=nginx 
# delete the deployment 
kubectl delete deployment nginx 
# check for pods again and you'll nothing will be shown 
kubectl get pods
This little exercise explains a bit how Kubernetes works."
tanzu,"The pod will be created based on a replicaset, that is created by the deployment."
tanzu,If we delete the pod the replicaset creates a new one.
tanzu,Deleting the deployment deletes the pod and the replicaset as well.
tanzu,"Next blog post will be about adding the Tanzu Content Library, creating a TKG cluster and how to monitor logs and performance."
tanzu,It is common for many large organizations to have their Kubernetes workloads running on more than one cloud provider.
tanzu,It is a great strategy to utilise the benefits of on-prem and public cloud.
tanzu,"In this blog, I will show you how to create, run and manage clusters across AWS and vSphere using Tanzu Kubernetes Grid (TKG)."
tanzu,"Brief intro to TKG
VMware Tanzu Kubernetes Grid‚Ñ¢ provides organizations with a consistent, upstream-compatible, regional Kubernetes substrate across software-defined datacenters (SDDC) and public cloud environments, that is ready for end-user workloads and ecosystem integrations."
tanzu,TKG is a bundle of tools that help run k8s in a production environment.
tanzu,"In addition to vanilla kubernetes, TKG includes Open Source tools like Cluster API, Calico for networking, Fluent Bit for logging, Contour for ingress etc."
tanzu,"Prerequisites
1."
tanzu,Deploy TKG management cluster to Amazon EC2 ‚Äî Follow steps in docs.
tanzu,2.
tanzu,Deploy TKG on vSphere ‚Äî Follow steps in docs.
tanzu,"Alternatively, if you are on vSphere 7, you could enable kubernetes Workload management and skip step and follow this link to add vSphere management cluster to your TKG cli."
tanzu,"Multiple TKG management clusters
Now that we have set up two different TKG clusters, lets see how we can manage them using the TKG cli."
tanzu,"tkg get management-cluster
+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî |
| MANAGEMENT CLUSTER NAME | CONTEXT NAME |
+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+
| tkg-mgmt-aws-zzzzz* | tkg-mgmt-aws-admin@tkg-mgmt-aws |
| wcp.vsphere.test.io | wcp.vsphere.test.io |
+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+
* indicates the management cluster which is selected."
tanzu,AWS management cluster is selected at the moment.
tanzu,"Create a cluster on AWS:
tkg create cluster my-aws-cluster --plan=dev --kubernetes-version=v1.17.3+vmware.2
Once it is done, run the following command to make sure the cluster is created."
tanzu,"tkg get cluster
+----------+-------------+
| NAME | STATUS |
+----------+-------------+
| my-aws-cluster | Provisioned |
+----------+-------------+
Create a cluster on vSphere:
Select the vSphere management cluster:
tkg set management-cluster wcp.abc.test.io
+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî‚Äî ‚Äî ‚Äî -+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî|
| MANAGEMENT CLUSTER NAME | CONTEXT NAME |
+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+
| tkg-mgmt-aws-zzzzz | tkg-mgmt-aws-admin@tkg-mgmt-aws |
| wcp.vsphere.test.io* | wcp.vsphere.test.io |
+ ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî‚Äî ‚Äî -+ ‚Äî ‚Äî‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî -+
Create a cluster in vSphere:
tkg create cluster my-tkg-cluster --namespace=demo --plan=dev --kubernetes-version=v1.16.8+vmware.1-tkg.3.60d2ffd
Once the cluster is created, you could verify by running the command or you could login to the vCenter UI to take a look."
tanzu,"Key takeaways:
I could use different versions of kubernetes across AWS and vSphere."
tanzu,I could use different storage classes across AWS and vSphere.
tanzu,Edit ~/.tkg/config.yaml to change storage classes or vm classes.
tanzu,Consistent experience creating clusters across the two IaaS.
tanzu,I can use the same TKG Cli to manage clusters.
tanzu,Yay!
tanzu,Starting an update or upgrade process in any VMware Tanzu Platforms that has Ops Manager is usually very easy.
tanzu,To achieve that you simply click ‚ÄúApply Changes‚Äù button.
tanzu,But tracking progress of installation or getting notifications about state of installation is not easy as well.
tanzu,"In that purpose, we ‚Äòll setup a slack integration project."
tanzu,"To achieve this, following tasks are explained in this arcticle."
tanzu,"Overview
Get Slack App and Webhook URL
Pull ‚ÄúVMware Tanzu (Pivotal) Installation Notifier‚Äù Repository
Edit ‚Äútanzu.env‚Äù File Regarding Your Environment
(Optional) Build ‚ÄúVMware Tanzu (Pivotal) Installation Notifier‚Äù Image
(Optional) Edit ‚Äúdocker-compose.yaml‚Äù
Run!"
tanzu,"Requirements
Linux/Unix Terminal Server must be able to reach both Ops Manager VM, Slack API and Github."
tanzu,Docker and Docker-Compose must be installed on terminal server.
tanzu,Git command line tool is preferred to download required repository.
tanzu,1.
tanzu,"Get Slack App and Webhook URL
A slack webhook url is needed to push notifications."
tanzu,If you already have it you can pass this task.
tanzu,"If not, you can follow ‚ÄúCreate Slack App with Webhook For Basic Usage‚Äù article below."
tanzu,"Create Slack App with Incoming Webhook For Basic Usage
Sometimes you may want to get update messages or notifications from your app or want to have a quick messaging with‚Ä¶
medium.com

2."
tanzu,"Pull Repository
We will use ‚ÄúVMware Tanzu (Pivotal) Installation Notifier‚Äù repository."
tanzu,This repository provides required program that interacts with Ops Manager API and send Slack notifications.
tanzu,"kurtburak/tanzu-installation-notifier
When a new update or upgrade process is started in Tanzu Application Service (TAS / PAS / PCF) or VMware Enterprise‚Ä¶
github.com

$ git clone https://github.com/kurtburak/tanzu-installation-notifier.git
$ cd tanzu-installation-notifier/
3."
tanzu,"Edit ‚Äútanzu.env‚Äù File Regarding Your Environment
Tanzu.env file contains required and optional parameters that used by program."
tanzu,Available parameters can be used are given in README.md file with definitions.
tanzu,Open tanzu.env file with your favorite text editor and fill epty values.
tanzu,"After editing, tanzu.env file must be looked like below."
tanzu,"# Tanzu Opsman variables
OPSMAN_IP=10.0.0.10
OPSMAN_USER=admin
SSH_USER=ubuntu
SSH_KEY=-----BEGIN RSA PRIVATE KEY-----\nH+eOG2j7....2iVnk+3YRn\n-----END RSA PRIVATE KEY-----
# Proxy Settings
# Leave empty if unneceissary
HTTP_PROXY=http://10.5.0.50:8080
HTTPS_PROXY=http://10.5.0.50:8080
NO_PROXY=10.0.0.10
# Notificaiton variables
SLACK_URL=https://hooks.slack.com/services/TL2BSJFTZ/BL73TSGJDS/hTfKSTYfksdKHGStdfƒ±asg
# Program settings."
tanzu,"Leave defaults
API_REQUEST_CYCLE=60
RUNNING_INFORM_PERIOD=60
Assuming using default ssh key, SSH_KEY parameter‚Äôs value can be obtain as running command;
cat ~/.ssh/id_rsa | sed -e ':a;N;$!ba;s/\n/\\n/g'
4."
tanzu,"(Optional) Build Image
Optionally you can edit and build your own image."
tanzu,docker build .
tanzu,"-t tanzu-install-watcher:local
5."
tanzu,"(Optional) Edit ‚Äúdocker-compose.yaml‚Äù
If you build your own image, you may want to use it with docker-compose."
tanzu,"sed -i 's/bkurt\/tanzu-install-watcher:latest/tanzu-install-watcher:local/g' docker-compose.yml
6."
tanzu,Run!
tanzu,Finally you are ready to go!
tanzu,"At VMworld 2019, VMware has doubled down on its strategy of offering a unified operating model for hybrid cloud (vSphere + public cloud) and multi cloud (more than one public cloud) by adding native Kubernetes support and an initial set of interesting AIOPs capabilities (project Magna) to the mix."
tanzu,"At the end of the day, VMware is in the enviable position of owning a base of approximately 500,000 vSphere customers that are an ideal target for converting into Kubernetes customers."
tanzu,"There are still 85% of enterprise applications that so far have escaped migration and modernization, simply because enterprises do not have the cycles required to go through this this often time consuming process."
tanzu,"VMware is laser focused on capturing these 500,000 targets accounts and 85% of remaining applications by making significant changes to its core portfolio."
tanzu,"Here are my Top 7 highlights from VMworld 2019 (also see my show summary in pictures and with fewer words):
#1: Project Pacific ‚Äî Kubernetes on vSphere

Project Pacific was the ‚Äúbig bang‚Äù at this year‚Äôs VMworld opening keynote."
tanzu,vSphere can now provision and run upstream Kubernetes in addition to and on top of ESXi.
tanzu,"‚ÄúThe integration goes so deep that we had to rewrite core parts of vSphere to support containers, pods, namespaces, scheduling policies, access and identity management and other core components of the software as core system objects that are now accessible to VMware administrators through the vSphere GUI and API, while developers receive an undiluted upstream Kubernetes experience, identical to what they would expect from GKE,‚Äù says Kit Colbert, CTO for Cloud Platforms at VMware."
tanzu,Read the rest of this article on my blog on LinkedIn.
tanzu,You can also find the show highlights in pictures here.
tanzu,"Day 2 Modern Apps Showcase Keynote
On the second day of VMworld, VMware gave to me~‚Ä¶ another look at Tanzu, VMware‚Äôs framework to tackle the challenge of building, running, and managing modern apps!"
tanzu,"Starting off Tuesday with a General Session of demos demonstrating how VMware has changed the landscape for apps, infrastructure, cloud, networking, security, and devices, I spent the day gaining a better grasp of what the full Tanzu portfolio and kubernetes integration has to offer, attending several breakout sessions to learn about Tanzu Mission Control, and a great Showcase Keynote on the modern app, Kubernetes, and the cloud native journey."
tanzu,"Overall, Day 2 was a day well spent gaining knowledge and experiences that I hope to bring back with me as a student and soon-to-be new graduate, meeting the challenges of an accelerating industry head on."
tanzu,"Modern App Showcase: Kubernetes and the Cloud Native Journey

Showcase Keynote: Kubernetes and the Cloud Native Journey with Craig McLuckie
This was a great keynote addressing the question, how do we make a Kubernetes infrastructure on-prem, on public cloud, or on the edge run so seamlessly, we can trade in our focus on maintaining infrastructure functionality for a sole focus on developing apps?"
tanzu,"Tanzu, of course!"
tanzu,"The word Tanzu in Japanese is a type of cabinet, alluding to VMware Tanzu‚Äôs role as an organized system and organizational tool for modern apps; in Swahili, Tanzu means tree branch, nodding at Tanzu‚Äôs role in proliferating and nurturing the growth towards the multi-cloud."
tanzu,"Beyond these semantics, Tanzu is overall a powerful platform for running modern apps."
tanzu,"In my Day 1 blog, I discussed what makes Project Pacific so exciting and briefly went over the three primary components of Tanzu: build, run, and manage."
tanzu,"Today, I attended a breakout session detailing how Tanzu manages modern application workloads, and in the section below I very quickly discuss some whats and whys of Tanzu‚Äôs management solution."
tanzu,"More Devs, No Problem: Managing Self-service Access to Kubernetes

Kubernetes is an enterprise‚Äôs dream technology, offering rapid innovation through software and increasing developer velocity, multi-cloud operations, and improved resource utilization."
tanzu,"However, as applications scale up in Kubernetes, the age old operations challenges remain: fragmentation across teams, issues of adequate visibility and security, and accurate cost reporting and control."
tanzu,"Across disparate Kubernetes Clusters, the challenge can rapidly become insanely complex."
tanzu,"Imagine managing separate security domains, upgrades, monitoring, and backups, cross-cluster traffic, and resources individually for dozens, if not hundreds, of clusters."
tanzu,Tanzu Mission Control offers a solution to the headache-inducing dilemma described above.
tanzu,"Tanzu Mission Control, like the mission control center of an aerospace expedition, is a single control point for a team to centrally manage what is otherwise a convoluted conglomerate of rapidly moving parts."
tanzu,It‚Äôs a one-stop control for Kubernetes and modern applications.
tanzu,"To summarize what it has to offer:
manage a fleet of cluster resources instead of single cluster operations, both in groupings of clusters as cluster groups, and through workspaces: a cluster set defined as an application on namespaces
define policies once and push them across clusters
manage cluster lifecycle consistently, and schedule cluster backups
a unified view of cluster metrics, logs, data, and costs
built to be extensible
In addition to addressing the pain of having to individually manage clusters, Tanzu Mission Control addresses the conflicting needs of developers, who need independence and self-service access to drive business forward, and IT operations who need visibility and control."
tanzu,"It has the following design goals:
enable grouping of physical resources
enable sharing of clusters across teams
enable self-service access to infrastructure
Tanzu Mission Control connects people structure and infrastructure within an organization and is a powerful tool to accelerate the industry along its cloud native journey."
tanzu,"Hearing from Customers

Design Studio session: Platform as a Service on vSphere
I attended my first Design Studio session for Platform as a Service (PaaS) on vSphere, listening in and learning about customers‚Äô goals, pain-points, solutions, and suggestions for PaaS in the public cloud and on-prem."
tanzu,Design Studio sessions at VMworld are meetings and discussions with a small group of customers for their feedback to existing and in-development VMware products and solutions to better understand where and how the company‚Äôs technology can help customers efficiently and effectively solve their problems.
tanzu,"It was a cool experience to see where the customer‚Äôs anecdotes and vSphere‚Äôs product development aligned and conflicted, and I gained insight into the process of gathering customer feedback and parsing it for actionable elements."
tanzu,"I also had the chance to attend a Meet-the-Experts session with Project Pacific engineers and product managers, and got to hear questions posed by engaged customers about the architecture and capabilities of Project Pacific‚Äôs supervisor kubernetes cluster and guest cluster services."
tanzu,"All in all, today I got to experience some community engagement with a bigger group, a different experience from manning the demo booth, and overall pretty cool to see the more customer-facing side of product development in action."
tanzu,And some fun!
tanzu,"Intern Day at VMworld, hanging out with intern friends :)
At the end of the day, I met up with other VMware interns who came for VMworld‚Äôs Intern Day event and wandered Solution Exchange for the Hall Crawl, grabbing lots of snacks and free swag!"
tanzu,"Spending VMworld so far with my team members, experts, and among a more professionally experienced crowd, it was fun to kick back a bit with friends and exchange stories and favorite experiences from the day."
tanzu,"With two packed days of learning and excitement conquered, and only one day left‚Ä¶bring on Day 3!"
tanzu,Monday General Session!
tanzu,Today was the first day of my first time ever at VMworld and it was an electrifying first experience to be here with my team for the reveal of Project Pacific ‚Äî the Kubernetes in vSphere workload platform my team had worked hard on for the past few years.
tanzu,"This summer, I have been privileged to join VMware as an intern with the vSphere and Project Pacific Product Management team, and I couldn‚Äôt ask for a better way to end my summer than at VMworld."
tanzu,Few things come close to the excitement of witnessing firsthand the public unveiling of Project Pacific and the buzz it‚Äôs creating.
tanzu,"From starting off the day with a packed auditorium Monday General Session by CEO Pat Gelsinger introducing VMware Tanzu including Tanzu Mission Control and Project Pacific, to dropping in between breakouts to my team‚Äôs demo booth, it goes without saying that Project Pacific is the highlight of my day 1."
tanzu,"Monday General Session: VMware is changing the game for multi-cloud and hybrid cloud applications

Kubernetes is an ubiquitous infrastructure that connects developers and operations."
tanzu,"CEO Pat Gelsinger kicked off Monday with an engaging General Session in which he discussed topics ranging from industry trends, the morality of technology, areas of impact, and VMware‚Äôs strategy in the multi-cloud and hybrid cloud domains."
tanzu,I was primarily engaged by his discussion of VMware Tanzu.
tanzu,"Some key points of interest:
Welcome Pivotal!"
tanzu,"VMware announced the acquisition of Pivotal to expand their portfolio of services available to efficiently build, run, and manage Kubernetes application across any cloud and any platform."
tanzu,Pivotal fits into VMware‚Äôs multi-cloud strategy and VMware Tanzu portfolio.
tanzu,Welcome Carbon Black!
tanzu,"Pat also announced the acquisition of Carbon Black to deliver enterprise-grade security for workloads, applications and networks spanning from device to cloud."
tanzu,Carbon Black fits into VMware‚Äôs multi-cloud security strategy.
tanzu,Introducing Tanzu!
tanzu,"Project Pacific: Kubernetes in vSphere
VMware Tanzu is a portfolio of services to build modern apps, run enterprise Kubernetes, and manage Kubernetes for Devs and IT Ops."
tanzu,"Tanzu will help you:
Build Modern Apps: Bitnami allows for flexible and efficient packaging and deploying of modern apps, while Pivotal, a pioneer in microservices and containers, is a leading cloud native platform provider that greatly enables multi-cloud app development."
tanzu,"Run Enterprise Kubernetes: Project Pacific is the rearchitecturing of vSphere with Kubernetes, extending vSphere for all modern application workloads, and enabling DevOps to collaborate more efficiently as well as empower developers and operators to work flexibly without overstepping or misaligning with the other."
tanzu,(More on this below!)
tanzu,"Manage Multi-cloud, Multi-cluster, Multi-team: Tanzu Mission Control is a control plane that is cloud neutral and allows for the management of all Kubernetes clusters and workloads from one central control point."
tanzu,"Aside from these and other (which I won‚Äôt delve into here) important announcements about VMware‚Äôs technological innovation, I was heartened by presentations of VMware technology‚Äôs impact through partnerships such as with techsoup, and support for customers like Angel MedFlight."
tanzu,"Beyond an interest in the technology that VMware brings to the table, to see the tangible and positive impacts accomplished by VMware products and people is among the coolest experiences I have at VMware and VMworld."
tanzu,"Introducing Project Pacific: Transforming vSphere into the App Platform of the Future

In this afternoon breakout session, Kit Colbert, CTO of Cloud Platform, discussed in depth why and how Project Pacific was tranforming vSphere."
tanzu,My team also used the above slide at our demo booth.
tanzu,"To briefly explain it:
Project Pacific embeds Kubernetes into the control plane of vSphere to unify control of compute, network, and storage resources."
tanzu,"ESXi Clusters will also function as Kubernetes Clusters, and networking and storage will be integrated such that all three components will be manageable via the Kubernetes native interface."
tanzu,"Modern applications are and will increasingly be built across Kubernetes Clusters, VMs, and vSphere Native Pods."
tanzu,"Project Pacific will allow for a declarative specification for all types of objects in a workload, and will allow for an application workload to be managed as a unit instead of management of individual VMs and clusters."
tanzu,Developers get self-service access across namespaces and resource pools assigned to them by IT Ops; Operators get to set policy and manage across namespace units without worrying about the workloads running inside.
tanzu,"I will be presenting my own in depth look at Project Pacific soon on this blog, but for the time being, the following links in addition to the above hyperlinks provide a good first glance."
tanzu,Struggling to move workloads to the cloud?
tanzu,"VMware's new tech may be the perfect on-ramp
VMware's new Project Pacific is a big step forward for VMware's Kubernetes offerings, but it's more important for what‚Ä¶
www.techrepublic.com

VMware vSphere goes Kubernetes native
As much as enterprises might want to modernize IT and go cloud, it's still a stubborn fact that 95 percent of IT‚Ä¶
www.infoworld.com

After spending the summer in internal discussion and seminars about Project Pacific through many changes in terminology and among a familiar team, it was very exciting to watch a presentation and dialogue with a fully engaged audience."
tanzu,I‚Äôm pretty excited to continue watching the ripple effect of Project Pacific discussion in the coming days and in subsequent breakout sessions.
tanzu,We ‚ù§ Project Pacific!
tanzu,My team and I at our demo booth!
tanzu,"Amidst exploring Solution Exchange, hustling to attend different sessions throughout the day, and browsing all manners of online resources and VMworld social media engagement, the Project Pacific demo booth was a steadfast anchor to which I returned, each time to an engaged crowd gathered around my team."
tanzu,"My first experience at VMworld thoroughly humbled and awed me more than I can process in this simple blog and single day‚Äôs reflection‚Ä¶nonetheless, onwards to day 2!"
tanzu,"Redis is a fast, open source in-memory data structure store, used as a database, cache, and message broker."
tanzu,"Redis provides data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyper loglogs, geospatial indexes, and streams."
tanzu,While implementing cloud native applications we mostly implemented only stateless applications so there is no option to persist the session.
tanzu,Some of web systems rely on sticky sessions that means maintaining user session in app server memory It‚Äôs violation of 12 factor rules.
tanzu,To store this kind of sticky session we can use Redis.
tanzu,Here I‚Äôm focusing on how to connect Redis with help of Steeloe Redis Service connector on Cloud Foundry (i.e.
tanzu,"PCF | TAS)

Tech Stack
Use case:
For example: Let‚Äôs take a Redis List."
tanzu,It‚Äôll hold the list of strings & we can push the elements from Left or Right.
tanzu,"Let‚Äôs assume if User insert the data in form once submitted, we can push the data in to Redis list & display All inserted records & provide an option to user to delete record from Redis Cache DB."
tanzu,Note: It‚Äôs not a valid business use case But here I‚Äôm focusing How to push data into Redis List & Consume those records.
tanzu,How to utilize the steeltoe service connector on Tanzu application service | PCF Platform.
tanzu,"Prerequisites:
1."
tanzu,PCF account (i.e.
tanzu,"PCF part of VMware Tanzu https://login.run.pivotal.io/login It may differ )
2."
tanzu,CF CLI Installation (i.e.
tanzu,https://docs.run.pivotal.io/cf-cli/install-go-cli.html ) ‚Äî Windows Platform choice.
tanzu,3.
tanzu,.Net 5 with Blazor Framework (i.e.
tanzu,"we can choose lower versions also)
4. steeltoe Packages from NuGet."
tanzu,5.
tanzu,Create a .net core supported version of build packs with PCF.
tanzu,"Note: I‚Äôm using previous BlazorApp1 project for redis cache insert, delete & get all keys related information ."
tanzu,for more details about code visit below articles.
tanzu,"Service Registry pattern
Config server
Create a Redis service using CF CLI."
tanzu,Please make sure to enable the Redis service option on marketplace within your ORG.
tanzu,"cf create-service p.redis CACHE_PLAN SERVICE_NAME // Syntax 
Example : 
cf create-service REDISSERVICE Trial  redisCacheTempDb
Example:
Add below NuGet packages:

NuGet packages
Update the Startup.cs file like below."
tanzu,"Startup.cs
Update the Program.cs file

Program.cs
Create a ProductInfo model class like below

Product Info Model class
Add sample blazor Form like below

M1service.razor
Update M1service.cs file like below

M1service.cs
Update Ms1.cs like below

Ms1.cs
Display inserted Redis DB data

M2service.razor
Update M2service.cs file

M2service
Update Ms2.cs get all

Ms2.cs -1

Ms2.cs -2 Delete
Update manifest.yml file

manifest.yml
Update Appsettings.json file with Redis Key Name & Enable Redis connection within app."
tanzu,"Appsettings.json
Redis client connector settings we can customized with different values based on use case."
tanzu,"Redis Client Connector Options
Publish the BlazorApp1 into PCF by using CF CLI ."
tanzu,If you‚Äôre using CI/CD pipeline means we need to configure according to pipeline rules.
tanzu,For now we can deploy through manual by using CF CLI.
tanzu,a.
tanzu,Publish BlazorApp1 into any local directory (i.e.
tanzu,C:\Blazor\).
tanzu,Make sure manifest.yml should be in published location.
tanzu,b. Login CF CLI & select corresponding Space with help of CMD.
tanzu,c. After login into PCF navigate to published location within same CMD CF CLI login session (i.e.
tanzu,"cd C:\Blazor\ )
d. After navigated into published location BlazorApp1 App then type cf push
e. You‚Äôre able to see deployment completed status logs of PCF in CMD."
tanzu,"Bound services of BlazordemoUI App like below

Bound services
Go To settings of Environment Variables VCAP_SERVICES of Deployed App we‚Äôre able to see bounded service details."
tanzu,"Environment Variables
After deployment UI like below

Sample Blazor Form

List page Redis Cache Data"
tanzu,"While vSphere with Kubernetes gaining adoption across all sort of business domains, the product team released the latest update to add a couple of features to the Tanzu Kubernetes Grid Services (TKGs)."
tanzu,The latest update provides the following key features to the Tanzu Kubernetes Grid services.
tanzu,"Native Registry Service trust
HTTP/HTTPS proxy support
Custom disk creation on TKGs nodes
Native Trust to the Integrated Registry Service
In this blog, I explore a design approach that focuses on the Native Registry Service Trust feature."
tanzu,Container Image Registry plays an essential role in the Cloud Native Development environment.
tanzu,One of the Kubernetes deployment‚Äôs mandatory configuration requirements is establishing the trust between the Container Runtime in the Nodes and the Container Image Registry.
tanzu,It allows the Container Runtime of the Nodes to pull the Images once the Kubernetes scheduler schedule the Pods on the respective Nodes.
tanzu,The problem with the environments where registries use self-signed certificates is that the CA certs need to be distributed across the nodes manually or during the cluster bootstrap phase.
tanzu,vSphere with Tanzu provides an Integrated secure Registry based on Harbor.
tanzu,"In vSphere with Kubernetes and NSX-T, with a Mouse Click, you could enable the Integrated registry."
tanzu,The registry provides native authentication as well as automatically create Projects corresponding to the Supervisor Cluster Namespaces.
tanzu,"Even though the Supervisor Cluster Nodes ( ESXi hosts) trust the Integrated Registry CA Certificates, the Tanzu Kubernetes Service (TKGs) Nodes do not automatically trust the Integrated Registry‚Äôs CA Certificate."
tanzu,"To establish trust between TKGs nodes and Integrated Harbor Registry, the platform admin needs to copy the CA Certificate manually across the TKGs nodes."
tanzu,"Since the TKGs nodes can be scaled-out and scaled-in based on the compute requirement, the consistent distribution of the CA Certificates is a painful operational task."
tanzu,The latest patch/update for the vSphere with Tanzu helps distribute the Integrated Registry Certificate during the TKGs bootstrap(Kubeadm Config) and avoid the manual process to populate the Integrated Registry CA Certificate across the TKGs nodes.
tanzu,"Though the native Harbor Registry of the vSphere/VCF with Tanzu provides a Secure and Integrated experience, it has only a limited set of features."
tanzu,The Integrated registry has not yet ported all upstream Harbor Registry features.
tanzu,"If those users are looking for a feature-rich OCI registry ‚Äî for example OCI Artifact Repository, Image Synchronization, Image Scanning, Flexible Authentication Model, etc."
tanzu,‚Äî still need to deploy either Harbor or another Non-Harbor OCI registry.
tanzu,"But if the user chooses to configure the external registry with a self-signed certificate, they end up with the requirement to port the CA certificate to all TKGs cluster nodes."
tanzu,"To save the situation, let us discuss an alternative Image Registry Infrastructure design."
tanzu,"Harbor is a Complete OCI registry, and it comes with a whole bunch of features to provide OCI registry requirements of a CI/CD environment."
tanzu,One of the cool features of the Harbor is its Replication Feature.
tanzu,The Replication Feature allows configuring Images or OCI Artifacts replication from one Harbor to another Harbor or another non-harbor OCI registry.
tanzu,The Replication Function can invoke using the following methods.
tanzu,"Manual Replication
Cron based Scheduler
Event-based (for example: An Image Push is an Event) Replication
Let us see how the event-based replication feature of Harbor could help to provide a solution to the problem."
tanzu,"Fig:1 External Harbor Registry as Part of the CI/CD Infrastructure
External Harbor Registry as Part of the CI/CD Infrastructure
As illustrated in the Diagram, Consider deploying an External Instance of the Harbor Registry, with all its cool features."
tanzu,This Instance of the harbor registry could act as a Point of Truthfor the Images and OCI artifacts in the CI/CD infrastructure.
tanzu,The External Harbor can run as a Kubernetes Service on the TKG clusters (preferred way) or on a Virtual Machine.
tanzu,"There are multiple types of distributions ‚Äî TKG Extensions, Bitnami Helm Charts, Harbor Compose, etc."
tanzu,‚Äî that are available to deploy Harbor Registry.
tanzu,"You may refer to some of the URLs provided at the end of the article, for the installation steps."
tanzu,Here I brief a design where External Harbor functions as the Central OCI Registry with the following Configurations.
tanzu,Create the Projects corresponding to the Projects in the Integrated Harbor registry at the External Harbor Registry too.
tanzu,Images and OCI artifacts push to the External Harbor Registry‚Äôs respective Projects as part of the CI/CD workflow.
tanzu,Configure an endpointto define the Integrated Harbor Registry as the Destination.
tanzu,Event-based Replication Pushes the Image changes at the External Registry to the corresponding Projects in the Integrated Harbor Registry.
tanzu,"Configuration Steps
To configure the Replication from the external to the Integrated registry, you need to get the Administrator username and password of the integrated Harbor Registry."
tanzu,"Due to the RBAC model of the vSphere with Tanzu platform, the SSO users ‚Äî even the administrator user- cannot access the objects like secrets, configmaps etc‚Ä¶
To get the Secret containing the Integrated Harbor Administrator Credentials, you need to execute the `kubectl` commands from the Supervisor Cluster Control plane Nodes."
tanzu,It allows you to perform tasks with the Supervisor Cluster-Admin privileges.
tanzu,"Step -1
1.1 Find the Namespace of the Integrated Harbor Registry from the VCenter Workload Management View."
tanzu,"Fig:2 Integrated Harbor Registry Namespace

Step-2
2.1 Login to the VCenter using your Credentials:
ssh root@<VCenter IP>
2.2 Execute the following Command after switching to shellto fetch the root User Passwordof the Supervisor Control Plane VMs."
tanzu,"/usr/lib/vmware-wcp/decryptK8Pwd.py
You get a really long Password (keep it safe!!!"
tanzu,that is your super-secret password of the Supervisor Control Plane root user.)
tanzu,"2.3 Login to one of the Supervisor Control Plane VMs Management Interface (Preferably the etcd Master ‚Äî The VM with two Management CIDR IPs)
ssh root@<Supervisior Control Plane VM Management IP>
Step-3
3.1 List the Secrets in the Integrated Registry Namespace
kubectl get secrets -n vmware-system-registry-1675912230
The Harbor Administrator Credentials are in the secretwith the name harbor-<id>-controller-registry
Please note, you see a different id in your installation."
tanzu,"Replace the idwith the one, you find in your environment."
tanzu,3.2 Execute the following Command to Extract the Harbor Administrator User Name.
tanzu,"kubectl get secret harbor-1675912230-controller-registry  -n vmware-system-registry-1675912230 -o jsonpath='{.data.harborAdminUsername}' | base64 -d | base64 -d
3.3 Execute the following Command to Extract the Harbor Administrator Password
kubectl get secret harbor-1675912230-controller-registry  -n vmware-system-registry-1675912230 -o jsonpath='{.data.harborAdminPassword}' | base64 -d | base64 -d
Step-4
Now it is time to configure the Replication in the External Harbor Registry."
tanzu,"As a reference configuration for this article, I created a Supervisor Cluster Name Space,tkgs-demo(Using the Workload Management Option of the vCenter)."
tanzu,A project with the same name automatically created in the Integrated Harbor Registry.
tanzu,"4.1 Create a Project with the same name in the External Harbor Registry
Fig:3 Create a Project in the External Harbor
Create New Project in the External Harbor
4.2 Define the Integrated Harbor as an EndPointin the External Harbor Registry."
tanzu,Provide the Integrated Harbor URL and Credentials while configuring the End Points.
tanzu,Test and Verify the Successful Communication between the registries.
tanzu,"Please note, uncheck the box Verify Remote Certto skip the Certificate verification."
tanzu,"Fig:4 End Point Configuration

Select Harbor as the Provider
Give a Name for the endpoint
Provide the URLof the Integrated Harbor Registry
Enter the Integrated Harbor Administrator User Name (Ref 3.2)
Enter the Integrated Harbor Administrator Password (Ref 3.3)
Uncheck Verify Remote Certto skip the Integrated Harbor Certificate Verification
After Configure the parameters Test Connection and press OK
4:3 Configure the Replication from the External Harbor Registry to the Integrated Harbor Registry."
tanzu,"Fig:5 Replication Rule Configuration

Give a Name for the Replication Rule
Choose Push based replication
Provide the Name of the Project to Create a Source Filter to omit the other Projects from the Scope of the Replication."
tanzu,"Optionally you can create additional filer rules based on Tags, Label, etc."
tanzu,"Select the EndPoint created in the previous step as the Destination
Enter the Destination Namespace
Select Event-Based as the Trigger Mode."
tanzu,7 &8.
tanzu,Optionally Select the remaining two Tick boxes to define this (External)Instance of the Harbor as the Source of Truth for the images.
tanzu,"Step:5
Now is the time to test the Event-Based Replication from the External Registry to the Integrated Registry."
tanzu,"5:1 Login to the External Harbor Registry Using the Docker Client
docker login <External Harbor URL/IP>
5:2 Tag an Image with the External Harbor Repository Path
docker tag <ImageID> <External Harbor URL/IP>/tkgs-demo/<Image Name>:<Tag>
5:3 Push the Image to the External Registry
docker push <External Harbor URL/IP>/tkgs-demo/<Image Name>:<Tag>
5:4 Verify the Image in the External Registry

5:5 Login to the Integrated Harbor Registry and Verify the availability of the Image in the Project."
tanzu,"Step:6
In this step, deploy a Pod using the replicated Image."
tanzu,( A basic smoke test!!!)
tanzu,*It is assuming that there is a TKGs cluster running in the namespace tkgs-demo and you currently logged in and switched to the TKGs context.
tanzu,"6.1 Creare a Namespace in TKGs (for example: tkgs-demo)
kubectl create ns tkgs-demo
6.2 Create an Image Pull Secret to authenticate with the Integrated harbor Registry
kubectl create secret docker-registry regcred --docker-server=<Integrated Harbor IP> --docker-username=<TKGs User Name> --docker-password=<TKGs Password> --docker-email=<*Optional Email> -n tkgs-demo
*Please note, TKGs is using Pod Security Policy to control the security-sensitive aspects of the pod specification."
tanzu,You may create appropriate Role Bindings to allow the Successful creation of the Pods in TKGs.
tanzu,"Ref: https://docs.vmware.com/en/VMware-vSphere/7.0/vmware-vsphere-with-tanzu/GUID-4CCDBB85-2770-4FB8-BF0E-5146B45C9543.html
6.3 Create a Pod manifest with Image Pull Secret

6.4 Check the status of the Pod
**Sample Output
[root@centos-wkstn tkgs]# kubectl  get po -n tkgs-demo
NAME            READY   STATUS    RESTARTS   AGE
tkgs-demo-pod   1/1     Running   0          91s
Conclusion
In the article, I explored a possible Registry Infrastructure design, which works in tandem with the new features available in Tanzu Kubernetes Grid Services part of the vSphere/VCF with Tanzu."
tanzu,"Even though the integrated Harbor Registry provides the essential functions for a CI/CD environment, many users prefer to deploy an External OCI registry to utilize the additional features."
tanzu,The design‚Äôs objective is to avoid the error-prone process of distributing the External Registries‚Äô CA Certificateacross the TKGs cluster.
tanzu,"In the design, I considered an External Harbor Registry as the Source of Truth for the CI/CD infrastructure."
tanzu,"Suppose you wish to go with a non-harbor registry in its place, you may configure an additional, Scheduler based Pull Replicationbetween the Non-Harbor and External Harbor Registry."
tanzu,"In that case, the External Harbor can act as an Intermediate Registry, where it pulls the Images from the Non-Harbor registry in a scheduled mode and Push to the TKGs Integrated Harbor Registry using Event-based replication."
tanzu,Following from our last three posts.
tanzu,There are three primary ways of standing up Kubernetes on vSphere.
tanzu,Each with there own benefits and drawbacks.
tanzu,This post will be the final post of our tree part post looking at VMware‚Äôs TKGS.
tanzu,"Tanzu Kubernetes Grid (TKG)
Deploy Kubernetes via Tanzu (TKG) without the need for a licensed Tanzu supervisor cluster."
tanzu,This does not provide a load balancer.
tanzu,"Tanzu Kubernetes Grid Service (TKGS)
Deploy and operate Tanzu Kubernetes clusters natively in vSphere with HA Proxy as the load balancer."
tanzu,Without VMware Harbor as a container repository.
tanzu,"- Deploying and configuring HA Proxy
- Deploying workloads via the supervisor cluster
- Creating namespaces and initial cluster configuration (this post)
VMware Tanzu Kubernetes Grid Integrated Edition (TKGI)
Fully featured Tanzu deployment with NSX-T.
- Deploying and configuring NSX-T
- Deploying workloads via the supervisor cluster
- Creating namespaces and initial cluster configuration
Prerequisites
If you haven‚Äôt already please read through our first post on TKGS as it provides a lot of detail on what TKGS is and the configuration we‚Äôll be using for our deployment."
tanzu,Further to the first post.
tanzu,Our second post covers the initial setup and configuration of the supervisor cluster.
tanzu,Which is required in order to create your first namespace.
tanzu,"Deploying TKGS Namespaces
No that we‚Äôve stood up and successfully configured and tested both our HA Proxy and supervisor cluster."
tanzu,The next stage is to deploy our first namespace.
tanzu,Each namespace will have its own Kubernetes cluster.
tanzu,With its own subsequent Kubernetes namespaces.
tanzu,Where you‚Äôll be able to deploy Zercurity and any other Kubernetes deployment.
tanzu,From our last post the context we were using was that of our supervisor cluster.
tanzu,For this next step we‚Äôll create our namespace and then use this new namespace as our next context from which we‚Äôre going to stand up our Kubernetes cluster.
tanzu,"Namespace creation
From the vSphere dashboard."
tanzu,"Click again on the Workload Management icon and from there make sure you‚Äôre on the Namespaces tab and click, New namespace."
tanzu,This will open the dialog below.
tanzu,Select our primary cluster used by our supervisor cluster.
tanzu,Give your namespace a name.
tanzu,We‚Äôre using production.
tanzu,"However, you may choose to dive these up by teams or projects."
tanzu,Or maybe if you‚Äôre resource constrained everything will just live under one namespace.
tanzu,Once you‚Äôve created your new namespace.
tanzu,Click on the namespace name which will take you to the namespace overview pane.
tanzu,"Adding permissions
From here we can our current user to the namespace with edit permissions."
tanzu,This can be done for additional users that require management access to the cluster.
tanzu,This will enable them to add additional nodes and provisioning requirements.
tanzu,"Adding storage
More importantly, we also need to let the namespace know which storage policies are available to it for persistent volume claims (PVC)."
tanzu,"Awesome, we‚Äôre ready to create our cluster."
tanzu,"Creating our cluster spec
If you‚Äôre still logged from our last post."
tanzu,You can use the logout command to close your session to the supervisor cluster.
tanzu,"$ kubectl vsphere logout
$ kubectl vsphere login --server=10.64.32.1 --insecure-skip-tls-verify
Here you‚Äôll be prompted for your login credentials and once you‚Äôve successfully authenticated you should be able to see the production context listed."
tanzu,"$ kubectl config use-context production
Now in order for us to create our Kubernetes cluster we need to create a spec to let the supervisor cluster know what to provision."
tanzu,Below is an example spec you can use.
tanzu,This spec will create one control plane and 3 worker nodes.
tanzu,If you‚Äôre planning on deploying a larger cluster then you can simply increase the number of workers and I wold set the control plane nodes to 3.
tanzu,To provide some redundancy.
tanzu,Create this file as tkgs-cluster-production.yaml .
tanzu,Anything defined within the spec can be updated at a later date.
tanzu,Some downtime will be incurred.
tanzu,"However, the cluster will come back up."
tanzu,"apiVersion: run.tanzu.vmware.com/v1alpha1
kind: TanzuKubernetesCluster
metadata:
  name: zercurity
  namespace: production
spec:
  distribution:
    version: v1.18.5
  topology:
    controlPlane:
      count: 1
      class: best-effort-small
      storageClass: tanzu-storage-policy
    workers:
      count: 3
      class: best-effort-small
      storageClass: tanzu-storage-policy
The storageClass will need to be the name of your storage policy."
tanzu,This will be all lower case.
tanzu,If you have used spaces then use hyphens as a substitute.
tanzu,You can check the policy name using $ kubectl get sc command.
tanzu,Which will retrieve the available storage classes.
tanzu,You can then copy over the name.
tanzu,As for the class this represents the instance size you want to provision.
tanzu,"You can get a list of the available instance types like so:
$ kubectl get virtualmachineclasses
The best-effort prefix will thinly provision resources."
tanzu,Where as the guaranteed prefix will allocate all the resources required to the VM.
tanzu,"You can get a detailed breakdown on the VM class with:
$ kubectl describe virtualmachineclasses best-effort-small
Once you‚Äôve created your spec file."
tanzu,"Deploy it like so:
$ kubectl apply -f tkgs-cluster-production.yaml
If there are no errors the shell will return."
tanzu,"You can check on the status of the creation of the cluster with the command:
$ kubectl get tanzukubernetescluster
$ kubectl get cluster
The status of the creation of he cluster will also be visible from the GUI."
tanzu,"Troubleshooting
Should you run into any issues there are a number of commands you can use to get an idea of what might be going wrong."
tanzu,"$ kubectl get machines
$ kubectl get virtualmachines
$ kubectl get cluster
$ kubectl describe tanzukubernetescluster
On the last command."
tanzu,Check that all the add-ons have the status of applied.
tanzu,"Error: ErrImagePull
If you‚Äôre getting image pull errors whilst the containers are creating then check that both the VMs being provisioned are route-able to the internet and that DNS is working to resolve domain requests."
tanzu,If you still have issues.
tanzu,Then try simplifying your deployment.
tanzu,We ended up having to create a separate cluster to troubleshoot some inter-VLAN routing issues.
tanzu,"Creating a default storage class
By default there is no default storage class provided (kubectl get sc)."
tanzu,"You‚Äôll have to manually specify the storage class when deploying for example helm apps like so:
helm install harbor bitnami/harbor --set global.storageClass=tanzu-storage-policy ...
To overcome this we need to update the running cluster spec to set our default storageClass."
tanzu,"kubectl edit tanzukubernetescluster zercurity
Then under the settings section add:
spec:
  distribution:
    fullVersion: v1.18.5+vmware.1-tkg.1.c40d30d
    version: v1.18.5
  settings:
    network:
      cni:
        name: antrea
      pods:
        cidrBlocks:
        - 192.168.0.0/16
      serviceDomain: cluster.local
      services:
        cidrBlocks:
        - 10.96.0.0/12
    storage:
      defaultClass: tanzu-storage-policy
Once you‚Äôve made the changes highlighted in bold."
tanzu,Exit the editor and then you can check you‚Äôre cluster storage spec (you‚Äôll need to login to the namespace first.
tanzu,See the accessing the cluster section).
tanzu,"$ hugh@hugh-ubuntu-dev-2004:~$ kubectl get sc
NAME                             PROVISIONER              
tanzu-storage-policy (default)   csi.vsphere.vmware.com  ...
Accessing the cluster
As with before."
tanzu,Logout of the previous session.
tanzu,This time we‚Äôre going to add our new cluster name and namespace parameters.
tanzu,"$ kubectl vsphere logout
$ kubectl vsphere login --server=10.64.32.1 --insecure-skip-tls-verify --tanzu-kubernetes-cluster-namespace production --tanzu-kubernetes-cluster-name zercurity
Once you‚Äôve logged in."
tanzu,Set the context to your new cluster.
tanzu,"$ kubectl config use-context zercurity
You can then check the status of all pods."
tanzu,"kubectl get pod -A
Deploying harbor
Harbor is an opensource container repository."
tanzu,"Not only does it provided permissioned access to pull and push docker images but it also provides vulnerability scanning, webhooks and other functionality."
tanzu,As we‚Äôve mentioned before Harbor cannot be deployed as part of TKGS through the vSphere management portal.
tanzu,"The option for Container repository simply isn‚Äôt there unless you‚Äôre using NSX-T. You can however, still deploy Harbor via helm."
tanzu,"$ kubectl create ns harbor
$ helm install harbor bitnami/harbor \
--set harborAdminPassword='adminpass' \
--set global.storageClass=tanzu-storage-policy \
--set service.type=LoadBalancer \
--set externalURL=harbor.test.corp \
--set service.tls.commonName=harbor.test.corp \
-n harbor
$ helm uninstall harbor -n harbor
You can check on the deployment status like so:
$ kubectl get pod -n harbor
NAME                                  READY  STATUS    RESTARTS  AGE
harbor-chartmuseum-657b95d5f7-fxzll   1/1    Running   0          9d
harbor-clair-586d8cf9f6-rhzzd         2/2    Running   0          9d 
harbor-core-5cd79cc5f6-2r2sw          1/1    Running   4          9d
harbor-jobservice-b6fff8654-kvnmn     1/1    Running   5          9d
harbor-nginx-55d7d6d846-vfr6c         1/1    Running   0          9d
harbor-notary-server-8695c547f5-hrvft 1/1    Running   0          9d
harbor-notary-signer-5647c4968c-pqwmc 1/1    Running   0          9d
harbor-portal-54cc4dbc8c-dgswz        1/1    Running   0          9d
harbor-postgresql-0                   1/1    Running   0          9d
harbor-redis-master-0                 1/1    Running   0          9d
harbor-registry-dd67784b8-hbthw       2/2    Running   0          9d
harbor-trivy-0                        1/1    Running   0          9d
Once everything is running you can get the external IP address of the LoadBalancer service:
$ kubectl get svc -n harbor
If you connect to this address you should see the harbor service up and running:

Its all over!"
tanzu,This is our last part into standing up TKGS on vSphere.
tanzu,We hope you found it helpful.
tanzu,Please feel free to get in touch if you have any questions.
tanzu,Following from our last two posts.
tanzu,There are three primary ways of standing up Kubernetes on vSphere.
tanzu,Each with there own benefits and drawbacks.
tanzu,This post will be the second of three looking at VMware‚Äôs TKGS.
tanzu,"Tanzu Kubernetes Grid (TKG)
Deploy Kubernetes via Tanzu (TKG) without the need for a licensed Tanzu supervisor cluster."
tanzu,This does not provide a load balancer.
tanzu,"Tanzu Kubernetes Grid Service (TKGS)
Deploy and operate Tanzu Kubernetes clusters natively in vSphere with HA Proxy as the load balancer."
tanzu,Without VMware Harbor as a container repository.
tanzu,"- Deploying and configuring HA Proxy
- Deploying workloads via the supervisor cluster (this post)
- Creating namespaces and initial cluster configuration
VMware Tanzu Kubernetes Grid Integrated Edition (TKGI)
Fully featured Tanzu deployment with NSX-T.

- Deploying and configuring NSX-T
- Deploying workloads via the supervisor cluster
- Creating namespaces and initial cluster configuration
Prerequisites
If you haven‚Äôt already please read through our first post on TKGS as it provides a lot of detail on what TKGS is and the configuration we‚Äôll be using for our deployment."
tanzu,"Deploying TKGS Workloads
No that we‚Äôve stood up and successfully configured and tested our HA Proxy."
tanzu,The next stage is to deploy our supervisor cluster.
tanzu,This will manage subsequent Kubernetes clusters.
tanzu,"Managing and orchestration, deployment, and management of TKGS clusters."
tanzu,"vSphere workload Management setup
Head on over to your vSphere dashboard."
tanzu,Under shortcuts you‚Äôll see Workload management.
tanzu,When you click on this link.
tanzu,You‚Äôll be presented with a few options.
tanzu,If you see the example below.
tanzu,Your organization is already licensed for Tanzu supervisor clusters.
tanzu,This is a new licensing model separate to the commented model of ESX + Kubernetes.
tanzu,You will require one of these new licenses.
tanzu,"During this transition period however, VMware does provide a 60 day trial."
tanzu,Which you can use freely.
tanzu,Post expiration your cluster will continue to function.
tanzu,Though all management functionality will be disabled.
tanzu,Once you have the following screen below.
tanzu,Ensure that NSX-T option is unavailable.
tanzu,If NSX-T is available you may want to deploy Tanzu on NSX-T.
tanzu,This is the TKGI version of Tanzu.
tanzu,Which is the preferred method of installation given the additional support and functionality included with NSX-T.
tanzu,"Installing TKGS on vCenter Server Network (Supports Tanzu Kubernetes clusters)
Once you‚Äôve chosen the vCenter Server network as your installation option."
tanzu,The Workload management screen will prompt you to choose a destination cluster for installation.
tanzu,This will perform pre-flight checks.
tanzu,If no cluster is available choose the incompatible tab so see the reason given for the incompatibility in order to resolve it.
tanzu,This will most likely be a licensing issue.
tanzu,"Pre-flight Tanzu checks
The control plane size depends on the size of your deployment."
tanzu,In most cases you‚Äôll be fine will a Small VM.
tanzu,Three VMs will be deployed with the specification shown.
tanzu,This will form the supervisor cluster.
tanzu,"Supervisor cluster sizing options
Right, onto the next step which is to choose the storage policy we created earlier."
tanzu,Which was a clone of the default vSphere storage policy.
tanzu,Choose your Tanzu storage policy from the list and click next.
tanzu,This load balancer section refers to both your management IP address for your HA Proxy server and the load balancer IP addresses we defined for our frontend network.
tanzu,"For reference here they are again:
Management network (VLAN 26)
Management IP: 10.64.2.10
Frontend network (VLAN 28)
Load balancer address: 10.64.1.1‚Äì10.64.1.254 (10.64.1.0/24)
It is critically important that the information entered here reflects that defined in our HA Proxy configuration."
tanzu,"Otherwise, you‚Äôll run into all sorts of obscure setup errors."
tanzu,"Name
This is the DNS name of our HA Proxy."
tanzu,This will be the first part of the host name you entered during the HA Proxy setup.
tanzu,"Type
Only HA Proxy is available at the moment ‚Äî so HA Proxy it is."
tanzu,"Data plane API addresse(s)
This is the IP address of the management IP address you provided."
tanzu,Including the data plane management API Port which defaults to 5556.
tanzu,"Username
During the last stage of the HA Proxy setup you provided and username and password."
tanzu,This username will be whatever you provided in the HA Proxy User ID field.
tanzu,"Password
This will be the password for the above information."
tanzu,"IP Address ranges for virtual servers
These are the IP address you provided as your Load balancer IP ranges."
tanzu,Which you‚Äôll have provided as a subnet.
tanzu,This field requires them to be provided as a range.
tanzu,In our HA Proxy we provided 10.64.1.0/24.
tanzu,So we‚Äôre going to provide: 10.64.1.1‚Äì10.64.1.254.
tanzu,Its very important that this address range does not overlap with any other services or the HA Proxy server itself.
tanzu,"Server certificate authority
This is the certificate authority you provided at the beginning of the HA proxy setup."
tanzu,If you elected to have you generated automatically for you.
tanzu,Then you‚Äôll need to grab it from the server.
tanzu,You can either download it the certificate by visiting the management server and downloading the PEM via Firefox.
tanzu,"Or you can fetch it from the HA Proxy server like so:
scp root@10.64.2.10:/etc/haproxy/ca.crt ca.crt && cat ca.crt

Configuring HA proxy within the workload manager
The next stage is just to re-provide information about your management cluster."
tanzu,"Network
This is the management virtual distributed switch we created on VLAN 26."
tanzu,"Starting IP Address
Please ensure DHCP is not running on the management network or the IP address have been reserved."
tanzu,The starting IP address is fixed IP address from which the supervisor VMs will be assigned.
tanzu,As there are three by default 10.64.2.50‚Äì10.64.2.52 will be allocated.
tanzu,"Subnet Mask
Your management networks subnet mask (255.255.254.0)."
tanzu,"Gateway server
Your management networks gateway."
tanzu,"DNS server
Your management networks DNS server or your site wide DNS server."
tanzu,"DNS Search domains
Your DNS domain."
tanzu,This says it optional but I would provide one as we‚Äôve found it improves the setup process and mitigates a few issues (see troubleshooting).
tanzu,"NTP server
Try and provide a local NTP server."
tanzu,Or at least use the NTP servers as configured by your ESX hosts.
tanzu,"Configuring the management network
Almost there."
tanzu,The last step now is to configure the workload network itself.
tanzu,I‚Äôd leave the IP address for services alone unless you‚Äôre going to be deploying a large cluster.
tanzu,This IP range is completely internal to Kubernetes and does not reflect any configuration in HA Proxy or the rest of your network.
tanzu,"The DNS server will however, need to either be your workload networks DNS server or your site wide DNS server."
tanzu,"Workload network (VLAN 27)
Management IP: 10.64.8.10
Management Gateway: 10.64.8.1
Network: 10.64.8.0/21
Subnet: 255.255.248.0 (2046 IPs available)
Workload starting address: 10.64.8.50‚Äì10.64.15.150
Next we just need to define our workload network."
tanzu,To do this use the ADD button above the table.
tanzu,"Once we‚Äôve filled everything in it‚Äôll look as follows (the workload network configuration dialogue is documented below):

Workload configuration screen for Tanzu TGKS
The workload network screen."
tanzu,Just as we‚Äôve done in prior steps we just need to re-enter our details.
tanzu,"Name
You can give it any name you like."
tanzu,"However, it must be alpha numeric."
tanzu,"Port group (V27 Tanzu workload)
Select our Tanzu workload port group."
tanzu,The same one HA Proxy uses.
tanzu,"Gateway (10.64.8.1)
Your Tanzu workload gateway IP address."
tanzu,"Subnet (255.255.248.0)
Your Tanzu workload subnet 255.255.248.0 (2046 IPs available."
tanzu,"IP Address ranges (10.64.8.50‚Äì10.64.15.150)
These will be the entire address range you want to be used for VMs being provisioned by the supervisor cluster."
tanzu,These will form your Kubernetes worker nodes.
tanzu,Click next and you‚Äôll see the workload network appear in the table.
tanzu,You can be fine multiple networks.
tanzu,Especially if you have smaller subnets that you need to define within a congested subnet.
tanzu,"Defining our workload cluster
Finally choose our Tanzu Content library."
tanzu,This will provided the installation process with machine templates required for standing up the supervisor cluster.
tanzu,"Tanzu content library
Hey presto!"
tanzu,Review and then re-review all your settings and check they match against those in our HA Proxy.
tanzu,Once the process starts it can take up-to 30 minutes to complete.
tanzu,"So measure twice, cut once."
tanzu,":)

Tanzu setup finalization
Finally click finish and grab a beer."
tanzu,"Tanzu supervisor cluster installation
As the installation kicks off you will see a load of warnings and errors like the one here."
tanzu,This is normal and the setup process will re-try the actions.
tanzu,These errors are usually whilst the system waits for another component to complete is setup.
tanzu,So just be patient the setup can take 15‚Äì30 minutes.
tanzu,"Tanzu errors during setup
Resource Type Deployment, Identifier vmware-system-netop/vmwa-resystem-netop-controller-manager is not found."
tanzu,This error is awaiting the vmware-system-netop image to be pulled and start running.
tanzu,If this issue persists after 30 minutes it is most likely there is a network configuration issue from the management network.
tanzu,Whilst the supervisor cluster is trying to start.
tanzu,Check traffic is routeable on the management network and the DNS server is reachable.
tanzu,"No resources of type Pod exist for cluster domain-c8
Kubernetes cluster  heath endpoint problem at <IP unassigned>."
tanzu,Details: Waiting for API Master IP assignment.
tanzu,This is a common whilst the VM spins up pods for the supervisor pod.
tanzu,Once you can see three healthy looking supervisor VMs and the Namespaces overview showing green.
tanzu,You‚Äôll be ready to deploy your first namespace.
tanzu,Which will contain the kubernetes cluster itself.
tanzu,That you can deploy workloads too.
tanzu,Which we‚Äôll cover in our next post.
tanzu,Our working Tanzu cluster.
tanzu,"Connecting to our new supervisor cluster
Lastly, to check everything is in order."
tanzu,Copy and paste the IP address visible from the Overview pane.
tanzu,"It will lead you to a page like so:

Kubernetes CLI tools landing page
This is our HA Proxy landing page which has automatically be configured to point to the new supervisor clusters."
tanzu,You can ssh onto the HA Proxy node and check the HA Proxy configuration in /etc/haproxy/haproxy.cfg to see whats going on.
tanzu,"Troubleshooting
If you can‚Äôt visit this page."
tanzu,Then first check to see if HA Proxy has been configured.
tanzu,If you still can‚Äôt reach the page check out our HA Proxy troubleshooting steps here.
tanzu,If that still leads to no success you can double check the configuration of your supervisor cluster from the Configuration page of your VMware cluster.
tanzu,"Tanzu configuration settings overview
These settings must match those set in HA Proxy."
tanzu,If there is a miss-match then you‚Äôll have to start over.
tanzu,If you‚Äôre still stuck.
tanzu,Then try deploying everything onto one subnet.
tanzu,Get that working and then move on from there.
tanzu,You can also check the supervisor logs under the monitoring section (Kubernetes Events).
tanzu,These only show events within the past hour.
tanzu,"Kubernetes events
Connecting to the supervisor cluster
Once you‚Äôve download the tool set which is available on Windows, Mac and Linux."
tanzu,"Linux I had to guess the URL manually:
wget https://10.64.32.1/wcp/plugin/linux-amd64/vsphere-plugin.zip
Copy these files into your /usr/local/bin/ directory."
tanzu,Ensuring they‚Äôre executable chmod +x /usr/local/bin/kubectl /usr/local/bin/kubectl-vsphere .
tanzu,"$ kubectl vsphere login --server=10.64.32.1 --insecure-skip-tls-verify

Username: administrator@test.corp
Password: 
Logged in successfully."
tanzu,"You have access to the following contexts:
   10.64.32.1

If the context you wish to use is not in this list, you may need to try logging in again later, or contact your cluster administrator."
tanzu,"To change context, use `kubectl config use-context <workload name>`
Now you‚Äôll have three contexts to choose from."
tanzu,Once you‚Äôve created a few namespaces they‚Äôll also appear here.
tanzu,"Though for now:
$ kubectl config use-context 10.64.32.1
You can then check the status of the supervisor cluster:
$ kubectl get nodes
NAME              STATUS   ROLES    AGE     VERSION
420f1f569680d..   Ready    master   5d17h   v1.18.2-6+38ac483e736488
420fdbfa2080b..   Ready    master   5d17h   v1.18.2-6+38ac483e736488
420fe058fd6bd..   Ready    master   5d17h   v1.18.2-6+38ac483e736488
You can also checkout all of VMware Tanzu‚Äôs available APIs like so helpful for debugging and checking the status of nodes:
kubectl api-resources --namespaced=false
Its all over!"
tanzu,Hopefully that‚Äôs given you a quick dive into standing up TKGS on vSphere.
tanzu,In our next post we‚Äôll be looking at creating our first namespace.
tanzu,Please feel free to get in touch if you have any questions.
tanzu,"VMware Tanzu Portfolio is basically a software collection to build, run and manage modern container applications."
tanzu,Tanzu Application Service (formerly PCF) and Tanzu Kubernetes Grid Integrated (formerly PKS) are main solutions in Tanzu portfolio.
tanzu,"In this article, we will discuss how we monitor these two platforms and applications on them and how it is automated."
tanzu,"Introduction
Why should we monitor something?"
tanzu,That is the key question.
tanzu,Monitoring is important because we want to be ensure that our applications and underlying infrastructures are up and running in a healthy state.
tanzu,What should we monitor?
tanzu,That is the another key question.
tanzu,Answer of this question is not as easy like previous question.
tanzu,There are so many metrics can be monitor.
tanzu,"In most cases, monitoring all available metrics is not a good approach."
tanzu,Because of monitoring too much many metrics can be confusing and it also requires more resource that increases cost.
tanzu,"Monitoring Tool Selection
Monitoring process basically has phase that are collecting, storing and visualization."
tanzu,"When we started to make some research on monitoring for TAS and TKGi, we realized that there are builtin solutions provided by VMware or its partners and also there are open source tools like Prometheus and Grafana."
tanzu,Builtin solutions are easy to to use but they are limited.
tanzu,"As we want to build a central monitoring system for any platform not only for TAS and TKGi, we want to be more flexible."
tanzu,This requirement bring us to Prometheus and Grafana.
tanzu,These tools have huge community support.
tanzu,There are many Prometheus exporter tools available.
tanzu,Coding a custom exporter is very easy.
tanzu,Grafana is very simple to learn and it is very flexible.
tanzu,"So that we decided to use Prometheus Exporters to collect metrics, Prometheus Server to store metrics and Grafana for visualization."
tanzu,"In addition, Alertmanager is used for alerting."
tanzu,There are so many documents available for these tools.
tanzu,I believe giving additional details about these tools unnecessary.
tanzu,"But if you are seeking more information you can follow links for official documentation;
Prometheus, Exporters, Alertmanager and Grafana."
tanzu,"Metric and Exporter Selection
First of all we have to think about what is most important for us."
tanzu,"For example in our case, applications are the most important thing."
tanzu,We host banking applications.
tanzu,Availability and fast response is top priority for us.
tanzu,So that we focused metrics related with these parameters and exporters that can be used for pulling them.
tanzu,Mainly there two types of metrics available for us.
tanzu,Application metrics and platforms metrics that vary by platform.
tanzu,Tanzu Application Service: TAS has builtin metrics and logging mechanism called Loggregator.
tanzu,Logs and metrics from applications and TAS components are collected and transported destination system.
tanzu,It can be seen in the figure below.
tanzu,For more details please continue to Cloud Foundry documentation.
tanzu,"Figure 1: Loggregator Firehose Architecture
In purpose of collecting app metrics we used Firehose Exporter."
tanzu,It is an opensource tool used to collect metrics from Loggregator Firehose system.
tanzu,We preferred to run firehose exporter on TAS but it can be also located in anywhere.
tanzu,"Architecture
As it can be seen in the figure below, there are two main part that are Tanzu Application Service and Tanzu Kubernetes Grid Integrated."
tanzu,Both of them has multiple foundations and clusters.
tanzu,Several Prometheus exporters used to collect metrics of platforms and applications.
tanzu,"In addition, Federated Prometheus architecture used for TKGi environment."
tanzu,"Figure 2: Monitoring Architecture
Central monitoring components Grafana, Prometheus and Alertmanager are installed using BOSH Prometheus release."
tanzu,BOSH Prometheus release is a an opensource project and it is located the repository below.
tanzu,"bosh-prometheus/prometheus-boshrelease
This is a BOSH release for Prometheus, Alertmanager, and Grafana."
tanzu,"It includes the following grafana panels: clock‚Ä¶
github.com

Cloud Foundry BOSH is a project that unifies release engineering, deployment and lifecycle management of applications."
tanzu,"BOSH can create and delete VMS, upgrade or patch operating system, install update and upgrade applications."
tanzu,BOSH also monitor applications and perform failure recovery.
tanzu,"Because of these useful features, we decided to use Bosh releases of Prometheus."
tanzu,"As you can see in Figure 2, there is two main sub part of monitoring architecture."
tanzu,One of them is TAS part and other one is TKGi (Kubernetes) part.
tanzu,We have several foundations that some of them has both TAS and TKGi tiles and some of them has only TKGi tiles.
tanzu,All monitoring related softwares like exporters and federated Prometheus instances are deployed automatically via Concourse Pipelines.
tanzu,We will discuss Concourse automation details in next section.
tanzu,"For TAS environments, a space called monitoring is created."
tanzu,All exporters runs on that space.
tanzu,Each exporter is added to central Prometheus as a target.
tanzu,So that central Prometheus pulls metrics directly from exporter endpoints.
tanzu,"For TKGi environments, monitoring namespace is created in each Kubernetes cluster."
tanzu,Federated Prometheus instances and some exporters are installed on monitoring namespace.
tanzu,There are also system exporters on kube-system and pks-system namespaces for system and kubernetes metrics.
tanzu,"In addition, most of the applications has its own metric publish endpoints."
tanzu,Federated Prometheus instance is configured to discover available pod metrics endpoints and scrape automatically.
tanzu,It can be done creating a scrape config job on Prometheus and assigning required annotations to pods.
tanzu,You can create or modify Prometheus config with configuration below.
tanzu,"apiVersion: v1
data:
  prometheus.yml: |-
    global:
      scrape_interval: 5s
      evaluation_interval: 5s
  scrape_configs:
    - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?"
tanzu,";(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name
You can also set required annotations to your pods."
tanzu,"apiVersion: v1
kind: Pod
metadata:
  annotations:
    prometheus.io/port: ""19000""
    prometheus.io/scrape: ""true""
After configuring both federated Prometheus and Pod annotations, federated Prometheus instance is added as target on central Prometheus."
tanzu,Finally we have all metrics for all platforms and applications in central Prometheus.
tanzu,Bosh Prometheus release also provides us Alertmanager and Grafana.
tanzu,We used these components for alerting and visualization.
tanzu,"Alertmanager
Alertmanager is responsible to handle alerts sent by other applications such as Prometheus."
tanzu,"It basically deduplicates, groups and routes alerts to receivers."
tanzu,"BOSH Prometheus release has predefined alert operators for Bosh, Cloud Foundry and Kubernetes."
tanzu,They are located in ‚Äòmanifests/operators‚Äô folder in the repository.
tanzu,We preferred to use both predefined alerts operator and custom alert rules created by us in our bosh Prometheus deployment.
tanzu,"Sample Bosh Prometheus deployment can be found below
bosh --non-interactive -d prometheus deploy \
manifests/prometheus.yml \
--vars-store vars/deployment-vars.yml \
--var-file bosh_ca_cert=vars/bosh-ca-cert \
-o manifests/operators/monitor-bosh.yml \
-o manifests/operators/monitor-bosh-foundations.yml  \
-o manifests/operators/monitor-cf-foundations.yml  \
-o manifests/operators/monitor-kubernetes-foundations.yml  \
-o manifests/operators/alertmanager-receivers.yml \
-o manifests/operators/custom_rules.yml \
-o manifests/operators/monitor-kubernetes-federation.yml \
...
Grafana
Grafana is a very powerful open source data analytics and visualization tool."
tanzu,Bosh Prometheus release includes Grafana installation and some dashboards ready to use.
tanzu,Dashboard provides by bosh release can be found in ‚Äòmanifests/operators‚Äô folder in the repository.
tanzu,"As you can see in the previous bosh Prometheus deployment command, monitor-‚Ä¶yml files also includes dashboards."
tanzu,"In addition to dashboards provided by bosh release, we also created our custom dashboards contains detailed information our applications run on TAS and TKGi."
tanzu,"Figure 3: Sample Custom Grafana Dashboard
Automation with Concourse
Automation is most crucial part of this monitoring project."
tanzu,Because we do not have a static or small environments.
tanzu,"Every TKGi cluster creation or TAS environment creation we need to install federated Prometheus instances and exporters, need to configure scrape configuration of central Prometheus, need to setup new alertmanager receivers and routes etc."
tanzu,All of these stuff cost so much operational effort unless we have automated tasks.
tanzu,In that purpose we have built automation pipelines using Concourse.
tanzu,Concourse is an open source project present a general approach to automation that makes it great for CI/CD.
tanzu,"Concourse has three basic concepts that are resources, tasks and jobs."
tanzu,Concourse pipelines consists of these three objects.
tanzu,All inputs and outputs of a job called as resources.
tanzu,"It can be docker image, git repository, time or anything else that defined on this link."
tanzu,Tasks are the smallest configurable unit in Concourse.
tanzu,A task can be thought of as a function that can either succeed or fail.
tanzu,It is a reusable object in jobs.
tanzu,Jobs determine the actions of your pipeline.
tanzu,"They determine how resources progress through it, and how the pipeline is visualized."
tanzu,The reason why we selected Concourse as automation tool is it is supported by VMware (Pivotal) and it works perfectly with Tanzu Applications.
tanzu,We already talked about we used Prometheus Bosh release for central monitoring components in previous chapters.
tanzu,"To install and configure Prometheus Bosh release, we built a pipeline called deploy-prometheus."
tanzu,"Figure 4: deploy-prometheus pipeline
In this pipeline, we have defined a repo resource that contains all installation and configuration files including Alertmanager alerts and Grafana dashboards."
tanzu,We also enabled auto trigger option.
tanzu,"So that if something changed in installation or configuration files, pipeline is triggered automatically."
tanzu,"We also dynamically update some configuration files like alertmanager-receivers.yml, monitor-kubernetes-federation.yml."
tanzu,Alertmanager-receivers.yml file stores receivers and routes definitions of alert manager.
tanzu,"When a org or a space is created in a TAS environments, the pipeline responsible for creating orgs and spaces updated alertmanager-receivers.yml file."
tanzu,So that deploy-prometheus pipeline is triggered and related receivers and routes ares created.
tanzu,Monitor-kubernetes-federation.yml file stores federated Prometheus scrape targets.
tanzu,"A pipeline responsible for creating TKGi clusters also installs federated Prometheus, kube-metrics and some exporters in the cluster and then updates monitor-kubernetes-federation.yml file with inserting federated Prometheus target address."
tanzu,"After the repo updated, deploy-prometheus pipelines updates central Prometheus config and central Prometheus starts to scrape metrics of newly created cluster metrics."
tanzu,"We also have some custom alertmanager and scrape config files to store manually updated receivers, routes and targets."
tanzu,Deploy-prometheus pipeline is also triggered automatically when these files updated.
tanzu,So that we have more flexibility over our monitoring systems.
tanzu,"Conclusion
To sum up, we have build a automated monitoring system for both Tanzu Application Service and Tanzu Kubernetes Grid Integrated platform."
tanzu,We preferred Concourse CI for automated tasks.
tanzu,"Installation Bosh Prometheus release, federated Prometheus, exporters and updating related configuration files are automated with Concourse pipelines."
tanzu,So that we have flexible and extendable monitoring systems.
tanzu,There are three primary ways of standing up Kubernetes on vSphere.
tanzu,Each with there own benefits and drawbacks.
tanzu,This post will be the first of three looking at VMwares TKGS.
tanzu,"Tanzu Kubernetes Grid (TKG)
Deploy Kubernetes via Tanzu (TKG) without the need for a licensed Tanzu supervisor cluster."
tanzu,This does not provide a load balancer.
tanzu,"Tanzu Kubernetes Grid Service (TKGS)
Deploy and operate Tanzu Kubernetes clusters natively in vSphere with HA Proxy as the load balancer."
tanzu,Without VMware Harbor as a container repository.
tanzu,"- Deploying and configuring HA Proxy (this post)
- Deploying workloads via the supervisor cluster
- Creating namespaces and initial cluster configuration
VMware Tanzu Kubernetes Grid Integrated Edition (TKGI)
Fully featured Tanzu deployment with NSX-T.

- Deploying and configuring NSX-T
- Deploying workloads via the supervisor cluster
- Creating namespaces and initial cluster configuration
What is VMwares Tanzu Kubernetes Grid Service (TKGS)?"
tanzu,"Tanzu Kubernetes Grid Service, known as TKGS, lets you create and operate Tanzu Kubernetes clusters natively in vSphere."
tanzu,Without having to use the CLI to standup and manage Tanzu supervisor clusters like we had to with Tanzu Kubernetes Grid (TKG).
tanzu,The big benefit of TKGS over TKG is the support and automated management of not only the supervisor clusters via the vSphere interface but also the automated provisioning of Load balancers.
tanzu,"Features
VMware Cloud Formation (VCF) is not a requirement."
tanzu,NSX-T not required.
tanzu,Virtual distributed switching (VDS) can be used instead to avoid NSX-T licensing.
tanzu,"The use of open source HA-Proxy for provisioning Load Balancers
Antrea CNI for TKG Pod to Pod Traffic, (Calico CNI also available)
Drawbacks
No PodVM support if NSX-T not used
No Harbor Image Registry (dependency on PodVM)
Deploying TKGS
This post forms part one of a three part series looking into deploying and settings up TKGS."
tanzu,"Configure networking (VDS)
First thing first, is understanding the network topology for the TKGS."
tanzu,There are three main networks you‚Äôll need to define.
tanzu,"Management network
This will be your administrative management network."
tanzu,Where you‚Äôll be able to access the HA proxy via SSH and administer the machine.
tanzu,The management network is also where the primary configuration service is defined on port 5556.
tanzu,For the TKGS cluster to configure the HA Proxy.
tanzu,"Workload network
This network is where your VMs will reside."
tanzu,"Fronted network
This is the network where your load balancers will be placed."
tanzu,For defining each of these networks they‚Äôll need to be placed on there own networks or subnets.
tanzu,I‚Äôll be placing each on their own VLAN and the workload and frontend network will reside on their own network separate network.
tanzu,So that the networks are easily distinguishable for the purpose of this post.
tanzu,"You maybe however, for simplicity have the workload and frontend networks on the same subnet."
tanzu,You need to ensure all three networks are route-able and DHCP is not running on the network.
tanzu,Not withstanding the HA Proxy configuration section.
tanzu,The configuration section of the workloads is quite involved.
tanzu,I recommend writing down the following for each network before you start.
tanzu,"Management network (VLAN 26)
Management IP: 10.64.2.10
Management Gateway: 10.64.2.1
Network: 10.64.2.0/23
Subnet: 255.255.254.0 (510 IPs available)
Workload network (VLAN 27)
Management IP: 10.64.8.10
Management Gateway: 10.64.8.1
Network: 10.64.8.0/21
Subnet: 255.255.248.0 (2046 IPs available)
Workload starting address: 10.64.8.50‚Äì10.64.15.150
Frontend network (VLAN 28)
Management IP: 10.64.0.10
Management Gateway: 10.64.0.1
Network: 10.64.0.0/23
Subnet: 255.255.254.0 (510 IPs available)
Load balancer address: 10.64.1.1‚Äì10.64.1.254
These networks will need to be defined on your router."
tanzu,Please ensure that these networks can talk (are routable) to one another.
tanzu,We will test this this again post HA Proxy configuration.
tanzu,"Right, with that out of the way you‚Äôll need to create a distributed port group for the management, workload and frontend network."
tanzu,You can share the same port group.
tanzu,"However, it is helpful to have them defined individually for fine grained controls and management."
tanzu,As these options cannot be changed once defined.
tanzu,"Configuring our Tanzu distributed port groups
One more thing to note is to double check the correct up-links are configured for the distributed port group."
tanzu,As each network must be routable.
tanzu,Checking our distributed port group up-links.
tanzu,"Configure Tanzu Storage Policy
Just like with our Distributed port groups."
tanzu,Its worthwhile configuring an independent storage policy.
tanzu,This includes tagging any storage vSANs you want the Tanzu cluster to use.
tanzu,If you‚Äôve not already added a tag to your vSAN datastore you can to so by heading over to your Datastores within vSphere.
tanzu,Select the datastore you want to use for Tanzu.
tanzu,Scroll down on the Summary page until you find the Tags section.
tanzu,"Here you‚Äôll be able to add a tag like so:

Once your tags have been defined."
tanzu,From the vSphere dashboard choose VM Storage Policies and clone the original vSAN Default Storage Policy to clone.
tanzu,"Clone the default storage policy
Then name your storage policy."
tanzu,We‚Äôre just calling ours Tanzu Storage Policy.
tanzu,Click Next and on the Policy structure screen.
tanzu,Ensure Enable tag based placement rules.
tanzu,This will let us select our TKG tags.
tanzu,"Enable tag based placement rules
On the next screen."
tanzu,I‚Äôve left the defaults as they are.
tanzu,Though you can choose your own redundancy requirements.
tanzu,On the Tag based placement screen you can now add your TKG tag with the Browse tags button.
tanzu,"Add the TKG placement tag
Check the storage compatibility with your data stores and finish up the creation of your new policy."
tanzu,"Configure content library
The last step before we create our HA Proxy is to create our content library."
tanzu,The content library is to allow Tanzu to fetch the required OVA images it needs in order to create the supervisor cluster and subsequent Tanzu cluster.
tanzu,To create a new content library head over to the vSphere dashboard.
tanzu,Under the Inventories section choose Content Libraries.
tanzu,Use the create button and give your Content Library a name.
tanzu,We‚Äôre using Tanzu VMware.
tanzu,"The content library we‚Äôre going to create is a Subscribed content library and the subscription URL you want to use is:
https://wp-content.vmware.com/v2/latest/lib.json
You want to make sure this content is downloaded immediately."
tanzu,Create the Tanzu content library.
tanzu,When the content library has been created you‚Äôll see the OVA templates downloaded under your recent tasks.
tanzu,"Awesome, the last thing to do is import the HA Proxy OVA itself."
tanzu,You can do this instead using the Deploy OVF Template.
tanzu,"However, its good to have it stored for future reference."
tanzu,"https://github.com/haproxytech/vmware-haproxy
We‚Äôre going to HA Proxy v0.1.10 as of this post which is available from here:
https://cdn.haproxy.com/download/haproxy/vsphere/ova/haproxy-v0.1.10.ova
Following the process above."
tanzu,Create a new Content Library.
tanzu,"However, this time you‚Äôre creating a Local content Library."
tanzu,Once the new Library has been created import the OVA using the Import Item from the Actions menu.
tanzu,"Importing the Tanzu HA Proxy OVA
Deploying HA Proxy
Now on to the ‚Äúfun‚Äù part."
tanzu,Standing up HA Proxy.
tanzu,From the HA Proxy OVA you downloaded.
tanzu,"Right click on it and select New VM from this template ‚Ä¶
The first stage is to simply name the new VM you‚Äôre looking to deploy."
tanzu,"Naming your new HA Proxy
The next step is to deploy the HA Proxy either with the Default configuration or Frontend Network."
tanzu,"Default
This will still let you provision Load balanced services within Kubernetes."
tanzu,It just means that the Load Balancer IP address will be provisioned on the same network as the workload network.
tanzu,"Frontend Network
This will split the Load balanced services out onto their own Network away from the workload network."
tanzu,For this example we‚Äôre using the frontend network to segregate our Kubernetes Load balanced services away from our workload network.
tanzu,"Tanzu Frontend Network
Next we need to apply the networks we defined earlier to the networks the OVA requires."
tanzu,If you selected the Default.
tanzu,The Frontend setting is ignored on this screen.
tanzu,"After setting the networks appropriately, click Next."
tanzu,"Applying the Network configuration settings for HA Proxy
The first part of the HA Proxy configuration will ask you for a root password."
tanzu,I would also advise permitting Root logon access for now.
tanzu,As its important to check the configuration of HA Proxy before we get onto deploying the Kubernetes workload.
tanzu,For the certificates section.
tanzu,You can include your own certificate authority with the CRT and certificate authority key.
tanzu,"However, if you leave these fields blank a certificate will be generated for you."
tanzu,"Define the root password for HA Proxy
This next part takes the networking configuration from the options at the beginning of the post."
tanzu,I will explain these options as we go.
tanzu,"Host name (haproxy01.test.corp)
This needs to be a fully qualified host name for the HA Proxy."
tanzu,This should include your network domain name.
tanzu,"DNS (10.64.2.1)
This is either your Managements network DNS server."
tanzu,Or a publicly accessible DNS server or one that is available across VLANs and subnets on your private network.
tanzu,In this example we‚Äôre using our management network DNS server.
tanzu,Which also happens to be our gateway server.
tanzu,"Management IP (10.64.2.10/23)
This is the Management IP address."
tanzu,This must include the network CIDR.
tanzu,"Management Gateway (10.64.2.1)
This is the gateway for the management network."
tanzu,"Configuring the HA Proxy management network
The next part is to define the Workload IP address and Frontend IP address."
tanzu,It is very important that these to IP address do not overlap with the workload and load balancer address range or the gateway itself.
tanzu,"Workload IP (10.64.8.10/21)
This is the workload IP address for the HA Proxy server residing on the Workloads network."
tanzu,This IP address must be outside the intended range for the provisioning of servers.
tanzu,"Workload Gateway (10.64.8.1)
This is the IP address of the gateway on the workload network."
tanzu,This gateway must be routable to the other HA Proxy networks.
tanzu,"Frontend IP (10.64.0.10/23)
This is the frontend IP address for the HA Proxy server residing on the Frontend network."
tanzu,This IP address must be outside the intended range for the load balancers within Kubernetes.
tanzu,"Frontend Gateway (10.64.0.1)
This is the IP address of the gateway on the frontend network."
tanzu,This gateway must be routable to the other HA Proxy networks.
tanzu,"Defining the HA Proxy networks
This next screen defines the Load balancing address space."
tanzu,This will be a subset of the network range on Frontend network.
tanzu,These address ranges must not conflict with the Frontend server (10.64.0.10) or the gateway server.
tanzu,Or any other pre-provisioned services that exist on this subnet.
tanzu,As Tanzu does not use DHCP.
tanzu,IP address are automatically provisioned in sequence for Load balancer services.
tanzu,"Therefore, the first 254 IP addresses forming a /24 of our Frontend network are going to be reserved."
tanzu,Leaving the renaming 10.64.1.1‚Äì10.64.1.254 range available which converts to 10.64.1.0/24.
tanzu,"Defining the load balancer address space
Lastly, we just need to set a password for the data-plane service."
tanzu,This will use the management IP address (10.64.2.10/23).
tanzu,With a default port of 5556.
tanzu,We‚Äôre going to use admin as the username and set our password.
tanzu,Setting the data-plane password.
tanzu,Finish the setup process and wait for the OVA to be deployed.
tanzu,You‚Äôll need to manually start the Virtual machine once its finished deploying.
tanzu,"Once the server has started you can check the data-plane server is available by visiting the following web address:
https://10.64.2.10:5556/v2/info
The user name and password are the settings you defined in the final stage of the setup process."
tanzu,This is not the root user.
tanzu,If you‚Äôve let HA Proxy self sign the server certificate authority (CA) you‚Äôll need to accept the warning message in your browser.
tanzu,"JSON output for the HA Proxy service
If this page isn‚Äôt showing we‚Äôre going to logon to the HA Proxy server anyway to check the configuration."
tanzu,"Checking HA Proxy
You can login via SSH to your HA Proxy server."
tanzu,"ssh root@10.64.2.10
The first thing to check is the IP address ranges have been correctly configured."
tanzu,"ip a
Ensure each interface matches the expected defined endpoints."
tanzu,"root@haproxy01 [ ~ ]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: management: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:8f:ce:26 brd ff:ff:ff:ff:ff:ff
    inet 10.64.2.10/23 brd 10.64.3.255 scope global management
       valid_lft forever preferred_lft forever
3: workload: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:8f:e5:ba brd ff:ff:ff:ff:ff:ff
    inet 10.64.8.10/21 brd 10.64.15.255 scope global workload
       valid_lft forever preferred_lft forever
4: frontend: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:8f:3d:28 brd ff:ff:ff:ff:ff:ff
    inet 10.64.0.10/23 brd 10.64.1.255 scope global frontend
       valid_lft forever preferred_lft forever
If the above is incorect."
tanzu,Or you need to adjust the routing tables.
tanzu,You can do so by modifying this file.
tanzu,"/etc/vmware/route-tables.cfg
You can also check all the running services have started correctly."
tanzu,"systemctl list-units --state failed
If the anyip service has failed."
tanzu,You‚Äôll need to ensure that the routes defined do not overlap and are within the defined frontend network.
tanzu,"You can check the complete status with:
systemctl status anyip-routes.service
You might see the following error:
Nov 20 15:30:07 haproxy01.test.corp anyiproutectl.sh[777]: adding route for 10.64.0.1/23
Nov 20 15:30:07 haproxy01.test.corp anyiproutectl.sh[777]: RTNETLINK answers: Invalid argument
If this is the case."
tanzu,I‚Äôll be because either your routes are invalid.
tanzu,Either missing or having an incorrect subnet.
tanzu,Or your subnets are overlapping.
tanzu,Or finally your subnets might be outside of the defined network subnets.
tanzu,Either way you need to check and update your anyip-routes configuration.
tanzu,"You can modify your routes like so:
root@haproxy01 [ ~ ]# cat /etc/vmware/anyip-routes.cfg 
#
# Configuration file that contains a line-delimited list of CIDR values
# that define the network ranges used to bind the load balancer's frontends 
# to virtual IP addresses."
tanzu,"#
# * Lines beginning with a comment character, #, are ignored
# * This file is used by the anyip-routes service
#
10.64.1.0/24
You can then restart the service systemctl restart anyip-routes.service and re-run the systemctl list-units --state failed ."
tanzu,Its all over!
tanzu,Hopefully that‚Äôs given you a quick dive into standing up TKGS on vSphere.
tanzu,In our next post we‚Äôll be looking at running the supervisor cluster which will manage and provision our Kubernetes clusters.
tanzu,Please feel free to get in touch if you have any questions.
tanzu,"Introduction
The native integration of Kubernetes within vSphere 7 brings a slew of innovations to the vSphere platform."
tanzu,"Various articles on the web discuss the benefits, design, and architecture of this new platform."
tanzu,Let us take a look at the multiple layers that make up the new platform.
tanzu,"At the heart of this new platform is the Workload Control Plane (WCP), a new service that runs within the vCenter appliance and responsible for managing the integration of Kubernetes with vSphere."
tanzu,The next layer is the Supervisor Cluster control plane VMs.
tanzu,"In its simplest definition, these VMs convert the traditional vSphere cluster to an environment able to understand and interpret the Kubernetes dialect."
tanzu,This control plane is also responsible for delivering multiple services for consumption by the platform.
tanzu,"Some of the standard services offered are Load Balancer (LB) services, registry service, Tanzu Kubernetes Cluster (TKC) service, Virtual Machine (VM) service, and others."
tanzu,The last layer is the individual service delivered by the previous layer.
tanzu,These services may be consumed individually or consumed by other services.
tanzu,"For example, the VM and LB services are consumed by the TKC service to deliver a conformant Kubernetes cluster to run application workloads."
tanzu,"Since these services are growing in number, this article will discuss advanced troubleshooting techniques for essential services like TKC, Registry (Harbor), and VM services."
tanzu,This platform is designed to bring vSphere administrator and DevOps engineers closer in their Day-1 and Day-2 responsibilities.
tanzu,"The blurring of duties between the two personas may cause some issues with seamless management of the platform, especially during troubleshooting scenarios."
tanzu,"While this article will not discuss specific troubleshooting scenarios, it will walk through some traditional, new, and advanced troubleshooting methods."
tanzu,"It will discuss how to access the platform‚Äôs multiple layers, helping the two personas‚Äô need to perform troubleshooting as part of their day two responsibilities."
tanzu,"Troubleshooting WCP vCenter Service
wcp is a standard vCenter service, running in the vCenter appliance."
tanzu,Its troubleshooting process is similar to troubleshooting other vCenter services.
tanzu,You can manage the wcp service using the service-control CLI options.
tanzu,"The wcp service is dependent on vpxd, eam, lookupsvc, vmware-vpostgres services."
tanzu,The logs for the wcp service are stored in the /var/log/vmware/wcp folder.
tanzu,/var/log/vmware/wcp/wcpsvc.log is of particular importance as it contains crucial troubleshooting information.
tanzu,Most of the wcp configuration files are stored in /etc/vmware/wcp folder.
tanzu,WARNING: Do not modify the contents of any of the files unless asked by VMware support.
tanzu,Doing so could lead to an unsupported and broken configuration.
tanzu,/etc/vmware/wcp/wcpsvc.yaml is of particular interest as it contains several configuration details on the Supervisor Cluster control plane configurations.
tanzu,WARNING: Do not modify the contents of any of the files unless asked by VMware support.
tanzu,Doing so could lead to an unsupported and broken configuration.
tanzu,"The binaries for setting up the Supervisor Cluster control plane VMs, Spherelet VIBs, and Supervisor Cluster Node Agent for ESXi are stored in /storage/lifecycle/vmware-wcp and /storage/lifecycle/vmware-hdcs folders."
tanzu,They are delivered through the vCenter lifecycle management process.
tanzu,WARNING: Do not modify the contents of any of the files unless asked by VMware support.
tanzu,Doing so could lead to an unsupported and broken configuration.
tanzu,"Troubleshooting Supervisor Cluster Control Plane
During the Supervisor Cluster‚Äôs initial setup, the Control Plane VMs are installed using the binaries stored in the /storage/lifecycle folder (see above)."
tanzu,"Also, depending on the type of networking (NSX vs. non-NSX) used, the ESXi hypervisor may (or may not) be configured with the spherelet VIBs and the node agents."
tanzu,Again the binaries are consumed from the /storage/lifecycle folder within the vCenter appliance.
tanzu,"Since the stability and availability of the Control Plane is very critical to the stability and availability of the entire platform, the control plane VMs are locked down."
tanzu,Limited access is provided to the VMs running the Kubernetes control plane.
tanzu,Most of the troubleshooting can be performed with the kubectl CLI after authenticating using the kubectl vsphere plugin.
tanzu,"Some of the standard commands are ‚Äî
# Use the command to authenticate to the Supervisor Cluster
kubectl vsphere login ‚Äî server Supervisor-Cluster-API-endpoint ‚Äî vsphere-username administrator@vsphere.local
# Get events logged by the control plane
kubectl get events -A or kubectl get events -n namespaces
# Get logs of various applications/pods running in the control plane
kubectl logs -n namespace pod-name
IMPORTANT: While the administrator@vsphere.local SSO user can perform most of the daily housekeeping functions of managing the Supervisor Cluster and the related functionalities; it does not have the all-powerful cluster-admin Kubernetes role to perform full administrative duties."
tanzu,This is by design.
tanzu,"Currently, the process to get cluster-admin role access is to log in to one of the control plane VMs and use the kubectl CLI to perform those functions."
tanzu,"The steps are explained below ‚Äî
WARNING: Use extreme caution while using these steps (only when asked by and in the presence of VMware Support)."
tanzu,"Incorrect changes could lead to a broken Supervisor Cluster and data loss, including corrupted TKC workload clusters."
tanzu,SSH into the vCenter appliance as root and execute the following command ‚Äî /usr/lib/vmware-wcp/decryptK8Pwd.py.
tanzu,"This should return something similar to this ‚Äî
Read key from file
Connected to PSQL
Cluster: domain-c8:bf950692-ec28-45cf-9228-13ce8e607244
IP: 192.168.10.40
PWD: WUwoRDlAY.....u9Aywjd1Ex8W/ZzqHQjC3NX7pyFv7IXhNyJ8CTvE08=
------------------------------------------------------------
Note the IP address and the password."
tanzu,The IP address is the floating IP for the Supervisor Control Plane.
tanzu,This is an IP assigned to one of three Control Plane VMs.
tanzu,"Using the IP address and the password captured in the above step, log in to one of the Control Plane VM using the root credentials."
tanzu,"Once logged in, use the kubectlCLI to execute required troubleshooting commands with the cluster-admin role."
tanzu,The above process could also be used to login to any Control Plane VMs to capture the necessary system logs for troubleshooting.
tanzu,"Troubleshooting Tanzu Kubernetes Cluster Service
The two areas where troubleshooting may be required are the Kubernetes environment (applications and configurations) and the VMs operating this Kubernetes cluster."
tanzu,"Kubernetes cluster troubleshooting in these scenarios is pretty conventional, following standard troubleshooting patterns using administrative roles."
tanzu,Use kubectl CLI after authenticating using the kubectl vsphere plugin.
tanzu,"kubectl vsphere login --server Supervisor-Cluster-API-endpoint --vsphere-username sso-user-name --insecure-skip-tls-verify --tanzu-kubernetes-cluster-name tkc-cluster-name --tanzu-kubernetes-cluster-namespace tkc-cluster-namespace
At times troubleshooting process may require a login to the VMs (nodes) operating this Tanzu Kubernetes Cluster."
tanzu,The method may vary depending on the networking stack that the Supervisor Cluster is using.
tanzu,"NSX based networking
In NSX based Supervisor Cluster, the VMs that operate the Tanzu Kubernetes Cluster (TKC) is on a logical overlay network and hence not easily reachable for SSH connectivity."
tanzu,"The recommended method to connect to the nodes is to execute a container running a basic Linux OS within the same namespace as the TKC, within the Supervisor Cluster."
tanzu,The private ssh key is mounted as a volume to the container.
tanzu,"Once ready, kubectl exec is used to SSH to the nodes."
tanzu,"With kubectl authenticated to the supervisor cluster, perform the following -
cat <<EOM > jumpbox.yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: jumpbox
  namespace: tkc-namespace
spec:
  containers:
  - image: ""photon:3.0""
    name: jumpbox
    command: [ ""/bin/bash"", ""-c"", ""--"" ]
    args: [ ""yum install -y openssh-server; mkdir /root/.ssh; cp /root/ssh/ssh-privatekey /root/.ssh/id_rsa; chmod 600 /root/.ssh/id_rsa; while true; do sleep 30; done;"" ]
    volumeMounts:
      - mountPath: ""/root/ssh""
        name: ssh-key
        readOnly: true
  volumes:
    - name: ssh-key
      secret:
        secretName: tkc-cluster-name-ssh
EOM
Execute this file on the supervisor cluster."
tanzu,"kubectl apply -f jumpbox.yaml
Get the IP addresses of the VMs that are running this TKC ‚Äî
for node in `kubectl get tkc tkc-cluster-name  -n tkc-namespace -o json|jq -r '.status.nodeStatus| keys[]'`
do
  ip=`kubectl get virtualmachines -n tkc-namespace ${node} -o json|jq -r '.status.vmIp'`
  echo ${ip}
done
Use the IP from the previous section to SSH into the VM -
kubectl -n tkc-namespace exec -it jumpbox -- /usr/bin/ssh -o StrictHostKeyChecking=no vmware-system-user@${ip}
Once logged in, you can use sudo to execute troubleshooting commands that require elevated privileges."
tanzu,"Non-NSX based networking
For non-NSX based networking, the steps are a bit simple since the VMs operating the TKC are generally on a public routable network."
tanzu,"In such a scenario, perform the following steps."
tanzu,"With kubectl authenticated to the supervisor cluster, get the private ssh key for the nodes, and save it in the user‚Äôs .ssh folder ‚Äî
kubectl get secret -n tkc-namespace tkc-cluster-name-ssh -o json |jq -r '.data."
tanzu,"""ssh-privatekey""'|base64 -d > ~/.ssh/id_rsa
chmod 600 ~/.ssh/id_rsa
Get the IP addresses (if not already available) of the nodes running the TKC -
for node in `kubectl get tkc tkc-cluster-name  -n tkc-namespace -o json|jq -r '.status.nodeStatus| keys[]'`
do
  ip=`kubectl get virtualmachines -n tkc-namespace ${node} -o json|jq -r '.status.vmIp'`
  echo ${ip}
done
SSH into the VM in question using your favorite ssh client ‚Äî
ssh -o StrictHostKeyChecking=no vmware-system-user@${ip}
Troubleshooting Registry service
Harbor Registry service is currently available through the Supervisor Cluster only on NSX based networking environment."
tanzu,This is because only this configuration provides the PodVM service required to deliver the Harbor Registry service.
tanzu,"Since this service runs within the Supervisor Cluster as a Kubernetes application, the troubleshooting process relies upon the standard Kubernetes toolkit like kubectl ."
tanzu,The Registry service is locked down to provide the necessary SLAs to the Tanzu Kubernetes clusters that would consume this service.
tanzu,"Hence, the Harbor registry's admin credentials are not readily available to perform administrative tasks on the Harbor registry."
tanzu,"At times, during standard troubleshooting, a need to configure/login to the Harbor environment may arise using the privileged administrative login."
tanzu,"To get the admin credentials, perform the following steps on the Supervisor cluster
kubectl get namespace |grep vmware-system-registry
# Replace xxxxxxxx with the registry ID found in the previous step
kubectl get secrets -n vmware-system-registry-xxxxxxxx harbor-xxxxxxxx-controller-registry '.data.harborAdminPassword'|base64 -d|base64 -d;echo
WARNING: Use extreme caution while using these steps (only when asked by and in the presence of VMware Support)."
tanzu,"Incorrect changes could lead to a broken Supervisor Cluster and data loss, including corrupted TKC workload clusters."
tanzu,Use the credentials to log in to the Harbor UI with admin credentials.
tanzu,This article will be updated frequently as new features and updates within the platform warrants a new troubleshooting methodology.
zipkin,"This is the third post of my microservices series, where I talk about my impressions of this architecture style using Java with Spring Boot."
zipkin,"The full series of articles are listed below:
Part I: Project setup, REST communication and Service Discovery
Part II: Fault tolerance and Configuration Server
Part III: API Gateway and Centralized logs
Part IV: Authentication and Authorization (it‚Äôs yet on my TODO list.. :-P)
The code implemented in each article is available on GitHub in a specific branch, and the final implementation is on the main branch."
zipkin,"In this article we will implement an API Gateway and a Centralized Log solution, again using a practical approach using Java and Spring Boot framework."
zipkin,The code of this article is available on GitHub in branch ‚Äòch-03‚Äô.
zipkin,"API Gateway
A very common pattern used in microservices is the mplementation of an API Gateway, that is the single entry point for all clients."
zipkin,"This become a first layer to access a service, that can be provided by one or more microservices."
zipkin,"Some requests are simply routed to the appropriate service, while others need to reach out multiple services."
zipkin,"Some advantages of this API Gateway are:
Single entry point to the API: encapsulates the system internal architecture, abstracting inner details from clients."
zipkin,It can provide personalized API to some clients (a.k.a.
zipkin,"‚ÄúBackends for Frontends‚Äù);
Provides better versioning and evolution for the API: It allows refactoring and adjustment of the microservices that provides the service behind the API, without impacting the clients;
Provides more security: The gateway can provide authentication and usage threshold per client."
zipkin,"This additional layer can also provide mechanisms to prevent malicious attacks, like DoS and SQLInjection, for example."
zipkin,"Allows usage monitoring: it is possible to monitor and manage requests and responses, providing better load balance, cache, billing and statistics about the API usage."
zipkin,"Of course there are some issues and disadvantages, since the gateway becomes a critical point of failure, and has to be properly deployed and manage."
zipkin,"The intended architecture in the example of this series of articles including the API Gateway will be like this:

Back to code, let‚Äôs setup a new project as the API Gateway using Spring Cloud Gateway, since it is the recommended library in newer Spring Boot versions (Zuul became deprecated):

Setup of API Gateway project at Spring Initializr
The complete pom.xml file of this project can be seen here."
zipkin,Now we have to address the routes at application.yml file.
zipkin,"Notice that each mapped route in the gateway is addressed to the respective microservice:
spring:
  application:
    name: API-GATEWAY
  cloud:
    gateway:
      routes:
        - id: PRODUCT-CATALOG-SERVICE
          uri: lb://PRODUCT-CATALOG-SERVICE
          predicates:
            - Path=/api/product/**
        - id: USER-INFORMATION-SERVICE
          uri: lb://USER-INFORMATION-SERVICE
          predicates:
            - Path=/api/user/**
        - id: SHOPPING-CART-SERVICE
          uri: lb://SHOPPING-CART-SERVICE
          predicates:
            - Path=/api/cart/**

server:
  port: 8085
The complete code for this API Gateway implementation is available here."
zipkin,"So, after running all the services, we can make a direct request to the shopping-cart, products-catalog or user-info microservices, or we can call them through the API Gateway (notice the Gateway port 8085), that will redirect to each service requested:

POST request to shopping-cart endpoint through the API Gateway
Centralized Log management
As the number of microservices grows, it can become harder and harder to manage the logs of each one and track down some request/response."
zipkin,"To better tracing the requests, we can use Zipkin server and Spring Cloud Sleuth."
zipkin,"This solution provides the ‚ÄòTraceId‚Äô, that is the unique identifier of the request, and ‚ÄòSpanId‚Äô, that represents each service the request reached."
zipkin,"The log will look like this:
[SERVICE-NAME,trace-id,span-id]
As illustrated below:

The generated logs and ids can be sent to Zipkin server, where it is possible to search and monitor each request by many parameters."
zipkin,"First of all, we need a Zipkin server up and running."
zipkin,We can download it this site (I chose to download the ‚Äòjar‚Äô version and run it with java -jar ‚Ä¶.
zipkin,"):

Zipkin server running
Now we have to add the zipkin and sleuth dependency in every microservice:
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-sleuth-zipkin</artifactId>
</dependency>
And add to the application.yml the base URL of Zipkin server (in all the microservices configs):
spring:
  // ... omitted configs ...
  zipkin:
    base-url: http://127.0.0.1:9411/
And that‚Äôs it!"
zipkin,It automatically will start to generate logs including the trace and span ids.
zipkin,"After launching all the microservices, and make some request (like POST at shopping-cart endpoint), we can trace the request at Zipkin page using some criteria, like the ‚Äòservice-name‚Äô for example:

Zipkin search page
And the result page should look like this:

Zipkin results page
Where you can detail even more the request info:"
zipkin,"When I started with this series of distributed tracing benchmarking related posts, the aim was to demonstrate that there though at a conceptual level there is very little difference between tracing and method invocation profiling the difference in terms of overhead and storage cost is immense."
zipkin,This difference is due to distributed tracing implementations always looking to move events over the network to some central point of trace reconciliation.
zipkin,Distributed tracing doesn‚Äôt distribute computation well.
zipkin,"Distributed tracing client libraries (and pipelines) do the minimum and offer hardly any value locally other than measuring the timing of activities, queuing (span) events up, and then if they can sending them over the wire."
zipkin,"Even then, they employ sampling to reduce load, and when that fails, they shed workload at will by dropping events."
zipkin,"Some vendors talk up how they don‚Äôt sample, but all drop, and at times, you don‚Äôt want this to happen."
zipkin,"Distributed tracing is just dumb and extremely slow ‚Äî dumb in that it does not transform the data into something meaningful, such as a status inference, at the source."
zipkin,"It creates a network of non-intelligent observers who push data along, when not sampling, deliberately dropping, or randomly dropping data."
zipkin,"Instead of dropping data, why not alternatively drop distributed tracing altogether."
zipkin,"OpenZipkin follows suit with Elastic, OpenTelemetry, and Jaeger in being yet another costly alternative to something like metering or signalling."
zipkin,"Instrumentation
Like in the other posts, I used an episodic machine memory played back by Stenos to create a benchmark environment for comparing tracing with profiling."
zipkin,The simulated playback of a recording file of size 6.1GB requires the tracing implementation to be loaded as a method callback interceptor.
zipkin,The callback code itself is short and straightforward.
zipkin,"Still, unfortunately, there was a need to add additional code to print out some metrics related to dropping and data transfer costs, as well as some client construction configuration as I attempted to reduce the high amount of event dropping."
zipkin,"Benchmark
Like with Jaeger, I tried running OpenZipkin in a container with a proper storage backend, but there were so many issues for the data to be trusted."
zipkin,"Instead, I ran OpenZipkin as a separate Java process with an in-memory storage component enabled and the maximum storage size set."
zipkin,"With a client queue size of 100,000 and storage size of 1,000,000:
span.total: 1,077,288,891
span.queued: 21,367
span.dropped: 1,034,791,489
span.bytes: 236,604,887,578
message.total: 18,726
message.dropped: 0
message.bytes: 9,360,932,873
./run.sh 1982.79s user 273.08s system 474% cpu 7:55.67 total
Without OpenZipkin, the run.sh script executes in 16s."
zipkin,"With OpenZipkin, an additional 7mins 40s is added."
zipkin,The span event drop rate is 96%.
zipkin,The size of a single span in terms of data transmission cost is approximately 220b ‚Äî that is 100 times fatter than a call event within the Stenos memory file.
zipkin,"With a client queue size of 10,000 and storage size of 100,000:
span.total: 1,077,288,891
span.queued: 7,715
span.dropped: 1,029,032,120
span.bytes: 236,609,716,859
message.total: 21,269
message.dropped: 0
message.bytes: 10,632,157,367
./run.sh 1928.01s user 279.96s system 465% cpu 7:54.24 total
With a client queue size of 1,000 and storage size of 10,000:
span.total: 1,077,288,891
span.queued: 2
span.dropped: 1,034,016,835
span.bytes: 236,610,355,399
message.total: 19,068
message.dropped: 0
message.bytes: 9,531,916,393
./run.sh 2014.88s user 293.06s system 482% cpu 7:58.17 total
I did try going in the opposite direction, increasing sizes, but very quickly, everything ground to a halt with so much garbage collection ongoing."
zipkin,It is important to note that the OpenZipkin backend server never had to persist the spans to disk much like I did with the other benchmarks.
zipkin,"To see how much overhead is added by the spans pipeline, we can configure the OpenZipkin to do pretty much nothing at all as follows:

./run.sh 1405.82s user 11.23s system 786% cpu 3:00.28 total
The overhead is still significant, but we have saved off nearly 5 mins."
zipkin,"Commentary
At this point, there is a typical pattern unfolding ‚Äî that is, dropping."
zipkin,Tracing is not suitable for instrumentation of code that does not involve the invocation of a remote routine.
zipkin,The placement of a custom span instrumentation somewhere in the application codebase could spell disaster for observability in production with all other remote related events being dropped at random.
zipkin,We need to imbue client libraries with intelligence and controllability.
zipkin,Not have them be dumb observers that dump data over an even dumber pipe.
zipkin,"Zipkin & Jaeger
To monitor the stability of the application , we need logging , metrics and tracing."
zipkin,"In microservices environment, Logging will help you to get the error details of a service, metrics will get you the abnormal trend of a service, but only tracing will help you pin-point where the service call has actually failed."
zipkin,"Let‚Äôs see how we can setup opensource distributed tracing software like Jaeger and Zipkin in GKE,
To enable distributed tracing , all the incoming requests to / from microservices should be enabled with trace ids and tags and they should report the traces to a collector."
zipkin,All the services should also forward the headers downstream and the tracer backend like Jaeger or zipkin should be able to query and search these traces.
zipkin,"To ease the instrumentation of the microservices, there are opentracing and opencensus library packages available for major languages like C++, Go , java, javascript, Python , Ruby etc."
zipkin,Opencensus is backed by google and opentracing is backed by CNCF and they have now jointly formed opentelemetry.
zipkin,"For the purpose of this demo i have used the bookinfo sample application , which is available as part of the Istio installation."
zipkin,"First let‚Äôs create a GKE cluster in us-central1 region, with min nodes as 3.
gcloud container clusters create demo --enable-autoupgrade --enable-autoscaling --min-nodes=2 --max-nodes=10 --num-nodes=3 --zone=$zone
Next we will go ahead and get the credentials for the cluster and create a cluster role binding."
zipkin,"gcloud container clusters get-credentials demo --zone $zone --project $project
kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value core/account)

GKE cluster
We will now download the latest stable version of istio for installation."
zipkin,"curl -L https://istio.io/downloadIstio | sh -
Verify the installation,
cd istio-1.5.4/bin
./istioctl verify-install
Now we will go ahead and deploy the istio ecosystem, as part of the installation it will also install grafana, prometheus, kiali and Jaeger
./istioctl manifest apply --set profile=demo --set values.tracing.enabled=true
If you want to use zipkin as the tracer, use the below command instead of above."
zipkin,"./istioctl manifest apply --set profile=demo --set values.tracing.enabled=true --set values.tracing.provider=zipkin
Next we label the namespace ‚Äòdefault‚Äô as istio-injection enabled, so all the services deployed will have a istio side-car proxy."
zipkin,"kubectl label namespace default istio-injection=enabled
Now we will deploy the application."
zipkin,"cd istio-1.5.4/
kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
Check whether the pods and services are running as intended,

GKE services
kubectl get services
kubectl get pods
kubectl exec -it $(kubectl get pod -l app=ratings -o jsonpath='{.items[0].metadata.name}') -c ratings -- curl productpage:9080/productpage | grep -o ""<title>."
zipkin,"*</title>""
Now we will create the gateway for the application,
kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml
Now open up the firewall rules
export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?"
zipkin,"(@.name==""http2"")].port}')
export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?"
zipkin,"(@.name==""https"")].port}')
gcloud compute firewall-rules create allow-gateway-http --allow tcp:$INGRESS_PORT
gcloud compute firewall-rules create allow-gateway-https --allow tcp:$SECURE_INGRESS_PORT
To introduce an error and visualize it in Jaeger / Zipkin, we will induce delay fault between the products and reviews service for the user jason, more details are available in the below link
kubectl apply -f samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml
Fault Injection
This task shows you how to inject faults to test the resiliency of your application."
zipkin,"Set up Istio by following the‚Ä¶
istio.io


Book Info application
Now lets open the Jaeger ui , by doing a portforward on the jaeger-query service."
zipkin,"kubectl port-forward --namespace istio-system $(kubectl get pod \
--namespace istio-system --selector=""app=jaeger"" \
--output jsonpath='{.items[0].metadata.name}') \
8080:16686

Google cloud shell ‚Äî Port forwarding the Jaeger Query Service
Click on web-preview on the cloud shell, Navigate to the error time span to the view the details."
zipkin,"Jaeger UI

Error identification in Jaeger UI
the DAG in Jaeger is given below,

Jaeger DAG
Lets see how we can view this error detail in zipkin, get the credentials of the cluster where you have deployed zipkin as the tracer, then execute the below command to do the port forward of the zipkin service and do a web-preview from the cloud shell."
zipkin,"kubectl port-forward --namespace istio-system $(kubectl get pod \
--namespace istio-system --selector=""app=zipkin"" \
--output jsonpath='{.items[0].metadata.name}') 8080:9411

Zipkin UI Lens
the DAG graph is displayed as below in zipkin

Zipkin DAG
The different error response flags are given below for your reference, you can use them to troubleshoot the issue."
zipkin,"DC - Downstream connection termination
UH - No healthy upstream hosts."
zipkin,UF - Upstream connection failure.
zipkin,UO - Upstream overflow.
zipkin,NR - No route configured.
zipkin,URX - Rejected because of upstream retry limit or maximum connection attempts reached.
zipkin,LH - Local service failed health check request.
zipkin,UT - Upstream request timeout.
zipkin,LR - Connection local reset.
zipkin,UR - Upstream remote reset.
zipkin,UC - Upstream connection termination.
zipkin,DI - The request processing was delayed for a period specified via fault injection.
zipkin,FI - The request was aborted with a response code specified via fault injection.
zipkin,RL - The request was rate limited locally by the rate limiting filter.
zipkin,UAEX - The request was denied by the external authorization service.
zipkin,RLSE - The request was rejected because there was an error in rate limit service.
zipkin,IH - The request was rejected because it set an invalid value for a strictly-checked header in addition to 400 response code.
zipkin,SI - Stream idle timeout in addition to 408 response code.
zipkin,"Thanks for reading through this post, hope it helped you ."
zipkin,"Photo by Marten Bjork on Unsplash
One of the challenges of running microservice architecture software is to be able to trace requests between the hosted services including the reverse proxy or the load balancer."
zipkin,This feature is very helpful for improving the effectiveness of the operation shifts and provides the SRE engineers with all the needed information for investigating incidents on the production environments.
zipkin,"While using the ‚ÄúX-Request-ID‚Äù header and pass it to the called service can help in correlating the logs from the involved services in responding to a single request, It does not provide the needed information about the flow of the request."
zipkin,"In other words, The ‚ÄúX-Request-ID‚Äù can not tell which service called which service."
zipkin,Comparing the timestamps of the logs can helps in getting this information.
zipkin,"However, It will be a lot of effort and it will not be accurate always."
zipkin,"Another way to trace web requests flows is my implementing and using OpenTracing frameworks, libraries, and tools for tracing web requests between microservices."
zipkin,"OpenTracing is comprised of an API specification, frameworks and libraries that have implemented the specification, and documentation for the project."
zipkin,OpenTracing allows developers to add instrumentation to their application code using APIs that do not lock them into any one particular product or vendor.
zipkin,"https://opentracing.io/docs/overview/what-is-tracing/
OpenTracing supports several programming languages such as Go, Ruby, and Python (The full list can be found here)."
zipkin,"In addition, several tools and third party services are already implying and supporting OpenTracing."
zipkin,One of the tools that support OpenTracing is Traefik which is a reverse proxy and load balancer.
zipkin,"In this post, I will review and demonstrate Traefik operating support."
zipkin,"Traefik OpenTracing Support
The main idea behind OpenTracing is built around two fundamental types:
Span: is the basic object of a distributed trace."
zipkin,The span represents an action or event occurred during serving the request.
zipkin,"It also encapsulates all the needed information regarding the action such as the start time, end time and attached tags."
zipkin,A distributed trace of a given request consists of one or more spans.
zipkin,Tracers: These are applications that are responsible for creating and updating spans.
zipkin,These applications can be used also to visualize the collected spans or traces.
zipkin,Each of the tracers compatible with OpenTracing API must provide clients to be integrated with services and collect the span data.
zipkin,"Example of such applications Jaeger and Zipkin,
Traefik supports several OpenTracing backends or tracers such as Jaeger, Zipkin, Instana, and Datadog."
zipkin,That means Traefik is utilizing several tracer clients and can be configured to publish events to different OpenTracing backends based on the needs of the project.
zipkin,"Implementation
In this section, I will present how to use the open tracing feature from Traefik with two different backend Jaeger and Zipkin,
Common Configuration
The below configurations are common and applies to all the supported backends."
zipkin,"The first items set the service name on the backend application, spans and traces can be searched based on this value."
zipkin,The second item allows the truncation of the span names in case they exceed the defined length.
zipkin,The 0 value can be used to disable this feature.
zipkin,"Zipkin
Below is all the Traefik configuration that can be used to integrate Zipkin with Traefik."
zipkin,"The Configuration items include:
zipkin: Enable Zipkin as a tracing backend."
zipkin,httpEndpoint: setting the Zipkin endpoint used for collecting the events.
zipkin,sameSpan: Use Zipkin SameSpan RPC style traces or not.
zipkin,id128bit: Use Zipkin 128 bit trace IDs.
zipkin,sampleRate: a value between 0 and 1 that represents the rate of the traced requests.
zipkin,This is helpful in case we need to trace only a percentage of the requests and not 100% or the requests.
zipkin,"After deploying Traefik with the above configurations, we will start seeing that Traefik added a set of HTTP headers to be able to trace the request and pass it also the backend service so they can contribute to the trace information in case they are also supporting OpenTracing."
zipkin,"The below Image show the added headers

The below image shows the Zipkin web interface, form this UI it possible to perform the following actions
Search for a specific request trace
View The trace tags and other details."
zipkin,View the trace flow and the component or services involved in serving the request.
zipkin,"For instance, as shown in the below image we can see the involved middleware and the entry points in serving the requests."
zipkin,"Jaeger
Jaeger is the default tracing backend for Traefik."
zipkin,Below is all the Traefik configuration that can be used to integrate Jaeger with Traefik.
zipkin,"The Configuration items include:
jaeger: Enable Jaeger as a tracing backend."
zipkin,samplingServerURL: The Jaeger sampling server URL.
zipkin,"samplingParam: The enabled sampling strategy, supported values are constz: 0 or 1 value that specifies either sampling or not."
zipkin,probabilistic: sampling based on a percentage value ranges between 0 and 1. rateLimiting: sampling a specific number of requests per second.
zipkin,localAgentHostPort: Jaeger agent address (IP + port) that will be used to send data to it.
zipkin,gen128Bit: Boolean value to enable generating 128-bit trace IDs.
zipkin,This is optional.
zipkin,propagation: Propagation header type either b3 or jaeger.
zipkin,traceContextHeaderName: The HTTP header name used for the trace id.
zipkin,endpoint: The jaeger collector URL (Optional).
zipkin,user: Jaeger user (Optional).
zipkin,password: Jaeger Password (Optional).
zipkin,"After deploying Traefik with the above configurations, we will start seeing that Traefik added the defined jaeger HTTP header to be able to trace the request and pass it the backend service so they can contribute to the trace information in case they are also supporting OpenTracing."
zipkin,The below Image show the added header.
zipkin,One difference between Zipkin and Jaeger is that Jaeger uses one HTTP header for defining the trace span while Zipkin is using several HTTP headers for defining the trace span.
zipkin,Another difference is the Backend UI.
zipkin,Jaeger UI is more friendly and supports more features such as trace filtering and comparing different traces.
zipkin,The below image shows the Jaeger interface and how the spans are viewed on the UI.
zipkin,Below is the docker swarm stack that I used to deploy Traefik with Both Zipkin and Jaeger.
zipkin,"Conclusion
Distributed Tracing is very helpful for debugging and monitoring modern distributed software architectures, such as microservices."
zipkin,Trafik supports several OpenTracing backends and it provides straightforward and simple configurations for integrating Traefik with these backends.
zipkin,Today I decided to share one of the challenges I have faced and the solution that I have found to solve it.
zipkin,What is the problem?
zipkin,"In a project, I was a Nodejs developer in a team."
zipkin,"In the backend of the project, we have some services that work together in a microservice architecture."
zipkin,These services write in Nodejs programming language.
zipkin,The problem arose when we recognized that some requests to a microservice could have taken longer than the usual time and we get the response with delay.
zipkin,So we want to know where the application spent most of its time and we do not have an idea about what occurs in the backend and why these requests get a longer time and what service or module creates this problem.
zipkin,"In the last few years, the microservice architecture pattern has become mainstream."
zipkin,"The pattern solves many problems of the monolithic architecture design but has some drawbacks, one of the biggest being how hard it is to debug the system as a whole."
zipkin,"In a microservice architecture, tracing is extremely challenging because requests will span multiple services, each executing one or more processes, across multiple servers
Distributed Tracing help to Microservices Architecture !"
zipkin,One of the best tools you can have in your belt when you are dealing with microservices is distributed tracing.
zipkin,"Distributed tracing lets you know what is happening in your system and which parts are involved, even in production."
zipkin,So this is a time that Zipkin can help you to trace your request.
zipkin,What is Zipkin?
zipkin,"Zipkin is an open-source distributed tracing system based on Google Dapper and initially developed by Twitter, is a Java-based distributed tracing application that helps gather timing data for every request propagated between independent services."
zipkin,It has a simple management console where we can find a visualization of the time statistics generated by subsequent services.
zipkin,"zipkin flow
The component in an instrumented app that sends data to Zipkin is called a Reporter."
zipkin,"Reporters send trace data via one of several transports to Zipkin collectors, which persist trace data to storage."
zipkin,"Later, storage is queried by the API to provide data to the UI."
zipkin,"First solution
So I decided to instrument my application by adding tracing to common pieces in the code."
zipkin,As my project was very huge I create a simple project and build a couple of Express microservices and use Zipkin-js to trace them.
zipkin,based on this article.
zipkin,After I build this and use the tracker in it everything is ok but tracer in my project did not work properly.
zipkin,Zipkin-js or display UI does not show the correct span and generate span in Zipkin-js is hard because we don‚Äôt have full control over it.
zipkin,"Furthermore, I think Zipkin‚Äôs document is not complete."
zipkin,So I was very frustrated and wanted to solve this problem.
zipkin,"After research on it, my CTO suggested to me to use OpenTelemtry library for the client of the tracer processes."
zipkin,It helped me further control on generate span.
zipkin,So I had to setup OpenTelemtry so that it can send traces to Zipkin.
zipkin,"In other words, Zipkinn is in its place in the backend."
zipkin,OpenTelemtry comes as a client-side and uses Zipkin‚Äôs protocol so it can speak with Zipkin and send a trace to it.
zipkin,"So my problem changed as follow:
I have a couple of Express microservices ( hello-service-1 & hello-service-2 ), Zipkin stay in the backend server and OpenTelemtry is in the client."
zipkin,I want to call hello-service-1 from sample client.
zipkin,In hello-service-1 call hello-service-2 and set trace for this request.
zipkin,it‚Äôs clear!
zipkin,you think we have 2 services for example login and purchase.
zipkin,Each user must log in first and then be allowed to do purchase actions.
zipkin,"So in this example, we have 2 services: login and purchase."
zipkin,purchase service call login service to check user access.
zipkin,"In this example, purchase as hello-service-1 and login as hello-service-2."
zipkin,So we want to trace a request when it starts from purchase and goes to login.
zipkin,We want to find out exactly where this request has spent more time.
zipkin,"Setup Project:
A solution that I find is to use express-http-context module to change request context such that I can set parent of a request."
zipkin,"tracer.js :

with createSpan and endSpan now I can easily use this function in everywhere I want to trace and create or end span

We are going to use got as our HTTP client to make the request."
zipkin,To get got working with Zipkin we need to instrument it.
zipkin,"I instrumented it manually:

got.js
Usage with express as a middleware:

service_1

service_2
Now, if we get both services up and make a request to localhost:8081 we can see a trace like this in our zipkin-ui:

we can now understand what is happening in our services just by looking at the trace."
zipkin,"Pretty neat, right?"
zipkin,":)
a github repo with the full example can be found here."
zipkin,"In this article, I will show you how to trace requests from Flask APIs using Zipkin."
zipkin,The request‚Äôs trace.
zipkin,All services are containerized and a docker-compose file is used to bring them all up.
zipkin,You can find the code in this GitHub repository.
zipkin,"Used Tools
Zipkin
Zipkin is a distributed tracing system."
zipkin,"Using Zipkin will make you able to see all the services that a request goes through, determine the duration time needed for each service."
zipkin,"What is a distributed tracing system:
From OpenTracing website:
Distributed tracing, also called distributed request tracing, is a method used to profile and monitor applications, especially those built using a microservices architecture."
zipkin,Distributed tracing helps pinpoint where failures occur and what causes poor performance.
zipkin,"Flask
Flask is a lightweight WSGI framework."
zipkin,It is one of the most popular Python frameworks.
zipkin,Here is their documentation.
zipkin,"py_zipkin
py_zipkin provides a context manager/decorator along with some utilities to facilitate the usage of Zipkin in Python applications."
zipkin,You can read more about py_zipkin here.
zipkin,We use py_zipkin here as the application is a Python app.
zipkin,"If you are interested in other languages, you can find a list of supported tracers by Zipkin here."
zipkin,"Docker Compose
Docker Compose is a tool that you can use to define and run multi docker containers."
zipkin,You use a YAML file to define all services and with just one command you can start them all.
zipkin,"To learn more about Compose, see their documentation."
zipkin,"The code
As shown in the following image, api_01 will send two requests, one to api_02 and the other to api_03."
zipkin,api_02 will send a request to api_03.
zipkin,"Dockerfile
Each API has its own Dockerfile."
zipkin,We build and ship the app environment using containers without the need to install or prepare the app env on the machine itself.
zipkin,So you don‚Äôt really need to install Python on your laptop.
zipkin,"From python:3.7

COPY ./requirements.txt /app/requirements.txt

WORKDIR /app

RUN pip install -r requirements.txt

ENTRYPOINT [ ""python"" ]

CMD [ ""app.py"" ]
In the requirements.txt file add
flask==1.1.1
requests
py_zipkin
docker-compose file
It is a very basic docker-compose.yaml file."
zipkin,"Contests of four services, a Zipkin server, and 3 flask APIs."
zipkin,"version: ""3.4""

services:
  zipkin:
    image: openzipkin/zipkin:latest
    container_name: zipkin
    ports:
      - ""9411:9411""


  api_01:
    build:
      context: api_01
    container_name: api_01
    ports:
      - ""5001:5000""
    environment:
      - 'ZIPKIN_DSN=http://zipkin:9411/api/v1/spans'
    volumes:
      - './api_01:/app'

...
All APIs‚Äô code is mounted inside the containers."
zipkin,If you changed the code it will affect directly.
zipkin,I made it this way for development porpoises.
zipkin,"api_01
Import some libraries."
zipkin,"from flask import Flask, request
import requests
from py_zipkin.zipkin import zipkin_span, create_http_headers_for_new_span, ZipkinAttrs, Kind, zipkin_client_span
from py_zipkin.request_helpers import create_http_headers
from py_zipkin.encoding import Encoding
To start a Flask server:
app = Flask(__name__)
# Start the app server
if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', threaded=True)
Start a Zipkin trace when a request is made to / route:
@app.route('/')
def index():
    with zipkin_span(
        service_name='api_01',
        span_name='index_api_01',
        transport_handler=default_handler,
        port=5000,
        sample_rate=100,
        encoding=Encoding.V2_JSON
    ):
        call_api_02()
        call_api_03()
    return 'OK', 200
zipkin_span will start a trace and creates the first span that is called ‚Äúindex_api_01‚Äù, then we will call the 2 functions call_api_02 and call_api_03."
zipkin,Each function will make a GET request to an API.
zipkin,"@zipkin_client_span(service_name='api_01', span_name='call_api_02')
def call_api_02():
    headers = create_http_headers()
    requests.get('http://api_02:5000/', headers=headers)
    return 'OK'


@zipkin_client_span(service_name='api_01', span_name='call_api_03_FROM_01')
def call_api_03():
    headers = create_http_headers()
    requests.get('http://api_03:5000/', headers=headers)
    return 'OK'
Notice that before calling the function a client span is created:
@zipkin_client_span(service_name='api_01', span_name='call_api_02')
Now we need to pass traceID and parent spanID to the next service to keep tracking the request."
zipkin,This can be done by passing headers that carry this information.
zipkin,"In addition, it creates a new spanID for the next span."
zipkin,"headers = create_http_headers()
api_02
In api_02 we are expecting that this API can only be called using api_01."
zipkin,"Also, we know that api_01 will send a request with headers that contain tracer information."
zipkin,"So we can start our Zipkin trace as the following
@app.route('/')
def index():
    with zipkin_span(
        service_name='api_02',
        zipkin_attrs=ZipkinAttrs(
            trace_id=request.headers['X-B3-TraceID'],
            span_id=request.headers['X-B3-SpanID'],
            parent_span_id=request.headers['X-B3-ParentSpanID'],
            flags=1,
            is_sampled=request.headers['X-B3-Sampled'],
        ),
        span_name='index_api_02',
        transport_handler=default_handler,
        port=5000,
        sample_rate=100,
        encoding=Encoding.V2_JSON
    ):
        call_api_03()
    return 'OK', 200
It is as the same as api_01 except for zipkin_attrs."
zipkin,Here we are telling Zipkin tracer not to start a new trace but use the one which information is passed in the headers.
zipkin,Then we call api_03 passing the new span information in the headers.
zipkin,"@zipkin_client_span(service_name='api_02', span_name='call_api_03')
def call_api_03():
    headers = create_http_headers()
    requests.get('http://api_03:5000/', headers=headers)
    return 'OK'
api_03
In api_03 we will start Zipkin trace as we did in api_02."
zipkin,"But after that, we will call a function that sleeps for 2 seconds
@zipkin_client_span(service_name='api_03', span_name='sleep_api_03')
def sleep():
    time.sleep(2)
    return 'OK'
And that is it."
zipkin,"Run the demo
Clone the code
You can find the code in this GitHub repository."
zipkin,"Start The Containers:
To start the containers run the following command:
docker-compose up --build
Then visit the api_01‚Äôs URL [ http://localhost:5001 ]
Remember the request flow."
zipkin,"To see this on Zipkin, visit Zipkin‚Äôs URL [ http://localhost:9411/zipkin ] then click on the search button to get traces saved."
zipkin,Select the trace that is saved last.
zipkin,Select the trace.
zipkin,And here we go!
zipkin,"As you can see from the previous image, api_01 made 2 requests ‚Äòto api_02 and api_03‚Äô."
zipkin,"Also, api_02 made a request to ‚Äòapi_03‚Äô
Each row here represents a span."
zipkin,You can create spans whenever it is needed.
zipkin,"The previous run used a basic installation, there are more advanced options and ways to create spans and to implement the whole solution."
zipkin,This demo wasn‚Äôt meant to be complicated as it is meant to be a POC.
zipkin,"For more information, please read the following documentation:
Zipkin official page
py_zipkin github repository
If you have any question, you can ask the Zipkin dev team on gitter, here"
zipkin,"Introduction
When it comes to developing applications within the microservice architecture, the number of microservices can grow quickly."
zipkin,Managing microservices becomes harder with each new or updated microservice.
zipkin,"When an application experiences a slowdown and its ‚Äúdata flow‚Äù goes through several different microservices, pinpointing the exact location of a slowdown may be difficult for a developer."
zipkin,"Before starting with the actual code and tutorial portion, let us start with a brief explanation of what tracing is."
zipkin,Tracing is a way to track a request from its starting point through the entire network of microservices.
zipkin,"In a typical Java microservice application, the ‚Äúchain‚Äù starts either with the front-end or API making a REST request to some entry microservice."
zipkin,"That microservice then handles the request (usually with JAX-RS) and queries other microservices, databases, or external applications."
zipkin,"As we can see, the number of requests inside the network increases and spreads out throughout multiple different destinations (especially in large applications)."
zipkin,"This is all well and good, but when a problem occurs a developer must go through a lot of logs (produced by the selected logging framework, such as Fluentd or Logstash ‚Äî in KumuluzEE you can use the KumuluzEE Logs extension to simplify logging) to find the problem."
zipkin,"If a problem is severe (such as a complete crash), a solution is usually discovered quickly or even handled automatically by some container orchestration tool (such as Kubernetes)."
zipkin,Tougher problems are the slowdowns in which the application still works but in a limited capacity.
zipkin,This is where the tracing comes in.
zipkin,"When implemented across the entire application, entire request flows are saved and presented to the user in an easy to use graphical interface."
zipkin,The base unit is called a span.
zipkin,A span can be an incoming or outgoing request; execution of a Java method; access to the database; etc.
zipkin,Each span contains basic information such as name and timestamps (additional data can be added within the code).
zipkin,"Spans are related to each other (children, nested spans) and together form a ‚Äútrace.‚Äù More detailed analysis can be made by joining microservices and their relations to a graph."
zipkin,"In conclusion, a trace is a sequence of events, called spans, which describe a path through the application."
zipkin,"KumuluzEE OpenTracing
KumuluzEE OpenTracing was released as an extension for the KumuluzEE framework."
zipkin,It is a part of MicroProfile specification.
zipkin,It supports both Jaeger and Zipkin.
zipkin,We will demonstrate how to add tracing to an existing KumuluzEE application using the KumuluzEE OpenTracing extension.
zipkin,The whole process will be demonstrated step-by-step with screenshots of each step.
zipkin,"Prerequisites
Before starting, make sure, that you have the following things ready:
Installed Java (8 and up)."
zipkin,"Installed Docker (for running Jaeger or Zipkin; this is optional if you are going to run Jaeger/Zipkin as a standalone service),
Cloned starting project from GitHub (https://github.com/kumuluz/kumuluzee-samples/tree/master/kumuluzee-opentracing-tutorial)."
zipkin,"Jaeger
Running Jaeger can be as simple as entering this line in the console:
$ docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.9
The Jaeger GUI is now accessible on http://localhost:16686."
zipkin,It consists of three main screens.
zipkin,"The first one is the ‚ÄúSearch‚Äù tab, which enables us to search through our traces with different criteria."
zipkin,"Search tab in Jaeger GUI
The second one is the ‚ÄúCompare‚Äù tab, which allows for a comparison of two spans."
zipkin,"Compare tab in Jaeger GUI
The last one is the ‚ÄúDependencies‚Äù tab, which displays a graph of our microservices and their respective connections (not shown due to being an empty page)."
zipkin,"Right now, we have no data."
zipkin,Sample data can be added by exploring the GUI because Jaeger adds its own traces.
zipkin,"Trace list in Jaeger GUI
We can now open one trace."
zipkin,"Trace details in Jaeger GUI
Zipkin
If you have chosen to use Zipkin instead of Jaeger, Zipkin can also be run inside Docker:
docker run -d -p 9411:9411 openzipkin/zipkin
The Zipkin GUI is accessible on http://localhost:9411."
zipkin,The interface is very similar to Jaeger.
zipkin,"The entry screen looks like this:

Search tab in Zipkin GUI
We can not test Zipkin yet due to not having any data (Zipkin does not store its own traces)."
zipkin,"Starting Project Structure
Before diving deeper, let us explain our starting project."
zipkin,"The project consists of 5 microservices:
master ‚Äî This is the entry point of the application."
zipkin,It is served on http://localhost:8080 (actual endpoint on v1/master).
zipkin,"When queried, it makes two requests: to the alpha endpoint v1/alpha and to the beta endpoint v1/beta."
zipkin,alpha ‚Äî This is the first of 4 ‚Äúslave‚Äù microservices.
zipkin,"It is served on http://localhost:8081 and has two endpoints: /v1/alpha (just returns a value) and /v1/alpha/beta, which queries the gamma endpoint v1/gamma."
zipkin,beta ‚Äî This is the second of 4 ‚Äúslave‚Äù microservices.
zipkin,"It is served on http://localhost:8082 and has one endpoint: /v1/beta, which queries alpha endpoint /v1/alpha/beta."
zipkin,Simulated lag is added to this request (random delay).
zipkin,gamma ‚Äî This is the third of 4 ‚Äúslave‚Äù microservices.
zipkin,"It is served on http://localhost:8083 and has one endpoint: /v1/gamma, which queries delta endpoint /v1/delta."
zipkin,This microservice is different because it uses a simulated database with CDI.
zipkin,delta ‚Äî This is the last of 4 ‚Äúslave‚Äù microservices.
zipkin,"It is served on http://localhost:8084 and has one endpoint: /v1/delta, which just return a value."
zipkin,"Microservices and their connections
Adding KumuluzEE OpenTracing Dependency
To start with tracing the first thing we need to do is add the KumuluzEE OpenTracing dependency to our application."
zipkin,"Locate the pom.xml file in the root folder and add the following dependency for Jaeger:
<dependency>
    <groupId>com.kumuluz.ee.opentracing</groupId>
    <artifactId>kumuluzee-opentracing-jaeger</artifactId>
    <version>${kumuluzee-opentracing.version}</version>
</dependency>
For Zipkin:
<dependency>
    <groupId>com.kumuluz.ee.opentracing</groupId>
    <artifactId>kumuluzee-opentracing-zipkin</artifactId>
    <version>${kumuluzee-opentracing.version}</version>
</dependency>
This needs to be done for all microservices."
zipkin,"At the time of writing this post, the latest version of KumuluzEE OpenTracing was 1.3.1."
zipkin,You do not need to add the version manually because the version is defined in the root pom as a variable and will be used automatically.
zipkin,"Just by adding this dependency, tracing is automatically enabled on all incoming JAX-RS requests."
zipkin,"To see how this looks inside your chosen tracing GUI, simply visit the master endpoint in your browser:
http://localhost:8080/v1/master."
zipkin,"After the page loads, we will see if any traces were added."
zipkin,"Traces in Jaeger without any names and connections between them

Traces in Zipkin without any names and connections between them
Commit for this step (for Jaeger)
We can see that there is a trace for each microservice with confusing names."
zipkin,"That is not what we want, but it is a good first step."
zipkin,"The next step is to add the service name configuration field in order to make our traces more readable since the default service name is the Kumuluz instance id, which is just a bunch of numbers and letters (as seen in the image)."
zipkin,We can do this in the config.yml file (located in src/main/resources).
zipkin,"Add the service name field:
kumuluzee:
  opentracing:
    jaeger:
      service-name: master 
    zipkin:
      service-name: master
We can also add the property kumuluzee.name, which will be used as a service name if the service name is not provided (the service name is checked first, then kumuluzee.name and lastly the instance id)."
zipkin,"Remember, this needs to be done for all five microservices."
zipkin,Let us rerun our microservices and try again.
zipkin,"Traces are now more human-friendly and readable:

Traces in Jaeger with added names

Traces in Zipkin with names
There are several other settings available, but we do not need them for this sample."
zipkin,"For more information about other settings, check the KumuluzEE OpenTracing GitHub page."
zipkin,Note: Settings for Jaeger and Zipkin are different.
zipkin,Make sure that you are setting the correct fields.
zipkin,"Commit for this step (for Jaeger)
Adding JAX-RS Outgoing Requests Tracing
As already mentioned before, incoming JAX-RS requests are traced automatically."
zipkin,The same does not apply to outgoing requests.
zipkin,"At the moment, we have traces for each individual microservice, but we want to see the whole trace grouped together."
zipkin,We need to add some code to achieve that.
zipkin,"First, locate the Resource.java file (src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/master) and change the initialization logic for the Client class."
zipkin,"private Client client = ClientBuilder.newClient();
with
private Client client = ClientTracingRegistrar.configure(ClientBuilder.newBuilder()).build();
For a microservice to resume the trace of some other microservice, the details of the trace need to be sent along with the REST request (achieved with HTTP headers)."
zipkin,This is what a ClientTracingRegistrar.configure method does: it makes sure that the required headers are added to each outgoing request.
zipkin,"After changing this line in all microservices (except the delta microservice, which does not have a client), the result should be the following trace:

Traces in Jaeger with added connections

Traces in Zipkin with added connections
If we open this trace, we can see the whole request with all the microservices in one."
zipkin,"Full trace view in Jaeger

Full trace view in Zipkin
This is exactly what we wanted; the overview of the whole request will all the timestamps."
zipkin,"We can also look at the ‚ÄúDependencies‚Äù tree now, which is updated with our microservices:

Dependencies view in Jaeger

Dependencies view in Zipkin
Commit for this step
Additional Features
We will demonstrate three additional features of tracing:
Handling exceptions in spans."
zipkin,Adding custom data to spans.
zipkin,Adding custom spans (such as database access).
zipkin,"Handling Exceptions
Exceptions are handled automatically by KumuluzEE OpenTracing."
zipkin,"To demonstrate this, we will throw an exception in the delta microservice."
zipkin,"Locate the Resource.java file (src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/delta) and add the following line:
@GET
public Response get() {
    throw new RuntimeException(""Something went wrong here."
zipkin,""");
    // return Response.ok(""delta"").build();
}
We now have to restart the delta microservice and refresh the page."
zipkin,"The created trace now looks like this:

Excepion preview in Jaeger

Exception preview in Zipkin
We can see from the trace that exception was added to the trace as a log."
zipkin,We will cover adding logs in the next section.
zipkin,"Adding Custom Data to Spans
If we look back to our project structure, we added some simulated lag to our application in the beta microservice."
zipkin,"Basically, we added a random delay from 1 to 1000 milliseconds to the request."
zipkin,We will add this parameter to the trace to see how long we have to wait for the request.
zipkin,We start by moving the wait time to a new variable.
zipkin,Then we inject the Tracer instance (we also added @RequestScoped for CDI injection).
zipkin,"After that, we can access the current span with tracer.activeSpan and add our delay to it."
zipkin,"We can do it in three ways: with adding a tag, adding a log entry or adding a baggage item."
zipkin,"We will demonstrate all three:
setTag();
log();
setBaggageItem();
Full code (src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/beta/Resource.java):
@Path(""beta"")
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
@RequestScoped
public class Resource {
    private Client client = ClientTracingRegistrar.configure(ClientBuilder.newBuilder()).build();
    @Inject
    private Tracer tracer;
    @GET
    public Response get() {
        try {
            int waitDelay = ThreadLocalRandom.current().nextInt(1, 1000 + 1);
            tracer.activeSpan().setTag(""waitDelay"", waitDelay);
            tracer.activeSpan().log(""Waited "" + waitDelay + "" milliseconds."
zipkin,""");
            tracer.activeSpan().setBaggageItem(""waitDelay"", String.valueOf(waitDelay));
            Thread.sleep(waitDelay);
            Response r1 = client
                    .target(""http://localhost:8081/v1"")
                    .path(""alpha"")
                    .path(""beta"")
                    .request()
                    .get();
            String response = r1.readEntity(String.class);
            return Response.ok(""beta->"" + response).build();
        } catch (Exception e) {
            return Response.serverError().build();
        }
    }
}
Choosing a method of storing custom data is up to the developer."
zipkin,"Tags are often used for storing metadata information (such as IP addresses, span types, versions, etc."
zipkin,"), logs are used for storing messages (such as exceptions) and baggage is used for storing data, which can be retrieved later with the getBaggageItem() method."
zipkin,This is not the only thing we can do with an injected tracer.
zipkin,"By injecting the tracer, you get access to its methods."
zipkin,The main thing you can do with it is start spans manually.
zipkin,You can read more in the OpenTracing documentation.
zipkin,"Also, read the documentation for more details on when to use each method of adding custom data to spans (baggage, log, or tag)."
zipkin,"Let us restart the beta microservice and see what our trace looks like now:

Additional data in Jaeger

Additional data in Zipkin
Commit for this step
Adding Custom Spans
The final thing we will do in this guide add tracing to functions outside of JAX-RS."
zipkin,This way we can include methods and functions that are outside of a REST service to the distributed trace.
zipkin,"Typical examples are calls to the database, calls to external applications using protocols other than REST services, and similar scenarios."
zipkin,"To demonstrate this, we will show how to add calls to the database."
zipkin,We have implemented a simulated database in our gamma microservice.
zipkin,The easiest way to add custom spans is to use the @Traced annotation and put it on the class.
zipkin,"This way, all the methods will be traced."
zipkin,This annotation can also be used on a single method if we only want to trace a specific method inside the class.
zipkin,It is also possible to annotate the class and then disable tracing on methods by annotating them and setting the property value to false.
zipkin,Annotating and setting the value to false can also be used to disable automatic tracing of JAX-RS incoming requests.
zipkin,We will put the @Traced annotation to our Database class and all methods inside the class will be traced.
zipkin,It is also possible to change the span name by changing the operationName parameter.
zipkin,"Let us see how this looks like inside the code (Database.java file, located in src/main/java/com/kumuluz/ee/samples/opentracing/tutorial/gamma):
@ApplicationScoped
@Traced(value = true, operationName = ""testingChangedOperationName"")
public class Database {
    private HashMap<Integer, String> data;
    @PostConstruct
    private void init() {
        data = new HashMap<Integer, String>();
        data.put(1, ""gamma"");
    }
    public String get(Integer id) {
        return data.get(id);
    }
}
As a result, we get the following span added to our trace:

Custom span inside trace in Jaeger

Custom span inside trace in Zipkin
We could achieve the same thing by injecting a tracer and manually creating the span."
zipkin,This is used when a developer wants a more fine-grained control over created spans.
zipkin,"That way, more that one span can be created inside one method."
zipkin,"Commit for this step
Summary
In this article, we have demonstrated the basic principles of distributed tracing for microservices."
zipkin,We implemented the tracing of an existing application using the KumuluzEE OpenTracing extension.
zipkin,We did not need to write a lot of code.
zipkin,We only changed a few lines and added some annotations.
zipkin,This shows how simple it is to add distributed tracing to your existing microservices and get all the benefits of distributed tracing such as tracing requests through an entire network of microservices and easier pinpointing of slowdowns.
zipkin,"Even though we covered the basics of tracing, we left a few things out."
zipkin,"For example, we did not include integration with a MicroProfile Config extension and KumuluzEE config frameworks, which would allow additional tracing configuration such as ignoring tracing on JAX-RS endpoints and changing the way that spans are named."
zipkin,We have explained more advanced features only briefly but would suggest the reader dig deeper into OpenTracing if they plan to use it in real-world applications.
zipkin,We also used the basic Jaeger/Zipkin configuration and ran the all-in-one Docker images.
zipkin,"Before running either one in production, consult the documentation for proper use cases and guidelines."
zipkin,Disclaimer: this article is an updated version of the original with the only difference being the added Zipkin part.
zipkin,"Useful Links and References
For more information, visit the following links:
KumuluzEE (https://ee.kumuluz.com/ and https://github.com/kumuluz/),
KumuluzEE Blog (https://blog.kumuluz.com/),
KumuluzEE OpenTracing (https://github.com/kumuluz/kumuluzee-opentracing),
MicroProfile (https://microprofile.io/),
MicroProfile OpenTracing (https://github.com/eclipse/microprofile-opentracing),
Jaeger distributed tracing (https://www.jaegertracing.io/),
Zipkin distributed tracing (https://zipkin.io/),
OpenTracing (https://opentracing.io/),
Original blog post (https://blog.kumuluz.com/developers/community/2019/02/11/kumuluzee-opentracing-jaeger)."
zipkin,"When companies began moving towards Microservices architect, the need of tracing the packets between services appeared to understand and fix bugs and troubleshoot latency problems in service architectures."
zipkin,"While logs can tell us whether a specific request failed to execute or not and metrics can help us monitor how many times this request failed and how long the failed request took, traces help us debug the reason why the request failed or took so long to execute by breaking up the execution flow and dissecting it into smaller events."
zipkin,"Zipkin is a distributed tracing system that does that job for you, and a lot of libraries appeared in different programming languages to support its protocol."
zipkin,"The Zipkin UI provides us with some basic options to analyze traced requests, but by using ELK stack; Elasticsearch can be used for long-term retention of the trace data and Kibana will allow you gain much deeper insight into the data."
zipkin,"However, I will talk in this article about integrating Zipkin with NodeJS Express project using zipkin-js library."
zipkin,"Tracing middleware
The best way to use zipkin-js is to implement its initialization inside an Express middleware."
zipkin,"In addition to zipkin-js we will need to use Zipkin-transport-http to send Zipkin trace data to a configurable HTTP endpoint (Zipkin server), and zipkin-instrumentation-express which is Express middleware and instrumentation that adds Zipkin tracing to the application."
zipkin,But always its better to write our own middleware just in case we needed anytime to implement another distributed tracing system.
zipkin,So having an abstract middleware for tracing and different implementation will always be the best case.
zipkin,"Next code shows such a middleware that can be used inside Express web application:
const { Tracer, BatchRecorder, jsonEncoder, ExplicitContext } = require(‚Äòzipkin‚Äô);
const { HttpLogger } = require(‚Äòzipkin-transport-http‚Äô);
const zipkinMiddleware = require(‚Äòzipkin-instrumentation-express‚Äô).expressMiddleware;
const { ZIPKIN_SERVER_URL } = process.env;
module.exports = class TracingMiddleware {
initializeMiddleware(app) {
app.use(zipkinMiddleware({ tracer: this.initializeTracer() }));
app.use(this.middlewareFunction);
}
initializeTracer() {
const ctxImpl = new ExplicitContext();
const recorder = new BatchRecorder({ logger: new HttpLogger({
endpoint: `${ZIPKIN_SERVER_URL}api/v2/spans`,
jsonEncoder: jsonEncoder.JSON_V2,
})});
this.tracer = new Tracer({ctxImpl,recorder, localServiceName: ‚Äúservice_name‚Äù});
return this.tracer;
}
middlewareFunction(req, res, next) { 
 res.header(‚ÄòtraceId‚Äô, (req && req._trace_id ?"
zipkin,"req._trace_id.traceId :‚ÄòNo Trace id‚Äô));
next();
}
};
initializeMiddleware function should be called while initializing the Express app passing that app to it as a parameter."
zipkin,That function will use zipkinMiddleware with a tracer initialized using initializeTracer function.
zipkin,"Also, I implemented a middleware function that will inject trace id and span id inside the response header."
zipkin,"trace id and span id stored from the middleware side inside the request object with the names (_trace_id, _span_id)."
zipkin,Which is unclear through the library documentation.
zipkin,"Integrate trace id and span id in internal communications between services
One important thing in a distributed tracing system is that each microservice should pass the trace id and span id to the next one when calling it, in NodeJS to call another service you will need to use some Http client library."
zipkin,"One of the most famous ones is Axios and luckily there is a library that does that job, zipkin-instrumentation-axios."
zipkin,This library will wrap Axios and inject the trace id and span id in the headers of all requests to other services.
zipkin,Keep in mind that you will need to use the same previous initialized tracer inside the middleware.
zipkin,"So we can modify the initializeTracer function to be as next:
initializeTracer() {
const ctxImpl = new ExplicitContext();
const recorder = new BatchRecorder({
logger: new HttpLogger({
endpoint: `${ZIPKIN_URL}api/v2/spans`,
jsonEncoder: jsonEncoder.JSON_V2,
})
});
this.tracer = new Tracer({ctxImpl,recorder,localServiceName: ‚Äúservice_name‚Äù});
this.zipkinAxios = zipkinInstrumentationAxios(axios, { tracer: this.tracer, serviceName: ‚Äúservice_name‚Äù });
return this.tracer;
}
So afterward we can export that Axios instance to be used in other classes that are responsible for communications to other services."
zipkin,A good way to achieve that is to implement a getter function inside the TracingMiddleware class that will get this initialized wrapped Axios instance.
zipkin,And you can use IoC library to initialize this middleware like addict-ioc with a singleton option so always you will get the same middleware instance whenever you are resolving it.
zipkin,"I hope that will help someone cause I wasted a lot of time just to configure this small thing because of the lack of documentation, while there is much more rich documentation in other programming languages like Java."
zipkin,"Let‚Äôs go back to 2015
Back in 2015 the microservices hype was really kicking off."
zipkin,"Back then Magnet.me consisted of 3 separate services:
rest-api : our monolith backend which exposed a RESTful API
web-frontier : our user-facing service serving up an AngularJS app
oauth : our authentication and authorisation backend
The concept of microservices promised us more flexibility: scaling up individual components of our backend, the ability to try out different programming languages, libraries, and approaches, while also limiting the blast radius of outages in case of failures."
zipkin,"But it would also mean a far more complex infrastructure, having to run, monitor, and automate general management of a multitude of services, as well as way of getting services to talk to each other somehow."
zipkin,After a short period of prototyping we ultimately settled on the approach covered in this post.
zipkin,"Consul
In 2015 we opted to use Consul to manage Service Discovery, and handle the configuration for our (micro)services in one centralized place."
zipkin,"Back then there weren‚Äôt that many options for Service Discovery, and seemingly every platform and tool had a different approach."
zipkin,"It‚Äôs worth noting that this was before Kubernetes, Docker swarm, etc really took off, and it really wasn‚Äôt clear which one was going to ‚Äúwin‚Äù in this space."
zipkin,"We also didn‚Äôt really want to buy into a specific tool, and potentially end up depending on a tool that was losing community support in the long-term."
zipkin,"Instead what we wanted was to pick the best approach for us, and find the best tool to support that approach."
zipkin,For us this was Consul.
zipkin,Consul makes Service Discovery very easy.
zipkin,It even exposes a DNS service to your cluster which your own services can use to find each other.
zipkin,In this setup you‚Äôd simply query that DNS service to get a location (IP address + port) for the service you‚Äôre trying to contact.
zipkin,"However, for reasons that will become more apparent later on, we decided to go a slightly different route."
zipkin,What were our options?
zipkin,"Back then there were basically 3 options we could pick from: Relying on DNS to locate other services, using a load-balancer with dynamic routing to direct traffic to a specific instance, or using a sidecar container which magically handles the network for you (typically these came along with a container orchestration tool)."
zipkin,"It‚Äôs important to note, that each service either registers itself somewhere on start-up, or that it‚Äôs automatically registered by the container orchestration tool when the service is started."
zipkin,"Relying on DNS
With this option, you‚Äôre using a custom DNS service to keep an actively updated view of where every instance of every service is running."
zipkin,"Services can either lookup addresses with a DNS client, or simply configure their runtime to use the DNS service as the default nameserver."
zipkin,"In that case if the front-end service wanted to retrieve information about a specific user from the backend, the front-end service would simply ask therest-api service by sending a HTTP request to http://rest-api.local.consul/users/1 or something similar."
zipkin,"Using a load-balancer
One alternative is using a centralized load-balancer of which every service knows the location, to redirect requests to one of the instances of the targeted service."
zipkin,The configuration of the load-balancer is actively updated as services get registered and deregistered from the cluster.
zipkin,Using this approach you‚Äôd simply send a HTTP request like http://rest-api.services.magnet.me/users/1 and the load-balancer would send it to an instance of rest-api.
zipkin,"Using a the sidecar-pattern to handle networking
This one felt a bit like black magic, and leverages container isolation."
zipkin,"If your service runs in a container, with this pattern your service is intentionally kept isolated from the rest of the network."
zipkin,Instead it can only talk to one other container called the sidecar.
zipkin,"This container receives HTTP requests from your service, and then directs them through the cluster, relaying back responses it receives."
zipkin,"Yeah, that‚Äôs no bueno‚Ä¶
We didn‚Äôt really like any of these options."
zipkin,Primarily because all of these options try to abstract away all the details and all of the control from your service.
zipkin,"Your service has no control over which specific instance of the service gets its request, only the guarantee that some instance will receive it."
zipkin,"Where that instance is located, or what the state of that instance is, is entirely hidden from the service, while there‚Äôs no real reason to do so."
zipkin,At the same time we were inspired by Netflix‚Äôs approach to microservices using Hysterix.
zipkin,Hysterix is a library that allows services to services to talk to each other in a distributed environment with fault-tolerance built in.
zipkin,"Requests get automatically retried on failures, and if downstream services get overloaded or become unresponsive, circuit-breakers prevent requests from being sent to the affected services, allowing them to recover."
zipkin,We really liked this approach but it also takes a considered approach to communicating this way.
zipkin,"Not only do you need to define what your service should do if a request cannot be executed within a timely fashion, but also how it can find and talk to several other instances autonomously."
zipkin,"Our approach
Our services register themselves with a local Consul agent when they start up, and automatically deregister themselves when they terminate."
zipkin,"In addition to this a service exposes its health over a HTTP endpoint, which it instructs Consul to check periodically."
zipkin,"To set this up, we use our own open-sourced library called Consultant."
zipkin,"When we want to make a request to another service we do the following:
We use Consultant to ask Consul to give us a list of instances that the local Consul agent is aware of."
zipkin,"Since Consul keeps track of the health of a service for us, we ask it filter out any unhealthy or unresponsive instances, and sort the list of instances by network distance (from closest by to furthest away)."
zipkin,We then randomly select and remove one instance from the list (heavily biased to closer by instances).
zipkin,"This acts as a bit of a round-robin effect, ensuring every instance gets a similar workload, while still avoiding services which would take longer to talk to."
zipkin,We then send off our request to that instance.
zipkin,"And if that request is successful, that‚Äôs basically the end of the story."
zipkin,"However, if we receive a 503 Service Unavailable, we‚Äôll know that this instance is no longer accessible or capable of handling requests."
zipkin,"We then select another instance from that same list (excluding instances we already tried), and resend the request to that instance."
zipkin,"It‚Äôs important to note that this is only possible because we have the ability to locate all these instances, and we have control over which instance we contact."
zipkin,"If we didn‚Äôt, there would be a significant chance we‚Äôd be sending requests to instances we already tried sending this request to before, but failed ."
zipkin,"We repeat this last step until either the request succeeds, a pre-specified timeout is exceeded, or if we tried all of the listed instances."
zipkin,"In these cases, it‚Äôs up to the service performing the request to determine what happens, and in most cases the error propagated back to the upstream service which made the request to our service, which in turn may decide to retry the request by itself."
zipkin,"Example of how our setup would recover from a downstream request that fails, and is subsequently retried on another instance."
zipkin,"To achieve all of this we wrote our own wrapper around async-http-client which uses Consultant to talk to Consul, and uses RxJava internally for sending off the request and retrying the request if it couldn‚Äôt send it to the selected instance of the targeted service."
zipkin,"This allows us to perform HTTP requests in a familiar way, while performing all of the service locating, and retrying on a lower level."
zipkin,"We already tend to write tiny clients for most of our microservices in our most predominantly used programming language in the backend, so this makes it really easy to call any services from almost any other service."
zipkin,Simplified example of how we‚Äôd describe a tiny client for getting users.
zipkin,Simplified example of how we can now fetch users over the network.
zipkin,"But we can do better‚Ä¶
This only retries requests if they failed with a 503 Service Unavailable status code."
zipkin,"What if we want to retry on an arbitrary error code, or an exception being thrown because of some entity could not be found, or networking issues throwing IOExceptions?"
zipkin,"For this we implemented an ExponentialBackoff class which will reattempt whatever Single or Observable stream it is attached to, when a problem occurs."
zipkin,"On which errors it retries, as well as how often and how fast can all be configured."
zipkin,"In a distributed environment that means that you‚Äôve drastically improved your chances of successfully executing a request, even if the network is having an off day."
zipkin,But this brings us to another problem: big fan-outs with retried requests.
zipkin,"Observability
When you take the microservices route, you‚Äôll quickly end up running a big variety of services ‚Äî all preferably with multiple instances."
zipkin,"But when you grow the number of services and instances over time, you‚Äôll eventually end up with a situation where a user request will arrive in your brokering service ‚Äî sometimes also called a BFF ‚Äî , which then needs to contact a variety of services, sometimes even in a nested fashion."
zipkin,We‚Äôll discuss the details on how we do this at Magnet.me in another post.
zipkin,But as you can imagine it‚Äôs important that you build some kind of logging mechanism for internal requests belonging to the same user request.
zipkin,"If not you‚Äôll never know why a certain request is timing out, or returns a generic 500 Server Error ."
zipkin,"To deal with this in our stack, we chose Zipkin a couple of years ago."
zipkin,"This means that when a user request enters our infrastructure, it‚Äôs assigned a unique trace ID."
zipkin,This trace ID is passed along through every internal request to downstream services.
zipkin,"Every internal client, and internal service, registers their outgoing and incoming requests with that trace ID to Zipkin."
zipkin,"This allows Zipkin to know which internal requests belong to which user request, and produces an easy to read interactive graph, allowing you to easily pinpoint any issues for any given user request."
zipkin,"Although you can search for a specific trace in Zipkin‚Äôs UI fairly easy, we also expose the trace ID in a HTTP header when answering the user request."
zipkin,"That way it‚Äôs easier to look that specific trace up, if you come across an anomaly in the logs, or in your own browser."
zipkin,We have since also started tracing operations on our Elasticsearch cluster as well as operations on Redis instances.
zipkin,This can give a very detailed view of what actually happens when a user request is processed.
zipkin,"In turn this may also lead you to the understanding that some fan-outs have simply gotten too big, and may need some optimization."
zipkin,Example of a Zipkin trace showing how the user request fanned out to multiple internal requests between our microservices.
zipkin,It‚Äôs also showing which requests/operations were slow relatively speaking.
zipkin,"Conclusion
We hope this gave you a nice peek into some of the core principles that shaped our stack and infrastructure over the years."
zipkin,"Although the bulk of this work was done in 2015 and 2016, much of it is still very relevant, and we see no reason to change anything."
zipkin,"If we had to build Magnet.me from scratch today, we might not pick the exact same tools, but the principles we followed are still sound and we‚Äôd probably follow those again."
zipkin,"Introduction
In this article, I would like to go through with you about how to view traces from both Jaeger and Zipkin as a single view."
zipkin,You might be thinking that it should be just fine to stick to one of the other.
zipkin,"However, with the increasing use of Microservices style architecture, choose of tracers is becoming independent."
zipkin,Jaeger and Zipkin support OpenTracing specification and each tracer works independently based on their own Propagation format implementation ‚Äî Jaeger and Zipkin B3.
zipkin,"System Architecture
Figure 1."
zipkin,"Architecture to illustrate the use case
Using the simple diagram above, you could see that each of the system is behaving independently and hence for this use case, I choose different tracer as well to present the practical problem which we could be facing in the real world."
zipkin,"Solution
Fortunately, we could integrate these two tracers nicely and elegantly."
zipkin,"Jaeger has provided quite a flexible way of working with Zipkin, which you can checkout on the Github Jaeger-Zipkin."
zipkin,"So, we can configure Jaeger to use Zipkin‚Äôs Propagation format ‚Äî B3 Propagation."
zipkin,"fun initTracer() {
    val samplerConfig = SamplerConfiguration().withType(""const"").withParam(1)
    val reporterConfig = ReporterConfiguration()
        .withLogSpans(true)
    val codecConfig = CodecConfiguration().withPropagation(Propagation.B3)
    val tracer = Configuration(""componentSvcA"")
        .withCodec(codecConfig)
        .withSampler(samplerConfig)
        .withReporter(reporterConfig)
        .withTraceId128Bit(true)
        .tracer
    GlobalTracer.registerIfAbsent { tracer }
}
Source code is available on Github Jaeger-Zipkin-Sample."
zipkin,The sample code is using OpenTracing Java Annotation library (article can be found on below).
zipkin,"OpenTracing Annotation
OpenTracing provides annotation driven based such as @Traced."
zipkin,"The annotation is very simple concept which makes very‚Ä¶
medium.com

Result
Once we configured Jaeger to use B3 Propagation format, the traces are in a single view as we expected to be."
zipkin,"In Microservice architecture, the calling chain is long and complex, to understand each component and the performance of it, you need something called distributed tracing."
zipkin,"The idea is simple, you generate a unique ID at the beginning of each request, and carry it along the whole calling chain."
zipkin,The ID is called Correlation ID¬π and you can use it to trace the performance of the entire request.
zipkin,There are two problems need to be solved.
zipkin,"First, how to make the ID available to every function you need to trace inside your application; second, how to pass the ID across the network when you need to call another Microservice."
zipkin,What is OpenTracing?
zipkin,"There are many tracing libraries, among which the most popular ones probably are ‚ÄúZipkin‚Äù¬≤ and ‚ÄúJaeger‚Äù¬≥."
zipkin,Which library do you choose?
zipkin,"That is always a headache because you can choose the most popular one at the moment, but what if later on there is a better one coming out?"
zipkin,"OpenTracing‚Å¥ tried to solve the problem by creating a common interface for tracing libraries, so you can switch to a different implementation library in the future without changing your code."
zipkin,How to trace server endpoints?
zipkin,"In our application, we use ‚ÄúZipkin‚Äù as the tracing library and ‚ÄúOpenTracing‚Äù as the generic tracing API."
zipkin,"There are usually four components in a tracing system, and I use Zipkin as an example:
Recorder: which will record the trace data
Reporter (or collecting agent): which collects the data from a recorder and sends the data to UI app
Tracer: which generates the trace data
UI: which is responsible for presenting trace data in a graphic UI
zipkin
The above is the component diagram of Zipkin, and I took it from ‚ÄúZipkin Architecture‚Äù‚Åµ."
zipkin,"There are two different types of tracing, one is in-process tracing and the other is cross-process tracing."
zipkin,Let‚Äôs talk about cross-process tracing first.
zipkin,"The client side code:
We use a simple gRPC program as an example, which has client side and server side code."
zipkin,We‚Äôd like to trace a request from the client side to the server side and return back.
zipkin,The following is the code to create a new tracer on the client side.
zipkin,"First it creates the ‚ÄúHTTP Collector‚Äù (the agent), which collects the tracing data and sends it to the ‚ÄúZipkin‚Äù UI."
zipkin,The ‚ÄúendpointUrl‚Äù is the URL for ‚ÄúZipkin‚Äù UI.
zipkin,"Second, it creates a recorder to record the information on an endpoint, and the ‚ÄúhostUrl‚Äù is the URL for gRPC (client) call."
zipkin,"Third, it creates a new tracer with the recorder we just created."
zipkin,"Finally, it sets the ‚ÄúGlobalTracer‚Äù for ‚ÄúOpenTracing‚Äù, which can be accessed in the whole application."
zipkin,The following is the gRPC client code.
zipkin,"It first calls the function ‚ÄúnewTrace()‚Äù mentioned above to create the tracer, then, it creates the gRPC connection which includes the newly created tracer."
zipkin,"Next, it creates the cache service client with the connection just created."
zipkin,"Finally, it makes the ‚ÄúGet‚Äù call to the cache service through the gRPC client."
zipkin,"Trace and Span:
In OpenTracing, an important concept is called ‚Äútrace‚Äù, which represents one calling chain of a request from the beginning to the end and the identifier is ‚ÄútraceID‚Äù."
zipkin,"Under a trace, there are many spans, each captures a unit of work inside the calling chain and it is identified by ‚ÄúspanId‚Äù."
zipkin,Each span has one parent and all spans of a trace formed a directed acyclic graph(DAG).
zipkin,The following is the diagram of the relationship among spans.
zipkin,I took it from ‚ÄúThe OpenTracing Semantic Specification‚Äù‚Å∂.
zipkin,"span
The following is the function ‚ÄúcallGet‚Äù, which makes a call to the gRPC server."
zipkin,"At the beginning of the function, it starts a span for this function and at the end, it finishes the span."
zipkin,"The server side code:
The code is similar to the client side code, it also calls ‚ÄúnewTracer()‚Äù(which is almost the same with the client side ‚ÄúnewTracer()‚Äù function) to create a tracer."
zipkin,"Then, it creates a ‚ÄúOpenTracingServerInterceptor‚Äù, which has the tracer inside it."
zipkin,"Finally, it creates the gRPC server with the interceptor we just created."
zipkin,The following is the picture of the trace and the spans in Zipkin after you run the above code.
zipkin,"One the server side, we didn‚Äôt write any code inside a function to generate the span, all we need to do is to create a trace and the server interceptor automatically generates the call span for us."
zipkin,"callSpan
How to trace inside a function?"
zipkin,The above picture didn‚Äôt give us what is going on inside a function.
zipkin,We need to write some code to do it.
zipkin,The following is the server side ‚Äúget‚Äù function and we added trace code.
zipkin,It first gets the span from the context and then creates a new child span and using the one we just got as the parent span.
zipkin,"Next, it does some action (for example, a database query) and then finishes the child span."
zipkin,The following is the picture of it.
zipkin,"Now it has a new span ‚Äúdb query user‚Äù on the server side, which we just added."
zipkin,"serverSpan
The following is the data for it."
zipkin,You can see the client starts at 8.016ms and the server starts at the same time.
zipkin,It takes about 16ms for the server side to finish.
zipkin,"traceBetweenServer
How to trace a database?"
zipkin,What if you need to trace what is going on inside the database call?
zipkin,"Then, database driver needs to support tracing and you need to pass the tracer into the database."
zipkin,What if the database driver doesn‚Äôt support tracing?
zipkin,"There are several driver wrappers, which can wrap any database drivers and make them supporting tracing."
zipkin,One of them is ‚Äúinstrumentedsql‚Äù‚Å∑ (The others are ‚Äúluna-duclos/instrumentedsql‚Äù‚Å∏ and ‚Äúocsql/driver.go‚Äù‚Åπ).
zipkin,I briefly looked at the code of them and they use the same approach.
zipkin,"Basically, they all create a wrapper for each function of the underlying database call and start a new span before each database operation and finish the span after the operation is done."
zipkin,"However, all of those wrappers only wrapped on ‚Äúdatabase/sql‚Äù interface, so no luck for NoSQL database."
zipkin,"If you can‚Äôt find a driver supporting OpenTracing for your NoSQL database, you may need to write a wrapper."
zipkin,It shouldn‚Äôt be difficult to do though.
zipkin,"One question is ‚ÄúIf I use OpenTracing with Zipkin and the database driver use OpenTracing with Jaeger, will that work?‚Äù It turned out that won‚Äôt happen."
zipkin,Most of the wrappers I mentioned above supporting OpenTracing.
zipkin,"In order to get the wrapper working, you need to register the wrapped SQL driver, which has the tracer in it."
zipkin,"Inside the wrapper, all tracing functions are called on the OpenTracing interface, so it doesn‚Äôt even know whether the underlying implementation is Zipkin or Jaeger."
zipkin,"Now, you see the benefit of using OpenTarcing."
zipkin,"At the time of creating the global tracer in your application, you do need to decide whether to use Zipkin or Jaeger, after that, each function in your application or third party libraries only calls the OpenTracing interface and everything will work."
zipkin,How to trace a client call?
zipkin,"Let‚Äôs say we need to call a RESTFul service in our gRPC service, how to trace that?"
zipkin,A simple answer is to use the HTTP header as the media to carry out the trace information.
zipkin,"No matter the Microservice is gRPC or RESTFul, they all use the HTTP protocol."
zipkin,"If it is a message queue, then put trace information in the message header."
zipkin,"(There are two different types of headers for Zipkin B3-propogation, ‚Äúsingle header‚Äù and ‚Äúmultiple header‚Äù, but JMS only supports single header)
One important concept is ‚Äútrace context‚Äù, which defines all the needed information to propagate a trace, such as traceID, parentId (parent spanId) and so on."
zipkin,"For more information, please read ‚ÄúTrace Context‚Äù¬π‚Å∞."
zipkin,"OpenTracing provides two functions to propagate the trace context: ‚Äúextract (format, carrier)‚Äù and ‚Äúinject (SpanContext, format, carrier)‚Äù."
zipkin,"‚Äúextarct()‚Äù retrieves the tracing context from a carrier, usually it is the HTTP header."
zipkin,"‚Äúinject‚Äù puts the tracing context into a carrier, so the tracing chain won‚Äôt break."
zipkin,"The following is the diagram for ‚Äúb3-propagation‚Äù, which I took from Zipkin."
zipkin,"b3PropogationWhite
But why didn‚Äôt we call those functions in our example?"
zipkin,Let‚Äôs review the code.
zipkin,"On the client side, when creating the gRPC client connection, we called a function named ‚ÄúOpenTracingClientInterceptor‚Äù."
zipkin,"The following is the partial code for ‚ÄúOpenTracingClientInterceptor‚Äù, which I took from ‚Äúclient.go‚Äù in ‚Äúotgrpc‚Äù¬π¬π package."
zipkin,"It gets the trace context from the Go context¬π¬≤ and inject it into HTTP header, so we don‚Äôt need to do it manually."
zipkin,"On the server side, we also called a function ‚Äúotgrpc.OpenTracingServerInterceptor‚Äù, the code of which is similar to the client side ‚ÄúOpenTracingClientInterceptor‚Äù."
zipkin,"Instead of injecting trace context, it extracts the trace context from the HTTP header and put it into the Go context."
zipkin,That is why we don‚Äôt need to manually call ‚Äúextract()‚Äù again.
zipkin,"In our code, we can directly extract the trace context from the Go context (opentracing.SpanFromContext(ctx))."
zipkin,"But for other HTTP based services such as RESTFul service, that may not be the case."
zipkin,So we need to explicitly extract the trace context from the HTTP header on the server side.
zipkin,"Of course, you can use an Interceptor or a filter as well."
zipkin,"The interoperability between trace libraries
One question is ‚ÄúIf I use OpenTracing with Zipkin and a third party Microservice using OpenTracing with Jaeger, will the trace work between them?‚Äù It looks similar to the database question we asked before, but they are very different."
zipkin,"For the database one, because the application and the database are in the same process, they can share the same global tracer, so it is much easier to solve."
zipkin,"For the Microservice one, generally speaking, it won‚Äôt work because OpenTracing only standardized the tracing API and it didn‚Äôt standardize on the trace context."
zipkin,"The World Wide Web Consortium (W3C) is working on a standard for ‚Äútrace context‚Äù¬π‚Å∞, and it published a candidate recommendation on 2019‚Äì08‚Äì09."
zipkin,OpenTracing lets the vendor to decide which trace context they use.
zipkin,It seems each vendor choosing its own trace context.
zipkin,"For example, Zipkin uses ‚ÄúX-B3-TraceId‚Äù as the trace ID and ‚ÄúJaeger‚Äù uses ‚Äúuber-trace-id‚Äù, so implementing OpenTracing doesn‚Äôt mean that a trace library can interoperate with each other across the wire."
zipkin,"One good news for ‚ÄúJaeger‚Äù is that you can choose to use ‚ÄúZipkin compatibility features‚Äù¬π¬≥ to generate Zipkin trace context when you create a Jaeger tracer, then they will be compatible with each other."
zipkin,"For other situations, you need to do the manual translation (between the extract and the inject) yourself."
zipkin,"The design of tracing
Write less code for tracing
One requirement for tracing should be writing as less tracing code as possible."
zipkin,"Ideally, you don‚Äôt need to any code and a framework, and the library will take care of it, but that is not easy to do."
zipkin,"There are three levels of tracing:
cross-process tracing
database tracing
in-process tracing
It turned out that cross-process tracing is the easiest one."
zipkin,"You can write a interceptor or a filter to trace every request, only minimum coding involved."
zipkin,Database tracing is also fine.
zipkin,"If using the wrapper we talked above, you only need to register the driver wrapper and pass in go-context (to database functions), which has trace context inside."
zipkin,You can use Dependency Injection to do it with minimum coding.
zipkin,In-process tracing is the most difficult one because you have to write tracing code for each individual function.
zipkin,I am not aware a good way to write a generic function to trace every function in an application.
zipkin,(Interceptor won‚Äôt be a good choice because it needs every function has a generic type (interface{}) for parameters and returns).
zipkin,"Fortunately, the first two levels probably are good enough for most people."
zipkin,"Some people may implement distributed tracing with service mesh, such as Istio or Linkerd."
zipkin,Tracing is best implemented by infrastructure rather than be mixed with your business logic.
zipkin,You will face the same problems we just talked about though.
zipkin,"The service mesh will take care the cross-process tracing, but you still need to coding in-function or database tracing."
zipkin,Some service meshes make it easier to propagate the trace context through the wire by providing integration with popular tracing vendors.
zipkin,"Trace Design:
Carefully designed spans, service names and tags play an important role in fully utilization of tracing power."
zipkin,Please read ‚ÄúSemantic Conventions‚Äù¬π‚Å¥ for detail.
zipkin,"Logging Trace ID
It is a common requirement to integrate tracing with logging, basically to log the trace ID in log message along a calling chain."
zipkin,"Currently, OpenTracing doesn‚Äôt expose traceID."
zipkin,You can either convert the ‚ÄúOpenTracing.SpanContext‚Äù to vendor specific ‚ÄúSpanContext‚Äù (both Zipkin and Jaeger exposed traceID through their own ‚ÄúSpanContext‚Äù) or convert the ‚ÄúOpenTracing.SpanContext‚Äù to a string and parse it to get the traceID.
zipkin,Converting to a string is better because it won‚Äôt mess up your dependency.
zipkin,"You don‚Äôt need to worry about it in the future because OpenTracing will expose traceID, please read here."
zipkin,"OpenTracing and OpenCensus
OpenCensus¬π‚Åµ is not another tracing interface, but a collection of libraries can integrate with other tracing libraries to finish the tracing job, so it is often compared with OpenTracing."
zipkin,"The question is ‚ÄúIf I use OpenTracing in my application and need to access the database which uses OpenCensus, will that work?‚Äù No, it won‚Äôt."
zipkin,"So, you need to be careful when choosing tracing interface to make sure it is supported by other libraries you need."
zipkin,"A good news is that you don‚Äôt need to make the decision in the future because they will ‚Äúmerge the project into one‚Äù¬π‚Å∂, and the problem is gone."
zipkin,"Conclusion:
Distributed tracing includes different scenarios, such as tracing inside a function, database tracing and cross-process tracing."
zipkin,"If you want to design a better tracing solution or choose the tools or libraries that are best fit for your use case, you need to be aware of issues and solutions in each scenario."
zipkin,"Today we are going to discuss a very important topic when we come to discuss microservices architecture, i.e."
zipkin,Distributed tracing across the system when we have so many small applications running and each application has one or many microservices.
zipkin,"In this kind of architecture, there are applications talking to each other and passing data around."
zipkin,"So today‚Äôs agenda would be to
Setup an application and check the traces via Zipkin."
zipkin,Set up multiple microservices.
zipkin,Set up communication between them.
zipkin,Show the traces of the applications in the UI.
zipkin,"Set up Zipkin and configure elastic search as the backend to persist the data
Let‚Äôs set up a simple application and there we will see the traces in the application and how to configure them."
zipkin,"mix new zipkin_random --sup
We just created a project with a supervisor just to understand the flow in a single application then we are going to create another project where we will do the distributed tracing, but for now, let‚Äôs set up the Open Telemetry in a single application."
zipkin,"just some simple steps and we are good to go, just make the following changes into the application."
zipkin,"after making the changes to your project you need to start the Zipkin server so that you can see the events going into the Zipkin via Zipkin-exporter which we configured into the config.exs
docker run -d -p 9411:9411 openzipkin/zipkin
Now let‚Äôs take our application for a spin and see are we getting some events or not :) I hope it should."
zipkin,"Zipkin random after calling the hello function
we have compiled our application and running it so we got the [true] then we have to see what happened to the Zipkin UI, so open the localhost:9411 as Zipkin is running via docker on 9411 port."
zipkin,"Zipkin UI
I hope you all can see this empty UI console, so to see our event we have to check in the corner about our event."
zipkin,"Click on the 15 mins search bar or you can filter it accordingly to 5 min or something, its up to you."
zipkin,"the events in the last 5 mins
Wow!"
zipkin,"I can see the event in my Zipkin UI and you can see more details too about how much total time it took, i.e."
zipkin,"around 101ms, cool isn‚Äôt it?"
zipkin,"üòÉ
If you click on this event it‚Äôll show you more details about it."
zipkin,"Zipkin event inside
So this is how our 1 event looks, now we have come to step 1, let‚Äôs go further and create one more function in the zipkin_random.ex so that we can see the nested event."
zipkin,"Here we created another function and here we are passing the delay from the first function, let‚Äôs compile it again and see what happens now."
zipkin,"Again true came it means everything went well and when we open the ZipkinUI, we should be able to see the last event üòÑ."
zipkin,"second event Zipkin
Wow again things went well and I‚Äôm able to see the event and now we can see the total duration was ~303ms and 2 events are there as shown in ZIPKIN_RANDOM(2) the tag, let‚Äôs check it out further and see more details."
zipkin,"second-event-details
Here we can see that total 2 events are there and the second event is the child of the first event, the second event took ~200ms and the total duration was ~300ms."
zipkin,Now the next doubt in your mind would be that what if we need more details about it?
zipkin,how to see those details?
zipkin,", Let‚Äôs explore one more API which is provided by the opentelemetry_api."
zipkin,"adding set_attributes
Here we have introduced a new API set_attributes which will help us see the attributes in a span."
zipkin,"We recorded the delay attribute value in second_event_span , so we should be able to see it in the Zipkin UI."
zipkin,"Zipkin-attributes-page-1
Here when we click on second_event_span we will see under the tags that delay_data is having value 200.

delay-data-in-second-span
Sweet, so we have the delay data and attributes in a single system, you can explore more about the OpenTelemetry APIs from the hex."
zipkin,Now let‚Äôs go distributed and see how we can do distributed tracing.
zipkin,We will create 3 new projects and will do tracing between them.
zipkin,"Now we will create 3 new projects name alpha , beta & charlie and will set up the Zipkin and Open telemetry in all of them and we will call alpha, then internally alpha will call beta & beta will call charlie then we will see the whole flow in the Zipkin UI."
zipkin,"mix new alpha --sup
mix new beta --sup
mix new charlie --sup
3 projects will get generated now let‚Äôs set up the Zipkin and Open Telemetry in all of them as we did for our previous application."
zipkin,"Add the dependency of opentelemetry & zipkin_exporter

Configure it so that Zipkin shows the event having service names."
zipkin,Register the events in application.ex for all three apps.
zipkin,"Now make the following changes in your alpha.ex, beta.ex, and charlie.ex

Here we are doing RPC call, you can do a normal HTTP call too if they are having HTTP endpoints, here in ERPC call I‚Äôm passing the parent context into the child context, similarly, you can also do with HTTP, you can pass the parent context in the header too."
zipkin,Now we will start our apps in three different terminals giving them ‚Äî sname and then we will see how they behave.
zipkin,"in terminal 1, navigate to folder alpha and run the following command
iex --sname alpha@localhost -S mix
in terminal 2, navigate to folder name beta
iex --sname beta@localhost -S mix
similarly in terminal 3 navigate to folder name charlie
iex --sname charlie@localhost -S mix
‚Äî sname is necessary when we are using the erpc call so that the apps can be referred by name while calling."
zipkin,Now call the function Alpha.start_call in terminal 1 where alpha is running.
zipkin,"Nice, we have called the Alpha application now it‚Äôll call the beta, then beta will call the charlie and return the response back to Alpha via Beta."
zipkin,When you open Zipkin UI you should see something like this.
zipkin,"Nice!, we are seeing the distributed trace in the Zipkin where we had one request to alpha then internally alpha called the beta and beta called charlie and we got the response back, now if we click on the trace."
zipkin,"Wow, we have done a distributed trace, the idea is simple just we have to pass the parent context to the child when we talk about the distributed tracing, in a single application, there is no need to pass the parent context around, it‚Äôll automatically take care of that, but when we talk about distributed tracing it is must that we pass the current context to the child so that Zipkin knows that this particular span is the child of some another span somewhere in the whole system."
zipkin,"Now let‚Äôs setup the Elastic search as a backend for the Open Zipkin, we can use any supported technology as a backend for Zipkin but here today we will talk about the Elastic Search with the Zipkin."
zipkin,"Setup Elastic Search & Kibana
docker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.2
Then run the image
docker run -p 9200:9200 -p 9300:9300 -e ""discovery.type=single-node"" docker.elastic.co/elasticsearch/elasticsearch:7.9.2
when you go to localhost:9200 you should see the response from the Elastic Search
{
  ""name"" : ""87f1ef7a7a08"",
  ""cluster_name"" : ""docker-cluster"",
  ""cluster_uuid"" : ""_j9aUs8vR-KctqsVJ5u_Bw"",
  ""version"" : {
    ""number"" : ""7.9.2"",
    ""build_flavor"" : ""default"",
    ""build_type"" : ""docker"",
    ""build_hash"" : ""d34da0ea4a966c4e49417f2da2f244e3e97b4e6e"",
    ""build_date"" : ""2020-09-23T00:45:33.626720Z"",
    ""build_snapshot"" : false,
    ""lucene_version"" : ""8.6.2"",
    ""minimum_wire_compatibility_version"" : ""6.8.0"",
    ""minimum_index_compatibility_version"" : ""6.0.0-beta1""
  },
  ""tagline"" : ""You Know, for Search""
}
Something like this."
zipkin,"Let‚Äôs set up the Kibana too just follow these steps
$ curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.9.2-linux-x86_64.tar.gz
$ curl https://artifacts.elastic.co/downloads/kibana/kibana-7.9.2-linux-x86_64.tar.gz.sha512 | shasum -a 512 -c - 
tar -xzf kibana-7.9.2-linux-x86_64.tar.gz
$ cd kibana-7.9.2-linux-x86_64/
Then once you install you should be able to see the localhost:5601 the Kibana port."
zipkin,Now one thing we have to configure from Zipkin to see the traces inside the Elastic Search is configuring the Elastic Search as a backend for Zipkin.
zipkin,Just stop the running docker of Zipkin now and do the following stuff in your terminal.
zipkin,"$ curl -sSL https://zipkin.io/quickstart.sh | bash -s
$ java -DSTORAGE_TYPE=elasticsearch -DES_HOSTS=http://127.0.0.1:9200 -jar zipkin.jar

Zipkin has been configured with ES, here we are telling Zipkin that Elastic Search on port 9200 is your backend and put all the data for the persistent into the ES."
zipkin,Let‚Äôs push some events from the alpha application and then we will configure the index in kibana to see the data.
zipkin,"Let‚Äôs configure the index from app management, create index page

configure the column

After configuring when we go to the discover page in Elastic Search, we see the data üòç

Here I will finish this story and in the later stories maybe we can talk more about the metaprogramming way to trace this stuff and how we can integrate it via telemetry to make it simpler, I would love to hear from you if you want that."
zipkin,Thank you!
zipkin,Last week I documented what I hope is the simplest possible Trillian personality.
zipkin,"Yesterday, I documented adding an inclusion proof."
zipkin,"Earlier today, I documented building a gRPC-based client and server for the personality."
zipkin,Here is a small addition that adds metrics (stats) and traces.
zipkin,"OpenCensus Exporter
With the addition of a straightforward configuration for an OpenCensus Exporter using the OpenCensus Agent, we have the ability to configure the Agent to convert incoming stats|traces into a wide selection of 3rd-party services."
zipkin,"Here‚Äôs the Basic Personality server configuration:
oc, err := ocagent.NewExporter(
 ocagent.WithAddress(*ocagEndpoint),
 ocagent.WithInsecure(),
 ocagent.WithReconnectionPeriod(10*time.Second),
 ocagent.WithServiceName(serviceName),
)
if err != nil {
 log.Fatal(err)
}
defer oc.Stop()
And here‚Äôs the Agent‚Äôs configuration to receive incoming stats|traces on :55678 and export the stats to Prometheus (on :9100) and the route the traces to thezipkin service on its port :9411:
receivers:
  opencensus:
    address: "":55678""
exporters:
  jaeger:
    collector_endpoint: ""jaeger:14268/api/traces""
  prometheus:
    address: "":9100""
  zipkin:
    endpoint: ""zipkin:9411/api/v2/spans""
zpages:
    port: 9999
NB A potential source of confusion."
zipkin,These DNS names are provided by Docker Compose to the services running on the network it creates.
zipkin,These names are accessible to other services within the solution.
zipkin,"In this case, the OpenCensus Agent (itself known as opencensus-agent) is able to refer to these other services by their service names (jaefer ,zipkin) but only within the solution."
zipkin,"Externally, we need to port map these services onto an available port on localhost."
zipkin,"OpenCensus Agent
The OpenCensus Agent export as a Prometheus Exporter on the host on :9100 so you can query http://localhost:9100/metrics and hopefully see:

We can confirm the OpenCensus Agent by checking its logs:
docker-compose \
--file=deployment/docker-compose.yml \
logs opencensus-agent
Attaching to deployment_opencensus-agent_1
opencensus-agent_1          | {""level"":""info"",""ts"":1562357412.0980296,""caller"":""config/config.go:490"",""msg"":""Trace Exporter enabled"",""exporter"":""zipkin""}
opencensus-agent_1          | {""level"":""info"",""ts"":1562357412.0983222,""caller"":""config/config.go:497"",""msg"":""Metrics Exporter enabled"",""exporter"":""prometheus""}
opencensus-agent_1          | 2019/07/05 20:10:13 Running OpenCensus Trace and Metrics receivers as a gRPC service at "":55678""
opencensus-agent_1          | 2019/07/05 20:10:13 Running zPages on port 9999
The OpenCensus Agent is configured (:9999) to show zPages so we can interrogate that endpoint:

/debug/tracez
NB I would have expected to see upstream gRPC traces reflected by the Agent but they‚Äôre not."
zipkin,So this is one problem.
zipkin,"Prometheus
The OpenCensus Agent is now a scrape target (via the above Exporter) for the Prometheus server."
zipkin,"So the Basic Personality client and server gRPC metrics are exported to the OpenCensus Agent, which exports them as a Prometheus Exporter and they‚Äôre then captured by this server:

Zipkin

For some reason ‚Äî to be explored ‚Äî Zipkin either isn‚Äôt receiving or isn‚Äôt able to process the traces routed through the OpenCensus Agent that are generated by the automatic ocgrpc handler."
zipkin,"You can confirm the Zipkin service logs too though these are verbose and not included here:
docker-compose \
--file=deployment/docker-compose.yml \
logs zipkin
Jaeger
When Zipkin wasn‚Äôt showing traces, I added Jaeger (another trace monitoring tool) to see whether it was Zipkin, the upstream OpenCensus Agent, or something else."
zipkin,Jaeger is reported its own traces but no others.
zipkin,"So, there‚Äôs something either in my configuration or the OpenCensus Agent that‚Äôs not working:

Conclusion
An ‚Äòamuse bouche‚Äô for integration stats and traces into the Basic Personality."
zipkin,It would be more awesome if it worked perfectly ;-)
zipkin,"In the previous blog, we went through some of the challenges associated with tracing."
zipkin,Lets address the first challenge here ‚Äî that of finding the root cause of a problem.
zipkin,"As the number of services increase, it is extremely difficult to perform the root cause analysis."
zipkin,In such a scenario it is all the more relevant to answer the following ‚Äî What is the big picture of the service landscape?
zipkin,How many services are there and how are they interdependent?
zipkin,"In other words, in order to perform root cause analysis (RCA), it is very important to know about the services and how they interact with each other."
zipkin,This ‚ÄòBig Picture‚Äô has different connotations for a business user and an Ops user.
zipkin,In this article we consider an Ops user who would be interested in understanding the service dependencies to debug performance issues.
zipkin,Tools like zipkin and jaegar already provide inbuilt service dependency graphs when used in greenfield scenarios.
zipkin,"But what do we do when we have brownfield and redfield services (which do not use zipkin , jaegar etc.)"
zipkin,?
zipkin,How do we arrive at service dependencies?
zipkin,Lets consider a usecase where the customer environment comprises of Brownfield services ‚Äî services that have their own logging framework.
zipkin,"Minimum expectation is that the framework logs among other details, correlation-id, source_to_dest_id and source_id."
zipkin,"Approach
Now for the above example, we need a mechanism to read and parse the custom logs, derive the service dependencies from the log, store the log and finally visualize the service dependency graph."
zipkin,"Elastic stack with filebeat, logstash, elasticseach and kibana would suit our requirements respectively for reading, parsing, storing and visualizing the service dependencies information."
zipkin,But how do we actually derive the service dependencies?
zipkin,This is where zipkin and the ecosystem provided by zipkin can be utilized to our advantage.
zipkin,Zipkin has it‚Äôs own data model.
zipkin,Zipkin Dependencies is a spark job that derives the service dependencies from the zipkin data model.
zipkin,The trick is to convert our brownfield log data model to zipkin‚Äôs data model and let zipkin spark job take over.
zipkin,Lets see how!
zipkin,"The high level approach is as follows (refer the diagram below) ,
1."
zipkin,"Read the custom logs from all the services
2."
zipkin,Convert or transform the custom logs into the format that zipkin expects.
zipkin,3.
zipkin,Use zipkin spark utility that uses the transformed data from step 2 above to generate the service dependency information.
zipkin,4.
zipkin,"Use the service dependency information to create the visualization
Refer the flowchart and the corresponding explanations below for more details about each step."
zipkin,"Implementation
Data Model
The sample logging data model logs many attributes."
zipkin,"But for this example, let us consider only the following:
{
‚ÄúcorrelationId‚Äù: ‚Äú101‚Äù,
‚Äúservice‚Äù: ‚ÄúAccount Service‚Äù,
‚Äúsource_destination_id‚Äù: ‚Äú3‚Äù,
‚Äúsource_id‚Äù: ‚Äú1‚Äù,
‚Ä¶‚Ä¶
}
#Step1-Filebeat
- type: log
# Change to true to enable this input configuration."
zipkin,"enabled: true
# Paths that should be crawled and fetched."
zipkin,Glob based paths.
zipkin,"paths:
- /path/to/service/logs/*.json
output.kafka:
hosts: [‚Äúxx.xx.xx.xx:9092‚Äù]
#Step2-Logstash
filter{
if ‚Äúfrom_kafka‚Äù in [tags] {
json {
source => ‚Äúmessage‚Äù
}
clone
{
clones => [‚ÄúserverEvent‚Äù,‚ÄùclientEvent‚Äù]
}
if ‚Äú_jsonparsefailure‚Äù in [tags] {
drop{}
}
if [type] == ‚ÄúserverEvent‚Äù or [type] == ‚ÄúclientEvent‚Äù
{
if [source_destination_id]
{
mutate
{
add_field => { ‚Äúid‚Äù => ‚Äú%{source_destination_id}‚Äù }
add_field => { ‚ÄúspanId‚Äù => ‚Äú%{source_destination_id}‚Äù }
}
}
mutate
{
add_field => {‚ÄútraceId‚Äù => ‚Äú%{correlationId}‚Äù}
add_field => {‚Äú[localEndpoint][serviceName]‚Äù => ‚Äú%{service}‚Äù}
}
if [source_id] {
mutate
{
add_field => {‚ÄúparentId‚Äù => ‚Äú%{source_id}‚Äù}
}
}
}
if [type] == ‚ÄúserverEvent‚Äù
{
mutate
{
add_field => { ‚Äúkind‚Äù => ‚ÄúSERVER‚Äù }
}
if !"
zipkin,"[source_id] {
mutate {
update => { ‚Äúid‚Äù => ‚Äú%{traceId}‚Äù }
}
}
if [source_id] {
if [spanId] {
mutate {
update => { ‚Äúid‚Äù => ‚Äú%{source_id}‚Äù }
}
}
}
}
if [type] == ‚ÄúclientEvent‚Äù
{
if !"
zipkin,"[spanId]{
drop{}
}
mutate
{
add_field => { ‚Äúkind‚Äù => ‚ÄúCLIENT‚Äù }
}
if !"
zipkin,"[source_id] {
mutate {
add_field=> { ‚ÄúparentId‚Äù => ‚Äú%{traceId}‚Äù }
}
}
}
if !"
zipkin,"[traceId] {
drop{}
}
mutate {
remove_tag => [ ‚Äúfrom_kafka‚Äù ]
}
}
}
#Step3-Logstash
input
{
elasticsearch {
hosts => [‚Äúlocalhost:9200‚Äù]
index => ‚Äúlogstash-*‚Äù
tags => [‚Äúfrom_es‚Äù]
schedule => ‚Äú17 11 * * * Asia/Kolkata‚Äù
}
}
filter{
if ‚Äúfrom_es‚Äù in [tags] {
if [kind] == ‚ÄúSERVER‚Äù
{
if !"
zipkin,"[id]
{
elasticsearch {
hosts => [‚Äúhttp://localhost:9200""]
query => ‚Äúkind:CLIENT AND parentId:%{parentId} AND traceId:%{traceId}‚Äù
fields => { ‚Äúid‚Äù => ‚ÄútempId‚Äù }
index => ‚Äúlogstash-*‚Äù
}
ruby {
code => ‚Äúevent.set(‚Äòid‚Äô, (event.get(‚ÄòtempId‚Äô)))‚Äù
}
} else if [parentId] and ([traceId] != [parentId])
{
elasticsearch {
hosts => [‚Äúhttp://localhost:9200""]
query => ‚Äúkind:CLIENT AND id:%{parentId} AND traceId:%{traceId}‚Äù
fields => { ‚ÄúparentId‚Äù => ‚ÄútempParentId‚Äù }
index => ‚Äúlogstash-*‚Äù
}
ruby {
code => ‚Äúevent.set(‚ÄòparentId‚Äô, (event.get(‚ÄòtempParentId‚Äô)))‚Äù
}
}
}
mutate { remove_field => [‚Äútags‚Äù]
remove_tag => [‚Äúfrom_es‚Äù]
}
##### Remove others
mutate {
remove_field => [ ‚ÄúcorrelationId‚Äù,‚Äùservice‚Äù,‚ÄùparentSpanId‚Äù,‚ÄùspanId‚Äù,‚Äùmessage‚Äù,‚ÄùtempId‚Äù,‚ÄùtempParentId‚Äù,‚Äùtype‚Äù,‚Äùpath‚Äù ]
}
mutate {
add_field => { ‚Äúfrom_es‚Äù => ‚Äúes‚Äù }
}
}
}
#Step2,3-Common Logstash Output
output {
if [from_es] {
elasticsearch {
hosts => [‚Äúlocalhost:9200‚Äù]
index => ‚Äúzipkin:span-%{+YYYY-MM-dd}‚Äù
manage_template => false
document_type => ‚Äúspan‚Äù
}
} else {
elasticsearch { hosts => [‚Äúlocalhost:9200‚Äù]}
}
}
#Step4-Zipkin Spark job
Run the spark job (probably schedule it once a day) using the following command
sudo ZIPKIN_LOG_LEVEL=DEBUG STORAGE_TYPE=elasticsearch ES_HOSTS=localhost:9200 java -jar zipkin-dependencies.jar
#Step5-Visualization

Service Dependency Graph in Kibana using https://github.com/dlumbrer/kbn_network
Conclusion
For resolving issues quickly, it is imperative to get the big picture."
zipkin,"Distributed tracing tools like zipkin, jaeger and the utilities around them are helpful in establishing the service dependencies thereby reducing the time drastically in resolving issues."
zipkin,"As we saw in the example above, instead of starting ground up, custom logs provided by brownfield services were transformed into zipkin data model."
zipkin,Zipkin spark utility then generates the service dependencies.
zipkin,"The elastic stack was used to read, store , parse and finally display the service dependencies in an intuitive manner."
zipkin,In the next blog (Part-3) we will see how to get the Big Picture relevant to the Business User.
zipkin,Disclaimer: The views expressed in this article are mine and my employer does not subscribe to the substance or veracity of my views
zipkin,What is Distributed Tracing ?
zipkin,One of the major challenges in microservices is the ability to debug issues and monitor them.
zipkin,A simple action can trigger a chain of microservice calls and it would be tedious to trace these actions across the invoked microservices.
zipkin,This is because each microservice runs in an environment isolated from other microservices so they don‚Äôt share resources such as databases or log files.
zipkin,"In addition to that, we might also want to track down why a certain microservice call is taking so much time in a given business flow."
zipkin,The Distributed Tracing pattern addresses the above challenges developers face while building microservices.
zipkin,"There are some helpful open-source tools that can be used for distributed tracing, when creating microservices with Spring Boot and Spring Cloud frameworks."
zipkin,This blog walks through the installation steps and implementations of these tools.
zipkin,"The Tools
Spring Cloud Sleuth: A Spring Cloud library that lets you track the progress of subsequent microservices by adding trace and span id‚Äôs on the appropriate HTTP request headers."
zipkin,"The library is based on the MDC (Mapped Diagnostic Context) concept, where you can easily extract values put to context and display them in the logs."
zipkin,Zipkin: A Java-based distributed tracing application that helps gather timing data for every request propagated between independent services.
zipkin,It has a simple management console where we can find a visualization of the time statistics generated by subsequent services.
zipkin,"ELK Stack: Three open source tools ‚Äî Elasticsearch, Logstash and Kibana form the ELK stack."
zipkin,"They are used for searching, analyzing, and visualizing log data in real-time."
zipkin,Elasticsearch is a search and analytics engine.
zipkin,"Logstash is a server‚Äëside data processing pipeline that ingests data from multiple sources simultaneously, transforms it, and then sends it to a ‚Äústash‚Äù like Elasticsearch."
zipkin,Kibana lets us visualize this data with charts and graphs.
zipkin,How do they work together ?
zipkin,"Based on the below diagram (Image A), when the Orchestrator Service makes a HTTP call on the service `/order/{orderId}`, the call is intercepted by Sleuth and it adds the necessary tags to the request headers."
zipkin,"After the Orchestrator Service receives the HTTP response, the data is sent asynchronously to Zipkin to prevent delays or failures relating to the tracing system from delaying or breaking the flow."
zipkin,"Sleuth adds two types of IDs to the log file, one called a trace ID and the other called a span ID."
zipkin,"The span ID represents a basic unit of work, for example sending an HTTP request."
zipkin,"The trace ID contains a set of span IDs, forming a tree-like structure."
zipkin,The trace ID will remain the same as one microservice calls the next.
zipkin,"Image A ‚Äî How Zipkin, Sleuth and ELK fit in."
zipkin,"The logs are published directly to Logstash in this example for convenience, but we can also use Beats."
zipkin,"Beats is a simple data shipper that either sits on servers or on containers, that listen to log file locations and ship them to either Logstash for transformation or Elasticsearch."
zipkin,"Installation of the needed tools
The guide assumes the user has docker pre-installed."
zipkin,If not you can follow the steps for installation here.
zipkin,"1) Installing Zipkin
Run the first docker command to pull the Zipkin image from hub.docker.com and then the next docker command to start it on port 9411."
zipkin,"$ docker pull openzipkin/zipkin
$ docker run -d -p 9411:9411 openzipkin/zipkin
Validate the setup by accessing the Zipkin web interface on the url: http://localhost:9411/zipkin/."
zipkin,The below screen (Image 1) should open up if there are no issues.
zipkin,"Image 1‚Äî Zipkin Dashboard
2) Installing ELK Stack
This install will be using the image `sebp/elk`, on this image we will be making changes to disable SSL and setup indexes for Elastic search on the Log-stash configuration files."
zipkin,"Create the 2 files with the configuration below:

The input configuration for disabling SSL

The output configuration for setting up ElasticSearch
Then create a `DockerFile` as below, using the configurations created above

Execute the below docker commands to build the image with tag `local-elk` and start all three components."
zipkin,$ docker build .
zipkin,"--tag local-elk
$ docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -it --name elk local-elk
The `docker run`, command starts up Kibana on port 5601, ElasticSearch on port 9200 and LogStash on port 5044."
zipkin,Validate the kibana setup by accessing the web console on url ‚Äòhttp://localhost:5601‚Äô.
zipkin,The below screen (Image 2) should show up on the browser.
zipkin,"Image 2 ‚Äî Kibana Dashboard
Validate Elasticsearch with the below curl command
curl http://localhost:9200/_cat/indices
This completes our installations !"
zipkin,"Example Microservices
As depicted in Image 3, we have three microservices."
zipkin,The Order service (running on port 8081) has operations to fetch an order based on a given Order ID.
zipkin,The Customer service (running on port 8082) has operations to fetch a customer based on a given Customer ID.
zipkin,The Orchestrator (running on port 8080) exposes an operation to get both the order and customer details for a given Order ID.
zipkin,The Orchestrator first calls the order service to get the order details then makes another call to the customer service to get the customer details and returns both the details.
zipkin,"You can find all the code here

Image 3 ‚Äî Simple microservice orchestration
To enable Sleuth, Zipkin and ELK stack, we need to make the below changes on all 3 microservices."
zipkin,"First change is the pom.xml, where we add the cloud-starter dependencies for both Sleuth and Zipkin, also the logback dependencies needed for logstash."
zipkin,"Dependencies for Zipkin, Sleuth and Logback."
zipkin,"The second change is to add the URL, in the application.properties for spring to publish data to Zipkin."
zipkin,"Zipkin URL in the spring application.properties
The final change is the logback.xml, to publish the logs to LogStash."
zipkin,"The appender publishes all the logs to Logstash running on port 5044, using an Async TCP Appender."
zipkin,Again as mentioned above Beats can be used to ship logs to Logstash too.
zipkin,"Logback xml to publish logs to Logstash
All the services that need to use the Distributed Tracing feature, will need the above three changes / additions."
zipkin,"Seeing the magic happen
Once all three services are up and running, we can test the setup by executing the below curl which returns the Order and Customer details."
zipkin,"curl -X GET http://localhost:8080/customer-orders/100
Now when we log on to the Zipkin dashboard and click the button ‚ÄúFind Traces‚Äù, you will notice a trace spanning 3 services."
zipkin,If you notice the trace has a Trace-Id on top and durations for each of the calls.
zipkin,"Image 4 ‚Äî Zipkin trace for the Order-Customer-Orchestrator
By stopping the customer-service, we can see the failure (Image 5) being flagged on Zipkin dashboard."
zipkin,"Image 5 ‚Äî A failure trace
Now lets the ELK Stack logs
Before we see the logs we need to configure the Kibana dashboard to use the index we created on log stash."
zipkin,"In the output configuration we, created the index with the name ‚Äòlogstash-local‚Äô."
zipkin,"On the Kibana dashboard, click on `Create Index Pattern`, enter that as the index pattern and click on ‚ÄúNext Step‚Äù."
zipkin,"Image 6 ‚Äî Zipkin trace for the Order-Customer-Orchestrator
The next step would be to select `timestamp`, on the configure setting screen."
zipkin,"Once the pattern has been created, you should see a screen as Image 7."
zipkin,"Image 7 ‚Äî Zipkin trace for the Order-Customer-Orchestrator
Now by clicking the discover link (the button as a compass on the left menu), we should be able to see the logs generated from the services."
zipkin,"We can also filter them by the TraceId‚Äôs, from the Zipkin dashboard."
zipkin,"Image 8‚Äî Search capability on Kibana
Conclusion
With tools like Sleuth, Zipkin and ELK Stack, Distributed Tracing doesn‚Äôt seem to be a very difficult problem to solve."
zipkin,"As the application grows, these tools can provide us with much-needed information on where requests are spending their time and help tracing the flow."
zipkin,There are also some other tools that provide the same solution like Opentracing and Jaeger.
zipkin,The world of microservices is like a maze where one can easily get lost.
zipkin,"Unlike monolithic systems, microservices ecosystem is more complex with many moving parts and disparate modules."
zipkin,"Typical challenges faced by organizations adopting microservices are manageability, dependency management, increased failure points, trace-ability of service transactions, disparate logging sources and service request correlation to name a few."
zipkin,This article discusses some of these challenges and potential solutions to address them using open source technologies.
zipkin,The current article discusses the challenges associated with tracing in the context of disparate services interacting with each other.
zipkin,"Challenges with tracing
‚ÄòTracing‚Äô brings forth a plethora of challenges with each challenge posing more questions."
zipkin,"Some of the challenges are as follows:
1."
zipkin,"Root cause analysis: As the number of services increase, it is extremely difficult to perform the root cause analysis."
zipkin,"Given the volatility of service runtime and location independence, finding the service dependencies for a given request is a challenge."
zipkin,In such a scenario it is all the more relevant to answer the following ‚Äî What is the big picture?
zipkin,How many services are there and how are they interdependent?
zipkin,2.
zipkin,SLA management across services: Ability to analyze a specific service behavior and violations of SLA parameters at any given point in time is a challenge.
zipkin,Therefore it is important to know ‚Äî What Service Level Objectives are getting violated in a sea of disparate services interacting with each other?
zipkin,"3. Business context propagation across services: In a typical microservices world, how is the business context propagated between services?"
zipkin,4.
zipkin,Integrated traceability management across legacy and new age digital ecosystems: What if the enterprise is dealing with a mix of micro services and legacy systems?
zipkin,How is the context propagated between legacy services to micro services?
zipkin,5.
zipkin,Non-standard log formats: Most of the applications use their own custom tracing frameworks to correlate information across subsequent service calls and don‚Äôt conform to common standards within the enterprise.
zipkin,How should this dichotomy be handled ‚Äî custom frameworks vis-s-vis standardized frameworks?
zipkin,6.
zipkin,Lack of correlation metadata in existing legacy services: Legacy applications use their own custom tracing frameworks without any means of correlation between subsequent service calls.
zipkin,How do we achieve traceability here?
zipkin,7.
zipkin,Poly-cloud traceability management: In a multi cloud enterprise how do we address the interesting challenge related to end-to-end traceability across services?
zipkin,"From above, it is clear that there is a need to enhance existing tracing capabilities across services and to additionally capture contextual data related to the application performance and other useful metrics."
zipkin,This is where Distributed Tracing comes into the picture ‚Äî something akin to leaving breadcrumbs while a request hops through different services.
zipkin,"Distributed Tracing
Observability in the context of monitoring comprises of metrics, logs and tracing."
zipkin,"Distributed tracing, an important pillar of Observability, is used extensively for debugging and monitoring distributed software architectures such as microservices."
zipkin,It is especially useful in pinpointing latency issues in microservice architectures.
zipkin,"Distributed Tracing ‚Äî Mechanisms
Non-intrusive tracing
Nonintrusive or Zero touch mechanisms trace the request flows, analyze and debug the performance of the services without requiring any modification to the source code."
zipkin,These mechanisms are especially useful in managing Legacy services ‚Äî i.e.
zipkin,services where logs are available but do not have intricate details (such as trace Id or correlation Id) for correlating across the business flows.
zipkin,"Nonintrusive tracing mechanisms use a combination of statistical and AI/ML techniques on these logs to discover the service interactions, the dependencies and the performance metrics associated with each interaction."
zipkin,There are not many matured frameworks in this category.
zipkin,"Refer the following paper for insights into one such non-intrusive distributed profiling tool called ‚Äúlprof‚Äù https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-zhao.pdf
Intrusive tracing
Distributed tracing mechanisms that fall under the ‚ÄòIntrusive‚Äô category require some amount of additional instrumentation using frameworks like Zipkin, Jaegar, etc."
zipkin,"This approach requires modification to existing services, and can be easily enabled in Greenfield services ‚Äî i.e services which are implemented from scratch using new age frameworks like cloud-sleuth for zipkin."
zipkin,"Similarly, the same approach can be applied in Brownfield services ‚Äî i.e."
zipkin,services which are undergoing minor repackaging or refactoring with inbuilt mechanism to log trace details across business flows.
zipkin,"Intrusive tracing mechanisms can be further classified as follows:
One-plus configuration
In this category, the application source code needs minor refactoring to include the libraries, or dependencies to be added across modules."
zipkin,It might also need some base code changes to generate meaningful instrumentation.
zipkin,"eg adding zipkin to spring cloud project entails adding zipkin dependencies to the pom.xml file
Zero touch configuration
This category requires zero changes to be made in the application source code."
zipkin,But they are not non-intrusive as they might require e.g.
zipkin,process id to be attached to the java agent (and probably restart of the software application).
zipkin,One such tool is java Agent InspectIT Ocelot that uses Java byte-code manipulation to set up the OpenCensus instrumentation library with zero-configuration.
zipkin,It just requires the java agent to be attached when starting the respective java application.
zipkin,"Conclusion
Distributed tracing tools are an indispensable part of the Observability toolkit in any organization embarking on microservice adoption."
zipkin,These tools enable the teams to debug performance issues and view the dependency graphs- thereby saving a lot of time and effort during root cause analysis.
zipkin,"However, there is always the other side to the coin."
zipkin,A business user might find the traces too technical and hard to understand.
zipkin,Added to that is the innate ‚ÄòSampling‚Äô employed by Open tracing tools.
zipkin,There is a possibility that only a small portion of all requests are collected and therefore the complete view could be missing.
zipkin,Would it not be interesting to have mechanism in place that caters to both IT and business?
zipkin,"Let‚Äôs explore this and more in my next blog
Disclaimer: The views expressed in this article are mine and my employer does not subscribe to the substance or veracity of my views"
zipkin,This post is all about understanding latency issues in any application and building a tracing platform to debug all those issues.
zipkin,Application development these days are getting more and more granular .
zipkin,Every system/service depends on multiple systems to complete one business request.
zipkin,"Micro- services is the next cool buzz word in the companies which, once were excited just with idea of Service Oriented Architecture."
zipkin,"But as more and more distributed we become, figuring out the bottleneck becomes further tough."
zipkin,It get‚Äôs really difficult to identify which part (actually which code block) is causing the lag.
zipkin,"Let‚Äôs take a simple application example below :

In the above simple service diagram, we are exposing a service, which internally makes another service call, make a DB call and does some CPU intensive tasks."
zipkin,"So for every service request, it need to go through three steps, each of which is in itself holds some business critical time."
zipkin,And the overall latency of the service depends on the sum total of latencies at eacf of the step.
zipkin,Overall latency = latency1 + latency2 + latency3.
zipkin,"This is a very simple example, but in the real case scenarios, our services can be internally interacting with many more micro services."
zipkin,"So at any time, to identify what is the exact cause of high latency, we need to know the latencies of each step for the same request."
zipkin,"Generic Tracing Platform
The proposed generic tracing platform is based on OpenCensus and using zipkin as the backend

OpenCensus
OpenCensus provides observability for your microservices and monoliths alike by tracing requests as they propagate through services and capturing critical time-series metrics."
zipkin,"The core functionality of OpenCensus is the ability to collect traces and metrics from your app, display them locally, and send them to any analysis tool like zipkin (also called a ‚Äòbackend‚Äô)."
zipkin,"However, OpenCensus provides more than just data insight."
zipkin,"After instrumenting your code with OpenCensus, you will equip yourself with the ability to optimize the speed of your services, understand exactly how a request travels between your services, gather any useful metrics about your entire architecture, and more."
zipkin,"More details about OpenCensus can be found here : https://opencensus.io/
Backend that we are using for the collecting trace is ZIPKIN

ZIPKIN
Zipkin is a distributed tracing system."
zipkin,It helps gather timing data needed to troubleshoot latency problems in microservice architectures.
zipkin,It manages both the collection and lookup of this data.
zipkin,Zipkin‚Äôs design is based on the Google Dapper paper.
zipkin,Applications are instrumented to report timing data to Zipkin.
zipkin,The Zipkin UI also presents a Dependency diagram showing how many traced requests went through each application.
zipkin,"If you are troubleshooting latency problems or errors, you can filter or sort all traces based on the application, length of trace, annotation, or timestamp."
zipkin,"Once you select a trace, you can see the percentage of the total trace time each span takes which allows you to identify the problem application."
zipkin,"More details about the zipkin can be found here : https://zipkin.io/
We are using ElasticSearch as the back-end storage for the zipkin."
zipkin,"Using ES gives us an advantage, as we can run more analytics on the traces collected, with the help of Kibana

How my application can start pushing trace data to Tracing platform ?You just need to add the libraries of opencensus, make little code changes and you are all set for start tracing your application."
zipkin,"I am attaching code snippet, for doing the same in Java and Python."
zipkin,"JAVA
pom dependency example
<dependencies>
<dependency>
<groupId>io.opencensus</groupId>
<artifactId>opencensus-api</artifactId>
<version>${opencensus.version}</version>
</dependency>
<dependency>
<groupId>io.opencensus</groupId>
<artifactId>opencensus-impl</artifactId>
<version>${opencensus.version}</version>
</dependency>
<dependency>
<groupId>io.opencensus</groupId>
<artifactId>opencensus-exporter-trace-zipkin</artifactId>
<version>${opencensus.version}</version>
</dependency>
</dependencies>
Sample java code
public class TracingToZipkin {
public static void main(String[] args) {
// 1."
zipkin,Configure exporter to export traces to Zipkin.
zipkin,"ZipkinTraceExporter.createAndRegister(""host-address"", ""tracing-to-zipkin-service"");
// 2."
zipkin,"Configure 100% sample rate, otherwise, few traces will be sampled."
zipkin,"TraceConfig traceConfig = Tracing.getTraceConfig();
TraceParams activeTraceParams = traceConfig.getActiveTraceParams();
traceConfig.updateActiveTraceParams(activeTraceParams.toBuilder().setSampler(Samplers.alwaysSample()).build());
// 3."
zipkin,Get the global singleton Tracer object.
zipkin,"Tracer tracer = Tracing.getTracer();
// 4."
zipkin,"Create a scoped span, a scoped span will automatically end when closed."
zipkin,"// It implements AutoClosable, so it'll be closed when the try block ends."
zipkin,"try (Scope scope = tracer.spanBuilder(""main"").startScopedSpan()) {
System.out.println(""About to do some busy work..."");
for (int i = 0; i < 10; i++) {
doWork(i);
}
}
// 5."
zipkin,"Gracefully shutdown the exporter, so that it'll flush queued traces to Zipkin."
zipkin,"Tracing.getExportComponent().shutdown();
}
private static void doWork(int i) {
// 6."
zipkin,Get the global singleton Tracer object.
zipkin,"Tracer tracer = Tracing.getTracer();
// 7."
zipkin,Start another span.
zipkin,"If antoher span was already started, it'll use that span as the parent span."
zipkin,"// In this example, the main method already started a span, so that'll be the parent span, and this will be
// a child span."
zipkin,"try (Scope scope = tracer.spanBuilder(""doWork"").startScopedSpan()) {
// Simulate some work."
zipkin,"Span span = tracer.getCurrentSpan();
try {
System.out.println(""doing busy work"");
Thread.sleep(100L);
thirdCall();
}
catch (InterruptedException e) {
span.setStatus(Status.INTERNAL.withDescription(e.toString()));
}
//span.setStatus(Status.OK.withDescription(""Successfully passed this method""));
//Annotate our span to capture metadata about our operation
Map<String, AttributeValue> attributes = new HashMap<>();
attributes.put(""use"",AttributeValue.stringAttributeValue(""demo""));
span.addAnnotation(""Invoking doWork"",attributes);
}
}
private static void thirdCall(){
Tracer tracer = Tracing.getTracer();
try (Scope scope = tracer.spanBuilder(""thirdCall"").startScopedSpan()) {
Span span = tracer.getCurrentSpan();
// Simulate some work."
zipkin,"try {
System.out.println(""doing busy work"");
span.setStatus(Status.INTERNAL.withDescription(""Error occured""));
Thread.sleep(700L);
}
catch (InterruptedException e) {
}
}
}
}
Python code example
#!/usr/bin/env python
import os
from datetime import datetime
import time
import sys
from opencensus.trace.tracer import Tracer
from opencensus.trace import time_event as time_event_module
from opencensus.trace.exporters.zipkin_exporter import ZipkinExporter
from opencensus.trace.samplers import always_on
# 1a."
zipkin,"Setup the exporter
ze = ZipkinExporter(service_name=""python-quickstart"",
host_name='<host-address>',
port=9411,
endpoint='/api/v2/spans')
# 1b."
zipkin,"Set the tracer to use the exporter
# 2."
zipkin,"Configure 100% sample rate, otherwise, few traces will be sampled."
zipkin,# 3.
zipkin,"Get the global singleton Tracer object
tracer = Tracer(exporter=ze, sampler=always_on.AlwaysOnSampler())
def main():
# 4."
zipkin,Create a scoped span.
zipkin,The span will close at the end of the block.
zipkin,"with tracer.span(name=""main"") as span:
for i in range(0, 10):
doWork()
def doWork():
# 5."
zipkin,Start another span.
zipkin,"Because this is within the scope of the ""main"" span,
# this will automatically be a child span."
zipkin,"with tracer.span(name=""doWork"") as span:
print(""doing busy work"")
try:
time.sleep(0.1)
except:
# 6."
zipkin,"Set status upon error
span.status = Status(5, ""Error occurred"")
# 7."
zipkin,"Annotate our span to capture metadata about our operation
span.add_annotation(""invoking doWork"")
if __name__ == ""__main__"":
main()
I hope with this tracing platform, you will able to find out which small flow inside your big service flow is the actual bottleneck causing high latency."
zipkin,"For any doubts or followup, please feel free to comment below ."
zipkin,zipkin-js-instrumentation-axios is NPM package to help you to addZipkin tracing support for the axios JS HTTP client library.
zipkin,"The source locates at https://github.com/geekeren/zipkin-js-instrumentation-axios, It supports all features of axios
Installation
npm install zipkin-js-instrumentation-axios --save
Usage
You need to use wrapAxios fucntion to wrap the native axios instance, and the axios instance's type/functions/attributes are not affected."
zipkin,"As a result, you can use zipkinAxios the same as axios
For example:
const axios = require('axios');
const wrapAxios = require('zipkin-js-instrumentation-axios');
const { Tracer, ExplicitContext, ConsoleRecorder } = require('zipkin');
const ctxImpl = new ExplicitContext();
const recorder = new ConsoleRecorder();
const localServiceName = 'service-a'; // name of this application
const tracer = new Tracer({ ctxImpl, recorder, localServiceName });
const remoteServiceName = 'weather-api';
const zipkinAxios = wrapAxios(axios, { tracer, localServiceName, remoteServiceName });
zipkinAxios.get('/user?ID=12345')
  .then(function (response) {
    console.log(response);
  })
  .catch(function (error) {
    console.log(error);
  });
Interceptors of Axios also supported
You can intercept requests or responses before they are handled by then or catch."
zipkin,"// Add a request interceptor
axios.interceptors.request.use(function (config) {
    // Do something before request is sent
    return config;
  }, function (error) {
    // Do something with request error
    return Promise.reject(error);
  });
 
// Add a response interceptor
axios.interceptors.response.use(function (response) {
    // Do something with response data
    return response;
  }, function (error) {
    // Do something with response error
    return Promise.reject(error);
  });
The test cases all passed:
axios instrumentation - integration test
    ‚úì should add headers to requests
    ‚úì should support request shorthand (defaults to GET)
    ‚úì should support both url and uri options
    ‚úì should support promise callback
    ‚úì should report 404 when path does not exist
    ‚úì should report when service does not exist (41ms)
    ‚úì should report when service returns 400
    ‚úì should report when service returns 500
You can go to /example folder and run npm install && node app.js to see the result of the example."
zipkin,Haystack is an Expedia-backed open source project to facilitate detection and remediation of problems with enterprise-level web services and websites.
zipkin,"Haystack uses tracing data to help locate the source of problems, providing the ability to drill down to the precise part of a service transaction where failures or latency are occurring ‚Äî and find the proverbial ‚Äúneedle in a haystack‚Äù."
zipkin,"Once you know specifically where the problem is happening, it‚Äôs much easier to identify and understand the appropriate diagnostic data, find the problem, and fix it."
zipkin,"Finatra is a web framework created by Twitter built on top of TwitterServer and Finagle, it is the web framework of choice for the majority of Scala core services at Hotels.com."
zipkin,"Recently, we wanted to integrate our services with Haystack in order to have distributed tracing information across service boundaries."
zipkin,Finatra supports out of the box tracing using standard Zipkin X-B3-* HTTP headers.
zipkin,In order to report this data to Haystack we needed to publish the tracing data to a proxy service we have running which forwards it to both Zipkin and Haystack.
zipkin,"zipkin-finagle
Fortunately for us, zipkin-finagle provides functionality for reporting tracing information over a network."
zipkin,"This library allows for tracing information to be sent via HTTP, Scribe, or published to a Kafka topic."
zipkin,"Creating a new zipkin tracer is simple once you bring in zipkin-finagle as a project dependency:
val config = HttpZipkinTracer.Config.builder()
   .host(""zipkin-host:80"")
   .hostHeader(""zipkin-host"")
   .initialSampleRate(0.0)
   .compressionEnabled(true)
   .build()
val tracer = HttpZipkinTracer.create(config, statsReceiver)
In the Finatra app's HttpServer class you have the ability to set the tracer and label to be used in reporting by overriding the configureHttpServer function."
zipkin,"override def configureHttpServer(server: Http.Server): Http.Server =
 server
   .withLabel(‚Äúservice-name‚Äù)
   .withTracer(tracer)
After this, sending tracing headers to the service will result in the data being published to Haystack for visualisation."
zipkin,"If you‚Äôre using Finagle clients to call other services as part of a request, these will automatically be propagated and all your dependencies will show up too."
zipkin,"Haystack tracing visualisation
Dealing with Futures
Finatra and Finagle are designed to operate in a non-blocking asynchronous way, allowing it to scale and keep the overhead of accepting a new request low."
zipkin,"There is no global requests thread pool to configure, just don‚Äôt block when you‚Äôre handling the request."
zipkin,"As such, when we are dealing with asynchronous code we don‚Äôt have the concept of a single request thread to do things like MDC, which is how you would normally keep track of per-request state such as tracing information."
zipkin,When using Scala Future[T] we need some way to manually keep track of the tracing information between thread boundaries.
zipkin,We found there was no elegant way to do this without creating a wrapper around Future which copies a context between execution threads.
zipkin,Alternatively you can create a custom ExecutionContext in which the Future can run that provides the same functionality.
zipkin,Problems arise when you use a third party library or some bit of code that doesn‚Äôt allow you to define the ExecutionContext or the return type.
zipkin,Twitter were an early adopter of Scala and provide a util library which duplicates and builds upon the Scala standard library features.
zipkin,"This includes the Twitter Future, a cancellable Future with no ExecutionContext to manage and the built-in ability to keep track of a Context across thread boundaries."
zipkin,The Finatra server uses them at the edge and Finagle clients return Twitter Futures too.
zipkin,"If you use them throughout your application instead of the standard Scala Future then you‚Äôll get tracing propagation for free, at the expense of being a little more tied into the Twitter ecosystem."
zipkin,"Twitter Service Loader
One thing to watch out for is the zipkin-finagle library defining a service in the META-INF/services folder."
zipkin,Finatra uses Guice for dependency injection and if a library defines a file in the services folder then it will auto-magically be created for you and registered in the service registry.
zipkin,"This can make it easier to integrate with Zipkin, you can ignore all the code changes above and instead set some environment variables to let the library create and register the service for you."
zipkin,In my team we tend to prefer explicitly defining behaviour rather than relying on magic components of frameworks to do this for us.
zipkin,"It‚Äôs why we moved away from Spring, manually wire everything, try to avoid internal shared libraries and write our own request filter logic."
zipkin,"Once we manually wired the tracer using withTracer we assumed that this would override the one being created from the service loader, but we were wrong."
zipkin,"Both were being created and running at the same time, causing the unconfigured default tracer to throw errors (it defaults to sending data to localhost)."
zipkin,"In order to disable this we have to modify our Docker file to add an additional Java opt:
ENTRYPOINT [‚Äú/bin/sh‚Äù, ‚Äú-c‚Äù, ‚Äúexec java $JAVA_OPTS -Dcom.twitter.finagle.util.loadServiceDenied=zipkin2.finagle.http.HttpZipkinTracer -jar service.jar $0 $@‚Äù]
This is a bit nasty, we have a hard coded class name in our Docker file and if it ever changes name then it‚Äôll start loading two HttpZipkinTracer instances again."
zipkin,That‚Äôs the cost of being able to define the tracer ourselves.
zipkin,"Shameless plug
Hotels.com are hiring!"
zipkin,If you‚Äôre passionate about software engineering and what we do sounds interesting check out our roles in Workday.
zipkin,"Let‚Äôs say your services get thousands of requests per second, you log enormously and you don‚Äôt miss any exception in your logging system."
zipkin,"Suddenly, the operation team sent you a message pointing to an error for a customer with id X on production and you couldn‚Äôt understand why all the people around you are over-stressed‚Ä¶ and then the penny dropped."
zipkin,The customer X is actually a friend of the boss!
zipkin,"(true story)
Ok‚Ä¶ Let‚Äôs see what you can do:
You searched X on your logging system and waited forever as there are TBs of logs."
zipkin,"Then you tried it again with a more detailed query such asuserId=X not in this and that but in this at time t , and got the resu‚Ä¶ oh, another problem!"
zipkin,Error: wrong query syntax.Your teammate said that you need to replace not in thiswith in not this.
zipkin,"After you also fixed that and waited about 10 secs, 24 results appeared on the screen!"
zipkin,Now you are ready to analyze them.
zipkin,"‚Ä¶ 10 minutes later‚Ä¶
You figured out that ServiceA called service ServiceB and as method LongRunningProcess in ServiceB took 3 seconds, service A returned 500."
zipkin,"After all, you are glad to find the bug in about 20 minutes."
zipkin,Let‚Äôs replay the process assuming that you use Open Tracing and Jaeger.
zipkin,"You visited Jaeger UI on your browser
You wrote userId=X to tags and set the date
You clicked search and the result is below:

Example request that Jaeger traced
In couple of seconds, you can understand that LongRunningProcess took actually 3 seconds, and as a result, ServiceA returned 500."
zipkin,"Open tracing is an open standard for distributed tracing, and Jaeger is the tool that implements the standard."
zipkin,Please check the Jaeger architecture from it‚Äôs official documentation beforehand.
zipkin,"Today, we are gonna create 2 APIs and 1 console client for our demo environment using .net core."
zipkin,I will also use a simple wrapper that I wrote as it brings simplicity in my opinion.
zipkin,Let‚Äôs start!
zipkin,"Clone the Repo & Prepare your environment
If you have .net core and docker installed on your workspace, you are ready to go."
zipkin,"Get the docker image for Jaeger and run it:
docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.6
Clone the repo I prepared for this article: https://github.com/skynyrd/opentracing-with-jaeger
We have one .net core solution containing 4 projects: ConsoleClient , ServiceA , ServiceB and JaegerWrapper."
zipkin,We are going to walk thru all of them.
zipkin,Let‚Äôs start with JaegerWrapper to understand the dynamics of the Jaeger client.
zipkin,JaegerWrapper: For syntactic sugar ‚Äî Because why not?
zipkin,"In order to use Jaeger client, we first need to understand how traces work in our code."
zipkin,"A trace is a data/execution path through the system, and can be thought of as a directed acyclic graph of spans."
zipkin,"A span represents a logical unit of work in Jaeger that has an operation name, the start time of the operation, and the duration."
zipkin,Spans may be nested and ordered to model causal relationships.
zipkin,‚Äî Official Jaeger docs.
zipkin,"In an application, we need to have a Tracer that manages our spans."
zipkin,I strongly recommend having one tracer in a microservice for simplicity.
zipkin,"After creating the Tracer and registering it, the jaeger client library starts to analyze the controllers in the system by default, even we don‚Äôt need to create a singleTraceand Span for that, all created by the OpenTracing.Contrib.NetCore library."
zipkin,"However, if we want to analyze a specific method, or add some additional tag/log to our spans, we need to create a Trace and bind a Span to it."
zipkin,"Important Note: If you create and activate a span when there is another active span in the system, it becomes a child."
zipkin,You can see it in the diagram above; parent spans are expandable.
zipkin,"I wrote a simple builder for this purpose and JaegerWrapper is a class library that contains it, you can use/copy if you like."
zipkin,"_traceBuilder
  .WithSpanName(""LongRunningProcess"")
  .WithTag(new StringTag(""exampleTag""), ""exampleValue"")
  .TraceIt(() =>
  {
    Thread.Sleep(3000);
  });
To give an example, this code block is for LongRunningProcess span represented by a yellow horizontal bar in the diagram above."
zipkin,We added exampleTag: exampleValue to it and we can even add more complex structures using WithLog method.
zipkin,Time consumed by TraceIt is published as a span duration in the GUI.
zipkin,"In the example, I used a simple Thread.Sleep(3000) , but you can also return something (Func instead of Action) e.g."
zipkin,":
var result = _traceBuilder
              ...
              .TraceIt(() => 
              {
                 return ""something""
              }
Passing across the APIs
If you are going to HTTP call a service and you want to preserve your span lifetimes, you need to notify the other service somehow."
zipkin,"For the most cases you would like to use the OpenTracing.Contrib.NetCore package to automate the configurations, but if you are curious, here is the logic behind that:
Jaeger solves it with HTTP headers that are going to append to the request."
zipkin,"You can also use JaegerWrapper for more abstraction:

Still using the OpenTracing.Contrib.NetCore is the clearest option for the APIs."
zipkin,"Configuration for WebAPIs
For ServiceA and ServiceB we need to register the services for Jaeger:
// In ConfigureServices method of Startup class:
GlobalTracer.Register(Tracer);
services.AddOpenTracing();
If you also want to use the wrapper, you can simply add these:
var serviceProvider = services.BuildServiceProvider();
services.AddScoped<ITraceBuilder>(t => 
    new TraceBuilder(serviceProvider.GetService<ITracer>()));
Example Calls
Have a look at AWorldController of ServiceA, we call ServiceB there but didn‚Äôt use any JaegerClient or JaegerWrapper method."
zipkin,"This is because we added OpenTracing.Contrib.NetCore library and it traces our requests in the black box, magically."
zipkin,"private static async Task<dynamic> GetBObject(string id)
{
    var httpClient = new HttpClient
    {
        BaseAddress = new Uri(""http://localhost:7334"")
    };

    var result = await httpClient.GetAsync($""/bworld/id/{id}"");

    if (result.IsSuccessStatusCode)
    {
        return await result.Content.ReadAsAsync<dynamic>();
    }
    
    throw new Exception(""uncovered area."
zipkin,""");
}
And check the Main method of the ConsoleClient."
zipkin,"This time, as this is not a WebAPI, we manually traced our call using JaegerWrapper."
zipkin,"traceBuilder.WithSpanName(""MainWork"")
    .WithHttpCall(client, url, HttpMethod.Get)
    .TraceIt(() =>
    {
        var response = client.GetAsync(url).Result;

        if (!response.IsSuccessStatusCode)
            throw new Exception(""uncovered area for the demo."
zipkin,""");

        var responseBody = response.Content.ReadAsStringAsync().Result;
        Console.WriteLine(responseBody);
    });
I used Zipkin instead of Jaeger on production couple of years ago, thus I don‚Äôt want to write anything about the performance."
zipkin,But I can say that Zipkin was quite performant.
zipkin,"If you have production experience with Jaeger, please comment below, I‚Äôm curious about it!"
zipkin,Thanks for reading.
zipkin,"Distributed tracing has a place in an engineer‚Äôs observability toolset, but after working with two large enterprise clients who have built their very own distributed tracing framework, tooling, and web console I cannot help feeling that the return on investment (RoI) is meager without an accompanying delivery of real automatic behavioral classification and analysis, along with in-depth runtime intelligence."
zipkin,Most organizations will give up funding such initiatives well before there is even glimmer of something of value other than a pretty view of some colored rectangles laid out across a large screen real estate.
zipkin,But that is a post for another time.
zipkin,Here I‚Äôd liked to discuss something that has troubled me the most from the very beginning ‚Äî a more fundamental architectural issue ‚Äî the overall approach to trace propagation and the transmission of such trace data to a backend trace storage service.
zipkin,"Failing to Scale
Netflix engineering recently published a post with the following warning:

Collecting trace data is not cheap as it should be, and it even more expensive at the storage endpoint, which is why it tends to be only used at microservices entry and exit points and even then at an extremely low sampling rate."
zipkin,"Lets, for now, leave aside the fact that developers and operations staff are forced to use other solutions for all the work that does go on between these two points."
zipkin,The propagation of some trace correlation identifier is typically piggybacked on the outbound service call to a microservice via request headers and across threads or coroutines within a process via a shared context or thread local.
zipkin,Each service must also transmit trace data to a remote trace storage backend.
zipkin,This requires that the backend storage be shared and accessible to all services.
zipkin,To reduce the large trace overhead a decision to trace a particular request is made at the root entry point and then propagated down through the call tree of remote network hops.
zipkin,"In theory, each point in the processing could employ a different strategy for selecting whether to continue trace but in practice no."
zipkin,At a recent client site they turned on the built-in distributed tracing within an Apache Cassandra cluster and brought the system to a halt.
zipkin,Never enabled since.
zipkin,"Because trace propagation is pushed downwards, it requires the sampling decision to be done prior to the actual request processing work ‚Äî before the system can assess whether a particular call and its traces are indeed valuable."
zipkin,The use of sampling only makes sense if the trace data were only being used to power a dashboard that was mostly metrics based and derived from the trace sample population.
zipkin,But this is not how engineers use tracing ‚Äî most turn to distributed tracing as a source of evidence in resolving outliers.
zipkin,"Unfortunately, there is no guarantee that the trace data for an outlier will be found in the storage backend if the decision to propagate, and in turn store, is done before completion of the service call and a proper ‚Äúvalue‚Äù (outlier) assessment made."
zipkin,It is no possible to eliminate the need to propagate trace data though I believe the industry has gotten it entirely backward and in (wrongly) doing so manufactured the scaling problem that Netflix has had to work around.
zipkin,"Back to the Future
In 2010 I put out a proposal for how activity-based metering could offer many of the benefits of distributed tracing without all the architectural complexity, limitations, and overhead of the approach advocated by Google and others ‚Äî an approach that eliminated the need to have all services share a connection to a single trace storage backend or have only just one storage backend."
zipkin,"More importantly, the decision to persist trace data was deferred until completion."
zipkin,"2010 Slide ‚Äî Distributed Metering for the Cloud
In most cases, there is no need to propagate trace identifiers."
zipkin,"Instead, a response to a request, whether synchronously or asynchronously delivered, includes an activity metering manifest that is sufficiently detailed for problem resolution at any point in the processing, and not just concerning wall clock."
zipkin,"The benefits of the approach include:
Reduction in remote calls to a trace storage backend
Ability to discard data collected on completion and after assessment
Aggregation of data collected is now done at call site and in-memory
No requirement to sync system clocks across all service endpoints
A call site can use the data collected to drive self-adaptation routines
A service can choose to expose and propagate internal service metering
A service can rename various meterings to better covey intent of use
Multiple storage backends can participate ‚Äî in-process or out-of-process
No need to share confidential contextual data with a single trace storage
Multiple resource meters are possible and not just wall clock time
Let‚Äôs not forget call trees don‚Äôt scale even if we could store them all."
zipkin,"If you need such a representation in production, then engineering is failing elsewhere."
zipkin,"A distributed system is one in which the failure of a computer you didn‚Äôt even know existed can render your own computer unusable ‚Äî Leslie Lamport
The fact of life is we‚Äôre building bigger, more complex and distributed systems."
zipkin,What used to be single server serving old-style personal home pages turned into the medium.com mediated blog post and various other ecosystems.
zipkin,"Simple bulletin board marketplace turning enormous systems of Amazon, eBay, and other online retailers."
zipkin,"This evolution is akin to life itself, as we progress from single cellular bacterias to humans we‚Äôre today, the thing got complicated."
zipkin,"More powerful, but complicated."
zipkin,"Now, let‚Äôs talk about your current system."
zipkin,Chances are not everything is new.
zipkin,Today almost every system uses numerical routines written in Fortran a few decades ago.
zipkin,"Similarly, in your bodies basic cell metabolism haven‚Äôt changed last 100s million of years."
zipkin,"Though with added complexity, some things did change."
zipkin,"Aside from superior featureset, e.g."
zipkin,"sight, speech, consciousness we evolve advanced monitoring equipment."
zipkin,"Just a single neuron acting and proto-eye doesn‚Äôt cut it, but a full-fledged eye does."
zipkin,Vast nerve network almost instantaneously detects issues in your body and alerts the control center.
zipkin,Imagine if you had to check every second did you stub your toe or are you bleeding?
zipkin,"Messages are sent and received via hormones on the gigantic message queue called circulation system, i.e."
zipkin,blood.
zipkin,Much bigger complexity than simple single cell organism and osmosis diffused operations.
zipkin,"Therefore, your new systems cannot be monitored as they were during lower complexity era."
zipkin,"Logs aren‚Äôt enough anymore, neither are metrics nor pprof and similar toolset."
zipkin,"In this article, I‚Äôm presenting tracing as another tool in your toolbox, both in monolith application and distributed setting."
zipkin,A very useful tool for specific use cases.
zipkin,"In this chapter, I‚Äôll briefly cover basic observability tools at our disposal."
zipkin,I‚Äôll also use a football analogy as a metaphor for the clearer explanation.
zipkin,"For those familiar feel free to skip to the latest section, tracing."
zipkin,"Logs
log - an official record of events during the voyage of a ship or aircraft."
zipkin,This is the simplest and most basic tool at our disposal.
zipkin,One log represents some event happening with associated metadata.
zipkin,"The most common metadata is when did the event happen, and other which application generated this event, on which host, what‚Äôs the level of this log event."
zipkin,"Usually log event levels are modeled after syslog levels, DEBUG, INFO, WARNING, ERROR, CRITICAL being used the most in the software."
zipkin,"On the application and system level, you usually have log sources and log sink."
zipkin,"Each source generates log data, and ships it to sinks."
zipkin,"Each sink can apply some fileting, e.g."
zipkin,only ERROR level or higher.
zipkin,"In practical terms this means you‚Äôre writing log level INFO or greater to stderr, but to the file, you‚Äôre dumping all logs."
zipkin,There are log management systems for gathering and searching logs.
zipkin,"One of the simpler is logfile with grep, more complex being journaling in systemd, and for production distributed systems you‚Äôre usually using ELK stack or graylog."
zipkin,"In the football analogy, playing scoring the goal would be a great log."
zipkin,"Something like: msg=""Ivan scored the goal"" time=""2018-01-12"" game_minute=""23""
The log data is useful for unique, rare events or somehow meaningful events."
zipkin,"For frequent events, it needs to be sampled down not to kill your log management system."
zipkin,"For example, do you want to log every time you received IP package on the server?"
zipkin,"Metrics
metric - a system or standard of measurement."
zipkin,"In observability context, metric is scalar value changed over time."
zipkin,This scalar value is usually a counter (e.g.
zipkin,"number of goals scored, HTTP requests), gauge (e.g."
zipkin,"temperature, CPU utilization), histogram (e.g."
zipkin,"number of 1xx,2xx,3xx,4xx,5xx HTTP response codes) or rank estimation (e.g."
zipkin,95% percentile response latency).
zipkin,"They are great for identifying the bottleneck, unusual behavior and setting SLOs(Service level objectives)."
zipkin,"Usually, alarms are tied to some metric, that is whenever the specified metric is outside given bound perform an action ‚Äî auto-heal or notify the operator."
zipkin,"For example, in human, we have a really important metric ‚Äî blood glucose level."
zipkin,"In a healthy human, too high value performs an auto-healing operation and releasing more insulin into our bloodstream."
zipkin,Another human metric would be pain levels in your left leg.
zipkin,"Usually, it‚Äôs near 0, but over the certain threshold you‚Äôre vividly aware of it ‚Äî that is an alarm is raised."
zipkin,"For computer systems, usual metrics are related to throughput, error rate, latency, resource (CPU/GPU/network/‚Ä¶) utilization."
zipkin,"Usual systems mentioned are statsd, graphite, grafana, and Prometheus."
zipkin,"Pprof & Flamegraphs
This tool is best for profiling CPU intensive applications."
zipkin,Before I explain what it offers you I want to cover how it works.
zipkin,X times per second it stops your program and checks which line is being executed on the machine.
zipkin,It collects all execution samples into buckets per line/function and later on reconstructed which function/line was executed which time %.
zipkin,"As if you‚Äôre snapshotting the football match and see who has the ball every 10 seconds, and from that reconstructing who had which ball ownership percentage."
zipkin,"Traces
If you remember anything from this blog post, remember this comet image:

As is burning through Earth‚Äôs atmosphere it leaves a trace over its path."
zipkin,From this trace we can deduce where it has been and how much time is spent there.
zipkin,A similar situation is within our programs.
zipkin,The trace represents single execution of request/operation.
zipkin,Trace is composed of multiple spans.
zipkin,Span is a meaningful unit of work in your system ‚Äî e.g.
zipkin,"database query, RPC call, calculation."
zipkin,"Span can be related, e.g."
zipkin,parent/child span.
zipkin,"Thus trace forms a tree of spans, or more generally a DAG (if you introduce complex followed by relations and other gimmicks)."
zipkin,"Each span can have useful metadata attached to it ‚Äî both indexed tagged key/value pair such as userId, http.statuscode, hostname or additional log data e.g."
zipkin,exact database query.
zipkin,"The tracing backend provides expected search capabilities, sorting by time, filtering by tags, etc."
zipkin,"In football example, we could have a trace representing scoring a goal."
zipkin,"It consists of 3 spans:
Ivan kicking the ball
The ball rolling to the goal
Ball entering the goal post
Common use cases
In this section, I‚Äôm going to cover top use cases for tracing."
zipkin,"Compared to other techniques like pprof, tracing can detect when your program was put to sleep due to IO waiting, resource contention or other reason."
zipkin,"Overall request overview
It allows you making a case study from an individual trace."
zipkin,Metrics aggregate while trace focuses the story on the individual request.
zipkin,What services did this individual request touch?
zipkin,How much time did it spend there?
zipkin,"What‚Äôs the time breakdown on CPU, GPU, network calls, etc."
zipkin,If you‚Äôre debugging your application searching through your traces for specific edge case and analysing that one is golden.
zipkin,Same with analyzing performance outliers.
zipkin,"Big slow bottleneck
When you got obvious bottleneck you know where you need to drill down."
zipkin,You‚Äôve narrowed down your search space to this particular operation.
zipkin,The causes for big slow bottleneck could be various.
zipkin,Perhaps you‚Äôre overusing lock and the program is waiting on one.
zipkin,Or the database query is underoptimizes/missing an index.
zipkin,"Finally, your algorithm worked for 10 users but after growing to 10 000 users it‚Äôs just too slow."
zipkin,"Find it, observe it, analyze it, and fix it."
zipkin,"Fanout
Fan out is the number of outgoing requests a service makes for each incoming requests."
zipkin,The bigger the fan out the bigger the latency.
zipkin,"Sometimes fan out is on purpose and useful, however in this context, we‚Äôre primarily talk about calling the same service over and over again where a bulk operation would be more suitable."
zipkin,"It‚Äôs the difference between:
SELECT id, name FROM users WHERE ...
versus looping over some id list and querying for each id:
SELECT name FROM users WHERE id = $1 AND ..."
zipkin,"This could happen inadvertently, e.g."
zipkin,using ORM framework deciding to do this thing.
zipkin,You‚Äôve fetched your ids and now you‚Äôre happily looping over them not knowing you‚Äôre issuing new database query each time.
zipkin,Other times it‚Äôs the issue with API design.
zipkin,"If you have internal API endpoint such as: /api/v1/user/{id} for fetching user data, but require bulk export it‚Äôs the same issue."
zipkin,"On the tracing, you shall see many small requests to the same service."
zipkin,Despite them being parallel (though they‚Äôre not necessarily) you shall hit tail latency problem.
zipkin,The probability you‚Äôre going to observe p-th percentile latency for the calling services drops exponentially with fanout degree.
zipkin,Here‚Äôs a simple figure illustrating it.
zipkin,"Chrome tracing format
This is simple JSON format specification for single process tracing."
zipkin,The catapult project includes the rendered for this specification.
zipkin,The same renderer available in chrome under chrome://tracing/ URL.
zipkin,"There are various support for spitting out this format, e.g."
zipkin,"tensorflow execution, golang tracing, chrome rendering itself, etc."
zipkin,And it‚Äôs easy to include it into your application if there‚Äôs no need for distributed tracing and your requirements are simple.
zipkin,"For example, this simple file:
[ { ""name"": ""Asub"", ""cat"": ""PERF"", ""ph"": ""B"", ""pid"": 22630, ""tid"": 22630, ""ts"": 829 }, { ""name"": ""Asub"", ""cat"": ""PERF"", ""ph"": ""E"", ""pid"": 22630, ""tid"": 22630, ""ts"": 833 } ]
Renders as:

If you‚Äôre interested in more I recommend at least skimming the specification."
zipkin,The biggest downside is working with the visualizer.
zipkin,"As a newcomer, I had a hard time finding how can I filter datapoint in categories, by name, and overall advance use cases beyond the basic scroll and see."
zipkin,"Distributed tracing
All‚Äôs fine and dandy on a single node, but trouble starts with distributed systems."
zipkin,The problem is how to connect/correlate traces coming from multiple nodes.
zipkin,Which spans belong to which trace and how are those spans related?
zipkin,Today most solutions take notes from Google‚Äôs dapper paper.
zipkin,Each trace has its own unique traceID and each span unique SpanID which are propagated across the node boundaries.
zipkin,"Though, there are multiple ideas about how this context should be propagated and whether to include additional data during that propagation (i.e."
zipkin,baggage).
zipkin,"Also, each backend has its own ideas how should you deliver trace/span data to them."
zipkin,"The first available backend was Zipkin, nowadays Uber‚Äôs Jaeger is now CNCF incubating project and a good place to start."
zipkin,"Also, various cloud providers have their own in-house SaaS tracing (Google‚Äôs stackdriver, AWS X-Ray, etc.)"
zipkin,"Here‚Äôs a screenshot from Jaeger frontend for searching and looking at your traces:

Since writing against specific backend could be a hard vendor lock-in, there have emerged two client vendor-neutral APIs ‚Äî open tracing and open census."
zipkin,"In this subsection, I‚Äôm going to compare open census and open tracing standard."
zipkin,"Both are evolving project with high GitHub start count, multi-language support with various middleware implementations for databases, HTTP‚Äôs RPCs, gRPC, etc."
zipkin,Open tracing is currently CNCF incubating project while Open census emerged from Google‚Äôs internal trace tool.
zipkin,Nowadays open census has its own vendor-neutral organization.
zipkin,"As for the feature set, the open census includes metrics inside its API while open tracing is metrics only."
zipkin,"In open census, you add trace exporters to the global set, while in the open tracing you have to specify them in each iteration."
zipkin,"They have global tracer concept, but at least in go‚Äôs they don‚Äôt offer to default on it, but you have to invoke it."
zipkin,"Furthermore, open tracing API feels more clunky and less polished compared to the open census."
zipkin,"For the propagation format, open census specifies the standard."
zipkin,"Open tracing on the other hand only specifies the API, and each supported backend much implement the standard propagation API."
zipkin,"What open tracing has is baggage concept, that is forcing some data to be propagated to each downstream service alongside span propagation context."
zipkin,"Open census example
This subsection shall describe basic open census building blocks."
zipkin,"For complete examples see their official documentation, it‚Äôs quite good!"
zipkin,They even feature great examples.
zipkin,"My examples are in go, but they support multiple other languages."
zipkin,For brevity import statement shall be omitted.
zipkin,"First, we start by defining trace exporter:
j, err := jaeger.NewExporter(jaeger.Options{ Endpoint: ""http://localhost:14268"", ServiceName: ""opencensus-tracing"", }) trace.RegisterExporter(j)
We can easily start it using Docker."
zipkin,"From their getting started page
docker run -d --name jaeger \ -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \ -p 5775:5775/udp \ -p 6831:6831/udp \ -p 6832:6832/udp \ -p 5778:5778 \ -p 16686:16686 \ -p 14268:14268 \ -p 9411:9411 \ jaegertracing/all-in-one:1.7
Then we start some span:
ctx, span := trace.StartSpan(ctx, ""some/useful/name"") defer span.End()
The ctx is an instance of standard‚Äôs library context.context
We can attach some indexed tagged key/value metadata to this span:
span.AddAttribute(trace.StringAttribute(""key"", ""value""))
Open tracing actually specifies some standardized keys (e.g."
zipkin,"error, http.statuscode, ‚Ä¶)."
zipkin,If you can I recommend using them despite open census not specifying any.
zipkin,"Or we could add some log data, that is annotations:
span.Annotate(nil, ""some useful annotation"") span.Annotate( []trace.Attribute{trace.BoolAttribute(""key"", true)}, ""some useful log data"", )
After we decided to use HTTP let‚Äôs inject open census middleware:
client = &http.Client{Transport: &ochttp.Transport{}} // client http.ListenAndServe(addr, &ochttp.Handler{Handler: handler}) //server
for client side we only have to include the right context into our request:
req = req.WithContext(ctx) resp, err := client.Do(req)
While on the server side we grab the context from the request and go on with our life."
zipkin,"func HandleXXX (w http.ResponseWriter, req *http.Request) { ctx := req.Context() // ... }
This chapter could be summarised as open census crash course/cheat sheet/in 5 minutes."
zipkin,"To summarise this blog post I recommend tracing for these use cases the most:
Reasoning about overall performance overview
Detecting big slow operations
Fan out detection
In here I presented various tools such as chrome tracing format, open tracing, and open census."
zipkin,"Of those, I recommend starting with open census and starting jaeger in a docker container."
zipkin,Use middleware wherever possible.
zipkin,"Finally, reap the benefits!"
zipkin,See how tracing benefits you and how can you best leverage it to your success.
zipkin,"The problem
Internal users wanted to know how long would it take for a message to flow through our data pipeline and have the results available in an output topic."
zipkin,"While it might look like a simple question, it hides immense complexity in a distributed system."
zipkin,Retrieving this type of information for each event passing through the pipeline is a difficult task without adequate monitoring.
zipkin,"Our answer at that moment: ‚ÄúIt depends‚Ä¶‚Äù
It was the start of further conversations and the poof of concept that follows."
zipkin,The primary aim was to have visibility over the time it would take a message to pass through our pipeline.
zipkin,Our secondary aim was to be able to investigate bugs and incidents in a distributed system.
zipkin,Observing these services becomes very difficult when it is happening at scale.
zipkin,"Millions of events can pass through dozens or hundreds of microservices, and only relying on application logs you realize that they are not fit for purpose, due to the nature of streaming systems and the high amount traffic passing through them."
zipkin,"While this problem can be addressed by better logging tools, tracing the error through the system would still be a strenuous endeavour."
zipkin,"After those conversations and identifying our needs, we settled into attempting to implement a distributed tracing solution, relying on its ability to give us an overview of the whole system as well as a focused view of a particular event."
zipkin,"This, in turn, will enable us to identify and investigate the services which potentially are responsible for the error, either via a top-down approach starting with an entire trace and then drilling down, or a bottom-up approach starting near the potential cause of the incident and expanding out from there."
zipkin,"Distributed tracing system
What is it, how it works and why is it needed
With microservices, the tasks of monitoring the whole application become an impossible feat, as any external monitoring service will give you an overall view about what is happening in your application, lacking the fine details of what happens with the data whilst inside the app."
zipkin,"A distributed tracing system allows us to monitor each request as it hits different services of our application, deployed on various systems, platforms, environments, and identify where failures or performance issues are occurring."
zipkin,"The idea behind how this system works is rather simple:
assign a trace id to each request
include that id in all log messages
pass that id through each service
record the start and end time for each span id as it flows through."
zipkin,"These steps will create for each traced request a so-called span with metadata referencing the service, endpoints and timestamps (see here https://zipkin.io/pages/data_model.html)."
zipkin,"In our case, by aggregating and correlating these spans, we can identify bottlenecks as well as understand the overall time it takes a message to pass through our pipeline."
zipkin,This is done by simply searching for the id in a monitoring system like Kibana or through the Zipkin UI.
zipkin,"Simply put, a distributed tracing system collects and saves data from each service monitored, correlates it based on a trace id, and makes it available for visualisation via an API."
zipkin,"Sample Zipkin data model
[
    {
      ""traceId"": ""5982fe77008310cc80f1da5e10147517"",
      ""name"": ""get"",
      ""id"": ""bd7a977555f6b982"",
      ""timestamp"": 1458702548467000,
      ""duration"": 386000,
      ""localEndpoint"": {
        ""serviceName"": ""zipkin-query"",
        ""ipv4"": ""192.168.1.2"",
        ""port"": 9411
      },
      ""annotations"": [
        {
          ""timestamp"": 1458702548467000,
          ""value"": ""sr""
        },
        {
          ""timestamp"": 1458702548853000,
          ""value"": ""ss""
        }
      ]
    },{
      ""traceId"": ""5982fe77008310cc80f1da5e10147517"",
      ""name"": ""get-traces"",
      ""id"": ""ebf33e1a81dc6f71"",
      ""parentId"": ""bd7a977555f6b982"",
      ""timestamp"": 1458702548478000,
      ""duration"": 354374,
      ""localEndpoint"": {
        ""serviceName"": ""zipkin-query"",
        ""ipv4"": ""192.168.1.2"",
        ""port"": 9411
      },
      ""tags"": {
        ""lc"": ""JDBCSpanStore"",
        ""request"": ""QueryRequest{serviceName=zipkin-query, spanName=null, annotations=[], binaryAnnotations={}, minDuration=null, maxDuration=null, endTs=1458702548478, lookback=86400000, limit=1}""
      }
    },..]
To remember:
one trace id can be attached to multiple span ids
one span id keeps track of metadata of a traced service + a parent id of the service sender
a trace is a correlation of all spans for one trace id
Zipkin
Developed by Twitter, written in Java, and open-sourced in 2012, this seems to be the overall preferred tool to gain transparency into your microservice architecture."
zipkin,"As a result, it is the tool I have used to create a proof of concept."
zipkin,"Need to know components :
Reporter: creates the spans we talked above and sends them to a collector via HTTP (or Kafka and Scribe)
Collector: validates and stores the spans
Storage: Used to store the spans
API: Used to access the saved data
WebUI: Zipkin comes with its own web UI for viewing the traces
Implementation
A demo is available at the current link."
zipkin,"https://github.com/data-rocks-team/kafka-distributed-tracing
To run this application, clone the repo, bring the services up via docker-compose up and start the Producer, Consumer and Streaming applications."
zipkin,"In this specific scenario I chose to use ElasticSearch to back my data (as I had a previous implementation of this service and docker file setup and some experience with it, however Cassandra can be used as well) and to bring up the services via docker-compose:
The services needed to run this spike are listed in the docker-compose: Zipkin, Kafka, Zookeeper and ElasticSearch."
zipkin,There are a few simple configuration details to look for in the docker-compose file you can find here: https://github.com/data-rocks-team/kafka-distributed-tracing/blob/master/docker-compose.yml ‚Äî such as pointing Zipkin to the storage we want to save and read data from.
zipkin,"Auto-topic creation is enabled, therefore it is important that the Producer, Consumer and the Streaming service are run in this order, to enable the topic creation and trace."
zipkin,"For this example, I have used the Brave instrumentation library, written in Java (https://github.com/openzipkin/brave)."
zipkin,"The applications required to demonstrate the tracing are the producer, consumer and a streaming service."
zipkin,"Producer
Steps:
Configure the reporter and the tracing library:
//CONFIGURE TRACING
final URLConnectionSender sender = URLConnectionSender.newBuilder().endpoint(""<http://127.0.0.1:9411/api/v2/spans>"").build();
final AsyncReporter reporter=AsyncReporter.builder(sender).build();
final Tracing tracing = Tracing.newBuilder().localServiceName(""simpleProducer_test"").sampler(Sampler.ALWAYS_SAMPLE).spanReporter(reporter).build();
final KafkaTracing kafkaTracing = KafkaTracing.newBuilder(tracing).remoteServiceName(""kafka"").build();
final Tracer tracer = Tracing.currentTracer();
//END CONFIGURATION
2."
zipkin,"Wrap the Kafka producer in kafkaTracing.producer:
final Producer tracedKafkaProducer = kafkaTracing.producer(producer);
3."
zipkin,"Create spans:
measurements are taken between the span annotations
use the reporter flush to force messages to be sent to Zipkin
//Create record
ProducerRecord<String, String> record = new ProducerRecord<>(""test_tracing"", null, ""Test"");
//Create span 
ScopedSpan span = tracer.startScopedSpan(""produce-to-kafka"");
span.tag(""name"", ""sending-kafka-record"");
span.annotate(""starting operation"");
span.annotate(""sending message to kafka"");  
tracedKafkaProducer.send(record);
span.annotate(""complete operation"");
span.finish();
reporter.flush(); 
// flush method which sends messages to zipkin  
logger.info(""End of application"");
Consumer
Steps:
Same configuration as in the producer: the only change takes place to the localServiceName
//CONFIGURE TRACING 
final URLConnectionSender sender = URLConnectionSender.newBuilder().endpoint(""http://127.0.0.1:9411/api/v2/spans"").build(); 
final AsyncReporter reporter = AsyncReporter.builder(sender).build(); 
final Tracing tracing = Tracing.newBuilder().localServiceName(""simpleConsumer_test"").sampler(Sampler.ALWAYS_SAMPLE).spanReporter(reporter).build(); 
final KafkaTracing kafkaTracing = KafkaTracing.newBuilder(tracing).remoteServiceName(""kafka"").build(); 
final Tracer tracer = Tracing.currentTracer(); 
//END CONFIGURATION
2."
zipkin,"Wrap the consumer into kafkaTracing
Consumer<String, String> tracingConsumer = kafkaTracing.consumer(consumer);
3."
zipkin,"Subscribe tracing consumer to topic tracingConsumer.subscribe(Collections.singleton(""test_tracing""));
4."
zipkin,"Read data and send spans to Zipkin: nextSpan starts sending and span.finish ends it
while(true){
    ConsumerRecords<String,String> records = consumer.poll(Duration.ofMillis(100));
for (ConsumerRecord record: records){
        Span span = kafkaTracing.nextSpan(record).name(""kafka-to-consumer"").start();
        span.annotate(""Start consuming"");
        logger.info(""key: "" + record.key() + ""value: "" + record.value());
        span.annotate(""Consume finished"");
        span.finish();
    }
}
Streaming:
Steps:
Add the configuration:
//CONFIGURE TRACING
final URLConnectionSender sender = URLConnectionSender.newBuilder().endpoint(""http://127.0.0.1:9411/api/v2/spans"").build();
final AsyncReporter reporter = AsyncReporter.builder(sender).build();
final Tracing tracing = Tracing.newBuilder().localServiceName(""Kafka_Streaming"").sampler(Sampler.ALWAYS_SAMPLE).spanReporter(reporter).build();
final KafkaStreamsTracing kafkaStreamsTracing = KafkaStreamsTracing.create(tracing);
//END CONFIGURATION
2."
zipkin,"Wrap kafkaStream into kafkaStreamTracing
KafkaStreams streams = kafkaStreamsTracing.kafkaStreams(builder.build(), config);
And there you go."
zipkin,"To see it in action follow these steps:
Bring up all the services: docker-compose up
Start the services: Producer, Consumer and Streaming
Navigate to localhost:9411
Start producing to the topic
Result:
The first window we see is the one with an overview of all the traces we have recored, included in the root, trace id, start time and how long it took for our message to traverse the pipeline and be consumed:

Overview of traces
In the following window, we have a detailed imaged for a specific trace, identifying all the spans (producer, streaming and consumer, with annotations recorded for each service:

Detailed view of a specific trace
For the code of this example please visit this Github page: https://github.com/data-rocks-team/kafka-distributed-tracing
Conclusion
Distributed tracing is a useful concept for monitoring flows of data in your distributed system by:
understanding the behaviour of your distributed system, through transparency and visualisation
tracing messages across multiple applications and systems
locating performance issues and errors
surfacing latency issues between services
identifying services that require optimisation
having an overview of your service dependencies
Zipkin:
Is an excellent tool for surfacing these types of information ‚Äî related to bottlenecks, errors, latency problems ‚Äî as they happen:
useful for monitoring a message passing through the pipeline, the services it is hitting and how long it takes on average to be consumed
out of the box UI with relevant information for developers to access and locate issues
easy to implement with instrumentation libraries written in multiple languages"
zipkin,"At Salesforce, we use Zipkin to perform distributed tracing for microservices."
zipkin,The Zipkin tracing data (called span) can provide performance insights in both production monitoring and pre-production testing.
zipkin,"However, the current Zipkin open source instrumentation and UI offers only primitive data tracing functionality and does not have in-depth performance analysis of the span data."
zipkin,The purpose of this project is to use machine learning approach for deep analysis of span data.
zipkin,The data we use in this study is functional and performance tests in pre-production staging environment.
zipkin,"Several potential network bottlenecks, microservices performance issues were identified in our studies."
zipkin,"Additionally, we also inspected the current coverage of our Zipkin instrumentation."
zipkin,1.
zipkin,"Methodology
Zipkin is a distributed tracing system that generates timing data recording the request and response data within microservices calls."
zipkin,"The client instrumentation is done via an internal library, any services who wish to be traced can implement this library."
zipkin,The current sampling rate is 1% to save amount of span data generated in the system.
zipkin,The Zipkin spans are then stored in Elasticsearch.
zipkin,"In this excise, we export the production tracing data into a separate Elastic search instance for off-line process."
zipkin,"We used python Elasticsearch library to queried the data and used the Machine Learning libraries such as Numpy, Pandas, Networkx, and Matplotlib to analyze the data."
zipkin,Then we used a Jupyter Notebook to display and visualize the results.
zipkin,The goal is that through analysis of this data we will be able to identify latency issues in the network and bring greater visibility to these problems.
zipkin,2.
zipkin,"Calculating Completeness Metrics on Trace Data
First of all, we want to examine how well the zipkin tracing coverage within Salesforce microservices."
zipkin,"Since Zipkin is currently under development, it would be good to examine the percent completeness of traces in order to measure how well we are doing the tracing job."
zipkin,The completeness of a trace is defined as the percentage of the root span that is traced.
zipkin,"In the following example, the sum of all sub-spans (50ms+30ms) divided by the length of root span (100ms)."
zipkin,"the completeness is 80%, i.e."
zipkin,some sub-spans are missing for tracing.
zipkin,Completeness of the root span is important because it measures how well we are doing in trace instrumentation completion.
zipkin,"Ideally, we want the microservices in production to be 100% traced."
zipkin,This analysis gives an overview of trace completeness and their distribution.
zipkin,This will help the instrumentation team and microservices owners to be aware that there are still works to do.
zipkin,The following is one of the examples of trace completeness metrics for a given 24-hour span data in August.
zipkin,As we can see the majority of traces are currently at 60‚Äì90% range.
zipkin,This indicates that not all microservices in the system are being traced.
zipkin,This metrics can serve as a dashboard to measure the tracing completeness as the instrumentation of distributed tracing matures.
zipkin,We would like to see rising completeness trends with time in our microservices network.
zipkin,3.
zipkin,"Identifying High Traffic Areas in the Network
Another use of distributed tracing is the ability to plot the microservices call graph to visualize the network topology."
zipkin,Following network graph is one of the examples we draw based on parent relationships of span data.
zipkin,"In this network graph, each dot represents a microservices endpoint."
zipkin,The lines between microservices are weighted based on the number of connections to and from those microservices.
zipkin,It is quite obvious to visualize the high traffic areas within our production network topology.
zipkin,The top three services with the most connections are identified by their hosting IPs.
zipkin,"They have 48, 46, and 42 connections to those services respectively."
zipkin,"This finding is helpful feedback to the architecture design of those microservices, as those services with too many connections may potentially become choking points in the system design."
zipkin,"If one of the above services fail, there will be a huge impact on a large number of depending services."
zipkin,"Additionally, there could be also potential performance impacts in the system since a large number of services depending on them."
zipkin,Those are valuable information for system designers and architect to optimize their designs.
zipkin,4.
zipkin,"Identifying Services with Exponential Latency Growth
Next, we want to identify those individual microservices that may have performance problems."
zipkin,The performance problem is defined as the response time with exponential latency growth when load increases.
zipkin,"The methodology we use begins with filtering spans by microservices, and then further filtering the spans that were generated as a result of a request from a calling microservices."
zipkin,"Then we can generate two datasets, one of which describes the number of spans generated per second (load), and another which describes the latencies of each of those spans per second(average latency duration)."
zipkin,"Since we have two datasets with the same timestamps, so we are able to merge them into one plot, i.e."
zipkin,the load against the response duration.
zipkin,"However, since the current sampling rate is only 1%, we found the raw plot is very noisy."
zipkin,"Hence, we take the logarithm of average latency and plotted again with the load."
zipkin,"If any service with their logarithm response time has a linear relationship with load, we identified the services with potential performance problems."
zipkin,"Here are the formulas we used:
y=C¬∑a^x
log(y) = log(C ¬∑ a^x) = log(C) + log(a^x) = log(C) + x ¬∑ log(a)
Let y ÃÉ = log(y), b = log(C), m = log(a)
y ÃÉ = m¬∑x+b
Now that we have converted an exponential data set into a linear data set, we compute a Pearson correlation on this data and filter for high correlations."
zipkin,To calculate the Pearson correlation we used scipy.stats.pearsonr which returns a tuple of size 2.
zipkin,The first element of the tuple is the Pearson correlation coefficient.
zipkin,The second element of the tuple is a p-value that indicates the probability of an uncorrelated system producing a dataset that has a Pearson correlation at least as extreme as the one computed from the dataset.
zipkin,We analyzed the microservices with a high load that were identified in the previous section and used the above methodology to identify the relationship between load and latency.
zipkin,"From this analysis, we identified several microservices that showed exponential growth in span latency with load."
zipkin,"Following graph is one of the samples of such microservices:

Please note that in the x-axis, the load (r/s) seems to be low because the sampling rate is only 1%."
zipkin,The analysis of distributed tracing data has allowed us to identify potential chocking points at high load situation.
zipkin,We can use this information to reach out to service owners to improve their algorithms and work on troubleshooting these latency issues.
zipkin,5.
zipkin,"Conclusions and Future Development
Analyzing microservices Zipkin tracing data allow us to identify network congestion, bottlenecks, efficiencies and the heat map in the production network."
zipkin,We use Python AI packages to analyze the data because the current Zipkin UI does not have such capability.
zipkin,"We suggest that those features can be added to Zipkin product line, including UI and dashboards."
zipkin,capability for daily metrics on a correlation between microservices load and latency and to be able to generate alerts if bottleneck or heat map is identified.
zipkin,These data analysis not only can be used in production performance monitoring but also can be used for debugging and problem-solving.
zipkin,6.
zipkin,"Honorable Mentions and Thanks
Thanks to Andrey Falko, Ryan Michela and many people from Big Data Monitoring Cloud for their feedbacks and contributions."
zipkin,"Why Microservice
What is the difference between building tech for an early stage start up and a mid-size organization ‚Äî at early stage you build tech against time and at mid-size against scale."
zipkin,Everything is time critical and design and development mostly revolves around ‚Äî how fast we can roll this out in production.
zipkin,"A growing company is establishing everything from business to operation to tech, so the solutions implemented on field are mostly things at trail."
zipkin,This is validated more so in the case when you are solving a problem which has never been solved before.
zipkin,"So, market and competition compel the organization at a neck break pace and if you don‚Äôt, you would overtake by competition which nullifies the whole purpose of starting up."
zipkin,"Phase 2 of the organization comes when you see that your solutions have worked, and you see a strong growth path for your business."
zipkin,This is the phase where you build everything for scale keeping in mind the volume of business 5‚Äì7 years down the line.
zipkin,The involves solving problems in a way which will be completely different from how we have done things initially.
zipkin,"For building scalable service stack, a lot terms and ideas pop on the web ‚Äî micro services, centralized logging, monitoring, alerting, auditing, spring cloud, Netflix OSS and many more."
zipkin,"Also, in discussion would be a self-healing micro service stack."
zipkin,I will come to everything eventually but first things first ‚Äî let me go through a brief about what all things were considered and how did we come up with the stack architecture.
zipkin,Mostly all business problem will have a solution that will require different components of business pipeline to talk to each and come up with a decision or transaction to perform.
zipkin,"This is what happens in physical world, until there is money in the wallet you can‚Äôt perform a purchase."
zipkin,"So, it makes logical sense to separate out the concerns in the system synonymous to the business component, example in this case being, if the logic for checking wallet balance changes in future, no change is effected in purchase."
zipkin,Micro service architecture fits the bill here since it is driven by Single Responsibility Principle.
zipkin,"Benefits
Simplifies development and enhancements
Testability becomes better as each service can be tested in silos
Continuous integration becomes easier as each service needed to pass automation criteria independently
Enables continuous deployment of large scale complex systems
Helps manage the hardware as you scale the service which has increased utilization
If you are using dockers the problem of machine utilization is also solved
It enables you to organize the development effort around multiple teams."
zipkin,Each 2 PT (two pizza team) owns and is responsible for one or more single service.
zipkin,"Each team can develop, deploy and scale their services independently of all of the other teams provided best practices for versioning are adopted by the org."
zipkin,Application start up time is reduced which speeds up deployment and also improves productivity.
zipkin,Fault isolation is improved drastically.
zipkin,Complete system doesn‚Äôt go down.
zipkin,Free to choose the technology implementation basis the problem being solved.
zipkin,"Complexity
Complex distributed architecture
Implementation of robust inter-service communication."
zipkin,Implementation of strategy for distributed transactions.
zipkin,Set up of strong co-ordination between different 2 PT teams.
zipkin,"Building micro services requires an investment of time and effort, so when is the right time when you should move from monolithic to a ¬µService based architecture."
zipkin,Operational pipeline of business has pretty much stabilized.
zipkin,The scale of business has reached a level where hardware/software optimization is required for business functions.
zipkin,"Since initially building a micro-services stack takes more time compared to a monolithic the pace of roll out should be aligned with business
And of course, organization should have enough money in the bank to sustain and build a team of engineers for maintaining development, testing and infra for the services."
zipkin,"Architecture
Below flow diagram gives a basic overview of stack set up."
zipkin,"Service Stack
I will talk about some basics consideration to be kept in mind while designing the complete stack."
zipkin,"Module Design
The first step for was to structure the overall code base in a way so as to achieve the maximum reusability of common modules across services."
zipkin,"We figured out some basic modules which are part of almost every web application and qualified them to be a part of a commons layer:
Entity state machine ‚Äî This module was needed to transition entities from one state to another, but the state transition could only be done by certain user role(s) in the application."
zipkin,Since it was user triggered operation it was decided to drop the FSM implementation and introduced a simple module which constrained flow from one state to another and also checked the user role.
zipkin,"So, the table would have columns as From_State, To_State and a bitmap of user roles."
zipkin,Being a loosely coupled design this allowed us a lot of flexibility in implementing multi step maker checker flows.
zipkin,"Task Manager and Scheduler ‚Äî This was designed as a micro task scheduler based on spring scheduler which handles the flow of maintaining its state machine, generating and mailing error files and retrying itself."
zipkin,We defined an abstraction layer and every implementation would implement a handler which would parse the payload JSON stored with each task row or do some other custom business processing.
zipkin,This simplified the initial task management for us.
zipkin,Import/export module ‚Äî The idea while designing it was to keep the user flow very simple and easy to use.
zipkin,"An abstraction layer was responsible for defining an import/export as sync/a-sync, validating the mandatory columns (stored in DB ‚Äî this solved our problem of defining a dynamic config for any import/export) and data types in each row and then passing on the data to a handler which was implement by the business processor."
zipkin,Each handler would receive a list of rows where it could do its custom validations and processing.
zipkin,The abstracted part also maintains an error log for every failed row which is later used to generate failed CSV file.
zipkin,This failed CSV file is formatted in the same way as the upload template except one additional column for error message.
zipkin,Audit Module ‚Äî As the name suggest the purpose of this was to keep a change log for all entities in the system.
zipkin,For all persistent objects we defined some marker base entities which prototypes them as audit-able.
zipkin,The audit flow is currently based on Hibernate‚Äôs post commit handler which passes on the before/after payload to an audit service.
zipkin,"The audit module is an independent Elastic based micro service which is responsible for determining the delta between the copies, indexing them in elastic and enable search via various keys for audit logs."
zipkin,For future this would rearchitected to a ‚Äúmysql-binlog+debezium+kafka-stream‚Äù based service which is much more resilient and accurate.
zipkin,The release versions and snapshots for these modules are managed via an arti-factory.
zipkin,Inclusion is easily managed via maven.
zipkin,"Service discovery and communication
Why is service discovery important in a micro-service architecture?"
zipkin,This brings us to the concept of client-side load balancing where a client or service node knows about all the IPs registered to a service domain and decide which IP to fire the request to.
zipkin,"In an up-scaling/down-scaling environment nodes constantly come up and go down and need to register themselves on service domain(s), post which a client-side load balancer distributes request coming on it."
zipkin,The basis for load balancer can be default ones or you can build a custom one (which was our requirement for a self-healing service design).
zipkin,The client-side load balancer can be separate layer or it can be managed in the application itself.
zipkin,Netflix OSS provides ribbon for this use case which binds which each service node as a sidecar.
zipkin,For our use case we have used Consul as service discovery & registry server.
zipkin,Reason for choosing this will come in further posts as this provides consul templates which we have used in our self-healing micro service architecture.
zipkin,For communication across services we are using Netflix OSS‚Äôs Feign Client and Hystrix for circuit breaker.
zipkin,"Feign Configuration:

For more libraries you can refer ‚Äî Spring Cloud which provides suite of tools for designing distributed systems."
zipkin,"Centralized Logging and Distributed Traceability

This is pipeline we chose to implement the logging."
zipkin,A detailed blog will follow soon on why we made this choice.
zipkin,"Sharing a brief from there -
‚ÄúFilebeat helps throttle the shipping of data (Filebeat uses a backpressure-sensitive protocol when sending data forward to account for higher volumes of data) as well as there is no loss of data as logs are written to a file first."
zipkin,"The major concern was eliminating logstash to prevent useless resource consumption, and that is achieved by using Inode."
zipkin,"Moreover, filebeat has configurations to optionally specify the Ingest pipeline which would process data before dumping it into ES indices, so we can specify the necessary grok filters in the pipeline and add it to the Filebeat config file."
zipkin,"Once data is there in Elasticsearch, all sorts of analytics and visualizations can be done through Kibana.‚Äù
Distributed tracing is being able to trace the request initiated through a client across all services it has been served by."
zipkin,"For this we are using Zipkin, a distributed traceability tool which seamlessly integrates with spring based services and also provides an out of box web UI for request tracing."
zipkin,It is based on Dapper and HTrace and works on by joining traces across http request/message boundaries.
zipkin,"It binds a span and a trace with each request/thread/message, terminologies for which are:
SPAN ‚Äî Basic unit of work with unique 64-bit Identifier
TRACE ‚Äî Tree like data structure, each node as a span
Sample demonstration of an incoming request being traced via Zipkin:

Besides being able to trace request it gives one major advantage in centralized logging."
zipkin,We were able to insert traceid and spanid through log4j in the application logs and through grok filtering were able to index it in elastic.
zipkin,Now searching a traceid in elastic helps me trace logs for a request across all services and debugging becomes a lot faster.
zipkin,The combination of centralized logging and distributed tracing has created quite a useful tool for debugging requests across services in app logs.
zipkin,"Monitoring and alerting
We needed to set up basic monitoring to be able to generate alerts and have real time charts for NOC teams to monitor."
zipkin,"Further use case was gathering data around application, database and instance behavior and be able to use that for self-healing service architecture."
zipkin,"After considering various options we finalized Prometheus, Alert Manager and Grafana."
zipkin,We piped the data from two sources ‚Äî spring actuator metrics and nginx logs.
zipkin,Set up is very simple with changes in pom and yml files.
zipkin,"Currently we are in the process of setting up a self healing deployment pipeline which involves decision making from above data and using docker, ECS, Nginx & Consul to orchestrate complete deployment, load balancing as per health score and continuous monitoring."
zipkin,"Once we have enough data ML models can be used to off load some of decision making and also find anomalies in different flow in the system, whether be it incoming requests, sudden spike in machine metrics, sudden spike in error count etc."
zipkin,We will soon share blog posts on setting up the above systems.
zipkin,The focus of this blog post was to give an basic overview of designing and setting loosely coupled architecture from the word go.
zipkin,This sets up a strong foundation of scaling up the system later.
zipkin,"Both business requirement and tech architecture require an upgrade for unforeseen and unpredictable issues, designing a system which is loosely coupled enables you to makes those changes much easily and with controlled releases and lesser rollbacks."
zipkin,This demonstration takes a look at instrumenting a typical Spring application with the Zipkin tracing tool-chain.
zipkin,Application developers wanting to observe system behavior without writing specific code will want to use this method.
zipkin,Lets take a look at ways to inject the necessary mechanics that underpin our tracing concerns.
zipkin,"Typically on the server-side, we can usually specify a filter or interceptor which is a pattern widely supported by HTTP/*RPC* frameworks."
zipkin,"WebMvcTraceConfiguration.java: SpringMVC supports custom Interceptors
The InterceptorRegistry lets us add additional logic around the execution of our HTTP requests."
zipkin,"In this case, we used an implementation of Spring‚Äôs HandlerInterceptor ‚Äî the Brave frameworks own TracingHandlerInterceptor which exhibits tracing during the service call."
zipkin,"Observing client-side HTTP calls is similar:

WebClientTraceConfiguration.java: RestTemplate supports an interceptor style."
zipkin,This interceptor pattern lets us compose our HTTP call with additional modification of behavior that for instance ‚Äî lets us insert tracing waypoints before and after a call has been made.
zipkin,We can now compose services with predictable tracing dynamics as shown in our example system seen in this github post.
zipkin,"It follows an application design like illustrated in the diagram below:

Application Setup for Tracing Sample."
zipkin,"Additionally, we may have to call services out of our control, but within the tracing scope."
zipkin,"That is OK, as spans may complete against an opaque system ‚Äî thus we may label our traces as such (e.g."
zipkin,call to www.my-social-network.com).
zipkin,The tracing system itself will take care of putting together all of the pieces in which case we know how operations exist and complete with each other.
zipkin,We can‚Äôt always control service interactions.
zipkin,"Ideally, all service calls should complete successfully or at the very least exhibit graceful degradation."
zipkin,Though it may not always be the case.
zipkin,"Therefore, tracing can help us see service limits, like bottlenecks‚Äî i.e."
zipkin,authorization system slowing down at high request rate for XYZ service call.
zipkin,Tracing ultimately serves an Operations concern ‚Äî Known as Application Performance Management which takes into account the reliability of a system at any point in it‚Äôs lifetime.
zipkin,"If you are concerned with system operability and inter-service dynamics, then packages like these can and will assist with your tracing needs:
Spring Cloud Sleuth
Zipkin
AppDynamics
Dynatrace
Check out the source code for the sample project at my github.com page."
zipkin,"For the curious, I have included some extra reading material on the topic."
zipkin,Happy Hacking!
zipkin,"With the proliferation of microservices, observability got a crucial role in operations and one of the observability means that got more exposure lately was Distributed Tracing."
zipkin,"If you don‚Äôt know what it is or, more important, what problem it solves you can watch the talk I gave at microXchg 2018 about the topic:

Slides available at https://speakerdeck.com/jcchavezs/distributed-tracing-understand-how-your-components-work-together
TL;DW: Distributed tracing helps engineering teams with distributed systems to understand their architecture, critical paths for a request across services and observe latencies, it also helps to observe real production requests to understand errors."
zipkin,A very common question about tracing is how to instrument an application (i.e.
zipkin,how to add observability means to your application).
zipkin,Instrumentation usually starts by adding tracing to common pieces in the code: RPC framework or routing middlewares.
zipkin,"Instrumentation with Zipkin
Zipkin is an open source distributed tracing tool created by twitter."
zipkin,"It has a beautiful community, a very mature model and it is available in many languages."
zipkin,In this post we will use the brand new zipkin-go official library.
zipkin,"Before we jump into the actual code I‚Äôd mention a couple of rules of thumb for instrumenting applications:
As an habit, pass the context.Context as the first parameter in your functions."
zipkin,This is not only a good practice in go but also allow tracer to retrieve information from upper level spans down in the stack.
zipkin,"Start with common frameworks (RPC frameworks, HTTP middlewares, etc."
zipkin,"), that would make it easier to plug tracing into existing applications."
zipkin,Make all attempts possible to be transparent with regards to library usage: 1. create wrappers (or decorators) that implement the same interface as the originals 2. try to use existing hooks like middlewares or handlers.
zipkin,That would me it easier the adoption.
zipkin,"It is discouraged to instrument business logic (domain nor application logic), all tracing data should come from infrastructure."
zipkin,"It should not affect the normal flow of the application, errors from instrumentation code should not affect the function‚Äôs original output."
zipkin,It should be optimized to add the least overhead possible otherwise you end up in the observer effect.
zipkin,"That said, it is important to differentiate the two main pieces to be instrumented:
In process tracing: Operations taking place inside the service."
zipkin,The most common one is a request being served from the application.
zipkin,Outbound tracing: Calls to external resources.
zipkin,Most common ones are RPC calls or database operations.
zipkin,In this example we will instrument a request and a HTTP call to an external resource.
zipkin,"The first step is to create a tracer instance:
package main

import (
   ""github.com/openzipkin/zipkin-go""
   ""github.com/openzipkin/zipkin-go/model""
   reporterhttp ""github.com/openzipkin/zipkin-go/reporter/http""
)

const endpointURL = ""http://localhost:9411/api/v2/spans""

func newTracer() (*zipkin.Tracer, error) {
   // The reporter sends traces to zipkin server
   reporter := reporterhttp.NewReporter(endpointURL)

   // Local endpoint represent the local service information
   localEndpoint := &model.Endpoint{ServiceName: ""my_service"", Port: 8080}

   // Sampler tells you which traces are going to be sampled or not."
zipkin,In this case we will record 100% (1.00) of traces.
zipkin,"sampler, err := zipkin.NewCountingSampler(1)
   if err != nil {
      return nil, err
   }

   t, err := zipkin.NewTracer(
      reporter,
      zipkin.WithSampler(sampler),
      zipkin.WithLocalEndpoint(localEndpoint),
   )
   if err != nil {
      return nil, err
   }

   return t, err
}
Once the tracer is in place, we need to add a middleware to the router in order to trace incoming requests."
zipkin,In this case we will use gorilla/mux but the middleware is a http.Handler implementation so it should work in any other router.
zipkin,"package main

import (
   ""log""
   ""net/http""

   ""github.com/gorilla/mux""
   ""github.com/openzipkin/zipkin-go""
   zipkinhttp ""github.com/openzipkin/zipkin-go/middleware/http""
)

func main() {
   tracer, err := newTracer()
   if err != nil {
      log.Fatal(err)
   }

   r := mux.NewRouter()
   r.HandleFunc(""/foo"", FooHandler)
   r.Use(zipkinhttp.NewServerMiddleware(
      tracer,
      zipkinhttp.SpanName(""request"")), // name for request span
   )
   log.Fatal(http.ListenAndServe("":8080"", r))
}

func FooHandler(w http.ResponseWriter, r *http.Request) {
   w.WriteHeader(http.StatusOK)
}
At this point, we should be able to see traces for our requests in zipkin."
zipkin,"You can start the zipkin collector by running:
docker run -d -p 9411:9411 openzipkin/zipkin
Once the service is up, if you curl -i http://localhost:8080 you should be able to start a trace for the request received by the router."
zipkin,The next big piece to be instrumented is a HTTP call to an external service.
zipkin,"For that we should first add the an instrumented transport to the http client:
package main

import (
   ""log""
   ""net/http""

   ""github.com/gorilla/mux""
   ""github.com/openzipkin/zipkin-go""
   zipkinhttp ""github.com/openzipkin/zipkin-go/middleware/http""
)

func main() {
   tracer, err := newTracer()
   if err != nil {
      log.Fatal(err)
   }

   // We add the instrumented transport to the defaultClient
   // that comes with the zipkin-go library
   http.DefaultClient.Transport, err = zipkinhttp.NewTransport(
      tracer,
      zipkinhttp.TransportTrace(true),
   )
   if err != nil {
      log.Fatal(err)
   }

   r := mux.NewRouter()
   r.HandleFunc(""/"", HomeHandlerFactory(http.DefaultClient))
   r.HandleFunc(""/foo"", FooHandler)
   r.Use(zipkinhttp.NewServerMiddleware(
      tracer,
      zipkinhttp.SpanName(""request"")), // name for request span
   )
   log.Fatal(http.ListenAndServe("":8080"", r))
}
And finally we just need to use this instrumented Post function in one of our handlers:
package main

import (
   ""bytes""
   ""net/http""
)

func HomeHandlerFactory(client *http.Client) func(http.ResponseWriter, *http.Request) {
   return func(w http.ResponseWriter, r *http.Request) {
      body := bytes.NewBufferString("""")
      res, err := client.Post(""http://example.com"", ""application/json"", body)
      if err != nil {
         w.WriteHeader(http.StatusInternalServerError)
         return
      }

      if res.StatusCode > 399 {
         w.WriteHeader(http.StatusInternalServerError)
         return
      }

      w.WriteHeader(http.StatusOK)
   }
}
That‚Äôs it."
zipkin,Now you are ready to see your data in zipkin (http://localhost:9411).
zipkin,‚Äúrequest‚Äù one span for the request received and one for the request made.
zipkin,If you have any doubt on how to use zipkin-go I strongly recommend you to head to the gitter channel where a great community will help you out with the library usage.
zipkin,What else can I do?
zipkin,"You can improve the instrumentation by using meaningful span names, a common practice among zipkin instrumentations is to use the http.route i.e."
zipkin,the pattern declared in the route.
zipkin,"For example GET /foo/{user_id} instead of request :
package main

import (
   ""context""
   ""net/http""

   ""github.com/gorilla/mux""
   ""github.com/openzipkin/zipkin-go""
)

// ZipkinHTTPRoute sets http.route if a span and gorilla mux
// template path are found."
zipkin,"func ZipkinHTTPRoute(ctx context.Context, r *http.Request) context.Context {
   if span := zipkin.SpanFromContext(ctx); span != nil {
      if route := mux.CurrentRoute(r); route != nil {
         if routePath, err := route.GetPathTemplate(); err == nil {
            zipkin.TagHTTPRoute.Set(span, routePath)
            span.SetName(r.Method + "" "" + routePath)
         }
      }
   }
   return ctx
}
Enjoy!"
zipkin,"According to ‚ÄúGoogle Dapper‚Äù a Large-Scale Distributed Systems Tracing Infrastructure, there are some more extensive open source projects can help us to using it within very convenient steps."
zipkin,What does ‚ÄúGoogle Dapper‚Äù going to solve?
zipkin,We do need trace latency and root-cause of frontend and backend services even errors.
zipkin,Dapper planed to solve tracing problem of remote procedure calls and then summary to trace tree as image left part to right part.
zipkin,And then OpenTracing comes in.
zipkin,OpenTracing implements APIs and interfaces base on ‚ÄúDapper‚Äù to help programers add trace code with low coupling library and produce public format tracing data.
zipkin,After all we can get tracing result as picture.
zipkin,"The OpenTracing Data Model
Causal relationships between Spans in a single Trace


        [Span A]  ‚Üê‚Üê‚Üê(the root span)
            |
     +------+------+
     |             |
 [Span B]      [Span C] ‚Üê‚Üê‚Üê(Span C is a `ChildOf` Span A)
     |             |
 [Span D]      +---+-------+
               |           |
           [Span E]    [Span F] >>> [Span G] >>> [Span H]
                                       ‚Üë
                                       ‚Üë
                                       ‚Üë
                         (Span G `FollowsFrom` Span F)
Common function calls
def top_level_function():
    span1 = tracer.start_span('top_level_function')
    try:
        ."
zipkin,.
zipkin,.
zipkin,"# business logic
    finally:
        span1.finish()
def function2():
    span2 = get_current_span().start_child('function2') \
        if get_current_span() else None
    try:
        ."
zipkin,.
zipkin,.
zipkin,"# business logic
    finally:
        if span2:
            span2.finish()
In fact, with OpenTracing‚Äôs workout, we did can start our tracing tasks, but there are ‚ÄúZipkin‚Äù and ‚ÄúJaeger‚Äù to be introduced."
zipkin,"Zipkin, it is a distributed tracing system too, has dependency-free library, and spring-boot server."
zipkin,But could be roll as a ‚ÄúTracer‚Äù to OpenTracing.
zipkin,"// All data are recorded against the same endpoint, associated with your service graph
localEndpoint = Endpoint.newBuilder().serviceName(""tweetie"").ip(""192.168.0.1"").build()
span = Span.newBuilder()
    .traceId(""d3d200866a77cc59"")
    .id(""d3d200866a77cc59"")
    .name(""targz"")
    .localEndpoint(localEndpoint)
    .timestamp(epochMicros())
    .duration(durationInMicros)
    .putTag(""compression.level"", ""9"");

// Now, you can encode it as json
bytes = SpanBytesEncoder.JSON_V2.encode(span);
Zipkin supply lots of modules to fit sorts of platform and programing languages supported includes AWS, GCP, Azure, Java, .NET, Node.js, Go, Fingle(Twitter rpc), Python, Spark, Php, js."
zipkin,Zipkin-UI support web interface for standard query support.
zipkin,"For example, with Docker-Zipkin and Zipkin .Net client Lib, we can illustrates well done job by Zipkin."
zipkin,"## to start zipkin docker and UI
$ docker-compose -f docker-compose.yml -f docker-compose-ui.yml up
## start compiled .net example frontend and backend web server
dotnet zipkin4net-master/Examples/aspnetcore/frontend.dll
dotnet zipkin4net-master/Examples/aspnetcore/backend.dll

with Zipkin library enhanced server/service
Jaeger\ÀàyƒÅ-g…ôr\, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies."
zipkin,"Uber Engineering starts use Zipkin and evolving new distributed tracing system for high scalability, to serve thousands of micro-services."
zipkin,So Jaeger extends more complex architecture for larger scale of requests and performance.
zipkin,"In particular, the Zipkin model did not support two important features available in the OpenTracing standard and Jaeger client libraries: a key-value logging API and traces represented as more general directed acyclic graphs rather than just trees of spans."
zipkin,"example image from LightStep [x]PM (Product)
When really steps in, there still some better choice, good example from the post ‚ÄúTracing http request in go with opentracing‚Äù."
zipkin,Following are some digests when implement to backend server with Golang.
zipkin,"Entry Point (Service backend)
// Jaeger tracer can be initialized with a transport that will
// report tracing Spans to a Zipkin backend
// zipkinURL point to server
transport, err := zipkin.NewHTTPTransport(
      *zipkinURL,
      zipkin.HTTPBatchSize(1),
      zipkin.HTTPLogger(jaeger.StdLogger),
)
if err != nil {
      log.Fatalf(""Cannot initialize HTTP transport: %v"", err)
}
// create Jaeger tracer
tracer, closer := jaeger.NewTracer(
      ""TracerName"",
      jaeger.NewConstSampler(true), // sample all traces
      jaeger.NewRemoteReporter(transport, nil),
)
// Close the tracer to guarantee that all spans that could
// be still buffered in memory are sent to the tracing backend
defer closer.Close()
Other just useful method for tag , log and error."
zipkin,// Adds a tag to the span.
zipkin,"// 
// Tag values can be numeric types, strings, or bools."
zipkin,"// The behavior of other tag value types is undefined at the 
// OpenTracing level."
zipkin,"SetTag(key string, value interface{}) Span
// LogFields is an efficient and type-checked way to record
// key:value 
// logging data about a Span, though the programming interface 
// is a little more verbose than LogKV()
LogFields(fields ...log.Field)
// set error flag of span
ext.Error.Set(span, true)
We don‚Äôt need to care about span relations for HTTP requests, and can get good enough tracing event and detail by Zipkin-UI."
zipkin,Just remember to take care about privacy or secret data leaks if hosted at public domains.
zipkin,"For a master table-of-contents for blog posts on microservice topics, please refer ‚Äî https://medium.com/oracledevs/bunch-of-microservices-related-blogs-57b5f1f062e5
This blog will demonstrate how you can set up a scalable distributed tracing infrastructure on Oracle Cloud
One of my earlier blogs showcased a simple example of distributed tracing for microservices (based on Spring Boot) using an example revolving around Spring Cloud Sleuth and Zipkin
Distributed tracing for microservices on Oracle Cloud with Spring Cloud Sleuth and Zipkin
medium.com

There are couple of key points which need to be highlighted with regards to the default behavior of the system
Sending data to Zipkin ‚Äî Spring Cloud Sleuth sends spans/trace data to Zipkin over HTTP
Persisting the trace data ‚Äî Zipkin stores span data in-memory
This is obviously not a bullet-proof solution
Single point of failure ‚Äî Since Zipkin is core component of our distributed tracing solution, it also has the potential of becoming a bottleneck both from an availability and performance standpoint
Ephemeral storage ‚Äî since Zipkin stores span data in-memory, it will be lost if the Zipkin instance restarts or crashes
Although nothing is perfect, this situation can be improved."
zipkin,"Here is an overview of what this blog will demonstrate in terms of the solution
Zipkin runtime ‚Äî we will continue to use Oracle Application Container Cloud as the runtime for the Zipkin server
Cassandra for persistent storage ‚Äî Oracle Data Hub Cloud is a managed Cassandra offering which we will use as the NoSQL persistent store for Zipkin
Kafka as the message bus ‚Äî Oracle Event Hub Cloud is a managed Kafka service which will be leveraged in order to decouple Spring Cloud Sleuth from Zipkin
Time to dive deeper‚Ä¶ !"
zipkin,"Use case overview
The use case is still the same as the earlier blog i.e."
zipkin,distributed tracing.
zipkin,"But this particular blog is focused on the infrastructure side of things, hence the sample itself is very simple ‚Äî so all we have is a single Spring Boot app (named inventory) to test things out (as opposed to a couple of microservices which were used as an example to illustrate the concepts in the earlier blog post)
Here is the high level flow
the inventory app sends span data to Kafka..
‚Ä¶ which is (asynchronously) consumed by Zipkin and persisted to Cassandra
The key focus is on
revamping the Zipin server to communicate to Kafka and Cassandra on Oracle Cloud
updating the inventory service to talk to Kafka rather than interface directly with Zipkin
Architecture components
Here is a diagram to give you a high level idea of what the architecture is..

High level arch diagram
Kafka (on Oracle Event Hub Cloud)
As mentioned above, since Kafka sits between your application (which is using Spring Cloud Sleuth) and Zipkin, trace data will be sent to Kafka which Zipkin can consume asynchronously and persist to Cassandra
Although it is another piece of infrastructure to deal with, the obvious benefits are
It acts as buffer and helps manage the back pressure ‚Äî think multiple microservices pumping trace data
It also helps with availability ‚Äî if the Zipkin cluster is unavailable, applications still continue enqueue data into Kafka which can be picked up by Zipkin when its back up
Both Zipkin server as well as the individual applications talk to Kafka
The Zipkin server component‚Ä¶
‚Ä¶ uses @EnableZipkinStreamServer (thanks to the spring-cloud-sleuth-zipkin-stream dependency) annotation to signal that it will be receiving span/trace messages from Kafka
the Spring Cloud Stream Kafka binder is pulled in via spring-cloud-starter-stream-kafka and this takes care of the Kafka consumer part
the application.properties use spring.cloud.stream.kafka.binder.brokers and spring.cloud.stream.kafka.binder.zkNodes to specify the co-ordinates of Kafka and Zookeeper respectively
Our Sleuth enabled Spring Boot microservice ..
.. also pushes trace/span data to Kafka spring-cloud-sleuth-stream and (the usual) spring-cloud-starter-stream-kafka modules
it also uses the same application.properties as the Zipkin server to specify Kafka and Zookeeper co-ordinates
Cassandra (on Oracle Data Hub Cloud)
Only the Zipkin server (not the applications) interacts with Cassandra to persist the trace data/messages it receives from Kafka."
zipkin,"It uses a Java driver for Cassandra and zipkin-autoconfigure-storage-cassandra3 module
The key highlights are the configuration parameters in application.properties
zipkin.storage.type ‚Äî value used is cassandra3
zipkin.storage.cassandra3.contact-points ‚Äî where is the Cassandra cluster
zipkin.storage.cassandra3.username and zipkin.storage.cassandra3.password ‚Äî quite obvious
zipkin.storage.cassandra3.keyspace ‚Äî which keyspace should Zipkin create objects in
zipkin.storage.cassandra3.ensure-schema ‚Äî if set to true, Zipkin automatically seeds the schema with the required objects (UDTs, tables etc.).."
zipkin,isn‚Äôt that sweet !
zipkin,"More details on the Cassandra objects in the next section
Service Bindings in Oracle Application Container Cloud
Its important to reiterate as to how important Service Bindings are and they how they make things much simpler in terms of secure and hassle-free communication between applications (Zipkin and other microservices) and downstream infrastructure components like Kafka (Eventh Hub) and Cassandra (Data Hub)
All you really need to do is declare a dependency (binding) and you‚Äôll get a internal communication channel set up for free without punching holes in the firewalls/access rules of the respective services
This concept will be highlighted in the upcoming sections and you can always refer to the official documentation for more info
Using Oracle Application Container Cloud Service
The Deployments page of an application enables you to redeploy the application, configure environment variables and‚Ä¶
docs.oracle.com

Let‚Äôs quickly cover the setup for our infrastructure components
Cassandra, and
Kafka
Infrastructure setup
Oracle Data Hub Cloud
Provision Cassandra cluster
Start by bootstrapping a new cluster ‚Äî detailed documentation here

Cluster create options
It is also possible to do this using a CLI
Below snippet shows a basic single node cluster running Cassandra 3.10.0

Oracle Datahub cloud Cassandra Cluster
Check Zipkin related schema objects
As mentioned above, Zipkin related Cassandra schema objects are auto created ‚Äî these include user defined types and tables
To check these,
SSH into the Cassandra cluster node ‚Äî documentation available here
Fire up cqlsh ‚Äî execute sudo su oracle (relevant information here) and then cqlsh -u admin `hostname`

Logged into cqlsh
get the details of your zipkin specific keyspace (which you configured in application.properties) ‚Äî e.g."
zipkin,"desc zipkin .. if don‚Äôt remember it, just use desc keyspaces and you should see yours there
Here is a screenshot of some of the objects

Zipkin schema objects in Cassandra
Oracle Event Hub Cloud (Kafka broker)
The Kafka cluster topology used in this case is relatively simple i.e."
zipkin,a single broker with co-located with Zookeeper).
zipkin,You can opt for a topology specific to your needs e.g.
zipkin,"HA deployment with 5-node Kafka cluster and 3 Zookeeper nodes
Please refer to the documentation for further details on topology and the detailed installation process (hint: its straightforward!)"
zipkin,"Kafka broker on Event Hub Cloud
Creating custom access rule
You would need to create a custom Access Rule to open port 2181 on the Kafka Server VM on Oracle Event Hub Cloud ‚Äî details here
Oracle Application Container Cloud does not need port 6667 (Kafka broker) to be opened since the secure connectivity is taken care of by the service binding
Build, configure & deploy
Start by fetching the project from Github ‚Äî git clone https://github.com/abhirockzz/accs-zipkin-tracing-infra-with-kafka-cassandra.git
Build
Zipkin server
cd zipkin
mvn clean install
The build process will create zipkin-dist.zip in the target directory
Inventory service
cd inventory
mvn clean install
The build process will create inventory-dist.zip in the target directory
Configuration
Before you launch these into the cloud, please tweak the configuration parameters as per your environment
deployment.json and manifest.json for Zipkin server

deployment.json and manifest.json for inventory service

Now that you have configured your apps, it‚Äôs time to deploy them
Deployment a.k.a push to cloud
With Oracle Application Container Cloud, you have multiple options in terms of deploying your applications."
zipkin,"This blog will leverage PSM CLI which is a powerful command line interface for managing Oracle Cloud services
other deployment options include REST API, Oracle Developer Cloud and of course the console/UI
You can download and setup PSM CLI on your machine (using psm setup) ‚Äî details here
Here are the CLI commands to deploy the apps
Zipkin ‚Äî psm accs push -n zipkin -r java -s hourly -m manifest.json -d deployment.json -p target/zipkin-dist.zip
Inventory ‚Äî psm accs push -n inventory -r java -s hourly -m manifest.json -d deployment.json -p target/inventory-dist.zip

Sanity checks
check service bindings, and,
access the Zipkin server to confirm its functional
After the Zipkin server has been successfully deployed, you can check Service Binding its details by navigating to the details screen -> Deployments section ‚Äî you will see both Data Hub (Cassandra) and Event Hub (Kafka) bindings along with their respective environment variables (cropped image)

Zipkin bindings to Kafka, Cassandra
Same applies for the inventory service (it binds only to Kafka)

Inventory service binding to Kafka
Finally, access the Zipkin server ‚Äî note the app URL e.g."
zipkin,"https://zipkin-<mydomain>.apaas.us2.oraclecloud.com

Zipkin on Oracle Application Container Cloud
Test drive‚Ä¶
Alright, everything is setup for us to test things out
Invoke inventory service
To start with, check the URL of the inventory app and invoke it a few times
curl https://inventory-<mydomain>.apaas.us2.oraclecloud.com/inventory/iPhone4
curl https://inventory-<mydomain>.apaas.us2.oraclecloud.com/inventory/iPhone5
curl https://inventory-<mydomain>.apaas.us2.oraclecloud.com/inventory/iPhoneX
Access Zipkin dashboard to see the span data

Zipkin dashboard with span/trace data
If you dig down further into the span, you‚Äôll see more details

Span details
Above is the span from our invocation of iphoneX (one of the three invocations listed above)."
zipkin,"This is relatively simple since you just have single service, but the same would apply if you had a chain of invocations with different (micro) services involved
If you dig in even further, there is more to unearth ‚Äî focus on the highlighted info

More details about a specific trace
Span data in Cassandra
you can double check Cassandra as well."
zipkin,"Using cqlsh, you execute select * from zipkin.traces; (assuming zipkin is the keyspace name)
You can also query other related tables
What about Kafka ?"
zipkin,"As you might understood, the span data is sent by Sleuth to a Kafka topic (unsurprisingly named sleuth) which is then consumed by Zipkin and persisted to Cassandra.. try this out as well
Use the kafka CLI to set up a consumer ‚Äî kafka-console-consumer.bat --bootstrap-server <event_hub_kakfa_IP>:6667 --topic sleuth
Invoke the inventory app again ‚Äî curl https://inventory-<mydomain>.apaas.us2.oraclecloud.com/inventory/AppleWatch
You will see a rather cryptic message whose contents are pasted below for your easy reference ‚Äî recall that you saw the same trace data in Zipkin before

Monitor the sleuth topic in Kafka for trace data
‚ô£‚ôÇcontentType ‚ôÄ‚Äùtext/plain‚Äù‚ÄºoriginalContentType ‚Äúapplication/json;charset=UTF-8‚Äù‚ô†spanId ‚Üï‚Äùe7bd0aabba1fa09c‚Äù‚ôÇspanTraceId ‚Üï‚Äùe7bd0aabba1fa09c‚Äù‚ôÇspanSampled ‚ô•‚Äù0""{‚Äúhost‚Äù:{‚ÄúserviceName‚Äù:‚Äùinventory‚Äù,‚Äùaddress‚Äù:‚Äù172.17.0.2"",‚Äùport‚Äù:8080},‚Äùspans‚Äù:[{‚Äúbegin‚Äù:1516776180246,‚Äùend‚Äù:1516776180258,‚Äùname‚Äù:‚Äùhttp:/inventory/AppleWatch‚Äù,‚ÄùtraceId‚Äù:8394174692565835560,‚ÄùspanId‚Äù:8394174692565835560,‚Äùexportable‚Äù:true,‚Äùtags‚Äù:{‚Äúmvc.controller.class‚Äù:‚ÄùInventoryApplication‚Äù,‚Äùhttp.status_code‚Äù:‚Äù200"",‚Äùmvc.controller.method‚Äù:‚ÄùgetInventory‚Äù,‚Äùspring.instance_id‚Äù:‚Äùinventory.oracle.local:inventory:8080"",‚Äùhttp.path‚Äù:‚Äù/inventory/AppleWatch‚Äù,‚Äùhttp.url‚Äù:‚Äùhttp://inventory-<mydomain>.uscom-central-1.oraclecloud.com:443/inventory/AppleWatch"",""http.method"":""GET"",""http.host"":""inventory-<mydomain>.uscom-central-1.oraclecloud.com""},""logs"":[{""timestamp"":1516776180246,""event"":""sr""},{""timestamp"":1516776180258,""event"":""ss""}],""durationMicros"":12550}]}
Summary
Well, that‚Äôs all there is to this blog post which was the second (and final) installment in the distributed monitoring series..
A quick recap never harms!"
zipkin,"we covered the drawbacks of the default monitoring setup and introduced Kafka and Cassandra as core infrastructure components to overcome some of the issues
went through the details of the architecture
provisioned the infrastructure on Oracle Cloud as ready-to-use managed services ‚Äî Data Hub Cloud and Event Hub Cloud
built and deployed our revamped apps to Oracle Application Container Cloud
and finally, tested everything end-to-end !"
zipkin,"Don‚Äôt forget to‚Ä¶
go through the Oracle Data Hub Cloud documentation for a deep dive
Oracle Data Hub Cloud Service ‚Äî Get Started
Documentation that helps administrators, developers, and users get started using Oracle Event Hub Cloud Service."
zipkin,"docs.oracle.com

check out the tutorials for Oracle Application Container Cloud ‚Äî there is something for every runtime!"
zipkin,"Oracle Application Container Cloud Service ‚Äî Create Your First Applications
Tutorials for Oracle Application Container Cloud Service."
zipkin,Learn to create your first applications.
zipkin,"docs.oracle.com

other blogs on Application Container Cloud
Latest stories and news about App Container Cloud ‚Äî Medium
Read the latest writing about App Container Cloud."
zipkin,"Every day, thousands of voices read, write, and share important‚Ä¶
medium.com

Cheers!"
zipkin,"Unless you were living under a rock, you probably already know that the Microservices architectural pattern has exploded in popularity over the last few years."
zipkin,This has been driven by the increasing ease of deploying services in the cloud and the desire to have small teams focused on building simple well factored services that applications are then built on.
zipkin,"In general this has worked well, but it has also lead to additional complexity in other areas:
Increased number of API surfaces to secure."
zipkin,"With smaller services, and many dependencies between services, there are necessarily many more endpoints to secure."
zipkin,"Compounding that is a move to a ‚Äútrust nothing‚Äù security model, including the internal network, and therefore devops teams need to put in place a mechanism for validating that that your microservice that my microservice is talking to is really your microservice."
zipkin,More services to monitor.
zipkin,"Montoring was already necessity before, but the Microservices architectural model adds another layer to this."
zipkin,"When there is a performance issue with a service, for example, you now can‚Äôt necessarily say it is an issue with that service or a backing store it uses."
zipkin,"Instead, it could be caused by any of the dependent services it uses as well."
zipkin,"Simple monitoring around the latency of services is not enough, you need measurements around each of the dependencies that service uses as well."
zipkin,Traffic Management.
zipkin,"The number of interconnections between services and constantly evolving services over a number of teams, mean we need to manage traffic between them in a number of ways: shifting traffic between different versions of an application, rate limiting, circuit breaking, and beyond to prevent cascading failures of dependent services."
zipkin,Istio is a project sponsored by the CNCF that aims to solve a number of these problems.
zipkin,This blog post will walk you through installing Istio and demonstrate how it works against a sample application.
zipkin,"I‚Äôm going to use Azure for this walkthrough, but all that is required to walk through this tutorial is a Kubernetes 1.9 cluster with RBAC enabled and an MutatingAdmissionWebhook Admission Controller."
zipkin,"If you are using another cloud, create your cluster, and skip the next section."
zipkin,"Azure Kubernetes Cluster Creation Notes
With the current defaults in ACS Engine, it‚Äôs necessary to override the default Admission Controllers to include MutatingAdmissionWebhook so that we can inject sidecar containers later automatically for our services."
zipkin,"You can do that by specifing this in your ACS Engine cluster.json (which also happens to be what the Kubernetes project recommends for all deployments of 1.9):
{
""apiVersion"": ""vlabs"",
""properties"": {
    ""orchestratorProfile"": {
        ""orchestratorType"": ""Kubernetes"",
        ""orchestratorRelease"": ""1.9"",
        ""kubernetesConfig"": {
            ""apiServerConfig"": {
                ""--admission-control"":        ""NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota""
            }
        }
    },
    ....
}
Installing Istio into your Kubernetes Cluster
This walkthrough assumes you have a Kubernetes 1.9 cluster with RBAC configured."
zipkin,"To get started, grab the latest release of Istio and add its CLI tool istioctl to your path by following the first four steps under ‚ÄúInstallation Steps‚Äù on the project website."
zipkin,"As of this writing, the helm chart does not work correctly, so do not take that path."
zipkin,"Instead with the project unpacked, apply it with kubectl from the root of the project:
$ kubectl apply -f install/kubernetes/istio-auth.yaml
You should see the core components of istio spin up and end up with a set of pods that look like this:
$ kubectl get pods -n istio-system
NAME                                      READY     STATUS    RESTARTS   AGE
istio-ca-797dfb66c5-5dc6f                 1/1       Running   0          2h
istio-ingress-84f75844c4-g666n            1/1       Running   0          2h
istio-mixer-9bf85fc68-l54vm               3/3       Running   0          2h
istio-pilot-575679c565-rkm82              2/2       Running   0          2h
Installing Automatic Sidecar Injection
One of the core functions of Istio is to proxy all of the traffic between your services."
zipkin,"This enables it to do very useful things like mutual authentication between the endpoints, do traffic splitting between now/next versions of your services, and measure the latency of requests."
zipkin,Istio accomplishes this by creating a sidecar container in each of your service pods that proxies this traffic by intercepting pod creation and doing this injection.
zipkin,"Creating this automatic injection is documented on the Istio project page, but for conciseness, here is the linear set of commands you need to execute from your Istio root to configure this."
zipkin,"First create a set of certificates for the Kubernetes CA:
$ ./install/kubernetes/webhook-create-signed-cert.sh \     
  --service istio-sidecar-injector \     
  --namespace istio-system \     
  --secret sidecar-injector-certs
Next, install the sidecar injection configmap:
$ kubectl apply -f install/kubernetes/istio-sidecar-injector-configmap-release.yaml
The, build the caBundle YAML that the Kubernetes api-server uses to invoke the webhook:
$ cat install/kubernetes/istio-sidecar-injector.yaml | \
     ./install/kubernetes/webhook-patch-ca-bundle.sh > \
     install/kubernetes/istio-sidecar-injector-with-ca-bundle.yaml
Finally, Install the sidecar injector webhook."
zipkin,"$ kubectl apply -f install/kubernetes/istio-sidecar-injector-with-ca-bundle.yaml
The sidecar injector webhook should now be running:
$ kubectl -n istio-system get deployment -listio=sidecar-injector
NAME                     DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE istio-sidecar-injector   1         1         1            1           1d
Install Bundled Tools
By default, Istio doesn‚Äôt inject its sidecar proxies into your application pods."
zipkin,"Instead, you need to direct it to inject the sidecars for a particular namespace."
zipkin,"Let‚Äôs do that now for the default namespace:
$ kubectl label namespace default istio-injection=enabled
The Istio distribution includes a sample application called BookInfo that we can use to see this injection, and other functions of Istio, in action."
zipkin,"Read about the architecture of this application in the link above and then install it with:
$ kubectl apply -f samples/bookinfo/kube/bookinfo.yaml
Once the pods have created, you‚Äôll notice that instead of the usual 1/1 that they are 2/2:
$ kubectl get pods
NAME                              READY     STATUS    RESTARTS   AGE
details-v1-64b86cd49-8tn9p        2/2       Running   0          15s
productpage-v1-84f77f8747-6dh6l   2/2       Running   0          13s
ratings-v1-5f46655b57-bpwkb       2/2       Running   0          14s
reviews-v1-ff6bdb95b-m8f6f        2/2       Running   0          14s
reviews-v2-5799558d68-8t7h8       2/2       Running   0          14s
reviews-v3-58ff7d665b-2hfx2       2/2       Running   0          13s
This indicates that Istio has injected a sidecar container into each of them that will do the proxying of traffic that we mentioned earlier."
zipkin,"Do a describe on one of the pods (your pod id will differ) to see this under the covers:
$ kubectl describe pod reviews-v1-ff6bdb95b-m8f6f
You‚Äôll note that the output includes two containers, the ‚Äòreviews‚Äô container and an ‚Äòistio-proxy‚Äô container."
zipkin,"You can see this application in action by finding up Istio‚Äôs public ip of its ingress controller:
$ kubectl get services -n istio-system | grep istio-ingress
istio-ingress            LoadBalancer   10.0.58.79     13.68.135.154   80:32552/TCP,443:31324/TCP                                         3h
Navigating to http://13.68.135.154/productpage (your ip will vary) and refreshing, you‚Äôll note that there are three versions of the application deployed (no stars, red stars, and black stars) that are being load balanced across."
zipkin,"Istio‚Äôs Visualization Tools
Istio also bundles a number of tools that are incredibly useful for managing, debugging, and visualizing our service mesh."
zipkin,"The first of these are Graphana and Prometheus, which are preconfigured with Istio dashboards."
zipkin,"In version 0.5.1, there is a bug with namespacing for Prometheus in the yaml definition."
zipkin,Edit install/kubernetes/addons/prometheus.yaml and search for ‚ÄúServiceAccount‚Äù.
zipkin,"Ensure that its definition starts like this and add the namespace if it is missing (this is fixed in master and it could be resolved in the latest release by the time you are reading this so just ignore this if it looks like the below):
apiVersion: v1
kind: ServiceAccount
metadata:
name: prometheus
namespace: istio-system
With that, you can install all of these tools with:
$ kubectl apply -f install/kubernetes/addons/prometheus.yaml
$ kubectl apply -f install/kubernetes/addons/grafana.yaml
$ kubectl apply -f install/kubernetes/addons/servicegraph.yaml
$ kubectl apply -f install/kubernetes/addons/zipkin.yaml
And once spun up, you should have all of these pods running in your cluster:
$ kubectl get pods -n istio-system
NAME                                      READY     STATUS    RESTARTS   AGE
grafana-648859cf87-gpjmw                  1/1       Running   0          2h
istio-ca-797dfb66c5-5dc6f                 1/1       Running   0          3h
istio-ingress-84f75844c4-g666n            1/1       Running   0          3h
istio-mixer-9bf85fc68-l54vm               3/3       Running   0          3h
istio-pilot-575679c565-rkm82              2/2       Running   0          3h
istio-sidecar-injector-7b559f7f6f-btzr9   1/1       Running   0          2h
prometheus-cf8456855-f2q2r                1/1       Running   0          2h
servicegraph-7ff6c499cc-wm7r2             1/1       Running   0          2h
zipkin-7988c559b7-hsw7x                   1/1       Running   0          2h
We can then connect to the Grafana frontend by port-foward‚Äôing its ports:
$ export GRAFANAPOD=$(kubectl get pods -n istio-system | grep ""grafana"" | awk '{print $1}') 
$ kubectl port-forward $GRAFANAPOD -n istio-system 3000:3000
And navigating in our browser to http://localhost:3000
Grafana is preconfigured with a number of dashboards, like this one to monitor Mixer, one of Istio‚Äôs components:

If you recently hit the book info application, you should see your requests in the Incoming Requests graph."
zipkin,"You can also visualize how your application‚Äôs services are communicating with each other with Service Graph:
$ export SERVICEGRAPHPOD=$(kubectl get pods -n istio-system | grep ""servicegraph"" | awk '{print $1}')
$ kubectl port-forward $SERVICEGRAPHPOD -n istio-system 8088:8088
Navigating to http://localhost:8088/dotviz after hitting a number of the pages of Book Info to visualize all of the interconnections between the services:

You can also see latency breakdown graphs using Zipkin:
$ export ZIPKINPOD=$(kubectl get pods -n istio-system | grep ""zipkin"" | awk '{print $1}')
$ kubectl port-forward $ZIPKINPOD -n istio-system 9411:9411
Navigating to http://localhost:9411, you can drill into a productpage request for example and see which service components are responsible for the overall latency:

More details about these tools is available in the Istio project."
zipkin,"Istio Traffic Management Tools
The heart of Istio‚Äôs tooling however is in its traffic management tooling."
zipkin,"The documentation does a great job of describing how to use these tools, so I‚Äôll just leave you with a link to a bunch of walkthroughs on how you can use this tooling to manage traffic between the services in your cluster to solve problems like circuit breaking, request routing, ingress, and fault injection."
zipkin,I hope you found this walkthrough helpful.
zipkin,"If you have feedback or like content like this, feel free to reach out or follow me on Twitter."
zipkin,Hey there!
zipkin,Today we‚Äôre going to talk about distributed tracing.
zipkin,"This post won‚Äôt give you much theory about the topic, instead it‚Äôs full of practice."
zipkin,"I‚Äôm going to take distributed ‚Äúpolyglot‚Äù-ish application, pick appropriate tracing tool and then marry the two."
zipkin,But what makes distributed tracing useful?
zipkin,"In short: it allows to get better observability of the distributed system (one of the 3 pillars of observability) and helps to setup accurate SLOs for business operations, including async ones."
zipkin,Details will follow.
zipkin,"Meet our lab rat
The web app to be instrumented is a toy project which sole purpose is to serve as a playground to try tools that help to build and control distributed apps: Kubernetes, Docker, distributed tracing, etc."
zipkin,"It‚Äôs made of several components written in Javascript (both web UI and one of backend services), Go, Java and Python."
zipkin,"Here‚Äôs a simple diagram of interaction between the components:

Please check the Github repo out if you‚Äôd like to get more details."
zipkin,"Let‚Äôs select instrumentation tool
In order to instrument the app properly, we need a proper tool."
zipkin,There are several distributed tracing tools in the wild.
zipkin,"I narrowed the scope and put these on my plate to choose from:
Zipkin
Jaeger
Opentracing
Opencensus
Acceptance criteria:
The tool should define a standard way of using tracing across different languages as well as standard wire protocol."
zipkin,"The tool should support the languages and frameworks used in the app: Javascript (both browser and server-side), Java, Go, Python3."
zipkin,"Visualisation of the traces should be there, for free, ideally installed in-premises."
zipkin,"Zipkin
Zipkin is a mature battle-tested project, its design is based on the Google Dapper paper."
zipkin,"If what I heard on LISA17 conference was true, then Zipkin is the most popular distributed tracing system in Canada (according to a survey)."
zipkin,The project provides tons of ways to integrate with the app.
zipkin,"Lots of languages are supported, many integrations with popular frameworks make the process seamless."
zipkin,"In case of any questions, vast community as well as numerous examples are there to help."
zipkin,Zipkin matches all criteria listed above.
zipkin,"Although, I got confused a couple of times by Zipkin libraries and data model."
zipkin,"For instance, some libraries use term traceId, others call the same thing a span."
zipkin,My personal opinion that Opentracing defines simpler interface.
zipkin,Verdict: maybe.
zipkin,"Jaeger
Jaeger is similar to Zipkin."
zipkin,"Built with different technology stack, it serves the same purpose."
zipkin,"However, Jaeger was thrown away because of:
lack of support of client-side Javascript
lack of support of Python3
Also, despite more fancy-looking UI, I found its search functionality a little bit annoying: you have to specify the name of the service, you cannot just search for all the traces that match given set of criteria."
zipkin,"With Zipkin it‚Äôs possible
Verdict: clearly no."
zipkin,"Opentracing
Well, Opentracing is not a real ‚Äútool‚Äù, but rather a standard, explaining how to make your code collect traces."
zipkin,"But how to manage the traces, how to transport them to the collectors and how to store collected data ‚Äî this is responsibility of certain implementations, for instance:
again Jaeger, which has been already rejected for this exercise."
zipkin,Zipkin.
zipkin,"There is a bridge between Zipkin and Opentracing standards, implemented for several languages."
zipkin,"Perhaps, it could be possible to integrate it in such way into Python and browser Javascript, but it‚Äôs definitely an overkill for the exercise."
zipkin,"There are other tracers listed in a corresponding page of Opentracing doc, however they are proprietary and could not be easily installed on my laptop."
zipkin,Verdict: still going with Zipkin without Opentracing.
zipkin,"Despite Opentracing provides simpler interface, I didn‚Äôt want to spend extra time for integrating a bridge to Zipkin."
zipkin,"Opencensus
Another attempt to standardise collection of traces (and not only traces), including wire protocol!"
zipkin,"Very interesting and promising concept, although almost everything is in alpha stage and being actively developed at the moment."
zipkin,I planned to collect tracing data with Opencensus and then forward them to Zipkin or Jaeger to store and visualise.
zipkin,"However, the project is being developer so quickly, so I might have ended up with outdated set of tools by the end of the exercise."
zipkin,Verdict: too immature at the moment.
zipkin,"Conclusion
After considering several options, I decided to go with Zipkin, because it was the simplest way at the moment."
zipkin,"It worth to investigate other options, they look pretty interesting for the long run (especially Opencensus that standardises collection of all 3 observability aspects: traces, logs and metrics)."
zipkin,"If you‚Äôre planning to implement distributed tracing in your organization, follow the advice that I heard many times from different people: start fast, then iterate."
zipkin,"Meaning, start with the simplest solution that requires minimal time for integration (e.g."
zipkin,"Zipkin), implement it within your team and, perhaps, 2‚Äì4 other teams, who agree to participate in the experiment."
zipkin,At this point you need to build enough expertise about distributed tracing in general and collect as many requirements for the tracing system as needed.
zipkin,"When it‚Äôs done, you‚Äôll be able to rethink your choice and either continue with the tool you picked or change to something else."
zipkin,"Injecting Zipkin into the app
There is nothing difficult with that, thanks to extensive Zipkin documentation."
zipkin,I‚Äôm going to give a brief explanation for each framework I used.
zipkin,"VueJS, Javascript (for web UI)
For the first time, things were a little bit complicated, but with the interceptor for vue-resource it became like a breeze."
zipkin,Please refer to the README to get step by step integration guide.
zipkin,"SpringBoot, Java (for users-api)
Extremely easy to integrate, just follow the manual."
zipkin,"echo, Go (for auth-api)
Actually, Zipkin provides a standard middleware and HTTP client that operate tracing data."
zipkin,"The only thing I needed to do is to convert Zipkin middleware to echo-specific middleware with a couple of simple steps:
//...initialise tracer...
e := echo.New()
tracingMiddleware := zipkinhttp.NewServerMiddleware(tracer)
e.Use(echo.WrapMiddleware(tracingMiddleware))
express, Javascript for nodeJS (for todos-api )."
zipkin,"HTTP part was very easy to integrate, because express framework is covered by corresponding instrumentation library."
zipkin,"However, if you take another look at the architecture diagram, you‚Äôll notice that todos-api sends messages to log-message-processor over Redis asynchronously."
zipkin,"I don‚Äôt want to lose this operation from the whole picture, that‚Äôs why a little bit of manual instrumentation is needed:
First, notice that there is a package that provides a CLSContext."
zipkin,It helps to simplify access to current span context in the code.
zipkin,"Basically, every time todos-api receives an HTTP request from frontend, it creates a span context and stores it in continuation local storage."
zipkin,Then later I can extract span context from the storage.
zipkin,What for?
zipkin,For serialising it into JSON object!
zipkin,Then it‚Äôs easy to include it into the message and send the message to the queue.
zipkin,"All necessary information, including traceID and spanId will be there, so log-message-processor can pick them up."
zipkin,"Here‚Äôs a method of TodoController that sends messages to Redis:
_logOperation (opName, username, todoId) {
  this._tracer.scoped(() => {
    var tracer = this._tracer;
    
    // get current span context from continuation local storage
    const traceId = this._tracer.id;
    // send the message to the queue
    this._redisClient.publish(this._logChannel, JSON.stringify({
      // include span context into the message
      zipkinSpan: traceId,
      
      // include actual business data into the message
      opName: opName,
      username: username,
      todoId: todoId,
    }))
  })
}
Python3 (for log-message-processor)
There is a third-party integration library from Yelp."
zipkin,"IMHO, it looks cumbersome, because the example suggests providing all Zipkin-related configuration parameters every time I need to start a new span."
zipkin,"I would rather create a tracer when my application starts, then pass it around where needed and then create new spans with it."
zipkin,Similar to what another instrumentation library for Opentracing does.
zipkin,"Anyways, for my little exercise py_zipkin is OK, but for bigger projects you may wrap it with some bells and whistles that hide cumbersome parts."
zipkin,"In my case ‚Äúintegration‚Äù looks like this:
zipkin_url = os.environ['ZIPKIN_URL'] if 'ZIPKIN_URL' in os.environ else 'http://127.0.0.1:9411/api/v1/spans'
# transport function to be used by the tracer as transport_handler
# see usage below
def http_transport(encoded_span):
  requests.post(
    zipkin_url,
    data=encoded_span,
    headers={'Content-Type': 'application/x-thrift'}
  )
message = receive_message_from_redis()
span_data = message['zipkinSpan']
with zipkin_span(
    service_name='log-message-processor',
    zipkin_attrs=ZipkinAttrs(
    trace_id=span_data['_traceId']['value'],
    span_id=generate_random_64bit_string(),
    parent_span_id=span_data['_parentId']['value'],
    is_sampled=span_data['_sampled']['value'],
    flags=None
  ),
  span_name='save_log',
  transport_handler=http_transport,
  sample_rate=100
):
  log_message(message)
As discussed earlier, span data comes with a message that log-message-processor receives from the queue."
zipkin,Distributed tracing my app!
zipkin,"All right, let‚Äôs take a look at the results of our little experiment."
zipkin,"The idea was to get better observability of the system, and here what I got after poking around for some time:

What I see here?"
zipkin,"All my activity: when (and how fast) I logged in, what kind of API calls were incurred by my actions."
zipkin,Scale this to a couple of thousands of users and you will feel the power in your hands :).
zipkin,"Let‚Äôs take a closer look at a trace of some operation:

First comes the span with name todos-api, it represents in fact interaction between frontend and todos-api:

Then comes ‚Äúwhitespace‚Äù between todos-api and log-message-processor spans: how long the message spent in Redis queue."
zipkin,"Finally, log-message-processor took ridiculously long for some reason."
zipkin,"Fortunately, it‚Äôs async operation, so end user doesn‚Äôt feel it."
zipkin,"Looks pretty helpful, isn‚Äôt it?"
zipkin,"To get even more awesomeness from distributed tracing, let‚Äôs imagine what questions can it help to answer."
zipkin,1.
zipkin,Which services my distributed app consists of?
zipkin,That‚Äôs right.
zipkin,"When you have enough tracing data collected, you can render it into huge dependency diagram displaying all your services and interaction between them."
zipkin,Zipkin gives it to you for free.
zipkin,Some other tools (e.g.
zipkin,commercial Instana) may even display such a diagram almost in real time.
zipkin,"Dependency diagram by Zipkin
2."
zipkin,Is there any violation in the architecture?
zipkin,"For instance, this particular toy-app requires log-message-processor to record no more than one log entry for every operation."
zipkin,"Duplicated log entries for the same operation can be confusing, not to mention that they waste storage space."
zipkin,Current setup makes Redis broadcast messages to all listener.
zipkin,"Thus, if I launch another log-message-processor, there will be duplicates."
zipkin,"Let‚Äôs take a look at it:

Oops!"
zipkin,2 log writes for the same POST action!
zipkin,Time to trigger an alarm and investigate what‚Äôs wrong :).
zipkin,3.
zipkin,Was there an action that took too long?
zipkin,"I‚Äôm not going to define ‚Äútoo long‚Äù here, because for different projects it means different things and actually gets us to SLA and SLO topics which should be discussed in another article."
zipkin,"Let‚Äôs just take a look at simple example of CREATE action:

It took ~2000ms in total and the majority of time was spent by log-message-processor."
zipkin,"That tells us that logging operation should be investigated and, perhaps, improved."
zipkin,"Moreover, if logging operation affects our dear customer, we could define an SLO like ‚ÄúNew log messages must become available within 1100ms after the user initiated CREATE operation‚Äù and monitor it with distributed tracing."
zipkin,Setting up an alert that sets off when the SLO is breached would be a good idea.
zipkin,"Unfortunately, Zipkin does not support alerting out of the box."
zipkin,4.
zipkin,Was there any failed action?
zipkin,This is an addition to the previous chapter.
zipkin,"If we can monitor latency of the operation, then we should be able to monitor errors, right?"
zipkin,Absolutely right!
zipkin,Let‚Äôs simulate a failure by switching off todos-api.
zipkin,Oops!
zipkin,A broken trace!
zipkin,"Let‚Äôs take a look at the details:

That‚Äôs pretty handy, isn‚Äôt it?"
zipkin,It shows that something bad happened and where it broke.
zipkin,"Looks enough to start fixing :)
Conclusion
Distributed tracing is extremely helpful tool."
zipkin,"If you‚Äôre just collecting logs and metrics, then you‚Äôre enjoying 2 of 3 observability aspects."
zipkin,Want to know more about your distributed app?
zipkin,Add some tracing!
zipkin,Distributed tracing allows you to control SLOs that are difficult to monitor with metrics and logs.
zipkin,"For instance, when a business operation spans several services and involves async processing (‚ÄúRecord created by user must be available to read back in 2000ms‚Äù), you can collect traces, monitor their duration and then reason on these data."
zipkin,Distributed tracing also helps to build service dependency diagram!
zipkin,How many times you struggled to remember which services are there and how do they communicate?
zipkin,"Most probably there are hand-drawn dependency diagrams, likely poorly maintained and missing some components."
zipkin,Tracing provides you the whole picture automatically.
zipkin,"Don‚Äôt spend too much time in front, trying to pick a ‚Äúproper‚Äù tool for tracing once and for all."
zipkin,"Start with the simplest solution, build expertise in distributed tracing domain, clarify requirements and only after that ‚Äî rethink your choice."
zipkin,"For instance, you may find that your whole company produces tons of data, so it‚Äôs easier to buy a commercial product than support something in house (like Zipkin or Jaeger)."
zipkin,"For a master table-of-contents for blog posts on microservice topics, please refer ‚Äî https://medium.com/oracledevs/bunch-of-microservices-related-blogs-57b5f1f062e5
Ok, so you have a cloud native/microservices-style architecture wherein you have multiple services which collaborate with each other to achieve something‚Ä¶ great!"
zipkin,"Debugging and troubleshooting can be tough
multiple (micro) services ‚Äî each doing their own thing
multiple instances per service ‚Äî after all, our services are stateless and horizontally scalable !"
zipkin,"sometimes you might not even have access to the underlying machine/VM/node ‚Äî just a vendor/product specific way to get access to the application logs
etc‚Ä¶."
zipkin,"There is nothing wrong with the above constraints ‚Äî in fact, they are inevitable with distributed apps in general (microservices or not), especially when they are running in managed PaaS (platform-as-a-service) environment
So what can we do to make things easier and manageable when its comes to in-depth app level visibility?"
zipkin,"There is no silver bullet as such, but Distributed Tracing is a tool which when used properly can help us
This blog demonstrates Spring Boot applications leveraging Spring Cloud Sleuth to keep track of app level transactions and transport the trace information to a remote Zipkin server
Although the focus is on Java based apps, the concept applies to any system/service which can produce tracing data in OpenZipkin format
Oracle Application Container Cloud serves as the runtime for
the Zipkin server and‚Ä¶
‚Ä¶ and the Spring Boot apps ‚Äî inventory and product (we will continue to use the same set of apps as we did in one of the previous blogs with minor modifications to demonstrate the concept)
Application Container Cloud | ACC | Oracle Cloud
Java Standard Edition and Node.js in the Cloud."
zipkin,"cloud.oracle.com

Architecture
the sample app is available on Github
abhirockzz/accs-spring-boot-zipkin-distributed-tracing
Contribute to accs-spring-boot-zipkin-distributed-tracing development by creating an account on GitHub."
zipkin,"github.com

The below diagram presents a high level overview

High level architecture
Dead simple ‚Äî thanks to Spring Cloud Sleuth (Zipkin module), the individual Spring Boot apps send the transaction data (traces) to Zipkin which can then be viewed using a dashboard provide by Zipkin itself
Here is a summary of the components/services
Zipkin
Zipkin server is a yet another Spring Boot app and it runs in an embedded Tomcat container (in this case)."
zipkin,"There is hardly anything required here except
using the zipkin-server and zipkin-autoconfigure-ui (for the visualization dashboard) dependencies and then ‚Ä¶
‚Ä¶ using @EnableZipkinServer on the Spring Boot bootstrap class does the trick!"
zipkin,"Inventory & Product services
For details of the inventory and product services, please refer to the Microservices service discovery on Oracle Cloud with Spring Cloud and Zookeeper blog post
Microservices service discovery on Oracle Cloud with Spring Cloud and Zookeeper
medium.com

The important things to know are
the apps use spring-cloud-starter-sleuth and spring-cloud-sleuth-zipkin modules (in pom.xml)
the application.properties point to the Zipkin server using spring.zipkin.baseUrl attribute
Zookeeper based service discovery has been excluded for the sake of simplicity and to focus on a single topic i.e."
zipkin,"distributed tracing
and it used RestTemplate instead of the FeignClient
Build & deployment
Start by fetching the project from Github ‚Äî git clone https://github.com/abhirockzz/accs-spring-boot-zipkin-distributed-tracing.git
Build
Zipkin server
cd zipkinserver
mvn clean install
The build process will create zipkin-dist.zip in the target directory
Inventory service
cd inventory
mvn clean install
The build process will create inventory-dist.zip in the target directory
Product service
cd product
mvn clean install
The build process will create product-dist.zip in the target directory
Deployment a.k.a push to cloud
With Oracle Application Container Cloud, you have multiple options in terms of deploying your applications."
zipkin,"This blog will leverage PSM CLI which is a powerful command line interface for managing Oracle Cloud services
other deployment options include REST API, Oracle Developer Cloud and of course the console/UI
You can download and setup PSM CLI on your machine (using psm setup) ‚Äî details here
Start by deploying Zipkin server application first since both our microservices will depend on it
Zipkin ‚Äî psm accs push -n zipkin -r java -s hourly -m manifest.json -d deployment.json -p target/zipkin-dist.zip
Once you have Zipkin up and running, note down it‚Äôs URL (highlighted below) from the Applications page in Oracle Application Container Cloud

Zipkin server deployed
Now, update the deployment.json for the inventory app to enter the Zipkin server info
{
 ""memory"": ""2G"",
 ""instances"": 1,
 ""environment"":{
 ""ZIPKIN"":""<ZIPKIN_URL>""
 }
}
Inventory service ‚Äî psm accs push -n inventory -r java -s hourly -m manifest.json -d deployment.json -p target/inventory-dist.zip
Note down the URL ‚Äî since it‚Äôll be used in the product service

inventory service deployed
Update the deployment.json for product app to include inventory and zipkin co-ordinates
{
 ""memory"": ""2G"",
 ""instances"": 1,
 environment"":{
 ""INVENTORY_SERVICE"":""<INVENTORY_APP_URL>"",
 ""ZIPKIN"":""<ZIPKIN_URL>""
 }
}
Product service ‚Äî psm accs push -n product -r java -s hourly -m manifest.json -d deployment.json -p target/product-dist.zip

Spring Boot (product) service deployed
Everything is ready for us to see things in action‚Ä¶
Test drive
Access the Zipkin server ‚Äî note the app URL e.g."
zipkin,"https://zipkin-<mydomain>.apaas.us2.oraclecloud.com

Zipkin on Oracle Application Container Cloud
Happy path
Start off by invoking the Product service endpoint a couple of times
e.g."
zipkin,"curl -X https://product-ocloud100.apaas.us2.oraclecloud.com/product/iPhoneX and curl -X https://product-ocloud100.apaas.us2.oraclecloud.com/product/AppleWatch
the product service internally invokes the inventory service to return a JSON response
{""name"":""iPhoneX"",""description"":""Description for iPhoneX"",""stock"":{""inventory"":8,""node"":""7e8127f0-c1a6-41db-b893-b786b773590b_67000ba4-ee1f-405c-9249-37ecd56b705d""}}
Let‚Äôs hop over to the Zipkin dashboard and query for latest traces (by clicking on Find Traces)

Query transactions in Zipkin
Two separate transactions (highlighted) were generated corresponding to our invocations
Noteworthy points
each transaction is broken into 2 spans
each span is produced by the service hop i.e."
zipkin,"product service calling inventory service
you can also see exactly how much time did the inventory service contribute in terms of the total time taken i.e."
zipkin,"in the first transaction inventory service took 7137 ms (7.137 secs) out of the 8.06 secs spent on the invocation
filtering by the service will give you the %age time spent
Filter just by the inventory service and then query Zipkin, this is what you‚Äôll see ‚Äî about 88% of the time was spent in the inventory service alone (in the first transaction)

Filter by application in Zipkin
Let‚Äôs look deeper into a specific transaction by clicking on the first one ‚Äî this will now give you a detailed split up and the sequence of invocation is obvious

Spawned spans
Clicking on the product span will give more details like invocation timelines and HTTP request information

Parent transaction (product service)
Notice the parent transaction ID in the below screenshot

child transaction (inventory service)
So far so good ‚Äî let‚Äôs stop the inventory service, see what happens and turn to Zipkin for help!"
zipkin,"Failure case
To stop (using the CLI) ‚Äî psm accs stop -n inventory
Invoke the product service again (couple of times) ‚Äî curl -X https://product-ocloud100.apaas.us2.oraclecloud.com/product/iPhoneX
You should see a HTTP 500 response
{
 ‚Äútimestamp‚Äù: 1517114482192,
 ‚Äústatus‚Äù: 500,
 ‚Äúerror‚Äù: ‚ÄúInternal Server Error‚Äù,
 ‚Äúexception‚Äù: ‚Äúorg.springframework.web.client.HttpServerErrorException‚Äù,
 ‚Äúmessage‚Äù: ‚Äú504 Gateway Time-out‚Äù,
 ‚Äúpath‚Äù: ‚Äú/product/MotoZ‚Äù
}

Failed transactions
I like red, but not in this case since it denotes danger ‚Äî looking further into the a specific transaction will reveal more

explicit error message
Additional considerations
these are items which haven‚Äôt been covered in this post but do deserved to be mentioned
Writing custom spans
tracing other systems (e.g."
zipkin,"DB)
Alright, that‚Äôs all for this blog post !"
zipkin,"Don‚Äôt forget to‚Ä¶
check out the tutorials for Oracle Application Container Cloud ‚Äî there is something for every runtime!"
zipkin,"Oracle Application Container Cloud Service ‚Äî Create Your First Applications
Tutorials for Oracle Application Container Cloud Service."
zipkin,Learn to create your first applications.
zipkin,"docs.oracle.com

other blogs on Application Container Cloud
Latest stories and news about App Container Cloud ‚Äî Medium
Read the latest writing about App Container Cloud."
zipkin,"Every day, thousands of voices read, write, and share important‚Ä¶
medium.com

Cheers!"
zipkin,This article briefly introduces how to use Zipkin to perform service analysis on Spring Cloud applications.
zipkin,"In practical application, Zipkin can be used in combination with stress testing tools to analyze the availability and performance of systems under high stress."
zipkin,"Imagine the following scenario: if your microservices grow gradually and the dependencies between services become increasingly complicated, how can you analyze the call relations and mutual influences between them?"
zipkin,"Service tracing analysis
An application comprised of microservices divides the problem domain through services and completes the operation through REST API to connect services."
zipkin,An entry service call may require the coordination of multiple background services.
zipkin,Any call timeout or error on the link may lead to the failure of the front-end requests.
zipkin,"The call chain of the service will become longer and longer, and form a tree-shaped call chain."
zipkin,"Although it doesn‚Äôt match the source, I think this should be ‚Äòservice call‚Äô‚Ä¶ a service call may require the coordination of multiple background services."
zipkin,"With the increasing services, the analysis on the call chain will become more and more detail-oriented."
zipkin,"Suppose you are in charge of the system below, and every small point in it is a microservice."
zipkin,The call relations between the microservices constitute the complicated network.
zipkin,"In view of the full-chain tracing issues for service-oriented applications, Google published the Dapper paper, introducing how they conducted service tracing analysis."
zipkin,The basic idea is to add an ID to the service calling requests and responses to indicate the relationships of upstream and downstream requests.
zipkin,"With this information, the service calling chains and dependencies between services can be analyzed in a visualized way."
zipkin,"Spring Cloud Sleuth and Zipkin
The open-source implementation corresponding to Dapper is Zipkin."
zipkin,"It supports multiple languages including JavaScript, Python, Java, Scala, Ruby, C# and Go."
zipkin,"Among them, Java supports different databases."
zipkin,"In this example, we prepare to develop two Spring Cloud-based applications and use Spring Cloud Sleuth to integrate with Zipkin."
zipkin,"Spring Cloud Sleuth is a kind of encapsulation of Zipkin and automates span and trace information generation, access of HTTP requests and sending collection information to the Zipkin Server."
zipkin,This is a concept map of Spring Cloud Sleuth.
zipkin,"Service REST calls
There are two demo services in this example: tracedemo, acting as the frontend service to receive requests from users; and tracebackend, acting as the backend service."
zipkin,The tracedemo calls the backend service through the HTTP protocol.
zipkin,"@RequestMapping(""/"")
public String callHome(){
    LOG.log(Level.INFO, ""calling trace demo backend"");
    return restTemplate.getForObject(""http://backend:8090"", String.class);
}
HTTP request calls using RestTemplate
The tracedemo application calls the backend tracebackend service through RestTemplate."
zipkin,Attention: the tracedemo address is specified in the URL as backend.
zipkin,"@RequestMapping(""/"")
public String callHome(){
    LOG.log(Level.INFO, ""calling trace demo backend"");
    return restTemplate.getForObject(""http://backend:8090"", String.class);
}
The backend service responds to the HTTP request, and the output log shows that it returns the classic ‚Äúhello world‚Äù."
zipkin,"@RequestMapping(""/"")
public String home(){
    LOG.log(Level.INFO, ""trace demo backend is being called"");
    return ""Hello World."
zipkin,""";
}
Introduce Sleuth and Zipkin dependent packages
We can see that this is a typical access from two Spring applications through RestTemplate."
zipkin,So which one of them injects the tracing information in the HTTP request and sends the information to Zipkin Server?
zipkin,The answer lies in the JAR packages loaded by the two applications.
zipkin,"In this example, Gradle is used to build applications."
zipkin,"JAR packages related to Sleuth and Zipkin are loaded in build.gradle:
dependencies {
    compile('org.springframework.cloud:spring-cloud-starter-sleuth')
    compile('org.springframework.cloud:spring-cloud-sleuth-zipkin')
    testCompile('org.springframework.boot:spring-boot-starter-test')
}
After the Spring application detects Sleuth and Zipkin in Java dependent packages, it will automatically inject tracing information to the HTTP request during RestTemplate calls, and send the information to the Zipkin Server."
zipkin,So where can we specify the address of the Zipkin Server?
zipkin,"The answer is: in application.properties:
spring.zipkin.base-url=http://zipkin-server:9411
Note: The Zipkin Server address is: zipkin-server."
zipkin,"Build a Docker image
Create two identical Dockerfiles for these two services to generate the Docker image:
FROM java:8-jre-alpine
RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/' /etc/apk/repositories
VOLUME /tmp
ADD build/libs/*.jar app.jar
RUN sh -c 'touch /app.jar'
ENTRYPOINT [""java"",""-Djava.security.egd=file:/dev/./urandom"",""-jar"",""/app.jar""]
The procedure for building a Docker image is as follows:
cd tracedemo
./gradlew build
docker build -t zipkin-demo-frontend ."
zipkin,"cd ../tracebackend
./gradlew build
docker build -t zipkin-demo-backend ."
zipkin,"After the image is ready, upload the image to your image repository with the `docker push` command."
zipkin,"Zipkin Server
Create Zipkin using annotation declarations
Introduce Zipkin dependent package in build.gradle."
zipkin,"dependencies {
    compile('org.springframework.boot:spring-boot-starter')
    compile('io.zipkin.java:zipkin-server')
    runtime('io.zipkin.java:zipkin-autoconfigure-ui')
    testCompile('org.springframework.boot:spring-boot-starter-test')
}
Add an annotation @EnableZipkinServer in the main program class
@SpringBootApplication
@EnableZipkinServer
public class ZipkinApplication {
public static void main(String[] args) {
        SpringApplication.run(ZipkinApplication.class, args);
    }
}
Specify the port as 9411 in application.properties."
zipkin,"server.port=9411
Build a Docker image
The Dockerfile here is the same as with the previous two services, so I won‚Äôt repeat the procedure here."
zipkin,"Deployment on Alibaba Cloud Docker
Create the docker-compose.yml file with the following content:
version: ""2""
services:
  zipkin-server:
    image: registry.cn-hangzhou.aliyuncs.com/jingshanlb/zipkin-demo-server
    labels:
      aliyun.routing.port_9411: http://zipkin
    restart: always
  frontend:
    image: registry.cn-hangzhou.aliyuncs.com/jingshanlb/zipkin-demo-frontend
    labels:
      aliyun.routing.port_8080: http://frontend
    links:
      - zipkin-server
      - backend
    restart: always
  backend:
    image: registry.cn-hangzhou.aliyuncs.com/jingshanlb/zipkin-demo-backend
    links:
      - zipkin-server
    restart: always
create an application
Using the orchestration templateOn Alibaba Cloud Docker, and visit the Zipkin endpoint, then you will see the effect of service analysis."
zipkin,"Visit the front-end application three times, and the page displays three service calls."
zipkin,"Click any trace, and you will see the duration of different spans on the request link."
zipkin,"Enter the Dependencies page, and you will see the dependency relationships between services."
zipkin,"From this process, we can see that Zipkin and Spring Cloud integration is successful."
zipkin,The visualization of service tracing analysis is also intuitive.
zipkin,It is worth noting that you also need to configure databases for Zipkin in a production environment.
zipkin,I will not go into the details here.
zipkin,The demo code of this article can be found here: https://github.com/binblee/zipkin-demo.
zipkin,"Distributed Business Tracing is a new approach to analyze microservices that will ease your daily routines and save you a lot of time, resources and money!"
zipkin,The shift from monoliths to microservices had a big impact in the last decade on daily life as developers and led to many new challenges that we still haven‚Äôt fully addressed yet.
zipkin,Especially analyzing problems and tracking down erroneous components of a complex distributed system has become much more difficult.
zipkin,"We now have to answer questions like:
How do we find out which services were involved when processing a transaction?"
zipkin,How do we figure out which service is causing a transaction to fail and why?
zipkin,How data is flowing through the system as it gets processed?
zipkin,"And more importantly, how long does it take to find the answers to the previous questions?"
zipkin,"Some of these questions can be answered by using distributed tracing tools like Zipkin, Jaeger, OpenTracing, OpenCensus and OpenTelemetry."
zipkin,But those answers are always limited to technical questions and details only.
zipkin,"However, what we are most interested in are business questions like:
What was the input to service A that caused the erroneous output B?"
zipkin,Which parameter caused service C to throw exception D?
zipkin,"Hey team E, could you please analyze why the following request to your application F is failing?"
zipkin,To address these challenges we‚Äôve developed a new type of distributed tracing tool called Trasier that easily integrates with a Springboot application.
zipkin,"And what separates Trasier from other tracing tools is, that it gives you additional insights into your data you never had before."
zipkin,"The situation
We‚Äôve created a simple online shop for selling plane tickets that consists of 4 microservices:

A simple front end application for customer interaction
Three backends for calculating offers, paying items and booking the tickets

And let‚Äôs further assume there is a bug in our payment service that causes some `checkPayment` transactions to fail and as a result, the booking will be reported as UNPAID even though the payment itself was successful."
zipkin,"Finding the issue ‚Äî the old way
In our example, the actual problem is hidden and only visible in the response of the payment service which is not treated correctly by our application and therefore disappears."
zipkin,How did we address such an issue back in the days?
zipkin,Get access to the input data that is causing the service to fail.
zipkin,"In the best case, this would have been provided as a XML attachment to an e-mail by the customer support."
zipkin,But oftentimes it was just a textual description of what the first level support analyzed.
zipkin,Setup the environment and a test case to reproduce the problem.
zipkin,"In the pre-microservices world, this sometimes meant starting up a rusty application server, while having a long coffee break."
zipkin,These days it means starting up all microservices required to reproduce the problem.
zipkin,"In our case, that‚Äôs all services."
zipkin,Put a breakpoint in our booking service and start reproducing the problem until we hit it to finally inspect the debug data to see what the actual problem is.
zipkin,"In this case, there was an exception while loading the payment, which then needs to be further investigated in our payment service."
zipkin,Sounds familiar to you?
zipkin,Debug the system to see where the problem is.
zipkin,"Finding the issue ‚Äî the easy way
This whole process is very complicated, time-consuming, error-prone and often doesn‚Äôt even lead to a result as things might have changed in the system."
zipkin,Here is how we analyze such a situation nowadays with Trasier.
zipkin,"Instead of waiting for customer reactions or first-level support, we track business errors live in our Distributed Business Tracing system."
zipkin,This means an error will pop up in our dashboard as it happens!
zipkin,"Alternatively, we can search for any keyword of the service call (including payload) to find the relevant business transaction and its Conversation-Id."
zipkin,We‚Äôll then be able to look at all the transaction information including the request/response data of that specific business process.
zipkin,That way we can easily identify the problem without even reproducing it.
zipkin,We can see the exception that happened during the payment validation.
zipkin,We can verify that the actual payment call before was successful or not.
zipkin,"As you may guess this means storing a lot of additional data, but it‚Äôs definitely worth the effort."
zipkin,The value of this new source of analytical data is much bigger than anything you had before.
zipkin,"Usually, the only source for analytical evaluation of your business processes is the data that gets stored in your RDBMS as an outcome of the business transaction."
zipkin,But what about all the information that was created and exchanged during the process?
zipkin,"This rarely ever gets stored, as it is not required afterward."
zipkin,"But for analytical purposes, it‚Äôs pure gold!"
zipkin,"There are many use-cases that I‚Äôll highlight in a future article like:
Generating business metrics by extracting data on-the-fly
Replaying business processes to easily reproduce bugs
Mocking system components by using the data of old business processes
Predictive business monitoring based on features extracted and rated on-the-fly
Follow us on Twitter to get notified about new publications."
zipkin,"The solution
With Trasier we‚Äôve built an open-source client for Distributed Business Tracing that is based on OpenTracing and comes with support for Spring applications and even a Springboot Starter for straight forward integration with most applications."
zipkin,Let‚Äôs see what it does.
zipkin,"The crucial difference
To fully benefit from the disruptive features that Trasier provides, we highly recommend to actively set the boundaries of your business processes by associating a Conversation-Id to all of your calls."
zipkin,This simple adaption will completely change the way you are handling bugs at the moment.
zipkin,And it will give you a unique opportunity to gain max.
zipkin,insights into your business data.
zipkin,The concept of Conversation-Id (typically a UUID) is to have a unique identifier that links all interactions of a customer within one business process.
zipkin,This identifier is not part of the business data itself but pure meta-information that will be passed along with your service calls automatically by Trasier.
zipkin,However the initiation and tracking has to be implemented in an application that knows the boundaries of a customers business process; most probably this is the front-end application.
zipkin,A major difference between Trasier and similar tools is its pure focus on Distributed Business Tracing.
zipkin,"An important aspect of this is, to intercept and store all the data that is sent between your services for later analysis or on-the-fly inspection."
zipkin,"And due to the linkage of all transactions of a business process by a unique Conversation-Id, you can truly disrupt many of your existing analytical processes."
zipkin,We‚Äôll cover the possibilities you‚Äôll get from this in a future article.
zipkin,Now let‚Äôs see how easy it is to integrate Trasier into our Springboot backend services.
zipkin,"Setup your Trasier account
Register your free Trasier account at https://www.trasier.com/#/register."
zipkin,Log in to the Dashboard on https://ui.trasier.com to create a Space for ingesting data or use the existing default space.
zipkin,Copy the client configuration to your Springboot application.
zipkin,"Setup your Springboot application
Add the Trasier client Springboot starter to your pom file."
zipkin,"Add the client configuration to your application.yml
Startup your application."
zipkin,Done.
zipkin,"Test your setup
To test your configuration you can go ahead and send a REST request to one of your services and Trasier will automatically intercept all incoming and outgoing requests to store them securely for later analysis."
zipkin,To access your data you can either use the full-text search to find any keyword of the service call (incl.
zipkin,payload) or you can use the associated Conversation-Id to access the business process directly.
zipkin,"Conclusion
Trasier is a tool that will change how you are currently handling bugs and how you are analyzing your business transactions."
zipkin,We‚Äôve learned that there is no easier and faster way of localizing problems.
zipkin,"Additionally to that, the possibilities due to the massive data lake that Trasier provides to you are enormous."
zipkin,"Additional information
The source code of the OpenTracing compliant Trasier Java client is maintained on Github."
zipkin,There is also a comprehensive demo application that shows how Trasier can be integrated into a Springboot application.
zipkin,"By default, this uses a NOOP-Tracer that logs the intercepted data to your console."
zipkin,The configuration for using our backends is on a separate branch.
zipkin,At the moment our SaaS backend services are closed source but we‚Äôre working on an OpenSource Server that uses ElasticSearch and Kibana and can be used on-premise for free.
zipkin,"In case your setup is not as straight forward as a simple Springboot application, you can find additional information in the Trasier Docs."
zipkin,If you need more information or a demo feel free to contact us at any time: info@trasier.com or visit us at www.trasier.com.
zipkin,"In this article, we‚Äôll see how to trace and view platform instrumentation (profiling) data with OpenTracing and Zipkin for a sample micro-services based application deployed on IBM Cloud Private (ICP)."
zipkin,"Examples of platform specific instrumentation data are processor execution efficiency (cycles per instruction), memory bus bandwidth, I/O bus bandwidth and so on."
zipkin,There are scenarios where a combination of application and platform specific instrumentation data is of immense help to definitively identify issues.
zipkin,"For example, in the case of memory-intensive workload, there could be a scenario where memory capacity is available, however, memory bus bandwidth might be starved, thereby negatively affecting the performance."
zipkin,Having platform instrumentation data available in the context of application is very helpful in identifying the root cause of the performance issue.
zipkin,"Overview of technologies involved
OpenTracing is an open and vendor-neutral distributed tracing standard for applications."
zipkin,It allows developers to instrument their code in a vendor neutral way.
zipkin,Zipkin is a distributed tracing system and supports OpenTracing.
zipkin,"For detailed information, please refer OpenTracing documentation."
zipkin,The following diagram gives an overview of the components involved when using OpenTracing with Zipkin backend.
zipkin,The diagram also shows the components involved in extracting platform instrumentation data from hardware performance monitoring counters (PMCs).
zipkin,"OpenTracing with Zipkin Backend and Platform Instrumentation
If you are interested in knowing more about our work related to leveraging platform specific instrumentation data in OpenTracing please refer to the following article ‚Äî https://goo.gl/Jdm5an
IBM Cloud Private (ICP), which is built on open source technologies, including Kubernetes, provides a platform that you can leverage to develop modern applications."
zipkin,You can read more about IBM Cloud Private here.
zipkin,"Pre-requisites
Following are the pre-requisites:
An IBM Cloud Private 2.1 installation with 1 master and at least 1 worker node."
zipkin,See Installing.
zipkin,Install the Kubernetes command line kubectl and configure it to connect to your IBM Cloud Private instance.
zipkin,See Accessing your IBM Cloud Private cluster by using the kubectl CLI.
zipkin,Configure the private Docker registry.
zipkin,See Pushing and pulling images.
zipkin,"Sample application
Sock-shop is a very popular microservices demo application simulating an e-commerce website selling socks."
zipkin,The following diagram gives an overview of the application.
zipkin,"Sock-shop Architecture
Src- https://github.com/microservices-demo/microservices-demo.github.io/blob/master/assets/Architecture.png
Adding platform specific instrumentation data
In order to enable capturing of platform instrumentation (profiling) data in your application with OpenTracing, following snippet needs to be added to your application code."
zipkin,Currently only ‚Äògolang‚Äô applications are supported with work underway to add support for Java.
zipkin,"In your application code, initialize OpenTracing backend with perfevents observer
obs := perfevents.NewObserver()
tracer := zipkin.NewTracer(‚Ä¶ , zipkin.WithObserver(obs), )
Specify the platform instrumentation data you need to collect as part of the trace span."
zipkin,"tracer.StartSpan(‚Äúnew‚Äù, opentracing.Tag{‚Äúperfevents‚Äù, ‚Äúcpu-cycles, instructions‚Äù})
This is all that is required to start collecting platform instrumentation data as part of your traces."
zipkin,"For the purpose of this article, the ‚Äòcatalogue‚Äô service was modified to add platform instrumentation ( cpu-cycles and instructions) data in the traces."
zipkin,"The modified code is available from the following github link ‚Äî https://github.com/bpradipt/catalogue
Deploying the sample micro-services application on IBM Cloud Private You can use the following Kubernetes yaml that comes with the application to deploy it on any Kubernetes cluster, including IBM Cloud Private."
zipkin,"https://github.com/microservices-demo/microservices-demo/blob/master/deploy/kubernetes/complete-demo.yaml
However, for the purpose of this article, we have used the following steps to deploy the sock-shop application in a heterogeneous cluster consisting of Intel and Power (ppc64le) nodes and platform instrumentation enabled for the ‚Äòcatalogue‚Äô service."
zipkin,"Steps
Populate the IBM Cloud Private Docker registry with the required Docker images
$ wget https://raw.githubusercontent.com/bpradipt/microservices-demo/ppc64le/deploy/kubernetes/image_bom.txt
image_bom.txt contains the list of required Docker images
$ wget https://raw.githubusercontent.com/bpradipt/microservices-demo/ppc64le/deploy/kubernetes/push_to_icp
$ chmod +x push_to_icp
$ ./push_to_icp [icp_private_registry]
In my setup, the Docker registry was available at mycluster.icp
$ ./push_to_icp mycluster.icp
This will ensure all the required Docker images are available in the IBM Cloud Private Docker registry."
zipkin,"Build the modified ‚Äòcatalogue‚Äô service code
$ git clone https://github.com/bpradipt/catalogue.git
$ cd catalogue
$ make image-ppc64le
This will create the catalogue Docker image (weaveworksdemos/catalogue) for Power (ppc64le)."
zipkin,Push the image to the IBM Cloud Private Docker registry.
zipkin,"$ docker tag weaveworksdemos/catalogue mycluster.icp:8500/sockshop/catalogue-ppc64le
$ docker push mycluster.icp:8500/sockshop/catalogue-ppc64le
Download the multi-arch deployment yaml
$ wget https://raw.githubusercontent.com/bpradipt/microservices-demo/ppc64le/deploy/kubernetes/complete-demo-multi-arch.yaml
$ kubectl create ‚Äìf complete-demo-multi-arch.yaml
The YAML assumes the images are available under ‚Äòsockshop‚Äô namespace in the IBM Cloud Private Docker registry ‚Äî mycluster.icp:8500
On successful deployment, you can retrieve the details of the front-end service to access the application and the zipkin service for accessing the traces."
zipkin,This is a short video showing the deployment and tracing in action.
zipkin,Hope you‚Äôll find this useful.
zipkin,Thanks to Hemant K Shaw for helping with the demo setup.
zipkin,He is also one of the key developers working on adding platform instrumentation support to OpenTracing.
zipkin,This series of blog posts is about the network related performance issues.
zipkin,The goal is to give you a set of tools to use that will provide you with insights that help you deliver fewer and shorter loading screens to your customers.
zipkin,"Make sure you check out the first part, too: Performance Monitoring for the Frontend ‚Äî An introduction

Getting Started
Now that we got the names right let‚Äôs take a look at how we might track a single span."
zipkin,"For that, we need a tracer to start spans with."
zipkin,You can see on line 13 that we need to set a sampler.
zipkin,A sampler is a function that returns a boolean indicating if a trace should be started or not.
zipkin,"It is useful to set, as you might only want to trace a certain percentage of users or only users who are connected to WIFI or something unique to your business."
zipkin,"In line 14 you see the service name is set to ‚Äúfrontend‚Äù, this will be shown on the left side."
zipkin,Now we have a working tracer that we might use to start some actual traces.
zipkin,Let‚Äôs talk about this in detail: The first thing you might notice is that we wrap the statements we want to trace in a scoped block and set the current id of the span so that Zipkin knows about which span we talk specifically.
zipkin,"The createRootId part means that we want to create a root span, we will later see how we can create child spans."
zipkin,"The next thing to note is that we record annotations one for client send, it marks the start point of our span and indicates that a client is about to send a request to the server."
zipkin,"If we wrote a server here, we would need to use the server receive annotation; for local spans (with no interaction between systems) we could use local operation start."
zipkin,"In line 15 we see the opposite part, the client receive annotation, it marks the end of the span."
zipkin,"As you already know spans can have names, in this case, we set it to ‚ÄúMy Span‚Äù via the RPC annotation."
zipkin,"RPC stands for Remote Procedure Call, which means we invoke a function on a server with this call."
zipkin,Last but not least we want to know the result of our API call.
zipkin,Therefore we record a binary log with the key ‚Äúresult‚Äù and the stringified response as value.
zipkin,"Extending Spans
There shall only be one root, so let us see how to define a child relation:

You need to be inside a scoped block of your parent so that you might extend it by running createChildId."
zipkin,"And that‚Äôs it, easy right?"
zipkin,"It get‚Äôs a bit more complicated when you try to connect two systems with each other, I will probably go over this in detail in a later part of the series."
zipkin,"For now, I would like to show you where you might take a look if you want to do such a thing:
- adding HTTP headers to a request
- extracting tracing context from a request
Local Spans
Finally, I would like to show you something neat @adrianfcole ‚Äèrecently added to Zipkin: Local Spans."
zipkin,"Whenever you find yourself in need to track something that only concerns one service, and that is either a synchronous computation or an asynchronous with a promise you should use local spans for the tracing."
zipkin,"You can either set the Annotations yourself, or you let Zipkin handle this for you, like in this example:

The first argument of local takes a span name and the second one a function."
zipkin,"If the function returns a promise the span ends when the promise resolves, otherwise it ends when the function is finished
Want to hear more from me?"
zipkin,"Feel free to subscribe to my newsletter, I send out news roughly once a month."
zipkin,Zipkin2 was released a few days ago.
zipkin,It offers new JSON model which is smaller and easier to handle than previous one.
zipkin,I tried Zipkin2 immediately.
zipkin,"At first, an important things is that Zipkin2 server can handle request from both Zipkin1 and Zipkin2 client."
zipkin,This means we can move our applications to Zipkin2 gradually.
zipkin,"A following picture is mixed tracing of Zipkin1 client and Zipkin2 client:

Next, I tried to store tracing data in Elasticsearch."
zipkin,"Zipkin supports Elasticsearch as one of storages, and we can use it by specifying Elasticsearch URL by environment variable like follows:
$ STORAGE_TYPE=elasticsearch ES_HOSTS=http://localhost:9200 java -jar zipkin.jar
Here is an example of the tracing data which is stored in Elasticsearch:
{
  ""_index"": ""zipkin:span-2017-09-15"",
  ""_type"": ""span"",
  ""_id"": ""AV6DyP-s1lXcfYRA_gW_"",
  ""_score"": 1,
  ""_source"": {
    ""traceId"": ""f69ea762746e11a5"",
    ""localEndpoint"": {
      ""serviceName"": ""zipkin-akka-actor"",
      ""ipv4"": ""10.198.80.33""
    },
    ""timestamp_millis"": 1505449540337,
    ""kind"": ""CLIENT"",
    ""name"": ""!"
zipkin,"- child-actor"",
    ""id"": ""121e5f0d86c12da2"",
    ""parentId"": ""128e8b168c4ca375"",
    ""timestamp"": 1505449540337441
  }
}
And here is an example of Zipkin V1 tracing data:
{
  ""_index"": ""zipkin-2017-09-15"",
  ""_type"": ""span"",
  ""_id"": ""AV6DxCUt1lXcfYRA_gW9"",
  ""_score"": 1,
  ""_source"": {
    ""timestamp_millis"": 1505449221231,
    ""traceId"": ""d9a5b347e53306a7"",
    ""id"": ""a8b40aa821535967"",
    ""name"": ""parent-actor"",
    ""parentId"": ""d9a5b347e53306a7"",
    ""timestamp"": 1505449221231197,
    ""duration"": 519199,
    ""annotations"": [
      {
        ""timestamp"": 1505449221231197,
        ""value"": ""sr"",
        ""endpoint"": {
          ""serviceName"": ""zipkin-akka-actor"",
          ""ipv4"": ""10.198.80.33""
        }
      },
      {
        ""timestamp"": 1505449221750396,
        ""value"": ""ss"",
        ""endpoint"": {
          ""serviceName"": ""zipkin-akka-actor"",
          ""ipv4"": ""10.198.80.33""
        }
      }
    ]
  }
}
As you can see, V2 JSON is smaller and simpler than V1 obviously, and also it can be handled easily."
zipkin,"For example, we can visualize the tracing data stored in Elasticsearch using Kibana easily."
zipkin,"Anyway, Zipkin2 looks better than Zipkin1 in a lot of points, and it also provides gradual migration way by backward compatibility."
zipkin,"Therefore, we can start to use it soon."
zipkin,"For our projects with lots of JAVA microservices, we use Zipkin to get insights into the calls that are made and where the bottlenecks might be."
zipkin,"Once we identified an interesting trace, we would like to know what the services were doing at the time."
zipkin,"However, we were initially missing the ability to link the Zipkin traces to the log messages of the microservices."
zipkin,Our JAVA microservices create JSON formatted log lines using the logback LogStash encoder.
zipkin,"They are picked up by Fluentd, put in Elasticsearch and accessed via Kibana."
zipkin,"In this post, we want to show how to add the Zipkin traceId and spanId to the JSON formatted log lines via the Mapped Diagnostic Context (MDC)."
zipkin,"When this is done, one can select a trace from Zipkin, put the traceId in Kibana for search, and pull up all the logging associated to that particular trace."
zipkin,"Todemonstrate how to do this, we created a sample project at merapar/zipkin-trace."
zipkin,"It contains three microservices: a, b and c. Service a will be our entry point by means of an HTTP web service."
zipkin,Service a can call service b via gRPC or service c via HTTP.
zipkin,Service b can call service c via either HTTP or gRPC.
zipkin,See the following image as generated by Zipkin.
zipkin,The reason for the different communication methods is to show that the propagation of the Zipkin traceId and spanId works across different protocols.
zipkin,What we want to achieve is the following.
zipkin,"If we start the three services and call http://localhost:8080/v1/a , we can see in Zipkin UI:

If we expand the trace, we get:

And after clicking on a span, we get another window with a ‚ÄòMore Info‚Äô button, which will reveal the traceId."
zipkin,The traceId c245caf56bff91fa can then be searched for in Kibana.
zipkin,"As an example, below is a screenshot of Kibana using another traceId from our live system:

So we are able to find the logging that belongs to a particular Zipkin trace in Kibana, using the Zipkin traceId as search parameter."
zipkin,In the next section we will describe how to configure this.
zipkin,The first thing that needs to be done is to setup Zipkin.
zipkin,We will use the openzipkin/brave library to do this.
zipkin,You will need at least version 4.3.4 for this to work.
zipkin,"In common/tracing of the common project, we created the following files:
ZipkinBraveConfiguration.java
ZipkinGrpcServerBuilderConfigurer.java
ZipkinHttpClientParser.java
ZipkinHttpServerParser.java
ZipkinWebConfiguration.java
RestTemplateConfiguration.java
GrpcServerInterceptorWrapper.java
We will not go over everything in the files."
zipkin,"The key to get the spanId and traceId put in the MDC is in this section of the ZipkinBraveConfiguration.java file:
@Bean
public Tracing tracing() {
    val tracing = Tracing.newBuilder()
            .localServiceName(serviceName)
            .currentTraceContext(MDCCurrentTraceContext.create());

    if (zipkinEnabled) {
        tracing.reporter(reporter());
    }
    return tracing.build();
}
The Brave library provides an MDCCurrentTraceContext which can be set on the tracing object."
zipkin,"We use the MDCCurrentTraceContext, because we use SLF4J as our logging framework."
zipkin,"If you are using Log4j-2 directly, you can use ThreadContextCurrentTraceContext instead."
zipkin,"We are also using LogNet/grpc-spring-boot-starter, to start our gRPC services."
zipkin,"The GrpcServerInterceptorWrapper.java file wraps Brave‚Äôs serverInterceptor, so that it can be used when defining the gRPC service with the @GRpcService annotation:
@Slf4j
@Component
@GRpcService(interceptors = GrpcServerInterceptorWrapper.class)
public class GrpcServiceBImpl extends ServiceBGrpc.ServiceBImplBase {
..."
zipkin,"Furthermore, we also like to use our own Executor to handle the incoming gRPC calls."
zipkin,"In the ZipkinGrpcServerBuilderConfigurer.java file we set the executor for the LogNet GRpcService:
@Component
public class ZipkinGrpcServerBuilderConfigurer extends GRpcServerBuilderConfigurer {

    @Autowired
    private Executor executor;

    @Override
    public void configure(ServerBuilder<?> serverBuilder) {
        serverBuilder.executor(executor);
    }
}
With the configuration done, everything is in place to:
Intercept incoming HTTP requests (See ZipkinWebConfiguration.java)
Intercept outgoing HTTP requests (See RestTemplateConfiguration.java)
Intercept incoming gRPC requests (See ZipkinBraveConfiguration.java and GrpcServerInterceptorWrapper.java)
Intercept outgoing gRPC requests (See ZipkinBraveConfiguration.java)
Expose the traceId and spanId in the MDC for logging."
zipkin,Here is an example of the output of the test project.
zipkin,"We configured our logback.xml to output log lines to console as follows:
<appender name=""CONSOLE"" class=""ch.qos.logback.core.ConsoleAppender"">
    <encoder>
        <pattern>%d [%X{traceId}/%X{spanId}] [%thread] %-5level %logger{36} - %msg%n</pattern>
        <charset>utf8</charset>
    </encoder>
</appender>
Now if we start the three services and call http://localhost:8080/v1/a , we can see in the logging of service a:
2017‚Äì06‚Äì28 12:34:20,038 [c245caf56bff91fa/c245caf56bff91fa] [http-nio-8080-exec-2] INFO zipkintrace.servicea.web.AController ‚Äî Received /a request: A:HTTP -> B:gRPC -> C:HTTP
2017‚Äì06‚Äì28 12:34:20,038 [c245caf56bff91fa/c245caf56bff91fa] [http-nio-8080-exec-2] INFO zipkintrace.servicea.ServiceA ‚Äî Calling ‚ÄòshortRunning‚Äô on service B
2017‚Äì06‚Äì28 12:34:20,038 [c245caf56bff91fa/c245caf56bff91fa] [http-nio-8080-exec-2] INFO z.servicea.services.ServiceB ‚Äî Calling ‚ÄòshortRunning‚Äô on Service B via gRPC
2017‚Äì06‚Äì28 12:34:20,536 [c245caf56bff91fa/c245caf56bff91fa] [http-nio-8080-exec-2] INFO z.servicea.services.ServiceB ‚Äî Result of ‚ÄòshortRunning‚Äô on Service B: 100
2017‚Äì06‚Äì28 12:34:20,536 [c245caf56bff91fa/c245caf56bff91fa] [http-nio-8080-exec-2] INFO zipkintrace.servicea.ServiceA ‚Äî Calling ‚ÄòlongRunning‚Äô on service B
2017‚Äì06‚Äì28 12:34:20,536 [c245caf56bff91fa/c245caf56bff91fa] [http-nio-8080-exec-2] INFO z.servicea.services.ServiceB ‚Äî Calling ‚ÄòlongRunning‚Äô on Service B via gRPC
2017‚Äì06‚Äì28 12:34:21,090 [c245caf56bff91fa/c245caf56bff91fa] [http-nio-8080-exec-2] INFO z.servicea.services.ServiceB ‚Äî Result of ‚ÄòlongRunning‚Äô on Service B: 300
From the logging we see that our traceId for this call is: c245caf56bff91fa."
zipkin,"Service a now calls service b twice via gRPC which can be seen in the following logging:
2017‚Äì06‚Äì28 12:34:20,041 [c245caf56bff91fa/f238828a188aec3d] [pool-3-thread-5] INFO z.s.grpc.serviceb.GrpcServiceBImpl ‚Äî Service B called with ‚ÄòshortRunning‚Äô via gRPC
2017‚Äì06‚Äì28 12:34:20,041 [c245caf56bff91fa/f238828a188aec3d] [pool-3-thread-5] INFO zipkintrace.serviceb.ServiceB ‚Äî Calling ‚Äò/c‚Äô on service C via HTTP in ‚ÄòshortRunning‚Äô
2017‚Äì06‚Äì28 12:34:20,414 [c245caf56bff91fa/f238828a188aec3d] [pool-3-thread-5] INFO z.serviceb.services.ServiceC ‚Äî Got HTTP response from service C: test call C
2017‚Äì06‚Äì28 12:34:20,538 [c245caf56bff91fa/8b076a2d1279d9aa] [pool-3-thread-8] INFO z.s.grpc.serviceb.GrpcServiceBImpl ‚Äî Service B called with ‚ÄòlongRunning‚Äô via gRPC
2017‚Äì06‚Äì28 12:34:20,538 [c245caf56bff91fa/8b076a2d1279d9aa] [pool-3-thread-8] INFO zipkintrace.serviceb.ServiceB ‚Äî Calling ‚Äò/c‚Äô on service C via HTTP in ‚ÄòshortRunning‚Äô
2017‚Äì06‚Äì28 12:34:20,786 [c245caf56bff91fa/8b076a2d1279d9aa] [pool-3-thread-8] INFO z.serviceb.services.ServiceC ‚Äî Got HTTP response from service C: test call C
Note that the traceId is the same in service a logging, but the spanId is indeed different for each call."
zipkin,Service b now calls service c via HTTP.
zipkin,"The logging of service c shows:
2017‚Äì06‚Äì28 12:34:20,112 [c245caf56bff91fa/06f7caee20fcca87] [http-nio-8100-exec-1] INFO zipkintrace.servicec.web.CController ‚Äî Received /c request via HTTP
2017‚Äì06‚Äì28 12:34:20,112 [c245caf56bff91fa/06f7caee20fcca87] [http-nio-8100-exec-1] INFO zipkintrace.servicec.ServiceC ‚Äî Running ‚Äòprocess‚Äô on service C
2017‚Äì06‚Äì28 12:34:20,542 [c245caf56bff91fa/74de642754d2d3b3] [http-nio-8100-exec-2] INFO zipkintrace.servicec.web.CController ‚Äî Received /c request via HTTP
2017‚Äì06‚Äì28 12:34:20,542 [c245caf56bff91fa/74de642754d2d3b3] [http-nio-8100-exec-2] INFO zipkintrace.servicec.ServiceC ‚Äî Running ‚Äòprocess‚Äô on service C
Again, the traceId is nicely propagated to service c as well."
zipkin,This traceId was used in the screenshots at the beginning of the article.
zipkin,"Our JAVA microservices are using the configuration described above to log everything in JSON format (using the net.logstash.logback.encoder.LogstashEncoder), which automatically includes all MDC values as key - value pairs."
zipkin,"With this, if we find interesting traces in Zipkin, we can now take the traceId and search for it in Kibana."
zipkin,"When we have retrieved the log lines associated with the traceId, we can figure out exactly what is happening in the system."
zipkin,"In the previous article, I configured a Zipkin proxy for Stackdriver trace to capture trace information from Spring Boot microservices with Spring Cloud Sleuth."
zipkin,"You can run the Zipkin proxy anywhere ‚Äî in on your local laptop, in your own data center, in a Virtual Machine, or in a container."
zipkin,This article will deploy the Zipkin proxy in Kubernetes (with Google Container Engine) and then deploy the microservices to send trace information to this proxy.
zipkin,"Create a new Kubernetes cluster
First, create a new Kubernetes cluster using Google Container Engine with gcloud SDK:
$ gcloud container clusters create mycluster --scopes default
This will create a new Kubernetes clusters and also download the Kubernetes credential to your local machine."
zipkin,It‚Äôs important to specify the scopes parameter.
zipkin,This scope will enable frequently used permissions such as creating a new trace record.
zipkin,Any container you deploy into this cluster will be able to inherit this permission.
zipkin,"You can have fine-grained control over the scopes, by specifying the trace.append scope."
zipkin,"Deploy the Zipkin Proxy
The Zipkin proxy for Stackdriver Trace is already containerized."
zipkin,"It can be deployed easily into Kubernetes directly from the command line:
$ kubectl run stackdriver-zipkin \
  --image=gcr.io/stackdriver-trace-docker/zipkin-collector:v0.2.0 \
  --expose --port=9411
This will deploy one instance of the Zipkin proxy container into the Kubernetes cluster, and exposing it as a service that‚Äôs accessible via the URL http://stackdriver-zipkin:9411/ from within the cluster."
zipkin,"Deploy the Sleuth Example
I‚Äôve containerized the Sleuth WebMVC Example into a container as well."
zipkin,I can also deploy both the frontend and the backend into Kubernetes.
zipkin,"Furthermore, I‚Äôll want to configure them so that they will consume services at the proper endpoints rather than from localhost."
zipkin,"To deploy the backend:
$ kubectl run sleuth-example-backend \
  --env=""SPRING_ZIPKIN_BASEURL=http://stackdriver-zipkin:9411"" \
  --env=""SPRING_SLEUTH_SAMPLER_PERCENTAGE=1.0"" \
  --image=saturnism/sleuth-webmvc-example \
  --expose --port=9000 \
  -- -Dexec.mainClass=sleuth.webmvc.Backend
This will configure a couple of application.properties entries directly from the environmental variable."
zipkin,"In particular, I want to make sure the backend is sending trace data to the Zipkin proxy in the Kubernetes cluster rather than http://localhost:9411."
zipkin,"This will also expose the backend as an internal service that is accessible from within the Kubernetes cluster, via http://sleuth-example-backend:9000."
zipkin,"Similarly, to deploy the frontend:
$ kubectl run sleuth-example-frontend \
  --env=""SPRING_ZIPKIN_BASEURL=http://stackdriver-zipkin:9411"" \
  --env=""SPRING_SLEUTH_SAMPLER_PERCENTAGE=1.0"" \
  --env=""BACKEND_HOST=sleuth-example-backend"" \
  --image=saturnism/sleuth-webmvc-example \
  -- -Dexec.mainClass=sleuth.webmvc.Frontend
This command also configures the backend hostname via an environmental variable."
zipkin,"Finally, I‚Äôd like to expose the Frontend as an external service, so that it‚Äôs accessible via a public IP:
$ kubectl expose deployment sleuth-example-frontend \
  --port=8081 \
  --target-port=8081 \
  --type=LoadBalancer
This will create a Google Cloud Platform Network Loadbalancer that will be able to route the traffic from a public IP to any of the frontend instances (only 1 instance at the moment)."
zipkin,"You will need to check whether the public IP has been assigned by running:
$ kubectl get svc sleuth-example-frontend
NAME                      CLUSTER-IP      EXTERNAL-IP       PORT(S)          AGE
sleuth-example-frontend   10.15.249.158   AAA.BBB.CCC.DDD   8081:30674/TCP   30s
Look for the EXTERNAL-IP, you can then access the Frontend via http://AAA.BBB.CCC.DDD:8081/
Generate Requests
I used Apache Bench to generate the requests against the newly created endpoint:
$ ab -n 1000 -c 10 http://AAA.BBB.CCC.DDD:8081/
If this worked properly, you should see the trace details in the Stackdriver Trace console:

Give it a Try
See Using Stackdriver Trace with Zipkin for more examples and FAQs to learn more about how to use the proxy."
zipkin,I‚Äôd like to hear your feedback and thoughts too.
zipkin,You can find more examples on my GitHub:
zipkin,"Suman Karumuri | Pinterest tech lead, Visibility
To ensure we‚Äôre providing a fast experience for Pinners, we‚Äôre constantly improving the request latency of our backend services."
zipkin,"Earlier this year, we open sourced Pintrace collector, and contributed the code to the OpenZipkin community."
zipkin,"In a previous post, we explained the architecture of Pintrace and how we trace backend applications."
zipkin,"In addition to using Pintrace to understand and improve the latency of our backend, we‚Äôve developed applications of trace data to solve a few day-to-day issues."
zipkin,"While there‚Äôs a lot of literature on how distributed tracing can be used for improving request latency, there‚Äôs surprisingly little documentation on how this trace data can be used in other ways."
zipkin,"Here, we‚Äôll share how we use the trace data to understand, debug and tune our backend services."
zipkin,Pintrace has been running in production for over six months now.
zipkin,"Currently, we‚Äôre sampling a small portion of production traffic (<0.5%) for tracing with negligible overhead."
zipkin,You can also use the Pintrace traces to answer several architectural questions easily.
zipkin,Some fun facts about Pinterest backend we noticed from our traces.
zipkin,A home feed request calls 24‚Äì48 backend services and makes 80‚Äì330 network calls.
zipkin,A search request talks to 21‚Äì28 services and makes 75‚Äì450 network calls.
zipkin,Our service dependency graph is fairly shallow with a max depth of 2.
zipkin,"We‚Äôll share examples of how we use traces to improve the latency of our backend, as well as how we‚Äôve made trace data a foundational substrate for all performance data at Pinterest, starting with mobile clients."
zipkin,"Understanding the request timeline
Even an individual trace of a request can provide a lot of insight into the system."
zipkin,It can tell us what actions took place during a request and how long each took.
zipkin,The image below shows a trace for a single home feed request.
zipkin,The trace visualization page consists of trace summary and a Gantt chart visualization of a trace.
zipkin,"Identifying services interacting with a request
The Zipkin UI shows a summary of the trace at the top of the Gantt chart."
zipkin,This kind of summary is useful to get an overview of the request execution.
zipkin,"This summary view provides the following insights:
It took 581ms for processing the request."
zipkin,The ngapi service interacted with 36 different backend services.
zipkin,Our architecture is shallow.
zipkin,A depth of 1 shows that each service at most called one more service.
zipkin,We made 97 network calls to process the request across 36 services.
zipkin,(since a majority of spans track network calls).
zipkin,"Breaking it down further, graph service has 20 spans which translates to 20 network calls since we only trace network calls in graph service."
zipkin,"Identifying duplicate computation
The spans in a trace show all the actions that occurred during a request."
zipkin,"However, when the same spans are repeated in a trace, it‚Äôs a sign of duplicate computation or computation that can be optimized using caching or other techniques."
zipkin,"Given the complex interactions between components in system and the software abstractions, these kinds of issues are unavoidable and not easily detected in complex systems."
zipkin,"So, If a trace contains identical spans, it‚Äôs worth taking a closer look."
zipkin,"For example, when looking for a trace for a home feed request we noticed two identical Thrift calls separated by a few milliseconds to our follower service backend."
zipkin,The image below shows an annotated screenshot of the trace.
zipkin,"When we looked at the code making these calls, we identified that the second call was unnecessary."
zipkin,The developer was not aware of the duplicate call since different methods in the code were using the same underlying API.
zipkin,"By deleting the duplicate call, we improved the overall call latency of home feed request by 20+ms or 5% and halved the load on the backend service by removing the duplicate call."
zipkin,"Performance bottlenecks
Identifying requests that took the longest time
Each span in a trace captures the amount of time it took to execute an operation."
zipkin,A Gantt chart (like the one shown in Figure 1) shows the spans in a waterfall view.
zipkin,"In this view, a blue bar shows the relative time during which the span was active during the request."
zipkin,By identifying the spans with the longest duration (widest blue bar) we can know where the request spent it‚Äôs time.
zipkin,"For example, in Figure 1, you can see the entire v3_home_feed call in ngapi took 581ms."
zipkin,By looking at the spans we can see that getfeed call to smartfeedservice took 177ms.
zipkin,"So, the request spent 30% of the time in the getfeed API call to smartfeedservice."
zipkin,"This is acceptable in this case, since smartfeedservice returns a list of pins to be shown in the home feed."
zipkin,"Identifying serial execution
The Gantt chart visualization of a trace can clearly show serial execution."
zipkin,The spans in a serial execution show up as a step pattern from the same service.
zipkin,"In Figure 1, we can see that the memcache_get calls are executed in parallel because they start at the same time."
zipkin,"However, in a later part of that trace we see get_many calls to memcache from ngapi executed in a step pattern as shown in the image below."
zipkin,The next image shows the step function pattern characteristic of a serial execution.
zipkin,Inspecting the code revealed a bug showing we failed to wrap memcache get_many call with a Python decorator that would run it asynchronously in a greenlet.
zipkin,"Once we made the call asynchronous by adding a Python decorator to the method, all our get_many calls to Memcache now run in parallel."
zipkin,"We confirmed the fix by looking at a trace generated from the new code, as shown in the image below."
zipkin,"Identifying architectural optimizations
By looking at a trace, one may identify opportunities for optimization."
zipkin,"For example, an architect can identify calls which can take advantage of a cache or other architectural optimizations."
zipkin,"However, improvements like these need deep domain expertise as they usually involve architectural changes."
zipkin,"For example, in the home feed trace in Figure 1, we saw that 30% of the time is spent identifying the Pins to be shown to a user."
zipkin,"By examining the rest of the trace (not shown in that image), we noticed that we spend roughly 40% of the time materializing a Pin i.e, building actual Pins from pin ids returned by smartfeedservice."
zipkin,"Currently, this logic needs calls to several services."
zipkin,"Based on this trace data, we‚Äôve started looking into ways to optimize pin materialization."
zipkin,A trace has also helped us identify the performance bottlenecks in the code.
zipkin,"For example, we realized we can make a call to the ads API much sooner, thus reducing the overall latency."
zipkin,We also identified several opportunities where the data can be cached by dependent services using a trace.
zipkin,We‚Äôre working on these optimizations in the first half of 2017.
zipkin,"Understanding program execution using custom spans
The generic Python Zipkin tracer generates a span for incoming and outgoing network requests like HTTP and Thrift calls."
zipkin,This is fine choice in many cases since the network latency accounts for most of the request processing time.
zipkin,"However, in cases where complex business logic is involved, capturing network calls alone is not very useful to understand what‚Äôs going on."
zipkin,"For example, a trace for the heavily used v3_get_experience API, we‚Äôd see a span that shows the API took 300ms with a few short network calls."
zipkin,But this trace wouldn‚Äôt tell why those network calls were made or how the remaining 300ms of time was spent.
zipkin,"So, we provided developers with the ability to add custom non-networked spans to their traces."
zipkin,Developers can add custom spans using a simple python context manager as shown in the code below.
zipkin,"with custom_span(‚Äòmy_operation‚Äô, tags={‚Äòkey1‚Äô: ‚Äòvalue1‚Äô, ‚Äòkey2‚Äô: ‚Äòvalue2‚Äô}):
‚Ä¶
By annotating v3_get_experiences API with custom spans, our experience framework team was able to get a deeper understanding of how time was spent in their API."
zipkin,After adding custom spans the team found several optimizations that would improve the latency by 20%.
zipkin,"Understanding performance impact during development
Given our complex monolithic python front-end, our developers don‚Äôt have good tools to understand the performance impact of a new change they make."
zipkin,"So, we trace all their requests automatically on development machines so they can easily trace their code and understand how the code works."
zipkin,"Improving time to triage
Tracking down P99 latencies
In a micro services architecture, understanding why a request is slow is very hard because any component in the request path can add to the latency."
zipkin,"With p99 latency, tracking down the problem is even harder because the latency can be added by any component in the request processing path for a wide variety of reasons."
zipkin,"A trace captures a request throughout its execution, so it can identify the component that is causing the slowness."
zipkin,"Since we sample a small percentage of the requests for tracing, the captured traces can identify p50, p75 and sometimes p90 latency issues easily."
zipkin,"Since p99 issues are rare, we have to search for traces over longer durations to find a trace with p99 latency."
zipkin,"Historically, we‚Äôve used traces to determine the root cause of a p99 latency issue in the followerservice."
zipkin,"The team member searched for a span of follower service whose duration was more than a second, the p99 latency for the follower service."
zipkin,"Comparing the p99 latency trace with a normal trace, we were able to quickly identify that the p99 latency issue was caused because the client was looking up too many keys in the database compared to a normal request."
zipkin,The issue was fixed by limiting the number of keys a client can lookup.
zipkin,Which cluster served this request?
zipkin,"For fault tolerance, it‚Äôs very common for people use multiple clusters or replicas of databases and caches."
zipkin,"During troubleshooting or debugging, the first questions an engineer would have to ask and answer are things like: Which memcache cluster a request is hitting?"
zipkin,Is this request served by the master or slave database?
zipkin,Logs are typically used to answer these questions.
zipkin,"Even with a distributed log search system, searching through logs would be cumbersome since we have to carefully comb through the application logs to identify the exact time of the request and then comb through the database or cache logs to identify the request around that time."
zipkin,The process requires inferring causality of events and extra context manually.
zipkin,Traces are a better alternative to logs for this use case since they capture the causality and the needed context like host ip and port of the remote server during a request.
zipkin,We can also annotate the span with additional information about the name of the database and the sql query executed etc.
zipkin,to simplify debugging.
zipkin,"For example, while investigating an incident the zen team would like to know whether a request was served from a mysql cluster or hbase cluster."
zipkin,"Since Pintrace captures the network address and port of every request, they use this information to do a DNS lookup to determine the cluster a request was served with."
zipkin,For performance we cache a lot of data across several memcache clusters.
zipkin,"While investigating a latency issue, we‚Äôd like to know if the cache was hit during a request and which one it was."
zipkin,"To simplify answering these questions we‚Äôve instrumented our memcache trace code to add the name of the memcache cluster serving the request to the span, which has helped in debugging several issues."
zipkin,"Latency pipeline
Pinterest is a data driven company, and so, several services measure the time it took to perform an action, like the time it takes to load a video or open the app."
zipkin,Some of these actions may contain sub-actions.
zipkin,"For example, opening the app will authenticate the user, send a request for home feed, download images and render the home feed."
zipkin,"Currently, this latency information is captured in custom data formats for each action, with its own backend data processing job and storage formats."
zipkin,"However, we noticed several parallels between the data format for actions data and the span data."
zipkin,"The Zipkin span can encapsulate the action data perfectly using span name as action name, a start time, an end time and a map of key value pairs to annotate the span."
zipkin,"Similarly, each sub-action can also be represented as a span and the parent child relationship among spans can be used for relating the sub-actions to an action."
zipkin,"By standardizing the data format for all these actions as a span, we can also standardize the data processing pipeline for processing this information."
zipkin,"In response, we‚Äôve started a process to standardize all the latency data into span format."
zipkin,"We‚Äôve also built a new pipeline called the latency pipeline to collect, process, store and query this information at scale using big data tools like Hadoop, Spark and Hive."
zipkin,"Currently, we process some mobile client latency metrics using this new pipeline."
zipkin,Watch out for a new blog post on this soon.
zipkin,What‚Äôs next?
zipkin,"In addition to strengthening existing use cases, we see several ways to use trace data in future."
zipkin,Use Pintrace to improve performance of our backend.
zipkin,Integrate our tracing system with our log search and metrics systems.
zipkin,Estimate the cost of serving a request and calculate charge back using trace data.
zipkin,Reduce time to triage for incidents using traces.
zipkin,End to end tracing: Expand Pintrace to trace a request from web and mobile clients all the way into Hbase queries.
zipkin,Enable tracing in C++ and go applications.
zipkin,Improve data quality of the collected traces.
zipkin,Improve the latency pipeline.
zipkin,"Conclusion
Pintrace started to trace requests across our backend services to improve request latency."
zipkin,"But, we soon realized that the span model, trace pipeline and the trace data provide novel ways for understanding, debugging and tuning our systems from mobile devices, backend services to databases."
zipkin,"With these new use cases, we see tracing infrastructure as the third pillar of monitoring our services in addition to metrics and log search systems."
zipkin,"In future, we plan to further analyze the trace data to gather insights for capacity planning, calculating charge back and estimating cost to serve a request."
zipkin,We are just getting started.
zipkin,"Related reading: Distributed tracing at Pinterest
Acknowledgements: The contributors to this project are Joe Gordon, Sam Meder, Naoman Abbas, Xiaoqiao Meng and Suman Karumuri."
zipkin,We can use some exiting libraries to trace API calls by Zipkin in Play Framework which is one of popular web frameworks in Scala.
zipkin,"akka-tracing
zipkin-futures
However they haven‚Äôt enough Play integration."
zipkin,"One day, I found that my collegue is writing a library that makes possible to trace in Play, so I enhanced that library and publish it as open-source."
zipkin,"GitHub - bizreach/play-zipkin-tracing: Provides distributed tracing for Play Framework using Zipkin‚Ä¶
play-zipkin-tracing - Provides distributed tracing for Play Framework using Zipkin."
zipkin,"github.com

At first, add folliwing dependency to build.sbt:
libraryDependencies ++= Seq(
  ""jp.co.bizreach"" %% ""play-zipkin-tracing-play25"" % ""1.0.0""
)
And add following settings to application.conf:
play.http.filters=filters.Filters
trace {
  service-name = ""zipkin-api-sample""
zipkin {
    host = ""localhost""
    port = 9410
    sample-rate = 0.1
  }
}
zipkin-trace-context {
  fork-join-executor {
    parallelism-factor = 20.0
    parallelism-max = 200
  }
}
play.modules.enabled  += ""jp.co.bizreach.trace.play25.module.ZipkinModule""
Add ZipkinTraceFilter to filter.Filters as:
package filters
import javax.inject.Inject
import jp.co.bizreach.trace.play25.filter.ZipkinTraceFilter
import play.api.http.DefaultHttpFilters
class Filters @Inject() (
  zipkinTraceFilter: ZipkinTraceFilter
) extends DefaultHttpFilters(zipkinTraceFilter)
OK, you are ready."
zipkin,Inject and use TraceWSClient instead of WSClient in controller to trace API calls transparently.
zipkin,"package controllers
import play.api.mvc."
zipkin,"{Action, Controller}
import play.api.libs.json.Json
import jp.co.bizreach.trace.play25."
zipkin,"{TraceWSClient, ZipkinTraceService}
import jp.co.bizreach.trace.play25.implicits.ZipkinTraceImplicits
import scala.concurrent.ExecutionContext
import javax.inject.Inject
class ApiController @Inject() (ws: TraceWSClient)
  (implicit val tracer: ZipkinTraceServiceLike, 
            val ec: ExecutionContext)
    extends Controller with ZipkinTraceImplicits {
def test = Action.async { implicit request =>
    ws.url(""hello-api-call"", ""http://localhost:9992/api/hello"")
      .get().map { res => Ok(res.json) }
  }
}
In addition, you can trace other blocking and non-blocking processes using methods of ZipkinTraceServiceLike."
zipkin,"// Trace blocking process
def test1 = Action { implicit request =>
  tracer.trace(""sync""){
    println(""Hello World!"")"
zipkin,"Ok(Json.obj(""result"" -> ""ok""))
  }
}
// Trace non-blocking process by Future
def test2 = Action.async { implicit request =>
  tracer.traceFuture(""async""){
    Future {
      println(""Hello World!"")"
zipkin,"Ok(Json.obj(""result"" -> ""ok""))
    }
  }
}
play-zipkin-tracing supports Play 2.3, 2.4 and 2.5."
zipkin,(also we will add Play 2.6 support in the future!)
zipkin,See the following README to know how to use in each versions of Play Fraemwork.
zipkin,"for Play Framework 2.3
for Play Framework 2.4
for Play Framework 2.5
This library is using Brave4 (Brave is a Zipkin client library for Java)."
zipkin,"Brave API had large changes in 4, so this library might be a good example of Brave4 usage."
zipkin,"By Suman Karumuri, Pinterest engineer, Visibility
The Pinterest backend consists of hundreds of microservices deployed across tens of thousands of machines."
zipkin,A simple request to the Pinterest home feed can make hundreds of network calls to dozens of backend services.
zipkin,"While we know how long a request takes to execute, previously, we didn‚Äôt know why a request was slow."
zipkin,"To collect this data, we built Pintrace, a distributed tracing pipeline that tracks a request as it‚Äôs processed across our Python and Java backend services."
zipkin,We also built Pintrace collector to help us debug performance issues.
zipkin,"Pintrace collector is a Spark job that reads spans from Kafka, aggregates them into traces and stores them in an Elasticsearch backend."
zipkin,"Today, we‚Äôre open sourcing Pintrace collector on Github, and contributing the code to the OpenZipkin community."
zipkin,"By releasing it to the community, we hope others can benefit from the project as much as we do."
zipkin,"Background
Tracking down the source of latency can be very challenging because the slowness can be caused by any one of our backend services."
zipkin,"Our metrics (OpenTSDB) and logging (ELK) infrastructure provide a coarse-grained view of how the requests are processed on the backend, but before Pintrace, it was hard to pinpoint why a request was slow."
zipkin,"To solve this challenge, we turned to distributed tracing, which tracks latency issues and shows where a request spends its time."
zipkin,"It provides fine-grained visibility into request execution by capturing request causality information (i.e., which downstream requests were executed as part of a request) in addition to request latency information."
zipkin,Pintrace is our in-house distributed tracing pipeline that tracks a request as it‚Äôs processed across our Python and Java backend services.
zipkin,"Before we look into the details, let‚Äôs define some terminology."
zipkin,Annotations are events occurring during a request.
zipkin,"For example, sending a request to the server is an annotation."
zipkin,A span represents a logical operation and contains a set of annotations that belong to that operation.
zipkin,"For example, a RPC call consisting of ‚Äúclient send‚Äù and ‚Äúclient receive‚Äù annotations is represented as a span."
zipkin,A trace is a graph of spans.
zipkin,A request execution is usually captured as a trace.
zipkin,All spans in a trace have the same trace ID.
zipkin,"For more details on how traces are structured, check out OpenTracing‚Äôs introduction."
zipkin,"Pintrace: a tracing pipeline
Building a distributed tracing infrastructure involves setting up a tracing pipeline."
zipkin,A tracing pipeline consists of two main components‚Äìsource code instrumentation and trace processing backend.
zipkin,The source code instrumentation is responsible for tracking the request across services and generating events (spans) as the request is processed along various services.
zipkin,"The trace processing backend is responsible for aggregating the generated spans, processing them into traces and storing them."
zipkin,The stored traces can be searched and visualized in a UI.
zipkin,The Pintrace tracing pipeline consists of several components shown in the following diagram.
zipkin,The components in blue are built in-house.
zipkin,"Source code instrumentation
Source code instrumentation is the bulk of the work when setting up a tracing pipeline."
zipkin,The instrumentation is responsible for generating spans that belong to the same request with the same trace ID.
zipkin,"To achieve this, the instrumentation does three tasks: (a) propagating the trace ID along with every request (b) generating the spans for every logical operation performed by that component and ¬© sending the generated spans to the backend."
zipkin,The first two responsibilities are implemented by a tracer.
zipkin,A logger implements the third responsibility.
zipkin,"At Pinterest, we log the spans to Kafka using an analytics tool called Singer."
zipkin,"Pintrace backend consists of Thrift services written in Python, Java, Go, Node and C++, each using different frameworks."
zipkin,"To trace a request across these services, we implemented a tracer for each language framework combination."
zipkin,"Pinterest has a common framework per language, and most services we‚Äôre interested in are written in Python and Java, so we only had to instrument Python and Java frameworks."
zipkin,"When we first started building Pintrace, the initial goal was to track down network request latency, so we focused solely on capturing the network activity of a request as spans in Python and Java applications."
zipkin,"Python instrumentation
Our Java services are fronted by a monolithic Python application called ngapi, a HTTP service that handles all incoming requests to our backend."
zipkin,"To serve a request, ngapi talks to several Java services over Thrift and implements a custom web framework based on the Python gevent library."
zipkin,"Since it‚Äôs a custom framework, we implemented our own tracer to trace the requests passing through it."
zipkin,We wrote a tracer for our web framework using the open tracing API.
zipkin,The tracer propagated the trace ID from the HTTP interface to the Java Thrift service using a custom Thrift wrapper provided by Finagle.
zipkin,"In addition, the tracer generated spans for all Thrift, Memcache and HTTP requests."
zipkin,"To report these spans, we wrote a logger that took the generated spans, converted them to Zipkin format and logged them to Kafka using Singer."
zipkin,"Since ngapi is managed in a monorepo and deployed as a monolithic application, the change to enable tracing is deployed in a single step across all frontend services."
zipkin,"Java tracer and logger
Our Java services use an in-house framework called ‚Äúservice framework,‚Äù a wrapper around Twitter‚Äôs Finagle library."
zipkin,"Since Finagle ships with a Zipkin tracer, we didn‚Äôt build a new tracer for our Java services."
zipkin,"By default, Finagle tracer writes the gathered spans to scribe or a log file, but since we wanted to write our spans to Kafka using Singer, we wrote a span logger that logs the spans to Singer."
zipkin,"Once the tracer and logger are in place, we enabled them in our service framework."
zipkin,"However, our service framework lacked a way to enable tracing in all apps at once."
zipkin,"To avoid duplicating this logic in more than 100 applications, we updated the service framework to have a global config and enabled tracing in it."
zipkin,Then we updated our Java apps to use this global config from the updated service framework.
zipkin,The hardest parts of enabling tracing in Java was making the change in hundreds of apps and working to deploy the changes across the organization.
zipkin,"Sampler
Even though our client instrumentation has really small latency overhead, there‚Äôs double digit computation overhead added by capturing the spans and logging them."
zipkin,"To reduce this overhead, as well as the cost of storing the generated traces, we only trace a small set of the overall requests."
zipkin,A sampler component decides which requests should be traced and randomly selects between 0 to 1 percent (typically 0.3 percent) of all of our backend requests.
zipkin,This rate can be dynamically adjusted using the decider framework.
zipkin,We also sample all requests on development machines so developers can use traces as part of their day-to-day activities.
zipkin,"Trace processing backend
The trace processing backend, as shown in the diagram above, is responsible for aggregating the spans from thousands of machines in our cluster, processing them into traces and storing and visualizing them."
zipkin,"Singer-Kafka pipeline
The Singer-Kafka pipeline is responsible for aggregating the spans generated by several processes across thousands of machines and writing them to a Kafka topic."
zipkin,We use Singer as our span aggregation pipeline.
zipkin,The Python and Java loggers log the spans to local files.
zipkin,The Singer daemon installed on each host tails these files and writes the spans to a Kafka topic.
zipkin,"Pintrace collector
We used the OpenZipkin backend to ingest the spans, but the captured traces revealed a few issues."
zipkin,"For example, some of our instrumentation can be faulty."
zipkin,"In those cases, we‚Äôd like to fix the faulty span or drop the span until we fix the instrumentation."
zipkin,"Even with careful sampling, at our scale, we see a lot of similar traces."
zipkin,"Instead of storing those traces, it‚Äôd be more cost-effective to further sample the traces at ingest time and only store high-value traces."
zipkin,"These features were challenging to add to our backend, so we built Pintrace collector, a Spark job that reads spans from Kafka, aggregates them into traces and stores them in an Elasticsearch backend."
zipkin,"We chose Spark for implementing the pipeline since it‚Äôs flexible and scalable enough to implement the needed filtering, grouping spans by trace ID and aggregating spans over time windows for analytics purposes."
zipkin,"As an added bonus, the Spark job allows us to run real-time analytics on the spans without storing them."
zipkin,The image below shows the internal architecture of Pintrace collector.
zipkin,StreamFactory is a extensible interface that ingests data from Kafka or any other transport.
zipkin,The ingested spans are then processed to ensure they‚Äôre properly formed using a data quality checker.
zipkin,"Optionally, the filtering step filters spans based on criteria like service name or annotations on the span."
zipkin,The aggregation phase groups the spans by time or trace ID.
zipkin,The final consumer stage persists the data to a storage system like ElasticSearch service.
zipkin,"Zipkin UI
As shown in the architectural diagram, we use Zipkin UI to search and view the traces stored in the ElasticSearch cluster."
zipkin,We‚Äôve also contributed a few bug fixes to the Zipkin UI.
zipkin,"Open sourcing Pintrace collector
Over the last year, we‚Äôve noticed others in the OpenZipkin community looking for the same solutions we implemented in Pintrace, such as more advanced sampling and stream processing to support Vizceral visualizations."
zipkin,We wanted to share our work with the community while also leveraging its collective expertise.
zipkin,"In order to be as open as possible, we‚Äôre contributing our code directly to OpenZipkin under zipkin-sparkstreaming code base."
zipkin,We encourage you to watch or collaborate with us in building Zipkin-spark.
zipkin,We hope you find the Pintrace collector as useful as we do.
zipkin,We can‚Äôt wait to see new ideas from the community.
zipkin,"For continued reading, read part 2: Applications of (pin)trace data
Acknowledgements: The contributors to this project are Naoman Abbas, Phoebe Tse, Ashley Huynh, Alejandro Garcia Salas, Emmanuel Udotong, Brian Overstreet, Xiaoqiao Meng and Suman Karumuri."
zipkin,We would also like to thank Adrian Cole for his feedback and advice during the project.
zipkin,"If you want a much more comprehensive article about OpenTracing, check out the following article."
zipkin,"Tracing HTTP request latency in Go with OpenTracing
In Go 1.7 we have a new package net/http/httptrace that provides a convenient mechanism for observing what happens‚Ä¶
medium.com

I thought that there was a lot of code and words for a single sitting, so I‚Äôve decided to distill most of it down for those of us that are new to application tracing."
zipkin,We will use the following library without the use of Jaeger.
zipkin,Most of the code was stolen from their /examples section.
zipkin,"openzipkin/zipkin-go-opentracing
zipkin-go-opentracing - OpenTracing Tracer implementation for Zipkin in Go
github.com

Our Application
We will set up a Proxy server."
zipkin,"When a request comes in, we will start a ‚Äúspan.‚Äù When the response comes back, we will end the span."
zipkin,"If we took this a step further, we could record ongoing requests and see which requests land on which services."
zipkin,"When we start our application, we will need to do a bit of initialization."
zipkin,"// Here are some of the necessary components that an application reporting to Zipkin will need
collector, err := zipkin.NewHTTPCollector(zipkinHTTPEndpoint)
if err != nil {
  fmt.Printf(""unable to create Zipkin HTTP collector: %+v"", err)
  os.Exit(-1)
}
recorder := zipkin.NewRecorder(collector, debug, hostPort, serviceName)
tracer, err := zipkin.NewTracer(
  recorder,
  zipkin.ClientServerSameSpan(sameSpan),
  zipkin.TraceID128Bit(traceID128Bit),
)
if err != nil {
  fmt.Printf(""unable to create Zipkin tracer: %+v"", err)
  os.Exit(-1)
}
// We will use this as the way to tracking traces between requests and responses
cache := make(map[int64]opentracing.Span)
In our request handler, we will start the trace."
zipkin,"// Here is where we create the start of our ""span""
// You can see that there isn't anything Zipkin-specific below
span := tracer.StartSpan(""GotRequest"")
cache[ctx.Session] = span
tracer.Inject(
 span.Context(),
 opentracing.HTTPHeaders,
 opentracing.HTTPHeadersCarrier(req.Header))
ctx.Logf(""%v"", req.Header)
// This tag is viewable by clicking on the trace *and* clicking
// on the span in the trace
span.SetTag(""Host"", req.Host)
span.LogEvent(""Injection"")
Finally, we use our response header to finish the span."
zipkin,"Shibuya Java is a Java meetup in Tokyo, Japan."
zipkin,I talked about Zipkin and Brave in 18th of this meetup at 28 January 2017.
zipkin,"Zipkin is a distributed tracing system created by Twitter, Inc and open-sourced in 2012."
zipkin,"In particular, it helps to extract performance bottleneck."
zipkin,Brave is a Java library to send tracing data to the Zipkin server.
zipkin,"Currently, Zipkin has been rewrote with Spring Boot, and a Adrian Cole who is a Pivotal engineer seems to be working as a full-time committer."
zipkin,"openzipkin/zipkin
zipkin - Zipkin is a distributed tracing system
github.com

openzipkin/brave
brave - Java distributed tracing implementation compatible with Zipkin backend services."
zipkin,"github.com

As a important point, Brave puts tracing data received from previous service into ThreadLocal in ServletFilter, and retrieve it and add to the HTTP header in the interceptor of the HTTP client library (Brave provides interceptor for Apache HTTP Components and OkHttp)."
zipkin,"So if the next service call is run on the another thread, tracing data can‚Äôt be related with a parent."
zipkin,"In addition, we can send tracing data to Stackdriver Trace which is a monitoring service provided by Google Cloud Platform by using stackdriver-zipkin instead of the default Zipkin server."
zipkin,We don‚Äôt need to setup and maintain our Zipkin server (and storage!
zipkin,"), it might be big help for us."
zipkin,"GoogleCloudPlatform/stackdriver-zipkin
stackdriver-zipkin - Adapters for using Zipkin instrumentation with Stackdriver Trace
github.com

Zipkin has client libraries for many languages and also external services support a Zipkin protocol like this Stackdriver."
zipkin,Zipkin has possibility to became a defacto tracing protocol not even as a individual tool in the future.
zipkin,There is a tiny example project of sending tracing data to Zipkin from servlet using Brave.
zipkin,"If you have interested in Zipkin, clone this repository and try to run it according to README."
zipkin,"Hi Readers, I present to you my new article which is based on spring sleuth and Zipkin projects from the spring cloud umbrella."
zipkin,Spring Sleuth and Zipkin are one of the most important projects which nowadays are in use since the microservices architecture has started coming in the picture.
zipkin,Most of the world nowadays is moving towards a microservices architecture for their different ERP based solutions which were earlier maintained as monolith based architecture.
zipkin,The following are brief snippets I have written about what are microservices and monolithic architecture.
zipkin,Monolith:- Monolith is a generalized term being used for application where the complete code of the application is bundled inside one complete package.
zipkin,"Let's say we have an e-commerce website where there are different business functionalities happening like placing an order, searching for a product, managing the order cycle, and managing the customer engagement platform as well."
zipkin,So everything is inside one complete bundle of the project.
zipkin,"Microservices:- As we have seen above for an e-commerce based application, where we have everything is inside one complete package."
zipkin,"Exactly reverse, For every single business functionality, we have one complete code package whereas for microservices architecture we have different services and different code package for each service to maintain."
zipkin,"As we can read above, So there are different additional responsibilities come with microservices architecture like the data transfer across all the services and then we have the monitoring part of the user journey and the application level."
zipkin,"So For monitoring the user journey web the user comes to the website, it's a very important aspect to analyze."
zipkin,"For that, we have a solution as you read through this page."
zipkin,"Spring Sleuth And Zipkin
Spring sleuth and Zipkin are basically a combination of two different projects under spring cloud which are actively getting used in monitoring the request when it goes from one service to another and to another."
zipkin,The following are some of the terms being used to track the request once it goes through different services.
zipkin,"TraceID
TraceID is the general term being used to track a request whenever the server receives a request from the user."
zipkin,"SpanID
SpanID is another general term being used to track whenever a specific span enters different services in its journey."
zipkin,"So basically I will explain these two terms with an example, Lets say we visit amazon.com."
zipkin,We clicked on ‚Äúshirts‚Äù.
zipkin,"And the request when we clicked on shirts, it went to the server asking for the details and data related to shirts."
zipkin,"So when this request is received at the server for the first time, a traceId is generated which remains the same whenever that request goes to any other service to fetch the data."
zipkin,"So now our request has gone to the second service to fetch some other data for that request, so now we will have the second spanId being generated."
zipkin,"So now to analyze this complete journey in microservices architecture, it's very difficult with existing monolithic architecture but with the monolith, we need to plugin the functionality which provides us the flexibility to read these kinds of data."
zipkin,Spring Sleuth and Zipkin help us to generate traceID and spanID as explained above and Zipkin is a kind of server with which we can analyze the data generated based on traceID and spanID.
zipkin,The following are some of the snippets we have to use.
zipkin,"Add the dependency in Build tool configurations:-

2."
zipkin,We can send the data to the Zipkin server in different ways like either in streaming formats like publishing the data to Kafka based queue and the second way of sending the data via HTTP api.
zipkin,3.
zipkin,We can add properties on the service side about application details and Zipkin related configurations as below.
zipkin,"As you can see above, I have listed three basic properties for Zipkin and spring boot application which helps us identify the data is coming from which service."
zipkin,4.
zipkin,When we are creating a server for Zipkin we can add the following dependency and start receiving the data on the Zipkin server and can visualize the data on the Zipkin dashboard and analyze different spans and traces and check the bottlenecks if any.
zipkin,So this is a very basic implementation of Spring sleuth and spring Zipkin which can be used as a starting point who so ever is starting to use it.
zipkin,I will keep on updating this article to make it easily understandable and to get the maximum value out of it.
zipkin,Please drop me a comment or a query about anything around this topic or around any web-based architectures.
zipkin,"Please refer to visual explanation above at https://www.youtube.com/watch?v=Y5YhmwRwiqM
And for more innovative content, Please subscribe to my Youtube channel at https://www.youtube.com/channel/UChfpeiqISmTnAa5F_gMB5kA"
zipkin,"Around the year ~2006, I worked at a consulting company and I was assigned as an Integration Solution Architect at a utilities client to implement Service Oriented Architecture."
zipkin,I remember my manager at the time insisted us to develop a framework that will generate a request ID and propagate the same request ID to all of the subsequent service calls.
zipkin,The manager also insisted on logging the service call durations and tying them all back to the same request ID.
zipkin,"The goals were to be able to:
Determine a chain of calls in the complicated world of services."
zipkin,Debug a request and figure out which service caused errors in the chain of service calls.
zipkin,Determine if services are meeting the Service Level Agreements in terms of latency/performance.
zipkin,"Fast-forward 10+ years, I realized what we implemented was in fact a form of distributed tracing."
zipkin,We need distributed tracing more than ever in the microservices world.
zipkin,"Stackdriver Trace
Google Cloud Platform has a distributed tracing solution called Stackdriver Trace."
zipkin,Stackdriver Trace is a managed service so you don‚Äôt need to manage the server components nor the complexity of storage yourself.
zipkin,Stackdriver Trace exposes an API so you can send trace information whether you are running your services on Google Cloud Platform or anywhere else.
zipkin,"Rather than writing custom code to consume the Google Cloud Trace API directly, I wanted to use off-the-shelf components and de facto standards so that I can have a portable application and avoid vendor lock-in (and I‚Äôm also a little lazy :)."
zipkin,"Stackdriver Trace is Zipkin Ready
The good news is there is already a Zipkin proxy for Stackdriver Trace."
zipkin,I can focus on writing my application with great frameworks (such as Spring Boot and Spring Cloud) and I can record and store distributed trace data without having to worry about the infrastructure.
zipkin,The proxy can run either as a JAR file or a Docker container.
zipkin,The way you configure them are the same.
zipkin,"UPDATE April 6, 2017: Stackdriver Trace Zipkin Proxy is now moved to openzipkin/zipkin-gcp repository!"
zipkin,"In addition, if you are using Spring Boot, you can use Spring Cloud GCP Trace starter that seamlessly integrates with Spring Cloud Sleuth."
zipkin,"You can find the latest version of the executable Zipkin proxy JAR in the Stackdriver Trace Maven repository, or download the latest version:
$ wget -O zipkin-stackdriver-collector.jar \ 'https://search.maven.org/remote_content?g=com.google.cloud.trace.adapters.zipkin&a=collector&v=LATEST'
There are several ways to configure this proxy to communicate securely with Stackdriver Trace:
If you have gcloud SDK installed, it will use the credentials from gcloud SDK without additional configuration."
zipkin,"If you run it on a Google Cloud Platform virtual machine or App Engine, it will be able to use the machine credentials without additional configuration."
zipkin,"If you want to run it everywhere with a consistent credential, you can configure it to use a service account via the environment variables."
zipkin,"Service Account
I like to be portable, so I chose to use a service account."
zipkin,"If you don‚Äôt want to use service accounts, see the next section."
zipkin,"To create a service account, navigate to IAM & Admin > Service Accounts and click Create Service Account:

Make sure to add the Cloud Trace Agent role for this service account, and select Furnish a new private key with JSON key type:

Finally, click Create to create the service account."
zipkin,This will also prompt you to download the service account JSON file.
zipkin,Store this file securely; this is the credential that will be used to send and store trace data.
zipkin,"If this credential was compromised, you can invalidate the key and furnish a new one."
zipkin,"Because this service account only has the Cloud Trace Agent role, the credential won‚Äôt be able to read any trace data, nor operate against any other Google Cloud Platform APIs."
zipkin,You can enable multiple roles with the same service account if your application needs consume multiple Google Cloud Platform APIs.
zipkin,"Run the Zipkin Proxy Locally
Let‚Äôs start the proxy with some environmental variables to point to the Google Cloud Project and the service account created previously:
$ PROJECT_ID=springboot-zipkin-example \
  GOOGLE_APPLICATION_CREDENTIALS=/path/to/service/account.json \
  java -jar zipkin-stackdriver-collector.jar
Once started, it‚Äôll accept Zipkin trace data on the default port (9411)."
zipkin,"If you don‚Äôt use a service account, but have gcloud SDK installed locally (and authenticated), you can start it without any additional configuration:
java -jar zipkin-stackdriver-collector.jar
Behind the scenes, the Zipkin proxy will translate the Zipkin request into Stackdriver Trace requests, and then send the requests to Stackdriver via the high-performance gRPC API."
zipkin,The proxy is also preconfigured with netty-tcnative component that is necessary for secured gRPC access.
zipkin,"Spring Boot and Spring Cloud Sleuth
Spring Cloud Sleuth is a Spring Boot component that can easily tie into the Spring Boot microservices frameworks and intercept service calls to record trace events."
zipkin,Sleuth comes standard with a Zipkin adapter.
zipkin,"If you have your own Spring Boot application, simply add Spring Cloud Sleuth dependencies:
<dependencies>
...
  <dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId
  </dependency>
  <dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-sleuth-zipkin</artifactId>
  </dependency>
...
</dependencies>
I‚Äôve found a useful example on GitHub that I‚Äôll use as my litmus test: https://github.com/openzipkin/sleuth-webmvc-example."
zipkin,"First, clone the example:
$ git clone https://github.com/openzipkin/sleuth-webmvc-example
$ cd sleuth-webmvc-example
By default, Sleuth doesn‚Äôt send the trace data for every single request."
zipkin,You probably don‚Äôt want to trace every single request either.
zipkin,The trace sampling rate can be adjusted by configuring the spring.sleuth.sampler.percentage property.
zipkin,"For demonstration purposes, I‚Äôll increase the sampling rate to 100%:
$ echo ‚Äúspring.sleuth.sampler.percentage=1.0‚Äù >> src/main/resources/application.properties
All set."
zipkin,"I can compile the code, start the backend, and start the frontend:
$ ./mvnw compile
$ ./mvnw exec:java -Dexec.mainClass=sleuth.webmvc.Backend
$ ./mvnw exec:java -Dexec.mainClass=sleuth.webmvc.Frontend
If you aren‚Äôt using Spring Boot ‚Äî no worries."
zipkin,Zipkin proxy can accept requests from any Zipkin compatible clients.
zipkin,"For example, Brave Zipkin client can be used with gRPC, JAX-RS, Jersey, RestEasy, and more."
zipkin,"Test It Out
So far so good!"
zipkin,"The backend runs on port 9000, and the frontend runs on port 8081."
zipkin,It‚Äôll take ~100 requests before aggregated trace metrics can be analyzed.
zipkin,"I used Apache Benchmark to generate the requests:
$ ab -n 100 -c 10 http://localhost:8081/
See the Data
At the moment, the Zipkin proxy can only receive trace data but it cannot be used to visualize nor analyze the data."
zipkin,But you can see the data directly in Stackdriver Trace.
zipkin,Navigate to Trace in the Google Cloud Platform console to see the data.
zipkin,"With enough data, you can see the aggregated summary that will show you the latency density distribution, percentiles, most recent traces, most frequent URIs, and more."
zipkin,"Overview of latency distributions

See a list of traces

See a trace in detail
Not only can I see the time distribution among the different requests, I can also see additional properties such as the Spring component name and the Spring controller class name and method."
zipkin,That‚Äôs useful!
zipkin,"Detect Performance Regression
What I found most compelling about Stackdriver Trace was the ability to compare and contrast the data between two different time periods."
zipkin,"Imagine you were running v1.0 of your application for a month, and upgraded to v1.1 tomorrow."
zipkin,"Even though it‚Äôs a minor revision upgrade, how do you know if you have performance regression?"
zipkin,"In Stackdriver Trace, simply select two different time ranges to compare the latency distribution:

Give it a Try
If you‚Äôd like to give it a try, you can sign up for the Google Cloud Platform free trial."
zipkin,See Using Stackdriver Trace with Zipkin for more examples on how to use it and FAQs.
zipkin,I‚Äôd like to hear your feedback and thoughts too.
zipkin,"In my last post, I detailed some of the reasons why software activity metering, as per the Probes Open API, is a far superior approach to application performance monitoring than traditional tagged call tracing."
zipkin,Satoris itself comes with a metering extension that generates a call trace tree.
zipkin,"I don‚Äôt want to completely discount tracing, so here I‚Äôm going to show how to extend Satoris to intercept and forward on the metering of a probe, an activity, onto a new proposed [distributed] tracing standard ‚Äî OpenTracing."
zipkin,Note: I was invited to and attended the first OpenTracing inception workshop.
zipkin,"Entering and Exiting
Before delving into the metering extension lets first consider the typical call processing pattern of a service."
zipkin,"The service receives an inbound request or message event, from an external client, service or resource."
zipkin,This triggers the execution of mapped handling method ‚Äî an entry point in the diagram below.
zipkin,The call then passes through various intermediary methods.
zipkin,Let‚Äôs call them transit points.
zipkin,"Finally, a method is called which doesn‚Äôt call to another method but instead makes a request to an external service or resource."
zipkin,"These are exit points in the diagram, though they might not be outbound."
zipkin,"Today, distributed tracing calls the entry point a server side span, and an exit point as client side span."
zipkin,All those many transit points are completely ignored by distributed tracing ‚Äî an incredible oversight for performance.
zipkin,"Fortunately, Satoris offers a way to address both approaches in the metering and interception of all points in the processing, then selectively forwarding on measurement data pertaining to those points deemed tracing spans."
zipkin,"Interception and Integration
Interception of a metered probe is straightforward."
zipkin,Write an interceptor factory class and register it with the enabled interceptor metering extension.
zipkin,"jxinsight.override.config
The factory class needs to create an interceptor when a thread, a context in the metering interface, is first metered by the metering engine."
zipkin,"InterceptorFactory.java
The interceptor returned by the factory represents the metered call stack for a particular thread, recording the outermost probe, an entry point, as well as the last metered probe, a transit or exit point."
zipkin,"InterceptorFactory.java
When a firing probe is begun by the metering engine the interceptor metering extension calls the begin method on the interceptor that‚Äôs mapped to the current thread."
zipkin,If the root isn‚Äôt set then a server side trace span is created with the clock time extracted from the probes meter readings.
zipkin,"InterceptorFactory.java
The end method on the interceptor is called by the interceptor metering extension when a metered probe has ended."
zipkin,If the probe was previously marked as the root then the span created when the probe was begun is finished.
zipkin,If the probe is instead the last metered probe then it must be a leaf and an exit point.
zipkin,"When a leaf, a client side span is created, then started, and finally finished using both low and high probe meter readings."
zipkin,Transit probes metered by the engine are not forwarded onto the tracing system.
zipkin,"InterceptorFactory.java
Testing and Tracing
To test the above interception code I created the following test class."
zipkin,"ExtensionTest.java
Running the Satoris instrumentation agent with the above configuration along with a sprinkling of print calls in the code the following is outputted."
zipkin,"console.output
Done!"
zipkin,Note: OpenTracing offers the ability to attach additional execution context to a trace span.
zipkin,This can be supported using the Environment interface obtainable from the thread context during both begin and end interception callbacks.
zipkin,Further Reading
zipkin,"A Portuguese, a Mexican and a Peruvian walk into a bar and order a beer‚Ä¶
‚Ä¶ in New Delhi."
zipkin,"Photo by Bhumika Singh on Unsplash
This sounds like the start of a classical bar joke, but was actually the day my colleagues and I were checking-in for our trip to Delhi."
zipkin,"That day, while looking for the trip in the Expedia‚Ñ¢ App, we experienced some latency when retrieving the trips list."
zipkin,"When we contacted the Trips team to report the latency, the maintainers of the flights service wondered why it was taking so long to respond."
zipkin,They started with Haystack to view the relevant distributed traces.
zipkin,Distributed Tracing is an observability tool for understanding latencies and error requests that traverse distributed systems.
zipkin,Its model is based on two main concepts: traces and spans.
zipkin,"A trace is a hierarchical tree of spans distributed over a timeline, describing the whole operation in a system, whereas spans represent meaningful operations between components of the system (e.g."
zipkin,a database call or an http request) linked by a parent-child relationship.
zipkin,One trace can contain many spans but one span can only belong to one trace and can have zero or one parent.
zipkin,"the /my-trips trace consists of several spans, a /auth one, and a /trips one which itself has /tracking and /flights spans
The whole graph represents a trace and every box represents a span
In the graph above we can see a hypothetical example trace at expedia.com where a call to /my-trips goes through the authorization service first to get the user context and then to the trips API which calls the tracking API and the flights API to retrieve the flights."
zipkin,Quite straightforward to understand isn‚Äôt?
zipkin,"However when the maintainers of the flights service looked at the distributed trace for the/my-trips request, it looked incomplete."
zipkin,There were many gaps in the timeline of what happened and it was really hard for them to understand why the flight listing was presenting a higher latency to respond.
zipkin,"To explain how we fixed that, I‚Äôll take a quick detour into our tracing implementation history."
zipkin,"Once upon a time‚Ä¶
Some time ago Expedia Group decided to use Zipkin instrumentation to complement the powerful features brought by Haystack

Unfortunately, in practice this was harder than expected: some of the legacy systems were emitting spans using UUIDs for traceId and spanId thus downstream services using Zipkin instrumentation met some incompatibilities as their IDs are 128-bit (two Long values) for traceId but 64-bit (one Long value) for spanId and parentSpanId hence the UUIDs (two Long values) can‚Äôt fit."
zipkin,Whether UUIDs for spanId are appropriate or not is not relevant to this story but it is worth mentioning that spanIds are only unique within a trace and hence using a high random value like UUID feels too heavy.
zipkin,"This is how the Mexican, the Portuguese and the Peruvian from three different brands inside Expedia Group, decided to tackle the problem, following their open source spirit and trusting that their complementary skills would end up with a solution or at least a nice story to tell (about either Indian beers or distributed tracing)."
zipkin,Brave is the standard distributed tracing library for Zipkin in Java (but not limited to Zipkin).
zipkin,It has quite a mature model and includes 25+ instrumentations out of the box.
zipkin,Our approach to avoid the problem of fitting a UUID (two Long) in the Brave‚Äôs spanId (one Long) was based on one main idea: We use any random IDs in the trace context but we keep the UUIDs in the context so later we could replace them for both reporting and propagation.
zipkin,"The idea is that no matter what the value of spanId we set in the context, if we keep the UUID somewhere, we could do the mapping later."
zipkin,"After digging in to the Brave API looking for a way to trick its model, we found we didn‚Äôt even need to trick it, there was a way to do exactly what we were looking for: Brave Extra Context API to store the UUIDs in the context."
zipkin,"Extra Context accepts objects, keeps them in the context and transmits them to its child contexts."
zipkin,"/**
 * Extra holds the information of the inbound context to be kept 
 * and use as replacement in propagation and reporting."
zipkin,"*/
internal data class OriginalIDs(
    val traceIdAsUUID: String, // The incoming trace ID in UUID
    val spanIdAsUUID: String,  // The incoming span ID in UUID
    val parentSpanIdAsUUID: String?, // The incoming parent span ID
                                     // in UUID
    val syntheticRootSpanId: Long,  // The synthetic local root span
                                    // ID for the trace
)
The OriginalIDs.traceIdAsUUID is the propagated trace ID in UUID format coming from the upstream call."
zipkin,The OriginalIDs.spanIdAsUUID is the propagated span ID in UUID format coming from the upstream call.
zipkin,The OriginalIDs.parentSpanIdAsUUID is the propagated parent span ID in UUID format coming from the upstream call.
zipkin,"The OriginalIDs.syntheticRootSpanId is a synthetic 64-bit value for the assigned spanId in the trace context, this is when we create the context on extraction, we set this value as spanId even when this value has no direct relationship with the propagated span ID from upstream."
zipkin,"// Copied from Brave as we need to generate IDs in the same way https://github.com/openzipkin/brave/blob/ae2b26adda/brave/src/main/java/brave/Tracer.java#L645
private fun nextId(): Long {
    var nextId = Platform.get().randomLong()
    while (nextId < 0L) {
        nextId = Platform.get().randomLong()
    }
    return nextId
}
internal class Extractor<C, K>(
    private val propagation: UUIDPropagation,
    private val getter: Propagation.Getter<C, K>,
): TraceContext.Extractor<C> {
    override fun extract(carrier: C): TraceContextOrSamplingFlags {
        var samplingFlags = SamplingFlags.EMPTY
        if (getter.get(carrier, propagation.debugKey) != null) {
            samplingFlags = SamplingFlags.DEBUG
        }
        val traceIdAsUIDString = getter.get(carrier, propagation.traceIdKey) ?"
zipkin,": return TraceContextOrSamplingFlags.create(samplingFlags)
        
        val spanIdAsUIDString = getter.get(carrier, propagation.spanIdKey) ?"
zipkin,": return TraceContextOrSamplingFlags.create(samplingFlags)
        val parentIdAsUIDString = getter.get(carrier, propagation.parentSpanIdKey) ?"
zipkin,": null
        var result = TraceContext.newBuilder()
        val syntheticRootSpanId = nextId()
        val extra = OriginalIDs(traceIdAsUIDString, spanIdAsUIDString, parentIdAsUIDString, syntheticRootSpanId)
        result = result
                 .sampled(true)
                 .debug(samplingFlags.debug())
                 // we will always replace the traceId
                 .traceId(nextId())
                 .traceIdHigh(nextId())
                 // if spanId == syntheticRootSpanId we replace the
                 // spanId from the original IDs
                 .spanId(syntheticRootSpanId) 
                 .extra(listOf(extra))
        if (parentIdAsUIDString != null) {
            // if spanId == syntheticRootSpanId we replace the
            // parent from the original IDs
            result.parentId(nextId()) 
        }
        
        return TraceContextOrSamplingFlags.create(result.build())
    }
}
This means, the value of syntheticRootSpanId (that can appear in TraceContext.spanId or TraceContext.parentSpanId) should be replaced by the OriginalIDs.spanIdAsUUID on reporting (i.e."
zipkin,sending the tracing information to the tracing collector) or propagation (i.e.
zipkin,propagating the context in subsequent calls).
zipkin,"As mentioned before, one advantage of the extra context is that they get transmitted to all descendant contexts and that solves the need for replacing the value of syntheticRootSpanId in TraceContext.parentSpanId of immediate children."
zipkin,"Once the local propagation of the UUIDs was guaranteed, we just needed to tackle outbound propagation and the reporting."
zipkin,"For both cases it was important to set a convention on how to turn Brave‚Äôs spanId into UUIDs (remember, child contexts will have 64 bit spanId and we need to report and propagate UUIDs), the easiest way was to prepend zeros to the value of spanId as UUID is composed of two Long."
zipkin,"That is easy:
val spanIdAsUUID = new UUID(0L, context.spanId)
This convention ensures the consistency of IDs between reporting and outbound propagation because we need to propagate UUIDs to downstream services anyway."
zipkin,"With all the details sorted out, we were ready to implement the solution for the both parts:
The outbound propagation piece was fairly straightforward as we just need to use the OriginalIDs.traceIdAsUUID and maybe replace the TraceContext.spanId value with the OriginalIDs.spanIdAsUUID if TraceContext.spanId == syntheticRootSpanId ."
zipkin,The reporting piece was a bit more complicated.
zipkin,"If we take a look at the Reporter API:
import zipkin2.Span;
...
public interface Reporter<S> {
   /**
    * Schedules the span to be sent onto the transport."
zipkin,"*
    * @param span Span, should not be <code>null</code>."
zipkin,"*/
    void report(S span);
}
We notice that span being used on reporting zipkin2.Span does not have access to the trace context."
zipkin,But again the Brave API came to rescue with the FinishedSpanHandler API.
zipkin,"This interface allows us to do changes in the reported span, and we have access to the context at this step."
zipkin,We took advantage of this by copying the information from the OriginalIds into synthetic tags which can be accessed and later ignored by the Reporter.
zipkin,"...
import brave.handler.MutableSpan as ZipkinMutableSpan
object SyntheticTagsHandler : FinishedSpanHandler() {
    private const val SYNTHETIC_ID = ""x-message-propagation-synthetic-id""
    private const val TRACE_ID = ""x-message-propagation-trace-id""
    private const val SPAN_ID = ""x-message-propagation-span-id""
    private const val PARENT_SPAN_ID = ""x-message-propagation-parent-id""
override fun handle(context: TraceContext, span: ZipkinMutableSpan): Boolean {
    val originalIDs = context.findExtra(OriginalIDs::class.java) ?"
zipkin,": return
    span.tag(SYNTHETIC_ID, originalIDs.syntheticId.toString(16).padStart(16, ‚Äò0‚Äô))
    span.tag(TRACE_ID, originalIDs.traceId)
    span.tag(SPAN_ID, originalIDs.spanId)
    if (originalIDs.parentSpanId != null) {
        span.tag(PARENT_SPAN_ID, originalIDs.parentSpanId)
    }
    return true
}
    internal fun isSyntheticTag(key: String): Boolean {
        return key == SYNTHETIC_ID 
            || key == TRACE_ID 
            || key == SPAN_ID 
            || key == PARENT_SPAN_ID
    }
    private fun getTraceId(tags: Map<String, String>): String = tags[TRACE_ID] ?"
zipkin,": throw NullPointerException(""Missing $TRACE_ID synthetic tag"")
    private fun getSyntheticId(tags: Map<String, String>): String = tags[SYNTHETIC_ID] ?"
zipkin,": throw NullPointerException(""Missing $SYNTHETIC_ID synthetic tag"")
    private fun getSpanId(tags: Map<String, String>): String = tags[SPAN_ID] ?"
zipkin,": throw NullPointerException(""Missing $SPAN_ID synthetic tag"")
    private fun getParentId(tags: Map<String, String>): String?"
zipkin,"= tags[PARENT_SPAN_ID]
}
This handler makes sure the original ids are added as tags and it is the serializer‚Äôs responsibility (or the reporter‚Äôs if there is no serializer) to obtain the final traceId, spanId and parentSpanId from the synthetic tags and discard the synthetic tags after that."
zipkin,"The advantage of this approach is big, we can not only use all Brave instrumentations without friction but we could also later introduce hybrid propagation ‚Äî meaning that we could accept both UUIDs and B3 for a progressive rollout ‚Äî as Expedia Group is moving towards B3 format for propagation."
zipkin,"We wonder what can‚Äôt be done with Brave (and what beer we should order when in Delhi)
Recommended readings/videos:
https://medium.com/nikeengineering/hit-the-ground-running-with-distributed-tracing-core-concepts-ff5ad47c7058
https://medium.com/observability/want-to-debug-latency-7aa48ecbe8f7
https://www.youtube.com/watch?v=WM_FZn7Wr0Y
https://www.youtube.com/watch?v=XcRWj5pMhdQ
https://medium.com/@autoletics/scaling-distributed-tracing-c848d911ae2e (more advance reading about distributed tracing)
Learn more about technology at Expedia Group"
zipkin,"Hi, This is a continuation of part-1, Where we have seen the development and running the distributed springboot microservices using docker and docker-compose."
zipkin,"If you haven‚Äôt read that, I recommend to please go through it once."
zipkin,"As we discussed earlier, Now we will see zipkin integration and monitoring the trace."
zipkin,"Photo by Anastasia Dulgier on Unsplash
To understand the integration part, we need to see the docker-compose file again and observe the environment variables closely:

Spring boot will first check for environment variables, then for application properties and then it will use the default values."
zipkin,"As we are setting environment variables through docker-compose, this values will be picked."
zipkin,"Simple example to convert application.properties to environment variables
eg:
    application.properties        environment variable
      custom.next-call             CUSTOM_NEXT_CALL
    spring.application.name      SPRING_APPLICATION_NAME
I will quickly go through all environment variables, to get a better understanding and also recommend to see the code to understand its functionality code."
zipkin,"Custom propertices:
CUSTOM_NEXT_CALL : type boolean -> flag used to calls other microservices."
zipkin,CUSTOM_URLS: type String Array -> list of other microservies endpoint.
zipkin,CUSTOM_DELAY: type long -> custom delay time.
zipkin,CUSTOM_DELAY_METHOD: type boolean -> flag used to call delay method.
zipkin,CUSTOM_MESSAGE: type String -> microservice response message.
zipkin,CUSTOM_HTTP_STATUS_SUCCESS: type boolean -> flag used to set http status code either 200(ok) or 500(internal server error).
zipkin,"Spring propertices:
SPRING_APPLICATION_NAME: to set application name."
zipkin,SPRING_ZIPKIN_ENABLED: to enable trace posts to zipkin server.
zipkin,SPRING_ZIPKIN_BASE_URL: to set zipkin base url.
zipkin,to get more spring cloud sleuth properties click here.
zipkin,"As we got a good understanding with the docker-compose file, Now I will quickly run the docker-compose file and show you the trace and telemetry we can get through Zipkin."
zipkin,"To start the docker-compose run the following command
docker-compose up
wait until all services are up as shown below:

Now hit the client-module service with the url: http://localhost:9900/module and wait for the response as show below:

As we can see the response, there are some modules with default message, some with custom message and some with error message, So let‚Äôs open zipkin and see the trace and connection of the request we did."
zipkin,"Open http://localhost:9411/zipkin/

Click on the trace to analize time distribution between the modules

Here we can clearly observe the time taken by each module to serve the request, and also failed request in red color."
zipkin,Let‚Äôs analyze module connection and identify the failed requests.
zipkin,"With this, we can easily identify the request flow through the distributed microservices, see the requests in-coming in and out-going, analyze latency and success rate."
zipkin,"Hope you learn some thing, Thanks for your time."
zipkin,Github link : https://github.com/indrajagadeesh/SpringBoot-distributed-tracing-with-zipkin
zipkin,Ever since microservices are increasing in demand and every organization focuses on a microservices architecture.
zipkin,What is Microservice Observability?
zipkin,"In general terms, it is the ability to observe all the behaviors be it a success, failure, or exception."
zipkin,"If we have observed all the behaviors, then we can act accordingly to solve those issues and make the application more robust and fault-tolerant."
zipkin,For Ex: Security Cameras record all the activities of a day.
zipkin,"When there is an unusual activity, security cameras are thoroughly observed and we will come to a conclusion on suspicious activity on a particular period of time."
zipkin,"Key Concepts of Observability
Metrics:- Stats around the microservices to understand what happened around it over a period of time."
zipkin,"Logging:- They help in analyzing what is happing around the system whether the requests are successful, failure, or exception."
zipkin,"Tracing:- In a microservice ecosystem, a workflow/request can talk to multiple services."
zipkin,So tracing helps us to track the workflow in a productive way.
zipkin,How to achieve all these in micro-service ecosystem?
zipkin,I am going to explain in spring boot how to achieve observability using Zipkin and spring cloud sleuth.
zipkin,"For this, we go over a use case spread across different microservices."
zipkin,I have created a simple use case in aggregator mode.
zipkin,"In the above diagram, we have a user registration use case spread across different service calls."
zipkin,This might be a simple use case but I have made it look complex so that we can trace the workflow/request.
zipkin,Aggregator Service:- This service will make multiple service calls and aggregate the response to the caller.
zipkin,Registration Service:- This service will register the user to the backend system and return the response to the caller here it is an aggregator service.
zipkin,Notification Service:- This service will trigger either an email or SMS after successful registration for the user.
zipkin,"RapidAPI Service:- This service will call some additional information after successful registration like tips, a fortune of the day."
zipkin,I am using RapidAPI for the same.
zipkin,"Use of Zipkin
Zipkin was originally developed at Twitter, based on a concept of a Google paper that described Google‚Äôs internally-built distributed app debugger dapper."
zipkin,It manages both the collection and lookup of this data.
zipkin,"To use Zipkin, applications are instrumented to report timing data to it."
zipkin,It helps in monitoring application latency by checking the traces of application logs.
zipkin,These traces backed by chronology order will help in analyzing the overall system performance and helps in identifying the piece which has latency.
zipkin,Zipkin has four components.
zipkin,How to install Zipkin?
zipkin,Zipkin can be installed in a standalone way or through a docker container.
zipkin,Please see the details here.
zipkin,"For the demo purpose, I have chosen a standalone way to download the jar and start as a java process."
zipkin,The jar here is a spring boot application.
zipkin,"java -jar <zipkin-jar-version>
After executing the above command, the Zipkin should start."
zipkin,"It started through the port 9411, Zipkin has web-UI available from 9411 port."
zipkin,Now open http://localhost:9411/zipkin/ to see UI.
zipkin,What is Sleuth?
zipkin,"Sleuth is from the spring-cloud family, generates traceid, spanid when communicating to multiple microservices to their headers and MDC."
zipkin,"This information is used by tools like Zipkin to store, index, and process them for metrics."
zipkin,"As it is from the spring cloud family added once to the classpath, automatically integrates with common communication channels of spring boot applications to external systems via RestTemplate, Zuul proxy, Queues (RabbitMQ, Kafka), MVC controllers."
zipkin,"Dependency:
<dependency>
      <groupId>org.springframework.cloud</groupId>
      <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>
Zipkin and spring cloud integration example:
We will consider the above-said use case for demo."
zipkin,"Dependencies to be added:
Few dependencies have to add for the Zipkin and sleuth integration and few properties have to include."
zipkin,"<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-dependencies</artifactId>
            <version>Greenwich.SR2</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
Properties to be added:
In addition to port and other specific properties for spring boot, Zipkin has to be enabled."
zipkin,"spring.zipkin.enabled=true
Microservices:
In order to serve the use-case, we have 4 microservices as we earlier discussed."
zipkin,Let's start all the microservices.
zipkin,I have posted one request.
zipkin,"Let's see Zipkin dashboard



The traceid, spanid are created from each microservice and Zipkin reads the data and shows us in UI."
zipkin,"The line
2020‚Äì08‚Äì13 11:57:26.453 INFO [rapidapi-service,64744084940f1721,779dcbd55b422fbb,true] 1334 ‚Äî ‚Äî [nio-8084-exec-1] c.s.r.controller.DailyTipsController: Daily Trips API Invoked‚Ä¶
The highlighted one is the key to Zipkin [service-name, trace-id, span-id, enabled], this is how Zipkin keeps tracking of the log trace."
zipkin,It‚Äôs the sleuth‚Äôs responsibility to create these ids and any of the distributed tracing service providers can make use of these ids to visualize workflow/request.
zipkin,"Now if one of the services is down, here RaipdAPI service is down


One of the services takes more time than usual."
zipkin,"In the notification-service, I made the thread idle for 500ms, I increased to 20 seconds."
zipkin,"As the rest template has read time out of 10 seconds, the request should throw read time out."
zipkin,A business logic exception can also be tracked in a similar way.
zipkin,As I initially stated that Zipkin is non-persistent and has only an in-memory data store.
zipkin,If the Zipkin server is restarted all the data is lost.
zipkin,"In order to make it persistent, it is providing few options out of the box for cassandra, Mysql and elasticsearch."
zipkin,I will try to make another post on cassandra and Mysql.
zipkin,"In 2010, Google put online a paper, ‚ÄúDapper, a Large-Scale Distributed Systems Tracing Infrastructure‚Äù."
zipkin,"Like many other Google publications on distributed systems, in the couple years following many open source projects started working on distributed tracing, all inspired by Dapper."
zipkin,"In June 2012, two years after the Dapper paper was out, Twitter opensourced Zipkin, the first distributed tracing open source project inspired by Dapper."
zipkin,Zipkin was created for application performance tuning.
zipkin,It has both tools to collect tracing data and a UI for visualization and trace data lookup.
zipkin,"As the first open source end to end solution in distributed tracing, Zipkin was widely adopted."
zipkin,"The community stayed relatively quiet for more than two years after Zipkin was released, until Kubernetes was started in 2014."
zipkin,"However, we needed to wait until 2015 to see some of the big advancements:
In February 2015, the author of the Dapper paper, Ben Silgelman, left Google and started Lightstep."
zipkin,"Also in February, Uber started an internal tracing project called Jaeger."
zipkin,"In June, Kubernetes 1.0 was released, together with the announcement of CNCF."
zipkin,"In November, the OpenTracing project was started by LightStep."
zipkin,OpenTracing was created to solve the problem of standardization.
zipkin,"To collect a complete distributed trace, trace context has to pass through all the components, which includes application code, dependent libraries, open source standalone services (nginx, mysql), and other vendor specific libraries and services."
zipkin,"Without a standard API to define the collection and passing of trace context, it‚Äôs almost not possible to collect the full trace without all components binding to a specific tracing vendor."
zipkin,"OpenTracing was built to solve that problem, by defining a standard API, so components from different vendors could implement the same API, to make it possible to collect end to end tracing data passing through different systems."
zipkin,"By 2016, projects became more mature."
zipkin,"In October, Uber open sourced Jaeger."
zipkin,Jaeger was inspired by Dapper and Zipkin.
zipkin,It has native support for the OpenTracing standard.
zipkin,"It provides backward compatibility with Zipkin, so if you have code already instrumented with Zipkin libraries, you can directly route data from Zipkin libraries to Jaeger backends."
zipkin,"In Oct 2016, OpenTracing was accepted by CNCF as the third hosted project."
zipkin,"Two months later, OpenTracing 1.0 was released."
zipkin,"2017 started with a new project created by Google, OpenCensus."
zipkin,"OpenCensus came to play quite late, but it started with a broader scope: trace plus metrics, to provide a single standard to collect both metrics and traces."
zipkin,"Unlike OpenTracing, which only defines a standard API and relies on third party vendors to provide specific implementations, OpenCensus starts with providing native libraries to support third party vendor backends."
zipkin,"This gives the project more control over the available solutions, and it‚Äôs also easier for developers to understand how different pieces work together."
zipkin,Why do we need OpenCensus when we already have OpenTracing?
zipkin,"As mentioned, OpenTracing only defines the tracing data spec, and has an API library defined for each common programming language like Java/Go/Javascript etc."
zipkin,"It does not provide actual implementation of the API, nor does it provide a backend system to store and analyze tracing data."
zipkin,"The advantage of this approach is, as a developer, you can choose different vendor implementations which support OpenTracing without worrying about being locked in."
zipkin,"As a third party vendor, you have enough flexibility to provide vendor specific features."
zipkin,The disadvantage is also obvious- developers need to find another vendor library which supports the OpenTracing API to build a end to end solution.
zipkin,"On the other hand, OpenCensus provides not only the spec and API, but also the implementation, which makes it much easier to build an end to end system."
zipkin,"In January 2018, OpenCensus 1.0 was released."
zipkin,"Even with standard API definitions like OpenTracing and OpenCensus, different tracing systems still use their own set of headers to propagate tracing context."
zipkin,"This creates an issue when tracing requests that pass through components from different vendors, especially the components that developers do not have direct control of, like managed services, load balancers etc."
zipkin,"In July 2018, Google and other vendors started work under W3C to define a standard HTTP context propagation header, so that tracing context can easily pass through components from different vendors."
zipkin,2019 started with the merge of OpenTracing and OpenCensus into OpenTelemetry.
zipkin,"As mentioned above, OpenTracing provides a lot of flexibility by only defining an API layer without providing implementation."
zipkin,OpenCensus provides an out of box implementation but lacks the flexibility to provide vendor specific features.
zipkin,"OpenTelemetry takes the best parts of the two, providing default implementations for all the tracing backends and vendors, while allowing users to choose a different implementation for vendor specific features."
zipkin,"Image from opentelemetry
Unlike other competing open source projects, the existence of two tracing standards brought lots of confusion to the community."
zipkin,"The merge created a single standard data source, where vendors can make the most of the rich tracing data to build their own tracing system and data analysis tools, and where developers just integrate once and have the full flexibility to switch between third party vendor tracing systems without worrying about being locked in."
zipkin,"In 2019 November, when the W3C tracing context specification entered proposed recommendation status, the standardization of distributed tracing was brought to another level."
zipkin,"Over ten years of development, distributed tracing evolved from one single paper to an active community with standardization on all the layers, from tracing only to overall observability, from latency optimization to root cause analysis and application performance management, from a single backend system to an end to end solution passing through boundaries."
zipkin,"In 2020, with OpenTelemetry starting to serve as the de facto standardization for tracing, metrics and logging, here is what we see coming to the distributed tracing systems:
More adoption of distributed tracing, merging with monitoring and logging systems,
More correlations between tracing, metrics and logging, and
More analytic tools with AI/ML to make more sense of telemetry data."
zipkin,"With Kubernetes as the underlying orchestration engine for micro services and applications, a tracing/observability system needs to not only cover the application stack, but also the virtual and container infrastructure."
zipkin,"With more adoption of converged tracing/ monitoring/ logging systems, Enterprise IT needs a platform which can help them to consistently deploy and manage the merging observability systems across multiple environments, based on their specific requirements, in a unified way."
