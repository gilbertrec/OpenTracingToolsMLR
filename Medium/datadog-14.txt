Monitoring thousands of RabbitMQ queues with Datadog
Dave Clark
Dave Clark
Follow
Nov 24, 2020 · 3 min read





The built-in RabbitMQ check included with Datadog doesn’t work well when RabbitMQ has a lot of queues; in our experience, at 10,000+ queues the metrics become pretty much impossible to gather and in fact actively harm the instances by polling the RabbitMQ Management API frequently. For example, here’s our cluster memory usage at the moment we turned off the Datadog check:

The bad performance isn’t the check’s fault, exactly: the Management API does not perform well with many thousands of queues. This is evident to anyone who has tried to use the Web UI; the overview page works but as soon as you try to view the list of queues for a busy vhost things get very slow.
As an alternative to the Datadog check, RabbitMQ added first-class Prometheus metrics in version 3.8 and we can route these to Datadog to get high-level, aggregate metrics with minimal performance impact. Then, for queue-level metrics, we can implement our own checks using the rabbitmqctl tool, which is considerably more performant than the Management API.
Prometheus metrics
First, ensure that RabbitMQ is publishing Prometheus metrics by enabling the plugin, then we can send them to Datadog using an OpenMetrics check similar to the following:
---
instances:
- prometheus_url: http://localhost:15692/metrics
  namespace: rabbitmq
  metrics:
  - rabbitmq*
init_config: {}
This will send all of RabbitMQ’s Prometheus metrics to Datadog with names like rabbitmq.rabbitmq_queue_messages. It’s possible to rename these metrics (see the docs above) but there’s a lot of them so it’s probably easier to just keep them as is and put up with the rabbitmq duplication in the names.

Collecting queue metrics
By default, the Prometheus metrics are aggregated. It’s possible to enable per-object metrics, but the docs advise against this for large deployments.
Instead, we’ll use the rabbitmqctl tool, which is much faster, even with thousands of queues. The basic idea is to run a recurring script which pulls queue information and sends their metrics to Datadog via the statsd daemon.
At LoyaltyLion, we have a lot of dynamic queues so we’re particularly interested in knowing which queues are full of messages to help identify issues such as orphaned queues or slow consumers.
To do this, we created a small Ruby script using the rabbitmqctl list_queues command, which returns metrics for each queue. With ~15k queues, this still takes less than a second to run; to pull the same information via the Management API would take upwards of a minute or more.
Feel free to use and adapt the code below for your own script. A few things of note:
The --local flag fetches metrics only for queues whose master is the current node. This is ideal if you’re running this script on every member of a cluster as it’ll reduce network traffic
Additional queue fields can be returned by passing them as arguments. Check the docs for a complete list
We run this script every 30s, as a systemd timer service

The result: per-queue metrics with minimal performance impact: