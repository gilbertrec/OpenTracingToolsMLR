Why and how we have changed all our monitoring stack
Miguel Angel Coll
Miguel Angel Coll

Jun 8, 2017·6 min read




Is not a secret for all of us working on IT that, an architecture pattern is changing the way we are doing things. Yes, I’m talking about microservices. But don’t worry, I am not going to describe this architectures pros and cons.
Microservices -combined with cloud and devops- are turning around our way of doing things, and monitoring is not the exception. The fact is that, while applications and dependencies are growing faster than ever, traditional monitoring tools (nagios, ganglia, Ca synthetic monitor, dynatrace,…) are unable to hold the pace. Therefore, a year ago in Hotelbeds Group we decide to move forward and start defining our new monitoring stack. In the following lines, I shall try to explain the definition and selection process ….
The Focus have changed
A year ago on an internal presentation I used the following two images to illustrate our new monitoring approach:

Traditionally we monitor systems by adding alerts based on predictable situations. For instance when the critical host CPU goes over a predefined threshold we know that we will face problems. In the most critical systems we also add synthetic monitoring that simulate our clients behaviour and measure the response in order to know our platform performance. But at the end, we always think on monitoring focusing on our systems.
The problem is that real life is more complicated and probably your environment are mostly like the following image:

But what is the main difference between those two images?
… Of course, the bulls are the main difference!
The bulls represents the clients. They are who set the real pace on our systems. They are who evaluate our performance (thousand of times per second). By knowing how our client is perceiving our performance, we really know how our systems are working. Therefore we have to change our focus from systems to clients, from synthetic measures to real transaction metrics. In fact when we start thinking on our client metrics we also have a better understanding which system metrics really matters.
Once you start monitoring your client’s performance you understand how to monitor your systems.
Analyze future problems
As an architecture team, we like to start with the analytic part on every problem. In this case we were not working on actual problems. Instead, we were facing new challenges that come out as a result of our new architecture patterns and so, moving on a more theoretical approach.
From the beginning we saw that we need to be ready for:
Increase of the number of applications and hosts to be monitored
More dependencies between applications
More applications involved by the same “transaction”
Business process even more difficult to model as a linear transaction.
More ephemeral infrastructure
Therefore, the new monitoring stack has to adapt to this new situation providing the necessary tools to work on these new scenarios.
As-is To-be
When we have a good understanding on what we need, we start challenging our entire monitoring stack. On the very beginning, we try to figure out if Nagios is the best solution. While comparing this so common open source tool with other more powerful -and expensive- tools like zenoss or Patrol, we found a game changer called Datadog. They offer a powerful solution to monitor systems based on metrics stored on the cloud.
Their new monitoring approach introduce more and more doubts on our current one.
Do we have to select a full stack tool that cover all our needs? Does this tool already exist? Can we try to se select a combination of best in bread? What should include?
With those questions in mind, we start drawing what a full monitoring stack have to include. Putting all together on a Venn Diagram and introducing our “as-is” technologies give us an eye view on the task we are facing.

Monitoring stack (as-is)
Once we have our As-is pretty clear we started working on the To-be, that usually is the hardest but funniest part of the process.
Integrations are the key
Very soon during the process, we notice that integration will be the key on our new monitoring stack. Having the possibility to collect metrics from our applications and integrate them with the synthetic monitoring, APM or AWS cloudwatch will move our monitoring tools to a next level.

The good news are that all the actual monitoring vendors know it and therefore the integrations supported are nowadays an important part of the product functionalities.
Three selection Process
Doing a selection process is part of our normal job as Technology architects. We start defining the aim of the selection, then introduce the players, if possible made a short list based on the most obvious and then we try to go deeper on the details on every product trying to understand all the pros and cons.
Outsourcing a POC is the same as viewing a demo
In order to do this selections we always try to test the products ourselves with a Proof Of Concept (POC) and we ever do our own POC’s. Outsourcing a POC is the same as viewing a demo, you will only be the beauty part and lost all the info about how product is installed, maintained, how it performs, etc.
Therefore it take some time to do a selection but, when it is about selecting technologies that will sustain your business on the future, it pays off.
The three big selection process were:
Metrics system: Datadog, Ganglia, riemman-influxdb-grafana
APM: New Relic, Dynatrace, AppDynamics, AppInternals
Synthetic Monitoring: Pingdom, New Relic, uptrends, monitis,
Probably I will explain these selections on future articles but, just to understand what we are looking for on every selection, common requisites were:
Scalable: as a solution and supporting services that scale up and down.
Cloud First: We prefer not to increase our own infrastructure with new systems.
Affordable: We cannot introduce a huge cost to our platform.
Easy to use and maintain: We want to delegate the use of the monitoring tools to the product teams as we are moving to devops.
After doing all the selections and documentation process the resulting monitoring stack were as follow:

Monitoring stack (to-be)
Big Bang or incremental approach
Putting in place a new architecture is even harder than the design process. Simplifying it to the maximum you can go for a big bang or a incremental approach. Big bang, in this case, means finding a budget for a big project that aims to change all your current monitoring tools and then start migrating applications until you decommission the older tools.
On the incremental approach, we just need to put in place the new tools and give all the other -new projects, product teams, other departments- the information they need to start using it.
In our case we go directly to the incremental approach, knowing that it will mean a longer path. Fortunately at that moment, we are reviewing also other parts of our architecture and, the projects needed on that evolution could also include the new monitoring tools.
I want to close this article by giving thanks to all the Technology Architecture team involved on this process and specially to Alfonso Fernandez (@alfonsof) Hotelbeds Group Chief Architect by those days. Without his perpetual questioning and support probably we had not gone so far.